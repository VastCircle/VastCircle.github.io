<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='针对不规则工作负载的事件触发可编程预取器 abstract 许多现代工作负载需要处理大量数据，通常伴随不规则的内存访问。现有架构在处理这些工作负载时表现不佳，因为现有的预取技术无法捕捉内存访问模式，导致这些应用程序严重依赖内存。尽管已经有一些技术可以通过显式配置预取器的遍历模式来显著提高性能，这些方法的适用性通常局限于特定的数据结构。
'><title>An_Event_Triggered_Programmable_Prefetcher_for_Irregular_Workloads</title>
<link rel=canonical href=https://VastCircle.github.io/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/><link rel=stylesheet href=/scss/style.min.46208cabd58e8bcef0cfb7d7ea6b561adcca3b91dd1fc6657493a44f03c5db75.css><meta property='og:title' content='An_Event_Triggered_Programmable_Prefetcher_for_Irregular_Workloads'><meta property='og:description' content='针对不规则工作负载的事件触发可编程预取器 abstract 许多现代工作负载需要处理大量数据，通常伴随不规则的内存访问。现有架构在处理这些工作负载时表现不佳，因为现有的预取技术无法捕捉内存访问模式，导致这些应用程序严重依赖内存。尽管已经有一些技术可以通过显式配置预取器的遍历模式来显著提高性能，这些方法的适用性通常局限于特定的数据结构。
'><meta property='og:url' content='https://VastCircle.github.io/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/'><meta property='og:site_name' content="VastCircle's blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='prefetch'><meta property='article:published_time' content='2024-11-29T23:39:07+08:00'><meta property='article:modified_time' content='2024-11-29T23:39:07+08:00'><meta name=twitter:title content="An_Event_Triggered_Programmable_Prefetcher_for_Irregular_Workloads"><meta name=twitter:description content="针对不规则工作负载的事件触发可编程预取器 abstract 许多现代工作负载需要处理大量数据，通常伴随不规则的内存访问。现有架构在处理这些工作负载时表现不佳，因为现有的预取技术无法捕捉内存访问模式，导致这些应用程序严重依赖内存。尽管已经有一些技术可以通过显式配置预取器的遍历模式来显著提高性能，这些方法的适用性通常局限于特定的数据结构。
"><style>:root{--article-font-family:"Noto Serif SC", var(--base-font-family)}</style><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@300;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex
<!--
extended
-->
on-phone--column extended"><div id=article-toolbar><a href=https://VastCircle.github.io/ class=back-home><svg class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg>
<span>Back</span></a></div><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header class=site-info><figure class=site-avatar><a href=/><img src=/img/avatar_hu9516569771622178000.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🍥</span></figure><h1 class=site-name><a href=/>VastCircle's blog</a></h1><h2 class=site-description>To shine , not to be illuminated</h2><ol class=social-menu><li><a href=https://github.com/VastCircle target=_blank title=GitHub><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com target=_blank title=Twitter><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol></header><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>friends</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/>论文阅读</a></header><h2 class=article-title><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/>An_Event_Triggered_Programmable_Prefetcher_for_Irregular_Workloads</a></h2><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Nov 29, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-words>16467字</time></div></footer></div></header><section class=article-content><h1 id=针对不规则工作负载的事件触发可编程预取器>针对不规则工作负载的事件触发可编程预取器</h1><h2 id=abstract>abstract</h2><p>许多现代工作负载需要处理大量数据，通常伴随不规则的内存访问。现有架构在处理这些工作负载时表现不佳，因为现有的预取技术无法捕捉内存访问模式，导致这些应用程序严重依赖内存。尽管已经有一些技术可以通过显式配置预取器的遍历模式来显著提高性能，这些方法的适用性通常局限于特定的数据结构。</p><p>为此，我们提出了一种事件触发的可编程预取器，结合了通用计算单元的灵活性与基于事件的编程模型，并配合编译器技术自动从带注释的原始源代码生成事件。这种方法允许做出更复杂的预取决策，而无需在需要中间结果时发生停滞。</p><p>通过使用我们的可编程预取系统，并结合从应用程序中提取的小型预取内核，我们在仿真中针对多种图算法、数据库和高性能计算（HPC）工作负载实现了平均3.0倍的性能提升。</p><h2 id=introduction>Introduction</h2><p>许多现代及新兴的工作负载需要处理海量数据，这些数据往往无法完全存储在当前系统的缓存中。这些数据访问通常是不规则的，难以提前预测，导致执行过程中频繁受到高DRAM延迟的影响而出现严重的内存瓶颈和停顿。</p><p>为应对这些挑战，目前有多种技术可供选择。一种方法是利用应用程序中的线程级并行性，通过激进的多线程技术来应对延迟，通过让多个线程同时处于等待状态来实现负载的并行化。例如，这种方法在运行于图形卡上的工作负载中较为典型。然而，这种技术的效果依赖于应用程序是否具备高度的线程级并行性，而这在大数据工作负载中往往并不成立。原因在于这些工作负载通常涉及对同一数据的复杂且不可预测的读写操作，并且很难为并行内核创建有效的分区。</p><p>另一种方法是预取技术，包括硬件预取单元或软件指令。然而，传统的基于地址的（如步幅）预取器仅适用于非常规则的计算，例如处理密集矩阵或完全顺序的内存访问。基于历史的预取器则仅适用于高度重复的计算。这两种方法都不适用于许多大数据应用，例如数据库、图算法和许多高性能计算（HPC）工作负载，这些应用通常表现出更加复杂和不规则的数据遍历，包括指针追踪和间接数组查找。</p><p>针对不规则访问，也有一些特定技术被提出，例如指针预取器，它通过观察内存加载来预取可能的指针。然而，这些技术无法在数组中进行预见性查找，无法处理常用的基于索引的数据结构（因为加载的内存不包含指针），并且由于缺乏对预取进行细粒度控制的能力，容易导致严重的内存过度预取。</p><p>尽管传统的隐式预取技术在这些工作负载中并不成功，但仍有可能通过其他方法来减轻内存访问延迟带来的开销。针对各种内存受限应用的技术已经出现，通过显式配置遍历模式，可为特定工作负载带来显著的性能提升。然而，目前此类架构技术高度专用化，仅适用于目标计算，因而难以应用于通用系统。此外，由于这些技术的固定功能特性，它们难以应对该领域中算法的快速演变。</p><p>为此，我们设计了一种基于事件的可编程预取系统，用于处理包括图算法、数据库和高性能计算（HPC）在内的多个领域的稀疏内存访问通用工作负载。**我们将一个传统的高性能乱序计算核心与一个专用的L1缓存预取结构相结合，并附加多个顺序执行的可编程预取单元.**这种基于事件的编程模型使得每个预取单元能够同时发出多个加载请求并对其作出响应，而不会导致停顿。这不仅允许系统基于先前预取的结果进行预取，还能够同时从多个数据结构中进行预取。</p><p>此外，我们提供了编译器技术，用于根据原始源代码为这些核心生成事件程序，从而通过注释指定需要预取的内容，减少对手动配置的依赖，尤其是针对简单访问模式。对于一组广泛的内存受限基准测试，我们实现了3.0×的平均性能提升，在缓存中对预取数据的利用率很高，并且对大多数工作负载的额外内存访问需求几乎可以忽略不计。</p><h2 id=existing-work>Existing Work</h2><p>文献中关于预取的研究非常丰富，我们在此总结与不规则内存访问工作负载最相关的研究，并突出了其中对这些工作负载有益的元素。以下是一些研究的概述，包括Mittal和Falsafi与Wenisch的工作。</p><h3 id=预取单元>预取单元</h3><p>许多针对不规则工作负载高效执行的研究集中在高度专用的预取单元。这些单元通过控制特定访问模式的内存访问，并利用数据的并行加载来提高性能，通常可以实现显著的性能提升。例如，<strong>SQRL</strong>和<strong>DASX</strong>是专为B树、向量和哈希表结构的迭代访问设计的预取系统。同样，<strong>Kocberber等人</strong>专注于通过并行哈希表遍历优化数据库内部连接操作。在后续的研究中，他们进一步在软件中模拟了类似的技术。</p><p>此外，<strong>Ho等人</strong>将预取单元的概念推广，通过将内存访问编码为一组规则，使加载和存储操作能够映射到数据流架构中。预取单元还能通过移除原始加载指令来实现能耗节约。然而，必须修改原始应用程序，产生与不具有提取器单元的设备不兼容的代码，并且通常不允许存储所提取的数据。</p><h3 id=可配置预取器>可配置预取器</h3><p>本文开发了一种在架构级别公开的可配置预取器，并且过去已经提出了显示其好处的想法。阿尔-苏赫尼等人在程序级别使用显式 Harbinger 指令来控制链表指针的获取。 Yang 和 Lebeck开发了一种用于链接数据结构的可编程预取方案。可编程提取器被允许停止，因此不能处理需要重叠存储器访问以实现高性能的模式。 Ainsworth 和 Jones 专门针对图形工作负载设计了一个可配置预取器，获得了大幅加速，但仅针对特定图形格式的特定遍历。科胡特等人设计一个可配置的预取器来获取列表的列表。</p><h3 id=隐式不规则预取器>隐式不规则预取器</h3><p>许多研究尝试通过传统的隐式预取方案来处理不规则结构，而无需显式配置。这种方法具有吸引力，因为它减少了手动干预的工作量，也无需重新编译。然而，尽管取得了一些进展，这些方法至今尚未被商用系统采用。</p><h4 id=指针预取器>指针预取器</h4><p><strong>指针预取器</strong>通过从核心读取的缓存行中提取所有可能的虚拟地址来实现预取，这种方法已在多种方案中提出。其主要缺点是<strong>过度预取率较高</strong>，此外，这些方案无法处理许多工作负载中出现的数组间接访问模式。</p><h4 id=依赖图流提取>依赖图流提取</h4><p>也有尝试通过检测依赖加载来在运行时提取依赖图流。这些方法通过在识别加载起点后，将动态检测到的加载流运行在可编程单元上，从而预取数据。然而，这需要在流水线的提交阶段增加大量的分析硬件，并需要显著的处理能力来运行检测到的加载流。</p><h4 id=runahead-方案>Runahead 方案</h4><p><strong>Mutlu等人</strong>提出了一种runahead方案，利用缓存未命中时的空闲芯片资源动态预取数据。然而，这种方法因严格依赖指令流而受限，无法实现显著的前瞻性预取，也无法基于其他已预取的数据进行进一步预取。<strong>Hashemi等人</strong>对此方案进行了扩展，使用运行时分析硬件访问所有微架构状态，生成关键指令的代码片段。这些片段仍可能在依赖加载时停顿，但通过更简单的硬件完成数据加载，并移除了一些冗余执行。</p><h4 id=数组间接模式预取>数组间接模式预取</h4><p><strong>Yu等人</strong>通过运行时分析执行代码，找到数组基址和每个数据元素的大小，从而捕捉步幅间接模式。这种方法实现了对单一模式的预取，但代价是缓存中需要复杂的分析硬件，这可能影响执行的关键路径。</p><h3 id=辅助线程>辅助线程</h3><p>一种针对不规则应用的预取解决方案是使用独立的CPU线程在软件中进行数据预取。以下是相关研究的总结：</p><h4 id=自动生成的预执行线程>自动生成的预执行线程</h4><p><strong>Kim 和 Yeung</strong>通过编译器分析自动生成“预执行线程”。这种方法的优点是不需要额外硬件，但它在高性能核心上使用额外线程，可能消耗大量能量。此外，该方法无法处理基于其他预取操作的预取，且容易因停顿而受限【28】。由于缺乏硬件事件队列，加载操作的同步变得困难且代价高昂。</p><h4 id=具有架构支持的辅助内核>具有架构支持的辅助内核</h4><p><strong>Lau等人</strong>提出了类似的方案，但增加了架构支持：在主核心旁边附加一个小型辅助核心以协助处理任务。这种紧耦合机制在一定程度上缓解了同步问题，但仍然会出现与上述相同的停顿。此外，单个核心通常无法满足复杂访问模式的处理需求。</p><h4 id=分离访问与执行线程的核心>分离访问与执行线程的核心</h4><p><strong>Ham等人</strong>提出了一个方案，将核心分为独立的访问线程和执行线程，运行不同代码。这种方法提供了更紧密的同步，并且由于每个线程是专用的，可以运行在更高效的硬件上。但它要求加载和计算单元都具有高性能，并且在处理复杂地址生成时仍会因中间加载而停顿。</p><h4 id=基于辅助线程的预取机制>基于辅助线程的预取机制</h4><p><strong>Ganusov 和 Burtscher</strong>通过硬件支持，将观察到的加载操作转发给新生成的线程，从而在软件中模拟常见的 Markov【26】和步幅预取方案。</p><h4 id=我们的改进>我们的改进</h4><p>我们在硬件中转发类似的数据，但创建了完全可编程的预取事件。这些事件能够对其他预取作出反应，支持真实数据结构的遍历，并通过许多专用单元的紧密耦合和运行自定义预取代码的轻量抽象来实现高效的并行性。</p><h2 id=motivation>motivation</h2><p>图1展示了数据库中常用的典型哈希连接内核的示例。我们通过对键数组的顺序访问进行哈希操作，间接访问哈希表数组，然后进行链表遍历。现有预取器在处理此类模式时面临多个挑战：</p><ol><li><strong>哈希函数导致的访问不可预测性</strong>
由于哈希函数的存在，对哈希表数组的访问是不可预测的，且分布在内存的各个位置，缺乏空间和时间局部性。在不知道哈希函数的情况下，预取器几乎无法准确预取相关条目。</li><li><strong>链表遍历的延迟问题</strong>
在链表遍历中，每个元素的处理工作量较少。尽管指针预取器可以识别<code>l->next</code>作为下一个需要处理的元素地址，但由于<code>while</code>循环中每次迭代的工作量不足，预取器无法掩盖加载下一链表项时的内存访问延迟。</li><li><figure class=gallery-image style=flex-grow:152;flex-basis:365px><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241207131949548.png data-size=562x369><img src=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241207131949548.png width=562 height=369 srcset="/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241207131949548_hu9190750475602985920.png 480w, /2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241207131949548_hu12636253816021822851.png 1024w" loading=lazy></a></figure></li></ol><p>图2(a)显示了未修改代码的执行方式。浅绿色框表示哈希计算和哈希表桶的加载，深绿色框表示链表项的加载。框中的对角线表示由于数据等待从更低级缓存或主存到达而产生的停顿。可以看出，由于代码缺乏时间和空间局部性，每次加载都会导致停顿。</p><p><figure class=gallery-image style=flex-grow:177;flex-basis:425px><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241207131717198.png data-size=1127x636><img src=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241207131717198.png width=1127 height=636 srcset="/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241207131717198_hu11404448108703432409.png 480w, /2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241207131717198_hu17326338218669514549.png 1024w" loading=lazy></a></figure></p><h3 id=软件预取>软件预取</h3><p>在这个示例中，软件预取比硬件预取器更有优势，因为我们可以在预取逻辑中编码哈希函数。图1显示了这种指令及其在代码中的位置。通过在<code>for</code>循环的未来固定迭代次数（即距离<code>dist</code>）预取，我们可以提前将哈希表元素加载到缓存中，以供后续使用。</p><p>然而，对于链表遍历，软件预取无法提供帮助，因为软件无法得知哈希表项预取的结果。我们只能预取当前哈希表项的链表，但这与硬件的情况一样，存在无法隐藏内存访问延迟的问题。</p><p>图2(b)展示了软件预取如何提升性能。黄色框表示预取地址计算和相应的预取指令。在本示例中，我们假设预取距离为1次迭代，即第1次迭代预取第2次迭代的哈希表桶，依此类推。如图所示，从第2次迭代开始，加载哈希表桶时没有停顿（尽管预取指令本身会产生一定的开销）。经过4次迭代后，执行时间比原始代码略短，但由于无法预取链表项，性能提升受到限制。</p><h3 id=多线程处理>多线程处理</h3><p>第三种选择是利用线程级并行性（Thread-Level Parallelism, TLP）。<code>for</code>循环的每次迭代都可以作为一个独立的线程执行，从而隐藏内存访问延迟。然而，这种算法并非完全并行，因为若以无序的方式执行迭代会改变输出键的顺序，因此需要同步机制以防止这种情况的发生。</p><p>图1展示了这一选项的代码，而图2(c)则展示了其在两个线程上的执行情况。当找到匹配的键时，线程需要等待其成为最老的迭代才能将结果写入输出数组，以保持顺序。这是通过调用<code>wait_til_oldest()</code>来实现的；同时，每次迭代结束时通过<code>signal_iter_done()</code>发出信号，用于跟踪当前最老的迭代。</p><p>在示例中（图2(c)），第2次迭代的第一个链表项找到匹配键。然而，由于核心0上的第1次迭代仍在运行，第2次迭代必须等待第1次迭代完成后才能将结果写入输出数组。尽管存在这一空闲等待时间，在本示例中，通过尽可能重叠执行与停顿，多线程版本的完成时间仍然比软件预取更快。</p><h3 id=辅助线程-1>辅助线程</h3><p>第四种预取方式是将循环中负责<strong>内存访问的部分复制到一个独立的辅助线程中</strong>。如果支持同时多线程（Simultaneous Multithreading, SMT），该线程可以在与主线程相同的核心的不同上下文中运行，以便将数据预取到主L1缓存中。图2(d)展示了该技术的执行情况。</p><p>此方法的根本局限在于，辅助线程无法以足够快的速度加载数据，无法<strong>始终领先主线程</strong>。辅助线程无法使用预取指令，只能在每次加载时停顿以利用加载结果。虽然可以通过使用多个辅助线程在一定程度上缓解这一问题，但这需要消耗大量的系统资源，因为我们需要足够多的辅助线程来隐藏所有的内存停顿。(辅助线程非常快可以吗)</p><p>为了实现这一点，我们需要让预取器能够对自身预取返回的数据作出反应，并让其了解所执行的计算内容，从而基于正在遍历的数据结构计算下一组预取地址。</p><h3 id=理想行为>理想行为</h3><p>在理想情况下，我们希望完全避免停顿。这种工作负载实际上包含大量内存级并行性（Memory-Level Parallelism, MLP），但现有技术无法充分利用。具体来说，我们<strong>可以在<code>in.key</code>数组上并行化，从而同时预取多个链表，并重叠顺序链表的预取操作</strong>。</p><p>如果我们能够将预取地址的计算与主线程的执行解耦，并避免在每次加载时停顿，就能够利用这些并行性，在数据即将被使用前将其加载到缓存中。这将导致如图2(e)所示的执行方式：在经历一个预热阶段后，计算可以不受停顿影响继续进行，因为数据会立即从一级缓存中获得。</p><p>为了实现这一点，我们需要让<strong>预取器能够对自身预取返回的数据作出反应，并让其了解所执行的计算内容，从而基于正在遍历的数据结构计算下一组预取地址。</strong></p><h2 id=programmable-prefetcher可编程预取器>Programmable Prefetcher(可编程预取器)</h2><p>与常见的跨步预取器一样，新的预取由<strong>缓存内的读取事件以及到达缓存的预取数据触发</strong>。使我们的方案适合更多样化和不规则应用的原因是，这些事件具有可编程行为，由<strong>配置的地址范围</strong>触发，这会导致运行小型的、完全可编程的事件代码序列，从而生成新的预取。由于每个事件都与前一个事件分开，因此它们是极其并行的，从而可以在许多微型可编程单元上实现高效和高性能的执行。对先前的预取做出反应的能力是其他具有可编程性的方案（例如软件预取或辅助线程）无法实现的，允许在不停止的情况下预取通常具有多个相关访问特征的不规则模式。</p><p><figure class=gallery-image style=flex-grow:245;flex-basis:589px><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206201718437.png data-size=1191x485><img src=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206201718437.png width=1191 height=485 srcset="/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206201718437_hu16517466288801699795.png 480w, /2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206201718437_hu11855639380807906099.png 1024w" loading=lazy></a></figure></p><h3 id=overview>overview</h3><p>图 3 展示了我们设计的总体架构。我们添加了可编程单元和支持硬件，用于根据程序的当前和未来工作集生成预取请求。预取器是基于<strong>事件</strong>的，以避免停顿，同时仍然能够通过早期预取结果支持进一步的预取操作。从主核发出的所有读取操作以及到达 L1 缓存的预取数据都会首先进入地址过滤器（见第 4.2 节）。被过滤为感兴趣的数据将进入观察队列，当调度器（见第 4.3 节）检测到有空闲的可编程预取单元（PPU，见第 4.4 节）时会将数据移出。</p><p>这些可编程单元是低频、顺序执行的核心，针对从调度器接收到的每个地址执行一个小型的定制计算，并生成零个或多个预取请求。它们利用加载事件中的数据、配置在全局寄存器中的状态以及由 EWMA 计算器（见第 4.5 节）计算的前瞻距离，来生成新的预取请求，这些请求被放入一个 FIFO 预取请求队列（见第 4.6 节）。当 L1 缓存有空闲的 MSHR 时，它会从预取请求队列中取出一个预取请求并将其发送到 L2 缓存。</p><p>在预取器未被使用的情况下，可以关闭其电源以避免影响性能。以下各小节将详细描述每个结构。</p><h3 id=address-filter>Address Filter</h3><p>地址过滤器对来自<strong>主核的所有加载操作以及从 L2 进入 L1 缓存的预取数据进行监听</strong>。此过滤器保存了多个需要<strong>监控的地址范围</strong>，并利用这些范围生成新的预取请求，例如图 1 中内核的哈希表（htab）。地址过滤器通过运行在主核上的显式地址边界配置指令进行配置。这些指令由编译器或程序员在为 PPU 创建代码时生成。(哈希表去取线性表吗??)</p><p>配置数据存储在过滤表中，其中包括每个重要数据结构的虚拟地址范围，以及两个指向小型计算内核的函数指针：<strong>Load Ptr</strong>（在观察到加载操作时运行）和 <strong>PF Ptr</strong>（在预取到该范围时运行）。</p><p>部分配置也用于调度目的（见第 4.5 节），这些条目在表中标记出来。<strong>过滤后的地址（观测值）会连同其函数指针以及（在预取观测情况下）预取的缓存行一起放入观察队列</strong>。地址范围可以重叠；若一个地址属于多个范围，则队列中会为每个范围存储一个条目。</p><h3 id=observation-queue-and-scheduler>Observation Queue and Scheduler</h3><p><strong>过滤后的地址会先放入一个小型观察队列中，随后再分配给核心</strong>。该队列是一个简单的 FIFO 缓冲区，用于存储观测值，直到有空闲的 PPU 可用。由于预取仅是性能优化措施，如果队列满了，可以安全地丢弃旧的观测值，而不会影响主程序的正确性。</p><p>当一个 PPU 空闲时，调度器会将数据的缓存行和虚拟地址写入该 PPU 的寄存器，然后将 PPU 的程序计数器设置为与该观测值相关联的预取内核，启动核心执行。调度器的任务仅仅是监控 PPUs，并在需要时从 FIFO 观察队列中为它们分配工作。</p><h3 id=programmable-prefetch-units-ppus>Programmable Prefetch Units (PPUs)</h3><p>PPUs 是一组顺序执行、低功耗的可编程 RISC 核，与预取器的调度器相连，负责生成新的预取请求。PPUs 与主核使用相同的字长，以便能够通过一条指令执行地址运算。默认情况下，预取单元是暂停的。当观察队列中有数据且有空闲的 PPU 时，调度器将最旧的观察值发送到该 PPU 执行。PPU 运行直到完成内核任务，通常只需几行代码。在执行过程中，它会<strong>生成若干预取请求</strong>，这些请求会被放入预取请求队列，然后 PPU 进入休眠状态，等待调度器重新唤醒。</p><p><strong>PPUs 共享一个单独的多端口指令缓存</strong>，<strong>但不与主核共享指令缓存</strong>；<font color=red>(执行的是相对于的函数指针吗?)</font>PPU 的代码与主应用程序代码是独立的，且任何观察值都可以由任意 PPU 执行。大多数应用程序所需的可编程预取代码非常小，因此指令缓存的需求较少：在第 7 节描述的基准测试中，每个应用程序的 PPU 从主存储器中获取的指令总量最多为 1KB。</p><p>PPUs 没有加载或存储单元，因此不需要数据缓存。<strong>它们只能读取转发给它们的单个缓存行、本地寄存器存储，以及全局预取器寄存器</strong>。去除访问其他内存的能力既简化了 PPU 的设计，也减少了它们发生停顿的可能性。尽管这限制了预取计算中可用的数据，但我们尚未发现需要额外数据的场景。通常，预取代码只需从缓存行中提取一些数据，执行简单的算术操作，然后将其与全局预取器状态（如数组的基地址）结合，生成新的预取地址。</p><p>由于无法访问其他内存，每个 PPU 也没有用于中间值的栈空间，但寄存器可以提供充足的临时存储。在实际应用中，这并未造成问题。</p><h3 id=moving-average-ewma-calculators>Moving Average (EWMA) Calculators</h3><p>对于某些应用，预取的前瞻距离无法通过固定值设置。它可能依赖于输入，并可能根据特定系统的时间统计信息变化。在一些工作负载中，特别是图的广度优先搜索中，预取距离可能在计算过程中发生变化，因为各阶段访问的元素大小不同 [1]。先前的研究通过考虑计算时间与内存访问时间之间的比率应对这一挑战。例如，Mowry 等人 [45] 将<strong>预取延迟除以循环中最短路径的指令数量</strong>，以确定需要预取的迭代次数。</p><p>我们推广了这一思想，并在硬件中动态执行计算，使用指数加权移动平均（EWMA）计算器为各种观察到的事件生成时间。EWMA 可以在硬件中高效实现，仅需少量状态存储 [18]，因此 PPU 不需要执行时间计算。我们动态计算完成一串预取所需的时间与每次循环迭代所需时间的比率，并据此决定在基础数组中需要提前预取多远。这意味着我们尝试预取刚好在当前预取完成后将被访问的元素。</p><p>当对某个数据结构的读取操作被观测到时，<strong>会记录该事件与该地址范围上前一个事件之间的时间</strong>。这可以为我们提供例如广度优先搜索中 FIFO 访问之间的时间间隔。为了计量加载操作的耗时，我们标记开始一次计时预取的 EWMA，并将当前时间附加到生成的事件中。随后将其传播到由此产生的预取操作，直到到达具有标志位的地址范围，然后使用事件之间的时间间隔作为加载时间 EWMA 的输入。</p><h3 id=prefetch-request-queue>Prefetch Request Queue</h3><p>预取请求队列是一个 FIFO 队列，包含由 PPU 计算得出的尚未处理的虚拟地址，用于预取操作。当 L1 数据缓存有空闲的 MSHR 时，它会从队列中取出最旧的条目，通过共享的 TLB 将其转换为物理地址，然后向该地址发出预取请求。与观察队列类似，如果队列已满，可以安全地丢弃旧请求，而不会影响应用程序的正确性。</p><h3 id=memory-request-tags>Memory Request Tags</h3><p>虽然数组范围（可以通过虚拟地址边界捕获）可以通过第 4.2 节讨论的配置步骤轻松识别，但预取器需要响应的结构不仅限于此。链式结构（如树、图、链表）可能在非连续的内存区域中逐个元素分配，并且在预取数据到达缓存时需要进行识别。</p><p>为了解决这个问题，<strong>我们在 MSHR 中存储一个标记，用来标识预取目标的数据结构</strong>，例如哈希表桶的链表。当预取请求返回数据并且带有已注册的标记时，缓存行将被<strong>发送到加载了该结构函数指针的 PPU</strong>，进行进一步的处理。每个结构都会有具体的结构函数.</p><h3 id=hardware-requirements>Hardware Requirements</h3><p>尽管预取器具有许多可编程单元，但每个单元都非常小，类似于微控制器的规模，例如 ARM Cortex M0+，其包含不到 12,000 个门电路（大约 50,000 个晶体管）[7]。根据公开数据 [4, 5]，在相似的硅工艺下，我们可以预计这十二个核心的硬件影响大约占 Cortex A57 处理器面积的 1.3%（不包括共享缓存）。在实际实现中，可能希望支持这些核心的 64 位操作，因此我们可以预期面积将增加到 2.6%。当我们为指令缓存、全局寄存器、预取请求队列和观察队列增加 8.5KiB 内存 [56] 时，总的面积开销仍然只有 3%。这一开销与 L1 数据缓存的面积相当。</p><h3 id=summer>summer</h3><p>我们开发了一个可编程预取器，它响应过滤后的加载和预取观察事件。这些输入到一组可编程单元中，这些单元根据事件运行内核以向缓存中发出预取。为了简洁起见，我们在这里省略了多核预取的介绍，但实现和预期结果是相似的 [1, 2]。以下部分描述了如何对其进行编程。</p><h2 id=os-and-application-support>OS and Application Support</h2><p>为了使预取器发挥作用，必须<strong>为每个应用程序生成定制代码</strong>。本节描述了用于这一目的的基于事件的编程模型，适用于多个 PPU 上的延迟容忍取指。它还考虑了与操作系统和上下文切换的交互。在本节中，我们假设预取代码是手动编写的。接下来，我们将在第 6 节中探讨编译器的支持.</p><h3 id=event-programming-model>Event Programming Model</h3><p>PPU 编程模型是基于事件的，这与预取指令的特点自然契合，因为预取指令在返回数据之前具有可变的延迟。事件生成预取操作，而不是加载操作，这些操作可以在数据到达核心时通过新事件进行响应。当资源可用时，预取请求会被发往内存层级，如第 4 节所述。这种方式自然具备延迟容忍性，避免了等待预取数据时 PPU 的停滞。</p><p>运行在 PPU 上的事件是由加载或预取到缓存中的地址决定的。如果预取操作返回数据，调度器可以选择任何 PPU 来执行相应的事件，而不必局限于发起事件的单元。这使得该架构适合处理需要加载中间值的预取操作，否则这些操作会导致预取器停滞。</p><p>这种编程方式的一个优点是，PPU 不需要在每个事件的计算之间保持状态。每个事件的代码类似于传统处理器中的标准 C 函数，但有一些限制。由于 PPU 无法访问内存（除非是发出预取请求），因此无法进行数据加载、存储或堆栈存储。PPU 可以访问的唯一数据是触发事件的地址、已观察到的缓存行（存储在本地寄存器中）和全局预取器状态（存储在全局寄存器中，如地址边界或配置的值，如哈希掩码）。</p><p>我们为 PPU 添加了特殊的预取指令，这些指令不同于软件预取，因为它们会在返回数据后触发随后的事件，由 PPU 处理。不能进行函数调用，因为没有堆栈，也不支持系统调用。预取事件可以随时终止，因为它们对于主核心上运行的应用程序的正确执行不是必需的。例如，当上下文切换时，当前应用程序被移出主核心，此时所有 PPU 会被暂停，且其预取事件会被中止。此外，任何通常会导致陷阱或异常的操作（例如除以零）都会立即终止预取事件。</p><h3 id=example>example</h3><p><figure class=gallery-image style=flex-grow:499;flex-basis:1198px><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206205302636.png data-size=1463x293><img src=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206205302636.png width=1463 height=293 srcset="/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206205302636_hu17618219161418557276.png 480w, /2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206205302636_hu6907335328717841296.png 1024w" loading=lazy alt=image-20241206205302636></a><figcaption>image-20241206205302636</figcaption></figure></p><p>考虑图 4(a) 中的程序。它的数据访问非常不规则，具有间接访问数组 B 和 C 的特点。然而，由于数组 A 的顺序访问，我们可以利用每次迭代中的内存层级并行性，来并行加载数据。这可以通过加载 PPUs 以执行图 4(b) 中的代码来实现。我们假设 A、B 和 C 都是 8 字节值的数组。通过在原始代码中插入指令，我们将数组 A、B 和 C 的地址范围分别配置为预取器的地址范围 0、1 和 2。同样，图 4(b) 中内核的地址也被提取并配置为预取器的相关加载事件。</p><p>当主程序对 A 进行读取时，预取事件被触发，从当前读取的地址开始，提前预取两缓存行。当预取完成后，获取到的数据将作为索引分别用于访问 B（<code>get_base(1)</code>）和 C（<code>get_base(2)</code>）。</p><p>需要注意的是，预取器代码是将一组阻塞加载转换为一组非阻塞的预取事件。主程序的核心代码保持顺序执行且没有改变，唯一的变化是插入了配置指令。大部分的缓存缺失应该通过 PPUs 提前发出加载请求来避免，从而减少核心程序的缓存缺失。预取器函数（<code>get_vaddr()</code>、<code>get_base()</code> 和 <code>get_fetched_data()</code>）是编译器内建函数，它们会被转换为寄存器读取或从附加的小型共享预取器状态内存中加载数据。</p><h3 id=operating-system-visibility>Operating System Visibility</h3><p>尽管 PPUs 拥有与常规核心类似的许多功能，但它们并不会被操作系统视为独立的核心，因此操作系统无法将进程调度到它们上。相反，操作系统只能看到需要在上下文切换时保存的状态。虽然在某些情况下，操作系统将 PPUs 视为完整核心可能是有用的，但避免与操作系统的交互简化了它们的设计（例如，它不需要特权指令）。因此，尽管预取器会发起页表遍历，但它无法处理页错误，遇到这种情况时我们会丢弃该预取。</p><p>预取单元仅用于提升性能，不能影响主程序的正确性。因此，所需保存的状态量很小。例如，我们不需要保留内部 PPU 寄存器，而只需在上下文切换时丢弃它们。出于同样的原因，我们也可以丢弃观察队列中的所有事件和获取队列中的地址。只要上下文切换不频繁，这将导致性能下降较小。EWMA 值在上下文切换时不需要保留，因为它们可以重新计算。</p><p>因此，在上下文切换时所需保存的内容仅是预取器配置：全局寄存器和地址表。</p><h2 id=compiler-assistance>Compiler Assistance</h2><p>手动编写事件需要大量的手动工作。更理想的方式是通过编译器从原始代码中生成这些事件，以便最终用户使用。软件预取[2, 12]是一种常见的技术，处理器可以在不等待结果的情况下将数据加载到缓存系统中。这种方法为最终用户提供了高层次的抽象，但如第3节所讨论的，直接执行时存在许多缺点。然而，我们可以通过逆向分析循环中出现的地址生成代码，来生成硬件事件，从而生成可编程预取器代码。这使得我们能够在不减慢主计算线程速度的情况下执行预取。我们提供了在LLVM [36]中实现的编译器传递，既可以将软件预取转换为可编程事件，也可以通过在程序员需要预取的循环中添加pragma，直接生成事件，从而提供了一系列的技术，权衡了手动工作与性能之间的平衡。伪代码如算法1所示。</p><h3 id=analysis>Analysis</h3><p>我们的编译器分析传递从软件预取指令开始，利用深度优先分析数据依赖图向后追踪。我们在遇到常量、循环不变值、非循环不变负载或phi节点时终止。目标是将预取地址生成拆分为一系列节点，最终形成一个以单个负载结尾的序列，并将在后续的传递中将其转化为PPU事件。</p><p>为了为PPU代码获得适当的提前量，软件预取指令必须位于一个具有可识别归纳变量的循环中。我们还需要一个使用归纳变量访问的数据结构，以便可以通过观察缓存中的负载来推断其值。</p><p>Phi节点标识要么是循环的归纳变量，要么是其他受控制流依赖的值。在前一种情况下，只要在深度优先搜索的当前迭代中没有找到负载，我们就可以将归纳变量替换为通过地址推断的代码，并将找到的指令集作为一组预取的第一个事件。后一种情况需要更复杂的分析，并且在实际中较为罕见，因此我们不再讨论。</p><p>如果在搜索中发现多个不同的非循环不变负载，那么将使用多个加载的值来创建地址，而事件不能由单个数据值的到达触发。在这种情况下，转换失败。然而，如果只找到一个负载，我们将这些指令打包成一个事件，并从负载开始重复分析。</p><p>图6展示了图5(a)中代码的控制流图。分析从预取指令（第14行）开始，对其输入v5进行深度优先搜索，并在达到第12行的负载时终止。由于这是一个非循环不变负载，这三条指令被打包成一个事件，分析重新从负载开始。接着，第二次分析传递在第10行的负载处终止，再次创建一个事件。最后，第三次分析传递在phi节点处终止，该节点对应于循环的归纳变量，因此创建了一个新的事件，不再需要进一步分析。</p><h3 id=array-bounds-detection>Array Bounds Detection</h3><p>预取器需要获取通过归纳变量访问的每个数组的地址边界，并将其存储在地址过滤器中，以便在监视到加载或预取时触发正确的事件。例如，在图6中的代码中，必须在观察到主核心对数组A的加载时执行事件A。返回的预取通过使用内存请求标签来处理，这些标签在第4.7节中进行了描述。</p><p>每个数组的起始地址可以通过地址生成指令轻松获取，在有类型的数组的情况下，结束地址也很简单，因为数组的大小是明确声明的。然而，在像C这样的语言中，数组通常表示为指针，这使得确定地址边界变得更加复杂。一种方法是针对常见情况进行模式匹配，例如，向后查找分配指令。另一种方法是识别循环终止条件，前提是该条件是循环不变的。</p><h3 id=code-generation>Code Generation</h3><p>代码生成阶段的任务是插入预取器配置指令、生成PPU代码并删除原始的软件预取指令。使用第6.2节中描述的分析，已知数组的边界，因此为每个数组的配置指令会放置在循环之前。同时，为PPU代码所需的任何循环不变值添加配置指令，将它们分配给唯一的预取器全局寄存器。</p><p>为了生成预取器代码，我们从第6.1节中通过分析识别的指令集合，转换为事件函数。在第一个事件中，我们用当前地址观察值（可以从PPU寄存器访问）减去基数组地址并除以数组元素的大小（通常转换为移位操作）来替换归纳变量的phi节点。我们用硬件预取指令替换每个事件中的最后一条指令，该指令可能是加载或软件预取。对于加载，我们添加回调，以便当此预取返回时，调用序列中的下一个事件。我们将所有循环不变值替换为对在主代码中配置的全局寄存器的访问。剩下的唯一加载必须是从当前预取或加载事件中观察到的数据，因此可以将其转换为寄存器访问。最后，删除现在不再需要的软件预取指令。然后使用死代码消除技术去除仅用于软件预取的代码，保留仍然需要的指令的公共子表达式。</p><h4 id=pragma-prefetching>Pragma Prefetching</h4><p>虽然软件预取是一种相对描述性较强的机制，可用于转换为硬件事件，但这仍然需要一些手动操作。一种选择是让编译器负责生成初始的软件预取【2】，然后将其转换为事件。然而，一个更简单直接的选择是直接指明需要进行预取的循环，并让编译器从头生成预取事件。我们通过一个自定义的预取编译指令（如图5(b)所示）支持这一功能，采用与第6.1节类似的深度优先搜索方法。</p><p>我们从具有间接访问的加载开始分析（这些加载很可能发生缺失），并基于发现的归纳变量进行预取。以这种方式生成代码意味着我们掌握的信息少于软件预取阶段的情况，因为软件预取阶段可以对哪些数据会发生缺失以及哪些数据将被访问进行运行时编码，而循环上的简单编译指令可能会遗漏这些信息（例如，数组访问的步长模式）。此外，如果没有更多信息，编译时无法决定哪些加载可能访问已在L1缓存中的数据，因此对这些数据结构的预取是多余的（尽管可以通过分析硬件在运行时禁用这些预取）。然而，对于简单模式，这种描述器与软件预取转换一样强大。</p><h2 id=evaluation>Evaluation</h2><p>为了评估我们的预取器性能，我们使用 gem5 模拟器【10】在全系统模式下模拟了一个高性能系统。该系统运行 Linux，并采用 ARMv8 64 位指令集，其配置如表 1 所示，与之前的研究验证过的配置类似【21】。</p><p><figure class=gallery-image style=flex-grow:81;flex-basis:194px><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206212742894.png data-size=591x729><img src=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206212742894.png width=591 height=729 srcset="/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206212742894_hu6047732684462417660.png 480w, /2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206212742894_hu13171037479579663573.png 1024w" loading=lazy></a></figure></p><h3 id=performance性能>Performance(性能)</h3><p><strong>图7显示</strong>，相比于未使用预取的情况，我们的可编程预取器在内存受限的工作负载中（详见第7节）通过手动编程(manual)可实现最高<strong>4.3倍</strong>的加速，而普通的<strong>步幅预取器</strong>(stride)和<strong>软件预取器</strong>(software)分别只能实现最高<strong>1.4倍</strong>和<strong>2.2倍</strong>的加速。</p><p>使用常规配置的<strong>马尔可夫全局历史缓冲器</strong>【48】未能实现任何加速，因为我们评估的应用程序访问的数据量过大，仅凭其有限的状态无法进行有效预测。当我们将状态量扩展至<strong>1GiB</strong>（大容量配置）时，仅在访问数据量较小的基准测试（如 G500List 和 ConjGrad）中获得性能提升。而其他应用程序由于访问的数据量即使对于一个非常大的历史缓冲器来说仍然过多，或者其内存访问模式不具有重复性，因而无法从该技术中获益。</p><p>通过编译器辅助的软件预取转换（<strong>converted</strong>）在大多数基准测试中获得了与手动编写事件相似的加速，但在 Graph500 工作负载中表现略逊。而基于<strong>pragma</strong> 的自动事件生成技术（<strong>pragma generated</strong>）能够对较简单的访问模式实现与手动编写事件相当的加速效果，但在我们的八个基准测试中有四个未能充分发挥其潜力。</p><p><figure class=gallery-image style=flex-grow:281;flex-basis:675px><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206213624315.png data-size=1520x540><img src=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206213624315.png width=1520 height=540 srcset="/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206213624315_hu9047025795724385010.png 480w, /2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206213624315_hu2542691706129141724.png 1024w" loading=lazy alt=image-20241206213624315></a><figcaption>image-20241206213624315</figcaption></figure></p><h4 id=speedups加速比>Speedups(加速比)</h4><p>三个基准测试通过软件预取获得了显著的性能提升，分别是 <strong>RandAcc</strong>、<strong>IntSort</strong> 和 <strong>HJ-2</strong>。它们的访问模式基于单一步长加载的数组间接访问，非常适合软件预取。这种空间局部性意味着预取地址计算不会引发大量的流水线停顿。然而，在极端情况下（例如 <strong>IntSort</strong>），软件预取导致了动态指令数量的显著增加，<strong>IntSort</strong> 增加了 113%，<strong>RandAcc</strong> 增加了 83%，<strong>HJ-2</strong> 增加了 56%。相比之下，在我们的方案中将预取地址计算转移到可编程预取单元（PPUs）后，加速比更高：<strong>IntSort</strong> 从软件预取的 2.0× 提升到 2.8×，<strong>RandAcc</strong> 从 2.2× 提升到 3.0×，<strong>HJ-2</strong> 从 1.4× 提升到 3.9×。</p><p>在其他基准中，步长和软件预取带来的收益较小，但我们的预取器能够解锁更多的内存级并行性，实现显著的加速。例如，在 <strong>HJ-8</strong> 中，步长和软件预取的加速几乎可以忽略，但我们的 PPUs 实现了 3.8× 的加速。</p><p><strong>G500-List</strong> 是唯一的显著例外，尽管实现了 1.7× 的加速，却是我们的预取器中表现最差的基准。这是因为该应用程序中不存在细粒度的并行性：图中每个顶点的出边被存储在一个链表中。当预取某个顶点时，每条边只能通过前一条边的指针来确定，这实际上将边的处理序列化了。相比之下，Peled 等人[50] 在同一基准测试中未能取得任何性能改进。</p><p>在图 7 中，<strong>PageRank</strong> 的软件预取和预取转换没有柱状条。这是因为 Boost 图形库代码使用了模板迭代器，迭代器只能访问边对(pair)，无法获取单个元素的地址，因此无法插入软件预取指令。通过编译器辅助的预取（包括 pragma 和软件预取转换）在 <strong>IntSort</strong>、<strong>ConjGrad</strong> 和 <strong>HJ-2</strong> 中表现良好。</p><p>在 <strong>PageRank</strong> 中，由于代码不允许插入软件预取指令（高层迭代器的限制），这对我们的 pragma pass 并不是问题，因为 pragma pass 在 LLVM IR 上工作，可以自动发现访问模式并生成事件。然而，在 <strong>IntSort</strong>、<strong>ConjGrad</strong> 和 <strong>PageRank</strong> 中，使用 pragma 自动生成的预取略微降低了性能，这是因为生成了一些无用的预取，而不是因为无法发现访问模式。</p><p><strong>RandAcc</strong> 中，pragma 转换获得的性能提升低于手动编写的软件预取。这是因为该基准反复迭代一个小的 128 项数组，手动预取时可以编码循环回绕的预取。而这一特性涉及多个控制流循环，自动化分析难以发现，因此我们的方案没有预取数组的前几个条目。但 pragma 方案对程序员的工作量要求比手动预取低得多，程序员只需标识目标循环，而无需手动指定预取逻辑和前瞻距离。</p><p><strong>HJ-8</strong> 在使用软件预取转换时获得了显著的性能提升，这是因为我们可以指定预取前 N 个哈希桶。这与软件预取不同，因为软件预取无法以延迟容忍的方式实现这一点（需要读取预取数据）。而对于 pragma 生成方案，由于 N 无法从代码中轻松推导，也存在类似的问题。通常，哈希表每个桶中元素较少，因此即使元素数目不同，保守的 “前 N” 方法也可以很好地工作。然而，通过手动预取，可以引入控制流循环，遍历每个桶，直到尝试预取空指针为止。</p><p><strong>G500-CSR</strong> 的性能随预取的程序员工作量增加而逐步提升。由于编译器转换无法处理控制流（软件预取本质上无法表达循环），因此无法预取数据相关的边范围，只能以固定 N 预取前 N 条边。此外，由于编译器 pass 假设一次只访问一个加载值，因此无法利用每个顶点的起始值和终止值会位于同一缓存行的知识。</p><p>在 G500-CSR 中，pragma pass 无法识别从顶点数据中获取边或访问值的需求，这是由于其中复杂的控制流。结果仅实现了两种从 FIFO 队列到顶点、从边到访问信息的 stride-indirect 模式，限制了可实现的预取性能。尽管如此，这仍然显著高于其他近期研究[50]，其在相同基准上获得的性能提升不足 10%。</p><p>由于 <strong>G500-List</strong> 严重依赖于链表形式的长边列表，其有效预取需要循环控制流。因此，无法将其表示为软件预取，编译器 pass 的作用也受到限制。</p><h4 id=对-l1-缓存的影响>对 L1 缓存的影响</h4><p>图 8 对此进行了更详细的探讨。图 8(a) 显示，尽管在大多数基准中，使用我们的预取器时 L1 缓存利用率很高，但在 <strong>G500-List</strong> 中却相对较低。在该应用中，对于较大的顶点，其边链表可能超过 L1 缓存的容量。遍历该链表可能导致预取的数据在使用前因容量缺失（capacity misses）而从缓存中被驱逐，原因可能是：
a) 对同一边链表的后续预取；
b) 对其他数据的预取或加载。</p><p>根本问题在于预取发生得过早，但没有机制可以延迟这些预取。除了在顶点被预取后启动边链表的预取之外，唯一的其他可能点是在实际应用线程开始处理该顶点时启动链表预取。然而，此时已经太晚，因为主线程需要依次处理这些边，导致预取和主应用的加载几乎同步执行（类似于图 2(d) 所示的情况）。</p><p>图 8(b) 显示，尽管如此，<strong>G500-List</strong> 的 L1 缓存读命中率确实从 0.34 提升到了 0.42，但提升幅度有限。然而，尽管如此，该应用仍然从边链表的提前预取中获得了一定的好处，因为这些边被放置在 L2 缓存中。在这种情况下，L2 缓存的命中率从 0.20 提升到了 0.57。</p><h3 id=analysis-1>Analysis</h3><p>我们现有的可编程预取器配置包含 12 个 PPU，每个 PPU 运行频率为 1GHz，而主内核的运行频率为 3.2GHz。我们现在表明，这实现了大部分好处，并且随着 PPU 数量及其频率的增加，扩展继续进行，因为预取内核是令人尴尬的并行.</p><h4 id=时钟频率>时钟频率</h4><p>图 9 显示了 PPU 时钟频率如何影响各个基准测试，以及减少 PPU 数量的影响。图 9(a) 表明，大约有一半的工作负载在提高 PPU 频率时收益不大。另一方面，<strong>HJ-2</strong> 需要 500MHz 的频率才能实现其最大加速比，而 <strong>ConjGrad</strong> 和 <strong>G500-CSR</strong> 的加速比随着 PPU 频率的提高持续增长。总体来看，大多数性能提升在 1GHz 时已能实现，此时几何平均加速比为 3 倍，而在 2GHz 时略微增加到 3.1 倍。</p><h4 id=ppu-数量>PPU 数量</h4><p>我们在图 9(b) 中探讨了 PPU 频率与 PPU 数量之间的关系，以 <strong>G500-CSR</strong> 为例，选择了一个随着频率增加而持续扩展的应用。我们将 PPU 频率的上限设为 4GHz，作为一个研究案例，用以评估这种关系；我们并不期望 PPU 的时钟频率达到此值。图中显示，通过将 PPU 数量加倍并将频率减半，能够维持加速比。例如，使用 3 个 PPU 在 2GHz、6 个 PPU 在 1GHz 或 12 个 PPU 在 500MHz 时，都能达到 1.9 倍加速比。运行在 PPU 上的预取内核是高度并行的，因为每次调用都是独立的，因此可以通过增加 PPU 数量或提高其频率来实现扩展。图中还显示，对于该工作负载，性能在 12 个 PPU 和 2GHz 时趋于饱和，进一步增加频率不会带来更多收益。</p><h4 id=ppu-活动>PPU 活动</h4><p>图 10 进一步探讨了在 1GHz 下，12 个 PPU 执行计算时的工作量。该图展示了每个 PPU 在计算过程中保持活跃的时间比例。我们的调度策略是从可用的 PPU 中选择 ID 最低的一个来分配预取工作。这意味着 ID 较低的 PPU 活跃的时间比 ID 较高的 PPU 更多。其他调度策略（如轮询）会将工作更均匀地分配，但不会改变整体性能，也无法进行这种分析。</p><p>当工作负载是预取-计算绑定时，增加更多的 PPU 或提高时钟频率会提升性能（如在 G500-CSR 中）；工作会均匀地分配给 PPU，所有 PPU 都保持忙碌。相比之下，像 PageRank、RandAcc 和 IntSort 这样的基准测试无法充分利用所有 PPU：这些工作负载中至少有一个 PPU 永远不会被唤醒。主要原因是它们仅需简单计算来识别未来的预取目标。这些应用在较慢的 PPU 上或使用较少的 PPU 时，也会达到相似的性能（如图 9(a) 所示）。</p><p>ConjGrad 是一个异常情况，虽然一些 PPU 执行的工作很少，但它依然随着频率的增加而扩展（如图 9(a) 所示）。这种行为的原因是，在 1GHz 时，并没有足够的工作量需要所有 PPU 都活跃，但预取操作略有延迟。因此，当时钟速度增加时，预取计算完成得更早，从而获得了些许额外的性能提升。与此不同的是，G500-CSR 也随着时钟频率的提升而扩展，提升频率可以增加更多的预取操作，从而提高性能。</p><p>没有应用程序的 PPU 是持续运行的：最大活动因子为 0.82。这反映了 PPU 仅在主核心发生事件时才会响应，因此在没有数据需要预取的阶段，它们是不需要的。</p><p><figure class=gallery-image style=flex-grow:362;flex-basis:870px><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221444153.png data-size=1135x313><img src=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221444153.png width=1135 height=313 srcset="/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221444153_hu12828022374792581116.png 480w, /2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221444153_hu10821685749307673837.png 1024w" loading=lazy></a></figure></p><p><figure class=gallery-image style=flex-grow:171;flex-basis:410px><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221511675.png data-size=580x339><img src=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221511675.png width=580 height=339 srcset="/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221511675_hu13434118408429887239.png 480w, /2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221511675_hu3098259951179837835.png 1024w" loading=lazy></a></figure></p><p><figure class=gallery-image style=flex-grow:193;flex-basis:464px><a href=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221521804.png data-size=584x302><img src=/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221521804.png width=584 height=302 srcset="/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221521804_hu17229592624111399246.png 480w, /2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/image-20241206221521804_hu17808589098043504456.png 1024w" loading=lazy></a></figure></p><h4 id=额外内存访问>额外内存访问</h4><p>为了高效执行，减少我们向内存总线添加的额外流量是理想的目标。通常，编程解决方案应该非常高效地进行预取，只针对计算所需的地址进行预取。除了两个 Graph500 基准测试外，其他大多数基准测试的额外访问值是微不足道的：预取非常准确且及时，因此不会预取未使用的数据。G500-List 因为缺乏细粒度并行性而增加了 40% 的额外访问。这是由于链表的基本限制，限制了及时预取，正如第 7.1 节所讨论的那样。G500-CSR 增加了 16% 的额外内存访问，由于每个顶点的工作量不均，预取距离必须相对于 EWMA 被高估</p><h4 id=事件触发>事件触发</h4><p>为了研究我们通过延迟容忍的基于事件的编程模型所获得的性能，我们扩展了系统以支持对用于进一步计算的数据进行加载阻塞：如果预取是链中的最后一个，那么核心将可供调度，但如果不是，必须停顿，因为在没有事件触发的情况下这是必要的。结果如图 11 所示。当访问模式是简单的步幅间接模式时，性能相对接近：我们只需要在步幅访问时停顿，并且通过在单个线程中预取整个缓存行来缓解停顿的开销，从而每 8 次访问就会发生一次停顿。这意味着内存级并行性仍然很高。然而，当访问模式变得复杂时，性能会显著下降。在复杂的访问模式下，停顿会限制甚至完全消除预取带来的性能提升，因此即使有来自十二个核心的大量并行性，延迟容忍事件仍然是系统能够正常工作的必要条件。</p><h2 id=conclusion>Conclusion</h2><p>我们提出了一种可编程预取器，它使用基于事件的编程模型，能够提取内存级并行性并提高各种不规则内存密集型工作负载的性能。在选择图形、数据库和 HPC 工作负载时，我们的预取器在不显着增加内存访问次数的情况下实现了平均 3.0 倍的加速。我们进一步提供了编译器技术，以减少程序员利用我们方案的性能优势的手动工作量，我们提出的两种方案平均加速 1.9 倍和 2.5 倍。</p><h2 id=附录>附录</h2><h3 id=参考文献>参考文献</h3><p><a class=link href="https://blog.csdn.net/weixin_49272453/article/details/140990388?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7ECtr-1-140990388-blog-104640587.235%5Ev43%5Epc_blog_bottom_relevance_base1&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7ECtr-1-140990388-blog-104640587.235%5Ev43%5Epc_blog_bottom_relevance_base1&amp;utm_relevant_index=2" target=_blank rel=noopener>哈希表</a></p><p><a class=link href=https://blog.csdn.net/qq_34734303/article/details/79705259 target=_blank rel=noopener>指数移动加权平均法</a></p><h3 id=版权信息>版权信息</h3><p>本文原载于 <a class=link href=https://vastcircle.github.io target=_blank rel=noopener>vastcircle.github.io</a>，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。</p></section><footer class=article-footer><section class=article-tags><a href=/tags/prefetch/>Prefetch</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-contents--wrapper><h2 class=section-title>Related contents</h2><div class=related-contents><div class="flex article-list--tile"><article><a href=/2025/spatial_memory_streaming/><div class=article-details><h2 class=article-title>Spatial_Memory_Streaming</h2></div></a></article><article><a href=/2024/secure_prefetching_for_secure_cache_systems/><div class=article-details><h2 class=article-title>Secure_prefetching_for_secure_cache_systems</h2></div></a></article><article><a href=/2025/memory_renaming_fast_early_and_accurate_processing_of_memory_communication/><div class=article-details><h2 class=article-title>Memory_renaming_fast_early_and_accurate_processing_of_memory_communication</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{DISQUS&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("//cdn.bootcss.com/pangu/3.3.0/pangu.min.js",function(){pangu.spacingPage()})</script><section class=copyright>&copy;
2023 -
2025 <a href=https://stack-theme-mod.vercel.app/>vastcircle</a>·<i class="fas fa-bell"></i> <a id=days>0</a>Days<br>共书写了267.4k字·共 80篇文章</br><span><p></section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.2.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a><br><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank>© Licensed Under CC BY-NC-SA 4.0</a></section><script>var days,number_of_days,s1="2024-10-06",s1=new Date(s1.replace(/-/g,"/"));s2=new Date,days=s2.getTime()-s1.getTime(),number_of_days=parseInt(days/(1e3*60*60*24)),document.getElementById("days").innerHTML=number_of_days</script></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><form action=/search/ class="search-form widget"><p><label>Search</label>
<input name=keyword required placeholder="Type something...">
<button title=Search><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></button></p></form><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#abstract>abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#existing-work>Existing Work</a><ol><li><a href=#预取单元>预取单元</a></li><li><a href=#可配置预取器>可配置预取器</a></li><li><a href=#隐式不规则预取器>隐式不规则预取器</a><ol><li><a href=#指针预取器>指针预取器</a></li><li><a href=#依赖图流提取>依赖图流提取</a></li><li><a href=#runahead-方案>Runahead 方案</a></li><li><a href=#数组间接模式预取>数组间接模式预取</a></li></ol></li><li><a href=#辅助线程>辅助线程</a><ol><li><a href=#自动生成的预执行线程>自动生成的预执行线程</a></li><li><a href=#具有架构支持的辅助内核>具有架构支持的辅助内核</a></li><li><a href=#分离访问与执行线程的核心>分离访问与执行线程的核心</a></li><li><a href=#基于辅助线程的预取机制>基于辅助线程的预取机制</a></li><li><a href=#我们的改进>我们的改进</a></li></ol></li></ol></li><li><a href=#motivation>motivation</a><ol><li><a href=#软件预取>软件预取</a></li><li><a href=#多线程处理>多线程处理</a></li><li><a href=#辅助线程-1>辅助线程</a></li><li><a href=#理想行为>理想行为</a></li></ol></li><li><a href=#programmable-prefetcher可编程预取器>Programmable Prefetcher(可编程预取器)</a><ol><li><a href=#overview>overview</a></li><li><a href=#address-filter>Address Filter</a></li><li><a href=#observation-queue-and-scheduler>Observation Queue and Scheduler</a></li><li><a href=#programmable-prefetch-units-ppus>Programmable Prefetch Units (PPUs)</a></li><li><a href=#moving-average-ewma-calculators>Moving Average (EWMA) Calculators</a></li><li><a href=#prefetch-request-queue>Prefetch Request Queue</a></li><li><a href=#memory-request-tags>Memory Request Tags</a></li><li><a href=#hardware-requirements>Hardware Requirements</a></li><li><a href=#summer>summer</a></li></ol></li><li><a href=#os-and-application-support>OS and Application Support</a><ol><li><a href=#event-programming-model>Event Programming Model</a></li><li><a href=#example>example</a></li><li><a href=#operating-system-visibility>Operating System Visibility</a></li></ol></li><li><a href=#compiler-assistance>Compiler Assistance</a><ol><li><a href=#analysis>Analysis</a></li><li><a href=#array-bounds-detection>Array Bounds Detection</a></li><li><a href=#code-generation>Code Generation</a><ol><li><a href=#pragma-prefetching>Pragma Prefetching</a></li></ol></li></ol></li><li><a href=#evaluation>Evaluation</a><ol><li><a href=#performance性能>Performance(性能)</a><ol><li><a href=#speedups加速比>Speedups(加速比)</a></li><li><a href=#对-l1-缓存的影响>对 L1 缓存的影响</a></li></ol></li><li><a href=#analysis-1>Analysis</a><ol><li><a href=#时钟频率>时钟频率</a></li><li><a href=#ppu-数量>PPU 数量</a></li><li><a href=#ppu-活动>PPU 活动</a></li><li><a href=#额外内存访问>额外内存访问</a></li><li><a href=#事件触发>事件触发</a></li></ol></li></ol></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#附录>附录</a><ol><li><a href=#参考文献>参考文献</a></li><li><a href=#版权信息>版权信息</a></li></ol></li></ol></nav></div></section><section class="widget categories"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-infinity" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M9.828 9.172a4 4 0 100 5.656A10 10 0 0012 12a10 10 0 012.172-2.828 4 4 0 110 5.656A10 10 0 0112 12 10 10 0 009.828 9.172"/></svg></div><h2 class="widget-title section-title">Categories</h2><div class=widget-categories--list><div class=widget><h3 class=widget-title></h3><div class=widget-body><div class=category-list><div class=category-list-item><a href=https://VastCircle.github.io/categories/a_prime_on_hardware_prefetch/ class=category-list-link>a_prime_on_hardware_prefetch<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/boom/ class=category-list-link>boom<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/boom%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/ class=category-list-link>boom代码阅读<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/cache/ class=category-list-link>cache<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/chipyard/ class=category-list-link>chipyard<span class=category-list-count>3</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/chisel/ class=category-list-link>chisel<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/cpu%E5%9F%BA%E7%A1%80/ class=category-list-link>cpu基础<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/gem5/ class=category-list-link>gem5<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/gpgpu%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/ class=category-list-link>gpgpu读书笔记<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/linux/ class=category-list-link>linux<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/riscv/ class=category-list-link>riscv<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/rocket-chip/ class=category-list-link>rocket-chip<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/runahead/ class=category-list-link>runahead<span class=category-list-count>3</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/ class=category-list-link>代码阅读<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B/ class=category-list-link>分支预测<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/ class=category-list-link>博客搭建<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E5%A4%84%E7%90%86%E5%99%A8/ class=category-list-link>处理器<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/ class=category-list-link>环境搭建<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/ class=category-list-link>环境配置<span class=category-list-count>3</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/ class=category-list-link>缓存一致性<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/ class=category-list-link>论文阅读<span class=category-list-count>12</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E8%AE%BF%E5%AD%98/ class=category-list-link>访存<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8/ class=category-list-link>超标量处理器<span class=category-list-count>12</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E9%A6%99%E5%B1%B1/ class=category-list-link>香山<span class=category-list-count>8</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81/ class=category-list-link>香山源代码<span class=category-list-count>3</a></span></div></div></div></div></div></section><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-infinity" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M9.828 9.172a4 4 0 100 5.656A10 10 0 0012 12a10 10 0 012.172-2.828 4 4 0 110 5.656A10 10 0 0112 12 10 10 0 009.828 9.172"/></svg></div><h2 class="widget-title section-title">Archives</h2><div class=widget-archive--list><div class=archives-year><a href=/archives/#2025><span class=year>2025</span>
<span class=count>33</span></a></div><div class=archives-year><a href=/archives/#2024><span class=year>2024</span>
<span class=count>47</span></a></div></div></section><section class="widget tagCloud"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg></div><h2 class="widget-title section-title">Tags</h2><div class=tagCloud-tags><a href=/tags/runahead/ class=font_size_6>Runahead
</a><a href=/tags/prefetch/ class=font_size_3>Prefetch
</a><a href=/tags/vector/ class=font_size_3>Vector
</a><a href=/tags/cache/ class=font_size_2>Cache
</a><a href=/tags/chipyard/ class=font_size_2>Chipyard
</a><a href=/tags/diplomacy/ class=font_size_2>Diplomacy
</a><a href=/tags/in-order/ class=font_size_2>In-Order
</a><a href=/tags/rocket-chip/ class=font_size_2>Rocket-Chip
</a><a href=/tags/%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B/ class=font_size_2>分支预测
</a><a href=/tags/%E5%AF%84%E5%AD%98%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D/ class=font_size_2>寄存器重命名</a></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>