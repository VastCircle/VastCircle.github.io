<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='内存访问 一般来说可以认为，Load 是没有副作用的（实际上，Load 会导致 Cache 加载数据，这也引发了以 Meltdown 为首的一系列漏洞），因此可以很激进地预测执行 Load。但是，Store 是有副作用的，写出去的数据就没法还原了。因此，Store 指令只有在 ROB Head 被 Commit 的时候，才会写入到 Cache 中。
'><title>乱序访存单元</title>
<link rel=canonical href=https://VastCircle.github.io/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/><link rel=stylesheet href=/scss/style.min.46208cabd58e8bcef0cfb7d7ea6b561adcca3b91dd1fc6657493a44f03c5db75.css><meta property='og:title' content='乱序访存单元'><meta property='og:description' content='内存访问 一般来说可以认为，Load 是没有副作用的（实际上，Load 会导致 Cache 加载数据，这也引发了以 Meltdown 为首的一系列漏洞），因此可以很激进地预测执行 Load。但是，Store 是有副作用的，写出去的数据就没法还原了。因此，Store 指令只有在 ROB Head 被 Commit 的时候，才会写入到 Cache 中。
'><meta property='og:url' content='https://VastCircle.github.io/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/'><meta property='og:site_name' content="VastCircle's blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content><meta property='article:published_time' content='2025-02-11T21:45:42+08:00'><meta property='article:modified_time' content='2025-02-11T21:45:42+08:00'><meta name=twitter:title content="乱序访存单元"><meta name=twitter:description content="内存访问 一般来说可以认为，Load 是没有副作用的（实际上，Load 会导致 Cache 加载数据，这也引发了以 Meltdown 为首的一系列漏洞），因此可以很激进地预测执行 Load。但是，Store 是有副作用的，写出去的数据就没法还原了。因此，Store 指令只有在 ROB Head 被 Commit 的时候，才会写入到 Cache 中。
"><style>:root{--article-font-family:"Noto Serif SC", var(--base-font-family)}</style><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@300;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex
<!--
extended
-->
on-phone--column extended"><div id=article-toolbar><a href=https://VastCircle.github.io/ class=back-home><svg class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg>
<span>Back</span></a></div><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header class=site-info><figure class=site-avatar><a href=/><img src=/img/avatar_hu9516569771622178000.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🍥</span></figure><h1 class=site-name><a href=/>VastCircle's blog</a></h1><h2 class=site-description>To shine , not to be illuminated</h2><ol class=social-menu><li><a href=https://github.com/VastCircle target=_blank title=GitHub><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com target=_blank title=Twitter><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol></header><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>friends</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/%E8%AE%BF%E5%AD%98/>访存</a></header><h2 class=article-title><a href=/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/>乱序访存单元</a></h2><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Feb 11, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-words>10990字</time></div></footer></div></header><section class=article-content><h2 id=内存访问>内存访问</h2><p>一般来说可以认为，Load 是没有副作用的（实际上，Load 会导致 Cache 加载数据，这也引发了以 Meltdown 为首的一系列漏洞），因此可以很激进地预测执行 Load。但是，Store 是有副作用的，写出去的数据就没法还原了。因此，Store 指令只有在 ROB Head 被 Commit 的时候，才会写入到 Cache 中。</p><p>当load的地址计算出来之后，可以去取数据，首先从store queue找，如果有地址和load地址相等，在store数据准备好之后，可以做数据转发。</p><p>如果没有找到，需要从cache中取</p><p>如果store慢到还没有写如store queue,load就完成了，就会出现错误，此时需要重新执行load指令和依赖与load指令的其余指令</p><h2 id=加载存储单元>加载存储单元</h2><p>最简单的方法是顺序执行，pipline会清空，store/atomic/uncached load 会有副作用</p><p>需要读写乱序， 需要提前执行load, 一种思路是等待所有的store执行完毕，另一种思路是用地址搜寻store,看看是否出现同一个地址的store和load,但是这样相当于做了一个全相连的buffer,面积大，延迟高。</p><p><a class=link href="https://repository.upenn.edu/cgi/viewcontent.cgi?article=1001&amp;context=cis_reports" target=_blank rel=noopener>A high-bandwidth load-store unit for single-and multi-threaded processors</a> 的解决思路是，把 Store 指令分为两类，一类是需要转发的，一类是不需要的，那么可以设计一个小的相连存储器，只保存这些需要转发的 Store 指令；同时还有一个比较大的，保存所有 Store 指令的队列，因为不需要相连搜索，所以可以做的比较大。</p><p>修复load-store相关性可以在store提交的时候，检查是否有地址冲突的load指令（ <a class=link href=https://docs.boom-core.org/en/latest/sections/load-store-unit.html#memory-ordering-failures target=_blank rel=noopener>Boom LSU</a> ),</p><p>可以在commit的时候重新执行load指令，如果结果不一致，把后面依赖冲刷掉，但是这样每条load需要执行两次 。<a class=link href="https://repository.upenn.edu/cgi/viewcontent.cgi?article=1228&amp;context=cis_papers" target=_blank rel=noopener>Store Vulnerability Window (SVW): Re-Execution Filtering for Enhanced Load Optimization</a> 属于重新执行 Load 指令的方法，通过 Bloom filter 来减少一些没有必要重复执行的 Load。还有一种办法，就是预测 Load 指令和哪一条 Store 指令有依赖关系，然后直接去访问那一项，如果不匹配，就认为没有依赖。<a class=link href=https://ieeexplore.ieee.org/document/1540957 target=_blank rel=noopener>Scalable Store-Load Forwarding via Store Queue Index Prediction</a> 把 Load 指令分为三类，一类是不确定依赖哪条 Store 指令（Difficult Loads），一类是基本确定依赖哪一条 Store 指令，一类是不依赖 Store 指令。这个有点像 Cache 里面的 Way Prediction 机制。</p><p>具体到 Load/Store Queue 的大小，其实都不大：</p><ol><li><a class=link href=https://ieeexplore.ieee.org/document/9000513 target=_blank rel=noopener>Zen 2</a> Store Queue 48</li><li><a class=link href=https://en.wikichip.org/wiki/intel/microarchitectures/skylake_%28client%29#Memory_subsystem target=_blank rel=noopener>Intel Skylake</a> Store Buffer 56 Load Buffer 72</li><li><a class=link href="https://ieeexplore.ieee.org/document/7029183?arnumber=7029183" target=_blank rel=noopener>POWER 8</a> Store Queue 40 Load Queue 44 (Virtual 128+128)</li><li><a class=link href=http://ieeexplore.ieee.org/document/755465/ target=_blank rel=noopener>Alpha 21264</a> Store Queue 32 Load Queue 32</li></ol><p>load pipline</p><p>下面来举例分析 LSU 中 Load Pipeline 每一拍需要做些什么。</p><p>以<a class=link href=https://raw.githubusercontent.com/OpenXiangShan/XiangShan-doc/main/slides/20210625-RVWC-%e8%ae%bf%e5%ad%98%e6%b5%81%e6%b0%b4%e7%ba%bf%e7%9a%84%e8%ae%be%e8%ae%a1%e4%b8%8e%e5%ae%9e%e7%8e%b0.pdf target=_blank rel=noopener>香山雁栖湖</a>微架构为例，它的 Load Pipeline 分为三级流水线：</p><ol><li>第一级：计算虚拟地址（基地址 + 立即数偏移），把虚拟地址送进 DTLB 和 L1 DCache（因为 VIPT，虚拟地址作为 index 访问 L1 DCache），从 DTLB 读取物理地址，从 L1 DCache Tag Array 读取各路的 Tag</li><li>第二级：从 DTLB 得到了物理地址，根据物理地址计算出 Tag，和 L1 DCache 读出的 Tag 做比较，找到匹配的 Way，从 L1 DCache 的 Data Array 读取对应 Way 的数据；把物理地址送到 Store Queue，查找匹配的 Store</li><li>第三级：根据从 L1 DCache 读取的数据和 Store to Load Forwarding 得到的数据，得到最终的读取结果，写回</li></ol><p>以<a class=link href=https://raw.githubusercontent.com/OpenXiangShan/XiangShan-doc/main/slides/20220825-RVSC-%e5%8d%97%e6%b9%96%e6%9e%b6%e6%9e%84%e8%ae%bf%e5%ad%98%e5%ad%90%e7%b3%bb%e7%bb%9f%e7%9a%84%e8%ae%be%e8%ae%a1%e4%b8%8e%e5%ae%9e%e7%8e%b0.pdf target=_blank rel=noopener>香山南湖</a>微架构为例，它的 Load Pipeline 分为四级流水线：</p><ol><li>第一级：计算虚拟地址（基地址 + 立即数偏移），把虚拟地址送进 DTLB 和 L1 DCache（因为 VIPT，虚拟地址作为 index 访问 L1 DCache），从 DTLB 读取物理地址，从 L1 DCache Tag Array 读取各路的 Tag</li><li>第二级：从 DTLB 得到了物理地址，根据物理地址计算出 Tag，和 L1 DCache 读出的 Tag 做比较，找到匹配的 Way，从 L1 DCache 的 Data Array 读取对应 Way 的数据；把物理地址送到 Store Queue，查找匹配的 Store</li><li>第三级：由于 L1 DCache 容量较大，需要的延迟比较高，在这一级完成数据的读取和 Store to Load Forwarding</li><li>第四级：根据从 L1 DCache 读取的数据和 Store to Load Forwarding 得到的数据，得到最终的读取结果，写回</li></ol><p>以香山昆明湖微架构为例，它的Load Pipline 分成</p><p>未完</p><p>为了减少额外的 1 个周期对 pointer chasing 场景的性能影响，南湖架构针对 pointer chasing 做了优化：pointer chasing 场景下，读取的数据会成为后续 load 指令的地址。为了优化它，南湖架构在流水线的第四级上做了前传，直接传递到下一条 load 指令的由虚拟地址计算出的 index，这样的话可以做到 3 cycle 的 load to use latency。为了优化时序，前传的时候，假设基地址加上 imm 以后，不会影响 index，这样预测的时候就不用加上 imm，时序上会好一些，不过这也限制了优化可以生效的 imm 范围。</p><p><figure class=gallery-image style=flex-grow:153;flex-basis:368px><a href=/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250212003916045.png data-size=1422x927><img src=/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250212003916045.png width=1422 height=927 srcset="/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250212003916045_hu15397080119635479537.png 480w, /2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250212003916045_hu10502182120977214539.png 1024w" loading=lazy></a></figure></p><p>苹果的专利就是读寄存器的一个前递，苹果的专利 <a class=link href=https://patents.google.com/patent/US9710268B2 target=_blank rel=noopener>Reducing latency for pointer chasing loads</a> 提到了它的 LSU 流水线设计以及前传的做法：</p><p>和香山南湖类似，它的 Load Pipeline 也是四级流水线（对应图中 Stage 3-6），功能也类似。不过它的 3 周期 load to load 前传的实现方法则不同。</p><p>这个专利的前传是从第三级前传到读寄存器的阶段，这样也可以实现 3 周期的的 load to load latency。这样的好处是，AGU 阶段保留，这对于 AGU 阶段比较复杂的 ARM 架构是比较好的，因为 ARM 架构下 AGU 阶段可能涉及到加法和移位，而 RISCV 只有立即数加法。不过这样也要求 Load 不命中 Store Queue，而是从 L1 DCache 获得，因为 Store to Load Forwarding 的合并操作是在第四级流水线，为了能在第三级流水线前传，只能预测它不命中 Store Queue，数据完全从 L1 DCache 中取得。</p><p>图中把 AGU 和 DTLB Lookup 并着画可能有一些问题，应该是先由 AGU 计算出虚拟地址，再走 DTLB Lookup。</p><h2 id=memory-dependence-predictor>Memory Dependence Predictor</h2><p>解决store-load依赖的，如果有依赖，等待依赖的store完成，如果没有依赖，可以直接load .为了保证正确性，Store 执行的时候，也要去看是否破坏了提前执行的 Load。</p><p>alpha 21264 load wait table , 对于那些出现过顺序违例的 Load 指令，打上一个标记，那么未来这个 Load 都要等到在它之前的所有 Store 执行才能执行。这个标记的方法也很简单，维护 Load 指令的 PC 到单 bit 的映射。 香山<a class=link href=https://github.com/OpenXiangShan/XiangShan/blob/dd16cea72b92bcf8a87750b14458be82fda5cfff/src/main/scala/xiangshan/mem/mdp/WaitTable.scala#L27 target=_blank rel=noopener>实现</a></p><div class=highlight><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#c678dd>val</span> <span style=color:#e06c75>data</span> <span style=color:#c678dd>=</span> <span style=color:#e5c07b>RegInit</span><span style=color:#56b6c2>(</span><span style=color:#e5c07b>VecInit</span><span style=color:#56b6c2>(</span><span style=color:#e5c07b>Seq</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>fill</span><span style=color:#56b6c2>(</span><span style=color:#e5c07b>WaitTableSize</span><span style=color:#56b6c2>)(</span><span style=color:#d19a66>0.</span><span style=color:#e06c75>U</span><span style=color:#56b6c2>(</span><span style=color:#d19a66>2.</span><span style=color:#e06c75>W</span><span style=color:#56b6c2>))))</span> <span style=color:#7f848e>// 2bit的计数器 
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>  <span style=color:#c678dd>val</span> <span style=color:#e06c75>resetCounter</span> <span style=color:#c678dd>=</span> <span style=color:#e5c07b>RegInit</span><span style=color:#56b6c2>(</span><span style=color:#d19a66>0.</span><span style=color:#e06c75>U</span><span style=color:#56b6c2>(</span><span style=color:#e5c07b>ResetTimeMax2Pow</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>W</span><span style=color:#56b6c2>))</span>
</span></span><span style=display:flex><span>  <span style=color:#e06c75>resetCounter</span> <span style=color:#c678dd>:</span><span style=color:#56b6c2>=</span> <span style=color:#e06c75>resetCounter</span> <span style=color:#56b6c2>+</span> <span style=color:#d19a66>1.</span><span style=color:#e06c75>U</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#7f848e>// read ports
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>  <span style=color:#c678dd>for</span> <span style=color:#56b6c2>(</span><span style=color:#e06c75>i</span> <span style=color:#c678dd>&lt;-</span> <span style=color:#d19a66>0</span> <span style=color:#e06c75>until</span> <span style=color:#e5c07b>DecodeWidth</span><span style=color:#56b6c2>)</span> <span style=color:#56b6c2>{</span> <span style=color:#7f848e>// raddr : pc(vaddr-1:1)
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>    <span style=color:#e06c75>io</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>rdata</span><span style=color:#56b6c2>(</span><span style=color:#e06c75>i</span><span style=color:#56b6c2>)</span> <span style=color:#c678dd>:</span><span style=color:#56b6c2>=</span> <span style=color:#56b6c2>(</span><span style=color:#e06c75>data</span><span style=color:#56b6c2>(</span><span style=color:#e06c75>io</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>raddr</span><span style=color:#56b6c2>(</span><span style=color:#e06c75>i</span><span style=color:#56b6c2>))(</span><span style=color:#e5c07b>LWTUse2BitCounter</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>B</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>asUInt</span><span style=color:#56b6c2>)</span> <span style=color:#56b6c2>||</span> <span style=color:#e06c75>io</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>csrCtrl</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>no_spec_load</span><span style=color:#56b6c2>)</span> <span style=color:#56b6c2>&amp;&amp;</span> <span style=color:#56b6c2>!</span><span style=color:#e06c75>io</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>csrCtrl</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>lvpred_disable</span>
</span></span><span style=display:flex><span>  <span style=color:#56b6c2>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#7f848e>// write port
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>  <span style=color:#e06c75>when</span><span style=color:#56b6c2>(</span><span style=color:#e06c75>io</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>update</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>valid</span><span style=color:#56b6c2>){</span>  
</span></span><span style=display:flex><span>    <span style=color:#e06c75>data</span><span style=color:#56b6c2>(</span><span style=color:#e06c75>io</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>update</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>waddr</span><span style=color:#56b6c2>)</span> <span style=color:#c678dd>:</span><span style=color:#56b6c2>=</span> <span style=color:#e5c07b>Cat</span><span style=color:#56b6c2>(</span><span style=color:#e06c75>data</span><span style=color:#56b6c2>(</span><span style=color:#e06c75>io</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>update</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>waddr</span><span style=color:#56b6c2>)(</span><span style=color:#d19a66>0</span><span style=color:#56b6c2>),</span> <span style=color:#e5c07b>true</span><span style=color:#56b6c2>.</span><span style=color:#e06c75>B</span><span style=color:#56b6c2>)</span>
</span></span><span style=display:flex><span>  <span style=color:#56b6c2>}</span>
</span></span></code></pre></div><p>store set , 一个load 依赖过的所有store 的集合 ， 如果一个 Load 的 Store Set 内的所有的 Store 都执行完了，那么这个 Load 就可以提前执行了，不用考虑别的 Store 指令。当然了，一开始并不知道 Load 依赖哪些 Store，所以 Store Set 是空的，此时 Load 可能会提前执行。当发现执行顺序错误，需要回滚时，就把导致回滚的 Store 添加到对应 Load 的 Store Set 当中。</p><ol><li>每个 Store 只能出现在一个 Store Set 当中，这个 Store Set 可以由多个 Load 共享。</li><li>执行 Load 之前，为了保证 Store Set 中的 Store 指令都完成执行，要求这些 Store 指令按照一定的顺序完成，那么 Load 只用等待 Store Set 内的最后一条 Store 指令，而不用考虑 Store Set 内所有 Store 指令完成。</li></ol><p>首先是 Store Set Identifier Table (SSIT)，这个表实现了 Load/Store 指令 PC 到 Store Set ID 的映射。通过 SSIT，就可以知道 Load 的 Store Set 是哪个 ID，哪些 Store 在这个 Store Set 当中。第二个表是 Last Fetched Store Table (LFST)，它记录了这个 Store Set 中最晚被取指的 Store 指令。</p><p>前面提到，为了简化依赖的检查，同一个 Store Set 内的 Store 指令需要按照顺序执行，那么 Load 只需要依赖 Store Set 的最后一条 Store 指令。这个就是通过 LFST 来实现的：</p><ul><li>每个 Store 首先根据 SSIT 找到自己的 Store Set ID，再用 Store Set ID 访问 LFST，如果里面已经有更早的 Store，那就要依赖这个更早的 Store；同时也会更新 LFST，把自己写进去。</li><li>同理 Load 也会根据 SSIT 找到 Store ID，用 Store Set ID 反问 LFST，去依赖最晚的 Store。</li><li>如果 Store 已经被执行（准确地说，Issue），自然后续的 Load 也不用等待它了，如果 LFST 记录的还是这条 Store，它就可以从 LFST 中清除掉。</li></ul><h2 id=store-to-load-forwarding>store to load forwarding</h2><p>对于那些依赖之前的 Store 的 Load 指令，如果 Store 还没有写进缓存，那么 Load 在执行的时候，就需要从 Store 要写入的数据里获取数据，这就是 Store to Load Forwarding。但实际情况可能会比较复杂，例如 Load 和 Store 只有一部分的重合，不重合的部分要从缓存中获取；或者 Load 和多个 Store 重合，要从多个 Store 分别取数据合并起来；或者前后有对同一个地址的 Store，那么要选取最晚的那一个。</p><p>首先来看看 Intel 在 Intel® 64 and IA-32 Architectures Optimization Reference Manual 中对 Core（不是 Core 系列 CPU）微架构的表述：</p><ol><li>尽量通过寄存器传递函数参数，而不是栈；虽然通过栈传参数，比较容易享受到 Store to Load Forwarding 的优化，但浮点的转发还是比较慢。</li><li>转发时，Load 的起始地址和 Store 相同。Load 的读取范围要包含在 Store 的写入范围之内。</li><li>如果要从 Store 写入范围的中间而不是开头读取数据，直接从中间开始读无法享受 Store to Load Forwarding，想要更好的性能，需要先从头开始读，满足转发条件，再通过位运算提取出想要的部分。</li></ol><p>ARM公版核： Load的起始地址等于store的起始地址或者正好中间，大于 8 字节的 Load 最多可以从两个 Store 中转发数据，此时每个 Store 分别贡献一半，例如两个 Store 分别写入 8 个字节，然后 Load 把 16 个字节读出来。小于或等于 4 字节的 Load 只能从一个 Store 中获取数据。</p><p>下面是在几款处理器上实测 Store to Load Forwarding 在各种访存模式下能否转发以及转发的条件：</p><div class=table-wrapper><table><thead><tr><th style=text-align:left>uArch</th><th style=text-align:left>1 ld + 1 st</th><th style=text-align:left>1 ld + 2 st</th><th style=text-align:left>1 ld + 4 st</th><th style=text-align:left>1 ld + 8 st</th></tr></thead><tbody><tr><td style=text-align:left><a class=link href=https://jia.je/hardware/2024/11/11/amd_zen5/ target=_blank rel=noopener>AMD Zen5</a></td><td style=text-align:left>Yes [1]</td><td style=text-align:left>No</td><td style=text-align:left>No</td><td style=text-align:left>No</td></tr><tr><td style=text-align:left><a class=link href=https://jia.je/hardware/2024/11/07/arm_neoverse_v2/ target=_blank rel=noopener>ARM Neoverse V2</a></td><td style=text-align:left>Yes [2]</td><td style=text-align:left>Yes [3]</td><td style=text-align:left>No</td><td style=text-align:left>No</td></tr><tr><td style=text-align:left><a class=link href=https://jia.je/hardware/2024/09/01/qualcomm_oryon/ target=_blank rel=noopener>Qualcomm Oryon</a></td><td style=text-align:left>Yes [4]</td><td style=text-align:left>Yes [5]</td><td style=text-align:left>No</td><td style=text-align:left>No</td></tr><tr><td style=text-align:left><a class=link href=https://jia.je/hardware/2024/12/26/apple_m1/ target=_blank rel=noopener>Apple Firestorm</a></td><td style=text-align:left>Yes</td><td style=text-align:left>Yes [6]</td><td style=text-align:left>Yes [6]</td><td style=text-align:left>Yes [6]</td></tr><tr><td style=text-align:left><a class=link href=https://jia.je/hardware/2025/01/10/intel_golden_cove/ target=_blank rel=noopener>Intel Golden Cove</a></td><td style=text-align:left>Yes [7]</td><td style=text-align:left>No</td><td style=text-align:left>No</td><td style=text-align:left>No</td></tr><tr><td style=text-align:left><a class=link href=https://jia.je/hardware/2025/01/12/intel_gracemont/ target=_blank rel=noopener>Intel Gracemont</a></td><td style=text-align:left>Yes [8]</td><td style=text-align:left>No</td><td style=text-align:left>No</td><td style=text-align:left>No</td></tr></tbody></table></div><ul><li>[1]: 要求 st 完全包含 ld</li><li>[2]: 要求 ld 和 st 地址相同或差半个 st 宽度</li><li>[3]: 要求 ld 和 st 地址相同</li><li>[4]: 要求不跨越 64B 边界</li><li>[5]: 要求 ld 对齐到 4B 边界且不跨越 64B 边界</li><li>[6]: 要求不跨越 64B 边界</li><li>[7]: 要求 st 完全包含 ld；特别地，在 st 和 ld 访问相同地址时，无 Forwarding 性能损失</li><li>[8]: 要求 st 完全包含 ld，ld 和 st 地址相同，不跨越 64B 边界；特别地，64b st 到 32b ld 转发允许 ld 地址和 st 地址差半个 st 宽度</li></ul><h2 id=memory-renaming>memory renaming</h2><p>Register Renaming 把物理寄存器重命名为架构寄存器，那么 <a class=link href=https://link.springer.com/article/10.1023/A:1018734923512 target=_blank rel=noopener>Memory Renaming: Fast, Early and Accurate Processing of Memory Communication</a> 类似地把内存重命名为寄存器。具体地，如果发现某个 Load 的数据总是来自于某个 Store，按照先前的做法，要等 Store 先执行，然后 Load 从 Store Queue 中拿到 Store 的结果，更进一步，不如直接把 Load 的目的寄存器复制为 Store 的源数据寄存器，相当于把内存重命名成了寄存器，Load 变成了简单的寄存器的 Move。</p><p>具体做法是，在 Memory Dependency Predictor 的基础上，还把 Store 写入的数据保存到 Value File 当中。当预测 Load 会从某个 Store 取数据时，就从 Value File 中取出对应的数据，提早执行依赖 Load 结果的指令。</p><h2 id=load-address-prediction>load address prediction</h2><p>把数据预取到寄存器上</p><p>在 1993 年的论文 <a class=link href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5389606" target=_blank rel=noopener>A load-instruction unit for pipelined processors</a> 提出了类似的想法：预测 Load 指令的地址，提前把数据从缓存中读取，如果命中了，把数据存到 Load Queue 中，当 Load 指令被执行，计算出实际地址时，如果实际地址和预测的匹配，就直接从 Load Queue 中取数据，而不用读取缓存，可以节省一个周期；如果缓存缺失了，就相当于进行了一次缓存的预取。为了实现地址的预测，需要维护一个 Load Delta Table，根据 Load 指令的地址来查询，Entry 记录了最后一次访问的地址以及每次访存地址的偏移 Delta，当 Delta 为 0 时，对应 Constant Address；当 Delta 不等于 0 时，对应 Stride Address。这个设计比较简单和保守，因为它要等到 Load 的地址实际计算出来才能 Bypass。</p><blockquote><p>提前用预测的地址向cache发起请求，等结果计算出来后，如果相同，直接将数据返回 ， 本身是load 指令计算出来之后再发起访存 ， 差了一拍</p></blockquote><p>下面来分析一个来自苹果公司的专利：<a class=link href=https://patents.google.com/patent/US20210049015A1 target=_blank rel=noopener>Early load execution via constant address and stride prediction</a>，它实现的优化是，当一条 load 指令的地址是可预测的，例如它总是访问同一个地址（<code>constant address</code>），或者访问的地址按照固定的间隔（<code>constant stride</code>）变化，那就按照这个规律去预测这条 load 指令要访问的地址，而不用等到地址真的被计算出来，这样就可以提前执行这条 load 指令。</p><p>既然是一个预测算法，首先就要看它是怎么预测的。专利里提到了两个用于预测的表：</p><ol><li>Load Prediction Table，给定 PC，预测 Load 指令要访问的地址</li><li>Load Prediction Learning Table，用于跟踪各个 PC 下的 Load 指令的访存模式以及预测正确率</li></ol><p>一开始，两个表都是空的，随着 Load 指令的执行，首先更新的是 Load Prediction Learning Table，它会跟踪 Load 指令的执行历史，训练预测器，计算预测器的准确率。</p><p>当 Load Prediction Learning Table 发现能够以较高的准确率预测某条 Load 指令时，就会在 Load Prediction Table 中分配一个 entry，那么之后前端（IFU）再次遇到这条 Load 指令时，通过检查 Load Prediction Table，就可以预测要访问的地址。</p><p>当 Load Prediction Learning Table 发现某条 Load 指令的预测错误次数多了，就会把对应的表项从 Load Prediction Table 和 Load Prediction Learning Table 中删除，此时就会回退到正常的执行过程，Load 指令需要等待地址计算完成才可以执行。</p><p>为了避免浪费功耗，如果 Load 指令的地址很快就可以算出来，那么预测也就没有必要了，此时即使做了预测，也不会带来很高的性能提升。判断的依据是，计算从预测地址到计算出地址耗费的周期数，如果超过一个阈值，那么优化就有效果；如果没有超过阈值，那就不预测。</p><p>那么，如果 Load 的地址需要比较长的时间去计算，但实际上又是可以预测的，那就可以通过 Load Address Prediction 的方法，来提升性能。</p><blockquote><p>感觉这个和stride prediction 就只相差了一个load prediction learning table , 先通过预测确保正确率，然后再通过prefetch去预测 ， 但是它做的是寄存器级的，就是已经要从cache取到寄存器了，所以得尽量的去保证正确率，不像从l2取到dcache 错误的惩罚其实不多</p></blockquote><p><figure class=gallery-image style=flex-grow:139;flex-basis:334px><a href=/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250216000944436.png data-size=1019x731><img src=/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250216000944436.png width=1019 height=731 srcset="/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250216000944436_hu6046732381341249307.png 480w, /2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250216000944436_hu11102086425387596471.png 1024w" loading=lazy></a></figure></p><h2 id=way-prediction>way prediction</h2><p>组相连结构在处理器的很多地方都有，例如各种缓存，那么在访问组相连结构的缓存的时候，首先需要用 Index 取出一个 Set，再进行 Way 的匹配。但缓存在硬件中通常是用 SRAM 实现的，读取有一个周期的延迟，因此读取的过程并没有这么简单，下面分析几种读取组相连缓存的设计：</p><p>第一种最简单的办法是，第一个周期根据 Index 把整个 Set 所有 Way 的 Tag 和数据都读出来，第二个周期就可以拿到所有的 Tag 和数据，比较 Tag 后得到结果。这个方法比较简单，缺点是功耗比较大，实际只命中最多一个 Way，却要把所有的 Way 和 Tag 和数据都读出来。</p><p>既然只有一个 Way 的数据需要用，一个直接的想法是把读取拆成两步：第一个周期根据 Index 把整个 Set 所有 Way 的 Tag 都读出来，只读 Tag 不读数据，比对 Tag 后，第二个周期再把 Tag 正确的那一个 Way 的数据读出来。这样省下了很多数据 SRAM 的读取功耗，Tag 的读取没有省，同时付出了多了一个周期的代价。</p><p>有没有什么办法改进呢？能否只读一个 Way 的 Tag 和数据？这就需要引入 Way Prediction，这在论文 <a class=link href=https://ieeexplore.ieee.org/document/799456 target=_blank rel=noopener>Way-Predicting Set-Associative Cache for High Performance and Low Energy Consumption</a> 中提出，它的思路是，引入一个预测器，预测这次访问会命中哪个 Way，然后第一个周期只读这一个 Way 的 Tag 和数据，如果 Tag 命中了，数据也有了，这样功耗和性能都是比较好的。不过如果预测错了，第二个周期就需要把其他几个 Way 的 Tag 和数据读出来，再比较一次</p><blockquote><p>预测第一周期只读一路 tag 和 data , 如果预测错误了 ， 下一周期把其他路的data 和 tag 读出来 , 如果预测对了就是净赚一周期， 预测错误其实也需要两周期， 第一周期需要做到 读取tag 和 data , 虚实转化 ， 比较tag 是否匹配 ， 如果不匹配需要发起请求</p></blockquote><p><figure class=gallery-image style=flex-grow:166;flex-basis:399px><a href=/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/brief-into-ooo-2-amd-way-prediction.png data-size=1486x892><img src=/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/brief-into-ooo-2-amd-way-prediction.png width=1486 height=892 srcset="/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/brief-into-ooo-2-amd-way-prediction_hu8184788893825638194.png 480w, /2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/brief-into-ooo-2-amd-way-prediction_hu15858005748187249413.png 1024w" loading=lazy alt=img></a><figcaption>img</figcaption></figure></p><ol><li>对于 VIPT 的 cache 来说，它的 tag 来自于物理地址，意味着如果要做 way 比对，判断哪一个 way 命中，需要等到虚实地址转换，得到物理地址以后，才能知道实际的 tag，才能去比对</li><li>Zen 5 为了避免等待虚实地址转换，基于虚拟地址计算出一个 8-bit 的 microtag(utag)，在一个类似缓存的 way predictor 结构里，保存每个 set 的每个 way 的 utag，同一个 set 内不同 way 的 utag 互不相同，way predictor 的 way 和 data cache 的 way 一一对应</li><li>访存的时候，读出那个 set 的所有 way 的 utag（12 路，每路 8 bit），用 utag 进行比对：<ol><li>因为 utag 互不相同，所以最多只有一个 way 命中</li><li>如果有且仅有一个 way 命中，下一个周期就去读取出这一个 way 对应的数据以及用物理地址算出来的 tag</li><li>如果没有 way 命中，则认为 miss</li></ol></li><li>由于 utag 完全用的是虚拟地址，它可能会出错，分两种情况：<ol><li>把 miss 的预测为 hit，比如出现了 hash 冲突，有两个 way 的 tag 不同，但是 utag 一样，只能预测其中一个 way，访问另一个的时候就会 miss</li><li>把 hit 的预测为 miss，比如两个虚拟页映射到同一个物理页，用物理地址算出来的 tag 相同，但用虚拟地址算出来的 utag 不同，这两个 utag 就会抢同一个 way 的位置（注：这个问题是可以解决的，比如不要求 way predictor 的 way 与 data cache 的 way 一一对应，在 way predictor 每个 entry 里面加上一个 data cache 的 way index，不过考虑到概率和开销，好处不明显）</li></ol></li><li>等虚实地址转换完成，再用物理地址验证访问是否正确</li></ol><blockquote><p>对于一般的cache , f0 发起req , f1 得到根据index 获取set 的 tag ， 同时进行虚实转化 ， 进行tag的比较 ，并发起data 的读取 ， f2 得到读取的data</p><p>zen5 , 会基于虚拟地址计算一个utag , 一个set中的way的utag不同 ，然后获取对应的way ,如果命中了，下一个周期读取对应的数据和计算出来的tag</p><p>utag不经过虚拟化， 这个感觉就是先用虚拟地址的tag比较出来，获取结果之后，然后用物理tag进行验证 ，可以提前一点虚实转化的时间 ， 这样主频会高一点， 本身有个周期需要虚实转化 + tag 比较 ， 现在可以单纯进行tag比较 ， 虚实转化可以这周期发起，下一周期得到 ，然后在比较物理tag , 那周期就会短一点 ， 并且这样读取多路的tag 和 读取 多路的utag + 一路的tag , 相比应该是前者功耗更低 (utag的位数很少)</p><p>顺便说一下，boom 是同时去读取data 和 tag 的</p></blockquote><h2 id=load-value-prediction>load value prediction</h2><p>对load 得到的值进行预测 。 设计了一个load value predictio , 根据load 的地址来索引 ，</p><blockquote><p>load addr prediction 是根据pc 去预测地址， 然后提前向 cache 发起访问 ， load value prediction 是根据 addr 去预测 load 的值 ， 提前把预测的值写入寄存器</p></blockquote><p><a class=link href=https://dl.acm.org/doi/pdf/10.1145/248209.237173 target=_blank rel=noopener>Value Locality and Load Value Prediction</a> 提出了 Load Value Prediction，就是对 Load 得到的值进行预测。它设计了一个 Load Value Prediction Table，根据 Load 指令的地址来索引，得到预测的读取的值。然后设计一个 Load Classification Table 来记录预测准确与否的历史，记录了 saturating counter，以此来判断是否要进行预测。预测时，可以提前把结果写入到目的寄存器内，但还要验证预测的正确性。验证的方式有两种：第一是依然完成正常的访存，把读出来的数据和预测的数据做比较；第二是针对预测正确率很高的 Load，从一个小的 Constant Verification Unit 确认这个值没有变过。</p><p>如果要拿分支预测来类比，BTB 记录分支的目的地址，对应这里的 Load Value Prediction Table，记录 Load 指令得到的值；BHT 记录分支的跳转方向，对应这里的 Load Classification Table，判断 Load 的可预测性。</p><blockquote><p>预测算法的一脉相传嘛</p></blockquote><p>Constant Verification Unit 类似一个小的针对 Load Value Prediction 的 L0 Cache，只记录那些预测正确率很高的 Load 的地址 - 值映射关系，可以在地址计算出来后查询，判断访存是否正确预测，如果正确，就不用访问缓存了。</p><p>根据论文 <a class=link href=https://predictors.fail/files/FLOP.pdf target=_blank rel=noopener>FLOP: Breaking the Apple M3 CPU via False Load Output Predictions</a>，苹果在 M3/M4/A17 等处理器的 P 核上实装了 Load Value Prediction 预测器，它会观察 Load 指令的访存的规律，如果一条 Load 总是读出来相同的数据，那就会预测它未来读出来还是相同的数据。它的各项参数如下：</p><ul><li>只支持 Constant value，即 load 指令读出来的数据不变</li><li>不支持 Striding value，即 load 指令读出来的数据构成等差数列</li><li>大概 240 次 load 相同的值后使能值预测以提升性能</li><li>对于 1/2/4 字节 load，可以预测出所有可能的值，意味着这最多 4 字节的值会记录在预测器内部</li><li>对于 8 字节 load，只能预测值等于 0 的情况，没有做 8 字节 load 的通用场景，背后的考虑可能是：<ul><li>8 字节比较长，开销大</li><li>8 字节且非零的 constant load 相对少见</li><li>指针也是 8 字节，避免预测的 8 字节的值被当成指针来用</li></ul></li><li>观察到可以预测最多 72 个 Load 的 Value，可能是 4 路组相连</li><li>用 load 指令的地址做 full tag，不能跨越上下文共享</li></ul><p>前面提到，苹果也实装了 Load Address Prediction，意味着在 M3/A17 及之后的处理器的 P 核上，既有 Load Address Prediction，又有 Load Value Prediction，分别对 Load 的地址和读出来的数据做预测。为此，苹果专利 <a class=link href=https://patents.google.com/patent/US20240362027A1/en target=_blank rel=noopener>Shared Learning Table for Load Value Prediction and Load Address Prediction</a> 设计了一种机制来同时支持两种预测，并且共享 Learning Table：</p><ul><li>前面分析苹果的 Load Address Prediction 专利时提到，硬件实现中会用到两个表，一个用来跟踪训练的状态（Learning Table），另一个用来进行实际的预测（Prediction Table）</li><li>类似地，Load Value Prediction 也会有类似的设计：一个 Learning Table 寻找潜在的可以被预测的 Load，一个 Prediction Table 跟踪正在被预测的 Load</li><li>既然两种预测都是针对 Load 进行的，就要考虑应用哪种预测，避免冲突，提升性能</li><li>具体的实现方法就是，用一个 Learning Table 解决 Value 和 Address 两种预测的训练，再分别给 Value 和 Address 设置各自的 Prediction Table</li></ul><blockquote><p>对于learning table , 感觉确实是常规字段 ，pc索引, 保存地址 ， 一些判定标志位， 置信度 ， 这种是不是就是cam 结构， pc是并行的去访问所有表项然后进行判断的 ， value 的优先级更高 ， 诶， 其实这种应该相当于全相联的cache</p><p>value prediction 也分配pc表项，确保它也能够被直接读取</p></blockquote><ul><li><p>专利中给出了一种可能的 Learning Table 的 Entry 的字段：</p><ul><li>Status: 状态，比如 Valid，Age，Priority 等等</li><li>PC tag: 区分不同 Load，Full Tag</li><li>Predicted address：预测的访存地址</li><li>Stride or value：适用 Address 还是 Value Prediction</li><li>Predicted stride/hash of value：预测的 Stride 或者 Value 的哈希</li><li>Striding load indicator: 是否是 Striding Load</li><li>Confidence level：预测的信心</li><li>Allocated in prediction table?：是否在 Prediction Table</li><li>Number of consecutive mis-predictions：连续的错误预测次数</li></ul></li><li><p>接下来讨论一条 Load 指令的训练过程：</p><ul><li><p>当一条 Load 指令第一次进入 Prediction Table 时，还不知道它是否能够被预测，它的 Address 还是 Value 能够被预测，此时它的地址和数据会记录在 Prediction Table 当中</p></li><li><p>当这条 Load 再次被执行时，如果它的值和上一次相同（使用哈希判断，节省开销，当然也可能出错），则标记为 Value 预测模式；如果值不相同，那就把这次 Load 的地址减去上一次 Load 的地址作为 Stride 保存下来，标记为 Address 预测模式</p></li><li><p>在 Value 预测模式下，持续跟踪 Load 的值是否预测正确：</p><ul><li>如果 Value 预测正确，则累积 Confidence</li><li>当 Confidence 超过阈值时，在 Value Prediction Table 中分配，启动 Value 预测</li><li>如果 Value 预测失败，则结束 Value 预测，切换到 Address 预测模式</li></ul></li><li><p>在 Address 预测模式下，持续跟踪相邻两次 Load 的地址的差值：</p><ul><li>如果发现连续两次访问的 Stride 相同，则标记为 Striding Load</li><li>反过来，如果两次访问的 Stride 不同，则取消 Striding Load 标记，重新识别 Load 的类型</li><li>如果 Striding Load 的 Stride 预测正确，则累积 Confidence</li><li>当 Confidence 超过阈值时，在 Address Prediction Table 中分配，启动 Address 预测</li></ul></li><li><p>接下来分析 Value Prediction Table，专利中给出了一种可能的 Value Prediction Table 的 Entry 的字段：</p><ul><li>Status: 状态</li><li>PC tag：区分不同 Load，Full Tag</li><li>Value acquired：数据是否已经保存到 Data 字段，如果没有，需要发送一个 Probing load 去把数据取进来</li><li>Probe Sent：标记是否已经发送 Probing load，避免重复发送</li><li>Data：记录了预测的数据</li><li>LRU：维护 LRU 信息</li></ul></li><li><p>接下来分析 Address Prediction Table，专利中给出了一种可能的 Address Prediction Table 的 Entry 的字段：</p><ul><li>Status: 状态</li><li>PC tag：区分不同 Load，Full Tag</li><li>Predicted Address：预测要访问的地址</li><li>Predicted Stride：预测的地址跨步</li><li>Striding load indicator：标记是否为 Striding Load</li><li>Intermittent striding loads：记录跨步访存的进度</li></ul></li></ul></li></ul><p><figure class=gallery-image style=flex-grow:151;flex-basis:362px><a href=/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250216231752850.png data-size=1100x728><img src=/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250216231752850.png width=1100 height=728 srcset="/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250216231752850_hu6946940706465229262.png 480w, /2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/image-20250216231752850_hu15106340724602338552.png 1024w" loading=lazy></a></figure></p><h2 id=stable-load>stable load</h2><p>论文 <a class=link href=https://arxiv.org/pdf/2406.18786 target=_blank rel=noopener>Constable: Improving Performance and Power Efficiency by Safely Eliminating Load Instruction Execution</a> 指出，很多 Load 指令总是从相同的地址取出相同的值，对于这种 Load 指令（称为 Stable Load），可以通过硬件的扩展来优化，提升性能。它是这么做的：</p><ol><li>检测这样的 Stable Load：Load 执行的时候，判断这次的 Load 地址和数据，与同一个 PC 的上一次 Load 是否相同，如果相同，就增加置信度</li><li>如果一段时间内地址和数据都不变（通过置信度判断），认为这是一个可以消除的 Stable Load</li><li>消除的方法是，直接把 Load 的数据复制给目的寄存器，跳过了地址计算，也不用访存</li><li>在 Register Monitor Table 中记录 Stable Load 使用的源寄存器，如果这些寄存器被修改了，那么大概率地址会发生变化，不再消除这条 Stable Load</li><li>在 Address Monitor Table 中记录 Stable Load 访问的地址，如果对这个地址有写入操作，或者被其他核心访问，那么大概率数据会发生变化，不再消除这条 Stable Load</li></ol><p>这篇论文可以认为是 Load Value Prediction 的变体：缩小 Load 指令优化的范围，只考虑数据 Constant 且源地址寄存器不变的 Load，此时不再需要去读缓存来验证正确性，同时也省去了地址的重复计算（Load Value Prediction 中，因为没有跟踪寄存器的变化，所以预测时，还是需要重新计算地址，去查询缓存或者 Constant Verification Unit）。</p><blockquote><p>感觉挺难满足要求的， 对于一个pc值，又要address 相同，又要data 相同 ，如果置信度够高 ， 直接进行数据复制 ， 访存和地址计算都不用了 ，条件挺苛刻的</p></blockquote><h2 id=data-prefetch>data prefetch</h2><p>数据预取的目的是预测程序的访存模式，提前把数据准备到缓存当中，提升缓存的命中率。以 AMD Zen 5 为例，它实现了这些预取器（来源：Processor Programming Reference (PPR) for AMD Family 1Ah Model 24h, Revision B0 Processors）：</p><ul><li>L2 Up/Down Prefetcher: uses memory access history to determine whether to fetch the next or previous line into L2 cache for all memory accesses.</li><li>L2 Stream Prefetcher: uses history of memory access patterns to fetch additional sequential lines into L2 cache.</li><li>L1 Region Prefetcher: uses memory access history to fetch additional lines into L1 cache when the data access for a given instruction tends to be followed by a consistent pattern of other accesses within a localized region.</li><li>L1 Stride Prefetcher: uses memory access history of individual instructions to fetch additional lines into L1 cache when each access is a constant distance from the previous.</li><li>L1 Stream Prefetcher: uses history of memory access patterns to fetch additional sequential lines into L1 cache.</li></ul><p>简单来说，Stream Prefetcher 就是取一段连续的 Cache Line，Stride Prefetcher 则是根据 Stride 去预取数据，未必是连续的 Cache Line，Up/Down Prefetcher 更好理解，就是取相邻的一个 Cache Line。Region Prefetcher 则比较复杂，属于 Spatial Prefetcher 的一种。</p><p>Intel 的处理器通过 MSR 1A4H 可以配置各个预取器：</p><ul><li>the L2 hardware prefetcher, which fetches additional lines of code or data into the L2 cache.</li><li>the L2 adjacent cache line prefetcher, which fetches the cache line that comprises a cache line pair (128 bytes). 这和 AMD 的 Up/Down Prefetcher 应该是一个意思</li><li>the L2 Adaptive Multipath Probability (AMP) prefetcher. 根据专利 <a class=link href=https://patents.google.com/patent/US20190138451 target=_blank rel=noopener>Systems and methods for adaptive multipath probability (amp) prefetcher</a> 的描述，这个应该属于 Spatial Prefetcher</li><li>the L1 data cache prefetcher, which fetches the next cache line into L1 data cache. 这个应该属于 Next Line Prefetcher</li><li>the L1 data cache IP prefetcher, which uses sequential load history (based on instruction pointer of previous loads) to determine whether to prefetch additional lines.</li></ul><p><a class=link href=https://www.sciencedirect.com/science/article/pii/S0065245821000784 target=_blank rel=noopener>Spatial Prefetching</a> 的思想是这样的：程序经常会访问数组，那么对数组每个元素的访问模式，应该是类似的。比如访问数组前十个元素有某种规律，那么访问接下来的十个元素应该也有类似的规律，只是地址变了而已。如果这个数组的元素的结构比较复杂，这个访存模式（例如从 0、256 和 320 三个偏移分别读取数据）可能既不满足 Stride 又不满足 Stream，此时就需要 Spatial Prefetcher 来介入。例如程序在同一个物理页内，总是会从 A、B、C 和 D 四个页内偏移读取数据，那么当程序从页内偏移 A 读取一个新的物理页的数据时，大概率新的物理页内 B、C 和 D 偏移处的数据将来会被读取，那就预取进来。</p><p>一种 Spatial Prefetcher 实现是 Spatial Memory Streaming (SMS)。它的做法是，把内存分成很多个相同大小的 Region，当缓存出现缺失时，创建一个 Region，记录这次访存指令的 PC 以及访存的地址相对 Region 的偏移，然后开始跟踪这个 Region 内哪些数据被读取了，直到这个 Region 的数据被换出 Cache，就结束记录，把信息保存下来。以上面的 0、256 和 320 为例子，访问 0 时出现缓存缺失，那就创建一个 Region，然后把 256 和 320 这两个偏移记下来。当同一条访存指令又出现缺失，并且偏移和之前一样时，根据之前保存的信息，把 Region 里曾经读过的地址预取一遍，按上面的例子，也就是 256 和 320。这里的核心是只匹配偏移而不是完整的地址，忽略了地址的高位，最后预取的时候，也是拿新的导致缓存缺失的地址去加偏移，自然而然实现了平移。从 AMD 的专利 <a class=link href=https://patentimages.storage.googleapis.com/a8/85/e2/35618e755d6ad3/US20180052779A1.pdf target=_blank rel=noopener>DATA CACHE REGION PREFETCHER</a> 来看，AMD 的 L1 Region Prefetcher 应该采用的是 SMS 的思想，缓存缺失时，创建一个 Region，记录这个 Region 中哪些数据被访问了。</p><p>另一种 Spatial Prefetcher 实现是 Variable length delta prefetcher (VLDP)，它的思路是，对访存序列求差分，即用第 k 次访存地址减去第 k-1 次访存地址，得到 Delta 序列，然后对当前的 Delta 序列，预测下一个 Delta，那么预取的地址，就是 Delta 加上最后一次访存的地址。从 Intel 的专利 <a class=link href=https://patents.google.com/patent/US20190138451 target=_blank rel=noopener>Systems and methods for adaptive multipath probability (amp) prefetcher</a> 来看，它的 AMP Prefetcher 实现思路和 VLDP 类似，专利中给出了一个例子：</p><ul><li>假如程序对某个物理页的访存模式是：0, 2, 4, 16, 15</li><li>求差分，得到：+2, +2, +12, -1</li><li>那么 AMP 预测器要做的就是：<ul><li>无历史时，预测第一个差分值：N/A -> +2</li><li>第一个差分是 +2 时，预测第二个差分值：+2 -> +2</li><li>已知前两个差分时，预测第三个差分值：+2, +2 -> +12</li><li>已知前三个差分时，预测第四个差分值：+2, +2, +12 -> -1</li></ul></li></ul><blockquote><p>sms 根据某一个物理页的访存模式去预测其他区域的 ， VLDP根据差值预测</p></blockquote><p>不过 Spatial Prefetcher 遇到动态分配的不连续的数据结构就犯了难（比如链表和树），因为数据在内存里的分布比较随机，而且还有各种指针，要访问的数据之间的偏移大概率是不同的。这时候就需要 <a class=link href=https://www.sciencedirect.com/science/article/pii/S0065245821000796 target=_blank rel=noopener>Temporal Prefetcher</a>，它的思路是跟踪缓存缺失的历史，如果发现当前缺失的地址在历史中曾经出现过，那就预取在历史中紧随其后的几次缓存缺失。比如链表节点按顺序是 A、B 和 C，第一次访问时，按照 A B C 的顺序出现缓存缺失，这些缺失被记录在历史当中；未来如果再次访问 A，预取器在历史中找到 A 的位置，发现其后的缓存缺失为 B 和 C，那就对它们进行预取。就好像预取器自己存了一份链表，提前去查后继的节点，也可以说是 Record and Replay 思想的实践。</p><h2 id=附录>附录</h2><h3 id=参考文献>参考文献</h3><p><a class=link href=https://jia.je/hardware/2022/03/31/brief-into-ooo-2/#%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE target=_blank rel=noopener>浅谈乱序执行</a></p><h3 id=版权信息>版权信息</h3><p>本文原载于 <a class=link href=https://vastcircle.github.io target=_blank rel=noopener>vastcircle.github.io</a>，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。</p></section><footer class=article-footer><section class=article-tags></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-contents--wrapper></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{DISQUS&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("//cdn.bootcss.com/pangu/3.3.0/pangu.min.js",function(){pangu.spacingPage()})</script><section class=copyright>&copy;
2023 -
2025 <a href=https://stack-theme-mod.vercel.app/>vastcircle</a>·<i class="fas fa-bell"></i> <a id=days>0</a>Days<br>共书写了290.2k字·共 82篇文章</br><span><p></section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.2.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a><br><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank>© Licensed Under CC BY-NC-SA 4.0</a></section><script>var days,number_of_days,s1="2024-10-06",s1=new Date(s1.replace(/-/g,"/"));s2=new Date,days=s2.getTime()-s1.getTime(),number_of_days=parseInt(days/(1e3*60*60*24)),document.getElementById("days").innerHTML=number_of_days</script></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><form action=/search/ class="search-form widget"><p><label>Search</label>
<input name=keyword required placeholder="Type something...">
<button title=Search><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></button></p></form><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#内存访问>内存访问</a></li><li><a href=#加载存储单元>加载存储单元</a></li><li><a href=#memory-dependence-predictor>Memory Dependence Predictor</a></li><li><a href=#store-to-load-forwarding>store to load forwarding</a></li><li><a href=#memory-renaming>memory renaming</a></li><li><a href=#load-address-prediction>load address prediction</a></li><li><a href=#way-prediction>way prediction</a></li><li><a href=#load-value-prediction>load value prediction</a></li><li><a href=#stable-load>stable load</a></li><li><a href=#data-prefetch>data prefetch</a></li><li><a href=#附录>附录</a><ol><li><a href=#参考文献>参考文献</a></li><li><a href=#版权信息>版权信息</a></li></ol></li></ol></nav></div></section><section class="widget categories"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-infinity" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M9.828 9.172a4 4 0 100 5.656A10 10 0 0012 12a10 10 0 012.172-2.828 4 4 0 110 5.656A10 10 0 0112 12 10 10 0 009.828 9.172"/></svg></div><h2 class="widget-title section-title">Categories</h2><div class=widget-categories--list><div class=widget><h3 class=widget-title></h3><div class=widget-body><div class=category-list><div class=category-list-item><a href=https://VastCircle.github.io/categories/a_prime_on_hardware_prefetch/ class=category-list-link>a_prime_on_hardware_prefetch<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/boom/ class=category-list-link>boom<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/boom%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/ class=category-list-link>boom代码阅读<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/cache/ class=category-list-link>cache<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/chipyard/ class=category-list-link>chipyard<span class=category-list-count>3</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/chisel/ class=category-list-link>chisel<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/cpu%E5%9F%BA%E7%A1%80/ class=category-list-link>cpu基础<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/gem5/ class=category-list-link>gem5<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/gpgpu%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/ class=category-list-link>gpgpu读书笔记<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/linux/ class=category-list-link>linux<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/riscv/ class=category-list-link>riscv<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/rocket-chip/ class=category-list-link>rocket-chip<span class=category-list-count>2</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/runahead/ class=category-list-link>runahead<span class=category-list-count>3</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/ class=category-list-link>代码阅读<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B/ class=category-list-link>分支预测<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/ class=category-list-link>博客搭建<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E5%A4%84%E7%90%86%E5%99%A8/ class=category-list-link>处理器<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/ class=category-list-link>环境搭建<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/ class=category-list-link>环境配置<span class=category-list-count>3</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/ class=category-list-link>缓存一致性<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/ class=category-list-link>论文阅读<span class=category-list-count>13</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E8%AE%BF%E5%AD%98/ class=category-list-link>访存<span class=category-list-count>1</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8/ class=category-list-link>超标量处理器<span class=category-list-count>12</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E9%A6%99%E5%B1%B1/ class=category-list-link>香山<span class=category-list-count>8</a></span></div><div class=category-list-item><a href=https://VastCircle.github.io/categories/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81/ class=category-list-link>香山源代码<span class=category-list-count>3</a></span></div></div></div></div></div></section><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-infinity" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M9.828 9.172a4 4 0 100 5.656A10 10 0 0012 12a10 10 0 012.172-2.828 4 4 0 110 5.656A10 10 0 0112 12 10 10 0 009.828 9.172"/></svg></div><h2 class="widget-title section-title">Archives</h2><div class=widget-archive--list><div class=archives-year><a href=/archives/#2025><span class=year>2025</span>
<span class=count>35</span></a></div><div class=archives-year><a href=/archives/#2024><span class=year>2024</span>
<span class=count>47</span></a></div></div></section><section class="widget tagCloud"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg></div><h2 class="widget-title section-title">Tags</h2><div class=tagCloud-tags><a href=/tags/runahead/ class=font_size_6>Runahead
</a><a href=/tags/prefetch/ class=font_size_3>Prefetch
</a><a href=/tags/vector/ class=font_size_3>Vector
</a><a href=/tags/cache/ class=font_size_2>Cache
</a><a href=/tags/chipyard/ class=font_size_2>Chipyard
</a><a href=/tags/diplomacy/ class=font_size_2>Diplomacy
</a><a href=/tags/in-order/ class=font_size_2>In-Order
</a><a href=/tags/rocket-chip/ class=font_size_2>Rocket-Chip
</a><a href=/tags/%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B/ class=font_size_2>分支预测
</a><a href=/tags/%E5%AF%84%E5%AD%98%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D/ class=font_size_2>寄存器重命名</a></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>