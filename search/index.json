[{"content":" image-20250320140942894 函数 free_area_init\n对应上面的for循环 ， 其他函数都是已经标示出来的\n再后面就是printk 了 ， 没有成功输出\n","date":"2025-03-20T14:06:30+08:00","permalink":"https://VastCircle.github.io/2025/%E5%8A%A0%E9%80%9F%E5%99%A8debug_linuboot/","title":"加速器debug_linuboot"},{"content":" 复制相应的基础文件到新的目录 cp -r minor derminor 替换所有的minor 为 dvrminor for file in *; do perl -pe s/minor/devminor/g $file \u0026gt; $file.tmp; mv $file.tmp $file; done 替换所有的MinorCPU 为 DVRMinorCPU for file in *; do perl -pe s/MinorCPU/DVRMinorCPU/g $file \u0026gt; $file.tmp; mv $file.tmp $file; done 替换所有的BaseMinorCPU.py 为 DVRBaseMinorCPU for file in *; do perl -pe s/BaseMinorCPU/DVRBaseMinorCPU/g $file \u0026gt; $file.tmp; mv $file.tmp $file; done mv BaseMinorCPU.py 对BaseMinorCPU , Sconscript 的 Minor 进行了全局替换 在RiscvCPU.py 里加入 以下代码 from m5.objects.BaseDVRMinorCPU import BaseDVRMinorCPU class RiscvDVRMinorCPU(BaseDVRMinorCPU,RiscvCPU) mmu = RiscvMMU() 把debug的每一个都做了修改 附录 https://richardustc.github.io/2013-05-21-2013-05-21-add-new-cpu-model-for-gem5.html\n参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-20T10:22:53+08:00","permalink":"https://VastCircle.github.io/2025/gem5%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84cpu_model/","title":"Gem5创建一个新的cpu_model"},{"content":"函数模板 template \u0026lt;typename type\u0026gt; ret-type func-name(parameter list){} template \u0026lt;typename T\u0026gt; inline T const\u0026amp; Max (T const\u0026amp; a, T const\u0026amp; b) { return a \u0026lt; b ? b:a; } template \u0026lt;class type\u0026gt; class class-name { } template \u0026lt;class T\u0026gt; class Stack { public: Stack(); ~Stack(); void push(T t); T pop(); bool isEmpty(); private: T *m_pT; int m_maxSize; int m_size; }; template \u0026lt;class T\u0026gt; Stack\u0026lt;T\u0026gt;::Stack(){ m_maxSize = 100; m_size = 0; m_pT = new T[m_maxSize]; } 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-19T17:10:31+08:00","permalink":"https://VastCircle.github.io/2025/c-_template/","title":"C++_template"},{"content":" 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-16T15:06:36+08:00","permalink":"https://VastCircle.github.io/2025/%E5%88%86%E4%BA%AB%E4%BC%9A/","title":"分享会"},{"content":"C++多态(polymorphism)是通过虚函数来实现的，虚函数允许子类重新定义成员函数，而子类重新定义父类的做法称为覆盖(override)，或者称为重写。\n可以使用基类的指针指向一个子类的对象 ，调用虚函数进行动态绑定 。\nc++ 即使不加override 在子类定义相同的方法也可以直接覆盖基类 , 虚函数主要是有需要通过基类的指针指向子类的需求 ，如果不是虚函数的话就是基类的值，但是虚函数的话可以输出子类的值\n虚函数的作用是允许在派生类中重新定义与基类同名的函数，并且可以通过基类指针或引用来访问基类和派生类中的同名函数。\n虚函数是C++中用于实现多态的机制。核心理念就是通过基类访问派生类定义的函数。如果父类或者祖先类中函数func()为虚函数，则子类及后代类中，函数func()是否加virtual关键字，都将是虚函数。为了提高程序的可读性，建议后代中虚函数都加上virtual关键字。\n#include\u0026lt;iostream\u0026gt; using namespace std; class A { public: void foo() { printf(\u0026#34;1\\n\u0026#34;); } virtual void fun() { printf(\u0026#34;2\\n\u0026#34;); } }; class B : public A { public: void foo() //隐藏：派生类的函数屏蔽了与其同名的基类函数 { printf(\u0026#34;3\\n\u0026#34;); } void fun() //多态、覆盖 { printf(\u0026#34;4\\n\u0026#34;); } }; int main(void) { A a; B b; A *p = \u0026amp;a; p-\u0026gt;foo(); //输出1 p-\u0026gt;fun(); //输出2 p = \u0026amp;b; p-\u0026gt;foo(); //取决于指针类型，输出1 p-\u0026gt;fun(); //取决于对象类型，输出4，体现了多态 return 0; 纯虚函数就是 基类不定义 ， 加 = 0\n附录 参考文献 C++多态\u0026ndash;虚函数virtual 及 override\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-13T17:16:58+08:00","permalink":"https://VastCircle.github.io/2025/c-%E8%99%9A%E5%87%BD%E6%95%B0/","title":"C++虚函数"},{"content":"安装 借助了链接1的方法和链接2的文件\nhttps://www.macxin.com/archives/10419.html\nhttps://bbs.kanxue.com/thread-285118.htm\nhttps://krakenfiles.com/view/XPjC9amGSm/file.html\n具体来说就是设置host + 解压 + 破解\nhost 设置有\n0.0.0.0 licensing.scitools.com 0.0.0.0 stats.scitools.com 使用 层级关系试图 Butterfly：如果两个实体间存在关系，就显示这两个实体间的调用和被调用关系Calls\nCalls：展示从你选择的这个方法开始的整个调用链条；\nCelled by : 展示了这个实体被哪些代码调用，这个结构图是从底部向上看或者从右到左看；\nCalls Relationship/Calledby Relationship:展示了两个实体之间的调用和被调用关系，操作方法：首先右键你要选择的第一个实体，然后点击另一个你要选择的实体，如果选择错误，可以再次点击其他正确即可，然后点击ok；\nContains:展示一个实体中的层级图，也可以是一个文件，一条连接线读作”x includes y“；\n.Extended By:展示这个类被哪些类所继承，\nExtends:展示这个类继承自那个类\n结构关系视图 Graph Architecture：展示一个框架节点的结构关系；\nDeclaration:展示一个实体的结构关系，例如：展示参数，则返回类型和被调用函数，对于类，则展示私有成员变量（谁继承这个类，谁基于这个类）\nParent Declaration:展示这个实体在哪里被声明了的结构关系；\nDeclaration File:展示所选的文件中所有被定义的实体（例如函数，类型，变量，常量等）；\nDeclaration Type:展示组成类型；\nClass Declaration:展示定义类和父类的成员变量；\nData Members:展示类或者方法的组成，或者包含的类型；\nControl Flow:展示一个实体的控制流程图或者类似实体类型；\nCluster Control Flow:展示一个实体的流程图或者类似实体类型，这个比上一个更具有交互性；\nUML Class Diagram:展示这个项目中或者一个文件中定义的类以及与这个类关联的类\n附录 参考文献 高效阅读嵌入式源码系列一\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-12T15:49:05+08:00","permalink":"https://VastCircle.github.io/2025/understand%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/","title":"Understand安装及使用"},{"content":"MinorCPU --- Pipeline - container for the pipeline, owns the cyclic \u0026#39;tick\u0026#39; event mechanism and the idling (cycle skipping) mechanism. --- --- Fetch1 - instruction fetch unit responsible for fetching cache lines (or parts of lines from the I-cache interface). --- --- --- Fetch1::IcachePort - interface to the I-cache from Fetch1. --- --- Fetch2 - line to instruction decomposition. --- --- Decode - instruction to micro-op decomposition. --- --- Execute - instruction execution and data memory interface. --- --- --- LSQ - load store queue for memory ref. instructions. --- --- --- LSQ::DcachePort - interface to the D-ache from Execute. 温习修改gem5 源码的方法（创建自己的simobject) 创建一个python 文件 ， 这个py类需要继承SimObject , 其中需要声明 cxx_header 和cxx_class , from m5.params import * from m5.SimObject import SimObject class HelloObject(SimObject): type = \u0026#39;HelloObject\u0026#39; cxx_header = \u0026#34;learning_gem5/part2/hello_object.hh\u0026#34; cxx_class = \u0026#34;gem5::HelloObject\u0026#34; # 其它自定义参数，可以在c++端使用 time_to_wait = Param.Latency(\u0026#34;Time before firing the event\u0026#34;) foo = Param.Int(114514, \u0026#34;test\u0026#34;) 编写simObject的c++ 文件 包含头文件（cxx_header)和源文件（cxx_class) , 可以访问相应的param\nHelloObject::HelloObject(const HelloObjectParams \u0026amp;params) : SimObject(params) { std::cout \u0026lt;\u0026lt; params.foo \u0026lt;\u0026lt; std::endl; } 向编译系统注册py和c++文件 主要是通过Sconscript 来吧相应的源文件 ， py 文件都加入进来\n代码分析 以下的堆栈是到\n如果要模拟流水线的行为 ， 首先在某个周期每个流水段应该同时进行 ， 因为后一段流水会依赖前一段流水前面的状态，所以说应该先去执行后一段流水，即倒着执行 。 倒着执行的话后一段流水得到的就是前一段流水上一个周期的状态。\nexecute.evaluate(); decode.evaluate(); fetch2.evaluate(); fetch1.evaluate(); InstId 用于标识流水线和指令的信息。这包括所有执行阶段的相关序列号和线程 ID。\nfield symbol generated by checked by function threadid T fetch1 需要线程数的地方 指令或流水线所属的线程id streamseqnum S execute Fetch1、Fetch2、Execute（丢弃行/实例） Execute 选择的流序列号。流序列号在 Execue 中的 PC（分支、异常）发生变化后发生变化，用于区分分支前和分支后指令流。 predictonseqnum fetch2 fetch2(预测后丢弃行) predictonseqnum表示分支预测决策。Fetch2 会根据其最后遵循的分支预测来标记行/指令/。Fetch2 可以向 Fetch1 发出信号，告知它应更改其提取地址并使用新的预测序列号标记行（只有当 Fetch1 预期的流序列号与请求的序列号匹配时，它才会这样做） 用于标识预测的指令流,由fetch2在分支预测的影响下附加 lineseqnum fetch1 debug 该缓存行或提取该指令的行的行提取序列号。 该指令所在代码行的序列号，即从该行获取的指令的序列号 fetchseqnum fetch2 fetch2 ( 作为分支的实例序列号) 当行分解为指令时，Fetch2 指定的指令获取顺序。 对于bubbles 指令，该值为0,对于指令流，该值按递增顺序分配 execseqnum decode execute(j检查指令标示in queues / FU/LSQ) 微操作分解后的指令顺序 在micro-op分解之后，该序列号按照递增顺序分配给分解后的指令 streamSeqnum的存在就是为了在分支预测失败之后可以把整条分支预测失败的路全部都冲刷掉 ，\n每遇到一条分支 ， streamSeqnum都会进行+1 ， 然后赋值\npredictionseqnum在分支预测为跳转的时候+1\nstreamseqnum在execute 阶段检测到stream change 的时候 + 1\nfetchseqnum在得到dyninst 的时候都会+1\nMinorDynInst 该类用于 Minor 核心的动态指令（Dynamic Instruction）。 MinorDynInst 实现了 BubbleIF 接口，并维护两种不同的序列号：\nfetchSeqNum（指令获取序列号） execSeqNum（执行序列号），分别表示微操作分解前后的序列编号。 一条指令的3种形式\nThings Predicate Explanation A bubble isBubble() no instruction at all, just a space-filler A fault isFault() a fault to pass down the pipeline in an insturction’s clothing A decoded instruction MinorDynInst::isInst() 指令实际上在 Fetch2 中传递到 gem5 解码器，因此是完全解码的。MinorDynInst::staticInst 是解码后的指令形式。 MinorDynInst 主要用于 Minor 核心 的 动态指令管理，其功能包括：\n维护 流水线阶段的指令序列号（fetchSeqNum 和 execSeqNum）。 记录 指令的基本信息（ID、PC 地址、静态指令）。 处理 分支预测（目标地址、是否改变控制流）。 追踪 指令的执行状态（是否在 LSQ、功能单元索引、内存访问翻译异常）。 控制 乱序执行 和 条件执行。 记录 指令的提交延迟 和 寄存器相关信息。 主要成员变量解析 静态变量 bubbleInst： 这是一个原型 bubble 指令（气泡指令）。 必须调用 MinorDynInst::init 进行初始化。 指令基本信息 staticInst：指向该指令的静态指令对象（StaticInstPtr）。 id：指令 ID（InstId）。 traceData：该指令的执行追踪信息（trace::InstRecord*）。 pc：指令的获取（fetch）地址，存储为 PCStateBase 的智能指针。 fault：如果该指令是一个伪装成指令的错误（fault），则该变量存储该错误信息。 分支预测相关 triedToPredict： 如果该指令是控制指令或系统调用（sys call），是否尝试预测其目标地址。 predictedTaken： 该指令是否被预测为改变控制流。 如果是，则后续指令将具有更新的 predictionSeqNum。 predictedTarget： 预测的 分支目标地址（智能指针）。 执行阶段相关 fuIndex：该指令分派到的功能单元（Functional Unit, FU）索引。 inLSQ：该指令是否在 Load/Store Queue（LSQ） 中，而不是在功能单元中执行。 translationFault：如果该指令涉及 内存访问，存储翻译异常信息。 inStoreBuffer：该指令是否已发送到存储缓冲区（store buffer）。 canEarlyIssue： 是否可以乱序执行该指令。 在本模型中，仅当 内存访问指令 需要提前发射，以便填补 指令获取延迟（fetch delay） 时才会发生。 predicate： 该指令是否 满足条件执行。 memAccPredicate： 该指令的 内存访问 是否满足条件执行（仅对 load/store 指令有意义）。 数据依赖管理 instToWaitFor： 该指令依赖的最新指令的 execSeqNum（执行序列号）。 主要用于 乱序执行 依赖关系的检查，例如 内存操作（memory ops） 的 initiateAcc（初始化访问）。 流水线相关 extraCommitDelay：该指令在流水线 提交阶段 的额外延迟。 extraCommitDelayExpr：额外提交延迟的时间表达式（TimingExpr*）。 minimumCommitCycle： 指令一旦发射，extraCommitDelay 变为 最小提交周期（minimumCommitCycle）。 该值用于 计算绝对时间内的提交延迟。 寄存器相关 flatDestRegIdx： 展平后的目标寄存器索引。 这样在 清除 scoreboard（记分板）时，可以使用和标记该指令时相同的寄存器索引。 forwardlinedata ForwardLineData 用于将缓存行从 Fetch1 传递到 Fetch2。与 MinorDynInsts 一样，它们可以是气泡（ForwardLineData::isBubble()）、携带故障或可以包含由 Fetch1 获取的行（部分行）。ForwardLineData 携带的数据归从内存返回的 Packet 对象所有，并且明确进行内存管理，处理后必须删除（由 Fetch2 删除 Packet）。\nForwardLineData 类用于表示流水线前向传输的数据行（可能是完整的缓存行或其片段）。它包含地址信息、数据存储、故障标记等，支持深拷贝、数据分配和复用。以下是主要成员变量的作用： ## 基本标志 bubbleFlag：标记该数据行是否为空（气泡），默认 true，表示没有有效数据。 地址与指令信息 lineBaseAddr：该缓存行的起始字节地址，可能小于等于 pc.instAddr()。 pc：指向该行内第一条指令的 PC（程序计数器）。 fetchAddr：该数据行的具体地址。 lineWidth：该数据行的宽度，不依赖 data.size，显式指定。 ## 故障处理 fault：表示该行数据是否存在故障。如果 bubbleFlag == false，seqNums 仍然有效，但 data 无效。 ##数据与存储信息 id：数据行的唯一标识，包含线程 ID、流 ID、预测 ID 等。 line：指向存储该行数据的 uint8_t* 数组（line[0] 对应 pc.instAddr() 位置的数据）。 packet：指向该数据行所属的数据包（Packet*）。 ##构造与复制 默认构造函数 ForwardLineData() 创建一个空的数据行。 复制构造函数 ForwardLineData(const ForwardLineData \u0026amp;other) 允许深拷贝，包括 pc 克隆。 赋值运算符 operator= 进行成员变量的逐一复制，并重新分配 pc。 析构函数 ~ForwardLineData() 释放 line 指针。 ## 辅助方法 isFault()：判断该行数据是否发生故障（fault != NoFault）。 setFault(Fault fault_)：设置故障，并可能清除 bubbleFlag。 allocateLine(unsigned int width_)：为数据行分配指定宽度的存储空间。 adoptPacketData(Packet *packet)：直接使用 packet 内的数据，而不重新分配存储空间。 freeLine()：释放 line 数据，注意 line 可能被多个 ForwardLineData 实例共享。 bubble()：创建一个气泡数据行（默认无效数据）。 isBubble()：检查当前数据行是否是气泡（bubbleFlag == true）。 reportData(std::ostream \u0026amp;os) const：输出数据行的详细信息（用于调试或日志记录）。 forwardInstData ForwardInstData 的 ForwardInstData:: insts向量 中最多可包含ForwardInstData::width()指令 。此结构用于在 Fetch2、Decode 和 Execute 之间传送指令，以及在 Decode 和 Execute 中存储输入缓冲区向量。\nForwardInstData 类用于流水线级指令数据的前向传输，主要在 Fetch2、Decode 和 Execute 阶段之间传递指令。该类支持指令批处理，并包含异常处理信息。以下是其核心成员及功能： ##指令存储 insts[MAX_FORWARD_INSTS]：存储传输的指令，使用 MinorDynInstPtr 进行引用计数管理。 numInsts：当前有效指令的数量，决定 insts 数组中哪些位置包含有效指令。 ##线程信息 threadId：与这些指令关联的线程 ID。 ##构造与复制 ForwardInstData(unsigned int width = 0, ThreadID tid = InvalidThreadID)：构造指定宽度 width 和线程 ID tid 的 ForwardInstData 对象。 ForwardInstData(const ForwardInstData \u0026amp;src)：拷贝构造函数，复制 src 对象的指令数组及相关信息。 operator =(const ForwardInstData \u0026amp;src)：重载赋值运算符，仅复制 numInsts 指定的有效指令。 ## 辅助方法 width()：返回当前 ForwardInstData 对象携带的有效指令数量（即 numInsts）。 resize(unsigned int width)：调整 ForwardInstData 的指令存储大小，并用“气泡”填充。 bubbleFill()：将 insts 数组从索引 0 到 width() - 1 位置填充为“气泡”（无效指令）。 isBubble()：判断 ForwardInstData 是否为空（即所有指令都是“气泡”）。 reportData(std::ostream \u0026amp;os) const：输出当前对象的详细信息（用于调试或日志记录）。 BranchData BranchData 是一个用于在 Execute 和 Fetch1 阶段之间传递分支信息的数据结构。它主要用于处理地址流（stream）的改变，例如分支预测、中断、暂停线程等场景\n## 1. 类的核心功能 BranchData 类的主要作用是： 传递分支信息，包括分支的原因、目标地址、线程 ID 等。 判断分支是否是流改变（isStreamChange）或真正的分支（isBranch）。 提供气泡（bubble）接口，用于表示无效或空的分支信息。 ## 2. 枚举类型 Reason Reason 枚举定义了分支的原因，分为两类： 不改变流的分支： NoBranch：无分支（气泡）。 CorrectlyPredictedBranch：正确预测的分支，仅用于传递信息。 改变流的分支： UnpredictedBranch：未预测的分支。 BranchPrediction：基于 Fetch2 的分支预测。 BadlyPredictedBranchTarget：预测的目标地址错误。 BadlyPredictedBranch：错误的分支预测（实际未分支）。 SuspendThread：暂停线程的取指。 Interrupt：中断引起的分支。 HaltFetch：停止取指（通常用于流水线排空）。 ## 3. 静态方法 isStreamChange： 判断某个 Reason 是否会导致流的改变。例如，UnpredictedBranch、BranchPrediction 等会改变流，而 NoBranch 不会。 isBranch： 判断某个 Reason 是否是一个“真正的”分支（即改变流且不是暂停或唤醒操作）。 ##4. 成员变量 reason： 分支的原因，类型为 Reason 枚举。 threadId： 与分支关联的线程 ID。如果无效，则为 InvalidThreadID。 newStreamSeqNum 和 newPredictionSeqNum： 新流的序列号和新预测的序列号，用于标识分支的目标流。 target： 分支的目标地址，类型为 std::unique_ptr\u0026lt;PCStateBase\u0026gt;，表示程序计数器（PC）状态。 inst： 导致分支的指令，类型为 MinorDynInstPtr。如果是气泡，则表示没有指令。 ## 5. 构造函数和拷贝控制 默认构造函数： 创建一个气泡（NoBranch）的 BranchData 对象。 带参构造函数： 初始化所有成员变量，包括分支原因、线程 ID、流序列号、目标地址和指令。 拷贝构造函数和赋值运算符： 支持深拷贝，特别是对 target 的拷贝。 ## 6. 气泡接口 bubble()： 返回一个表示气泡的 BranchData 对象（reason == NoBranch）。 isBubble()： 判断当前对象是否是气泡。 ## 7. 流改变和分支判断 isStreamChange()： 判断当前分支是否会导致流的改变。 isBranch()： 判断当前分支是否是一个“真正的”分支。 ## 8. 调试和报告接口 reportData()： 将分支信息输出到指定的输出流（std::ostream），用于调试或日志记录。 operator\u0026lt;\u0026lt;： 重载了 \u0026lt;\u0026lt; 运算符，用于打印 BranchData 的内容，方便调试。 fetch1::fetchRequest FetchRequests 表示 I-cache 行提取请求。它们用于 Fetch1 的内存队列，并 在遍历内存系统时被推送到Packet::senderState或从中弹出。\nFetchRequests 包含一个用于该获取访问的内存系统请求（mem/request.hh ）、一个数据包（Packet， mem/packet.hh）（如果请求到达内存）和一个可以用 TLB 源预取故障（如果有）填充的故障字段。\nFetchRequest 负责管理取指请求的队列和状态转换，涵盖从 TLB 查询到内存访问的整个过程。它继承了 BaseMMU::Translation（用于 TLB 查询）和 Packet::SenderState（用于封装成 Packet），以支持多阶段的取指请求处理。\n## 1. 主要成员变量 状态管理 FetchRequestState state：表示当前取指请求的状态，包括： NotIssued（未发出） InTranslation（正在翻译，已提交到 ITLB） Translated（翻译完成） RequestIssuing（请求已发往内存） Complete（完成，可能是成功取回指令或发生错误） 标识与指令信息 InstId id：该取指请求对应的指令 ID。 Addr pc：要取指的 PC 地址。 数据包与请求 PacketPtr packet：存储当前请求的 Packet，在内存系统返回数据后可能会被更新。 RequestPtr request：底层的请求对象，表示当前 FetchRequest 的内存请求。 错误信息 Fault fault：如果取指过程中发生错误（例如缺页），会存储在这里。 关联的 Fetch1 Fetch1 \u0026amp;fetch：该请求归属于的 Fetch1 取指单元。 ## 2. 主要方法 请求管理 void makePacket()：创建用于内存事务的 Packet。 bool isComplete() const：判断该取指请求是否已完成，即 state == Complete。 bool isDiscardable() const：判断该请求是否可以丢弃，而不会影响 TLB 查询或内存访问的执行。 MMU 相关（TLB 处理） void markDelayed()：表示 TLB 响应被延迟（但不做实际处理）。 void finish(const Fault \u0026amp;fault_, const RequestPtr \u0026amp;request_, ThreadContext *tc, BaseMMU::Mode mode)： 当 ITLB 响应返回后，该方法被调用，更新 fault 和 request，然后将请求传递到下一级端口进行内存访问。 调试与日志 void reportData(std::ostream \u0026amp;os) const：输出该 FetchRequest 对象的详细信息（用于日志记录和调试）。 ## 3. 生命周期管理 构造函数 FetchRequest(Fetch1 \u0026amp;fetch_, InstId id_, Addr pc_) 初始化 fetch、id、pc，状态设为 NotIssued。 创建 Request 对象并赋值给 request。 析构函数 ~FetchRequest() 负责清理 FetchRequest 相关的资源（如 packet 和 request）。 ## 4. 取指请求处理流程 请求创建 FetchRequest 对象被创建，初始状态为 NotIssued。 TLB 查询 请求进入 ITLB，状态变为 InTranslation。 地址翻译完成 ITLB 返回结果，调用 finish() 方法，状态变为 Translated。 发送到内存 取指请求被封装成 Packet 并提交到内存，状态变为 RequestIssuing。 等待内存响应 若请求需要重试（如 IcacheNeedsRetry），则保持在队列中。 请求完成 当数据返回后，FetchRequest 被更新，状态变为 Complete，可以传递到 Fetch2 处理阶段。 pipline ------------------------------------------------------------------------------ Key: [] : inter-stage BufferBuffer ,--. | | : pipeline stage `--\u0026#39; ---\u0026gt; : forward communication \u0026lt;--- : backward communication rv : reservation information for input buffers ,------. ,------. ,------. ,-------. (from --[]-v-\u0026gt;|Fetch1|-[]-\u0026gt;|Fetch2|-[]-\u0026gt;|Decode|-[]-\u0026gt;|Execute|--\u0026gt; (to Fetch1 Execute) | | |\u0026lt;-[]-| |\u0026lt;-rv-| |\u0026lt;-rv-| | \u0026amp; Fetch2) | `------\u0026#39;\u0026lt;-rv-| | | | | | `--------------\u0026gt;| | | | | | `------\u0026#39; `------\u0026#39; `-------\u0026#39; ------------------------------------------------------------------------------ 四个流水线阶段通过MinorBuffer FIFO（buffer.hh，最终源自TimeBuffer）结构连接在一起，该结构允许对阶段间延迟进行建模。在前向相邻阶段之间有一个MinorBuffers（例如：从 Fetch1 到 Fetch2 的线路），而在 Fetch2 和 Fetch1 之间，在后向有一个缓冲区，用于承载分支预测。\nFetch2、Decode 和 Execute 阶段具有输入缓冲区，每个周期都可以接受来自上一阶段的输入数据，如果该阶段尚未准备好处理该数据，则可以保留该数据。输入缓冲区以与接收时相同的形式存储数据，因此 Decode 和 Execute 的输入缓冲区包含来自其前一阶段的输出指令向量（ForwardInstData( pipe_data.hh )），其中指令和气泡位于与单个缓冲区条目相同的位置。\n阶段输入缓冲区为其前一阶段提供了一个可保留（buffer.hh）接口，以允许在其输入缓冲区中保留插槽，并向后传达其输入缓冲区占用情况，以允许前一阶段计划是否应该在给定的周期内进行输出。\nEvent handling: MinorActivityRecorder Minor 本质上是一个可循环调用的模型，具有根据管道活动跳过循环的能力。外部事件主要由回调接收（例如Fetch1::IcachePort::recvTimingResp），并导致管道被唤醒以服务推进请求队列。\nTicked (sim/ticked.hh) 是一个基类，它将评估成员函数和提供的SimObject结合在一起。它提供了一个Ticked::start /stop接口来启动和暂停定期发出的时钟事件。Pipeline 是 Ticked 的派生类。\n在评估调用期间(evaluate call)，阶段可以通过调用MinorCPU::activityRecorder -\u0026gt;activity()（针对不可调用的相关活动）或 MinorCPU::wakeupOnEvent() （用于阶段回调相关的‘唤醒’活动）。\nPipeline::evaluate包含对每个单元进行评估的调用以及对管道空闲的测试，如果没有单元发出信号表示它可能在下一个周期变为活动状态，则可以关闭时钟滴答。\n在管道 ( pipeline.hh) 中，阶段以相反的顺序进行评估（因此 ::evaluate 也将以相反的顺序进行评估），并且它们的反向数据可以在每个周期写入后立即读取，从而使输出决策“完美”（允许同步停止整个管道）。从 Fetch2 到 Fetch1 的分支预测也可以在 0 个周期内传输，从而使 fetch1ToFetch2BackwardDelay 成为唯一可以设置为低至 0 个周期的可配置延迟。\n可以调用MinorCPU ::activateContext和MinorCPU::suspendContext接口来启动和暂停线程（MT 意义上的线程）以及启动和暂停管道。执行指令可以调用此接口（间接通过 ThreadContext）来闲置 CPU/其线程。\ncpu.cc MinorCPU 是一个顺序执行（in-order）的 CPU 模型，包含四个固定的流水线阶段： Fetch1：从内存取指令行 Fetch2：将指令行分解为宏操作（macro-ops） Decode：将宏操作进一步分解为微操作（micro-ops） Execute：执行微操作 整个流水线由 minor::Pipeline 进行管理，MinorCPU 继承自 BaseCPU，但它本身不直接持有 exec_context，而是由 minor::ExecContext 负责维护执行上下文。 ## 1. 主要成员变量 ## pipeline minor::Pipeline *pipeline：管理 CPU 的流水线，协调四个阶段的执行。 minor::MinorActivityRecorder *activityRecorder：记录流水线的活动状态，CPU 通过它管理空闲行为。 ## 线程管理 std::vector\u0026lt;minor::MinorThread *\u0026gt; threads：存储 CPU 运行的线程，每个线程都有自己的 ThreadContext。 enums::ThreadPolicy threadPolicy：线程调度策略，如 RoundRobin（轮询调度）、Random（随机调度）等。 ## 端口 MinorCPUPort：MinorCPU 的请求端口基类，由 Fetch1 和 Execute 创建派生类用于指令/数据访问。 Port \u0026amp;getDataPort() override：获取数据端口的引用。 Port \u0026amp;getInstPort() override：获取指令端口的引用。 ## 调度与随机数生成 Random::RandomPtr rng = Random::genRandom();：用于生成随机数（如随机调度线程）。 std::vector\u0026lt;ThreadID\u0026gt; roundRobinPriority(ThreadID priority)：基于轮询方式生成线程优先级队列。 std::vector\u0026lt;ThreadID\u0026gt; randomPriority()：基于随机方式生成线程优先级队列。 ## 模拟相关 minor::MinorStats stats：存储 CPU 的统计信息。 Counter totalInsts() const override;：返回指令执行总数。 Counter totalOps() const override;：返回操作数总数。 void tick()：更新 CPU 的周期计数，流水线的时钟管理由 Pipeline 处理。 ## 2. 主要方法 （1）初始化 \u0026amp; 状态管理 void init() override;：CPU 初始化。 void startup() override;：CPU 启动时调用。 void wakeup(ThreadID tid) override;：激活指定线程。 （2）线程控制 void activateContext(ThreadID thread_id) override;：激活指定线程。 void suspendContext(ThreadID thread_id) override;：暂停指定线程。 （3）序列化 void serializeThread(CheckpointOut \u0026amp;cp, ThreadID tid) const override; void unserializeThread(CheckpointIn \u0026amp;cp, ThreadID tid) override; void serialize(CheckpointOut \u0026amp;cp) const override; void unserialize(CheckpointIn \u0026amp;cp) override; （4）切换 CPU 上下文 void switchOut() override;：CPU 切换出当前状态。 void takeOverFrom(BaseCPU *old_cpu) override;：从 old_cpu 继承状态。 （5）流水线控制 DrainState drain() override;：CPU 进入 drain（排空）状态。 void drainResume() override;：恢复 CPU 运行状态。 void signalDrainDone();：通知 Pipeline 触发 drain 完成事件。 void wakeupOnEvent(unsigned int stage_id);：当流水线阶段因事件重新激活时调用。 ## 3. 执行流程 初始化 MinorCPU 通过 init() 和 startup() 进行初始化，创建 Pipeline 并设置活动记录器。 线程状态 threads 被创建，每个线程都有 ThreadContext。 取指 Fetch1 通过 getInstPort() 访问指令存储器，从 ITLB 进行地址翻译。 指令行被 Fetch2 解析成宏操作，进入 Decode 阶段。 解码 Decode 将宏操作拆分为微操作（micro-ops），推送到 Execute。 执行 Execute 执行微操作，可能涉及访存（getDataPort()）。 若发生访存重试，则 Pipeline 处理重试逻辑。 线程调度 采用 roundRobinPriority() 或 randomPriority() 选择下一个线程执行。 流水线控制 wakeupOnEvent(stage_id)：当某个流水线阶段因事件重新激活时触发。 signalDrainDone()：在 DrainState 变为 Complete 时通知 Pipeline。 4. 关键特性 顺序执行 固定四级流水线，确保执行顺序严格按照 取指 -\u0026gt; 译码 -\u0026gt; 执行 的顺序进行。 线程调度 支持 Round Robin 和 Random 调度策略，适用于多线程环境。 可扩展流水线 采用 minor::Pipeline 进行流水线管理，可在 Fetch1、Fetch2、Decode 和 Execute 之间添加自定义处理逻辑。 支持 Checkpoint 通过 serialize() 和 unserialize() 进行状态快照存储和恢复。 fetch1 Fetch1负责从 I-cache 中获取缓存行或部分缓存行，并将它们传递给Fetch2以分解为指令。它可以从 Execute和 Fetch2接收“流更改”指示，以发出信号指示它应更改其内部获取地址，并使用新的流或预测序列号标记新获取的行。当 Execute 和 Fetch2同时发出流更改信号时，Fetch1将接受 Execute的更改。\nFetch1发出的每一行都会带有唯一的行序列号，可用于调试流变化。\n从 I-cache 提取数据时，Fetch1 会请求从当前提取地址 (Fetch1::pc) 到参数 fetch1LineSnapWidth 中设置的“数据快照”大小末尾的数据。后续的自主行提取将在快照边界提取整行，大小为 fetch1LineWidth。\nFetch1仅在Fetch2输入缓冲区中预留空间时才会启动内存提取。该输入缓冲区为系统提供提取队列/LFL。\nFetch1 包含两个队列：请求和传输，用于处理转换行提取地址（通过 TLB）的阶段以及适应对内存的提取请求/响应。\n一旦通过调用 itb-\u0026gt;translateTiming 将来自Fetch1的获取请求发送到 ITLB，它们就会作为新分配的 FetchRequest 对象推送到请求队列中。\nTLB 的响应将请求从请求队列移至传输队列。如果每个队列中有多个条目，则可能会获得不在请求队列头部的请求的 TLB 响应。在这种情况下，TLB 响应在请求对象中被标记为状态更改为已翻译，而将请求推进到传输（和内存系统）则留给对Fetch1::stepQueues 的调用 ，该调用在收到任何事件后的循环中调用。\nFetch1::tryToSendToTransfers — 布局：文档标题：执行基础文档：gem5 文档父级：cpu_models 永久链接：/documentation/general_docs/cpu_models/execution_basics —\n负责在两个队列之间移动请求并将请求发送到内存。失败的 TLB 查找（预取中止）将继续占用队列中的空间，直到它们在传输的开头被恢复。\n来自内存的响应将请求对象状态更改为“Complete”，并且 Fetch1::evaluate 可以获取响应数据，将其打包在ForwardLineData对象中，并将其转发到Fetch2的输入缓冲区。\n由于Fetch2::inputBuffer中始终保留空间，将输入缓冲区的大小设置为 1 会导致非预取行为。\n当发生流的改变时，已翻译的请求队列成员和已完成的传输队列成员可以被无条件丢弃，为新的传输让路。\nfetch1::evaluate 功能： 这是 Fetch1 阶段的核心函数，负责处理分支信息、取指操作以及缓存队列的管理。 根据来自 Execute 和 Fetch2 的分支信息调整指令流。 在未达到取指限制时，选择一个线程进行取指操作。 处理缓存队列中的请求，并将完成的取指结果传递给下一阶段。 关键逻辑： 检查每个线程是否被阻塞。 处理来自 Execute 和 Fetch2 的分支信息，决定是否改变指令流。execute的改变优先 调用 fetchLine() 生成取指请求。 具体需要检测当前在in-flight 的请求数量是否为达到取指限制，如果未达到，调用fetchLine ,并获取nextStageReserve的一个槽位 调用 stepQueues() 处理缓存队列中的请求。 处理完成的取指请求，并将结果传递给下一阶段。具体就是先判断指令是否会被丢弃 ， 然后进行相应的处理 。 标记流水线为活动状态 fetch1::changeStream 根据分支信息更新线程的PC, streamSeqNum 和 predictionSeqnum ， 更新线程状态， 更新取指地址\nstreamSeqNum在changeStream 要么不变，要么增加 ，predictionSeqnum 可以减少\nfetch1::fetchLine 为选中的线程生成取指请求。 具体操作包括： 计算对齐的取指地址。 创建 FetchRequest 对象，表示一个取指请求。 提交地址翻译请求到 ITLB。 将请求放入 requests 队列。 每fetchLine 一次， lineSeqNum 都会 + 1 ，\n具体request 再说\nfetch1::stepQueues 功能： 推进缓存队列中的请求，处理内存系统中的取指请求。 将已翻译的请求从 requests 队列移动到 transfers 队列。 关键逻辑： 检查 requests 队列中的请求是否已完成翻译。 调用 tryToSendToTransfers() 将请求移动到 transfers 队列。 fetch1::request::isDiscardable 判断请求是否需要丢弃。 如果请求的流序列号或预测序列号与当前线程的状态不匹配，则请求属于旧的指令流，需要丢弃。 fetch1::processResponse 处理取指响应，将取指结果封装为 ForwardLineData，并传递给下一阶段（Fetch2）\nfetch1::popanddiscard 从队列中移除并释放已处理的请求 ，就是吧transfers 的第一个移除了\nfetch1::transfers transfers 队列是 Fetch1 阶段中的一个关键数据结构，用于存放已经完成地址翻译（ITLB 翻译）并准备发送到内存系统的取指请求，或者已经从内存系统返回的取指响应。\nclass FetchRequest : public BaseMMU::Translation, public Packet::SenderState { public: enum FetchRequestState { NotIssued, // 未发出 InTranslation, // 正在翻译 Translated, // 翻译完成 RequestIssuing, // 正在发出 Complete // 完成 }; FetchRequestState state; // 请求状态 InstId id; // 请求 ID PacketPtr packet; // 内存请求包 RequestPtr request; // 内存请求 Addr pc; // 取指地址 Fault fault; // 错误信息 transfers 队列的生命周期 ##（1）请求进入 transfers 队列 条件： 取指请求完成地址翻译（ITLB 翻译）。 取指请求准备好发送到内存系统。 操作： 将请求从 requests 队列移动到 transfers 队列。 ##（2）请求发送到内存系统 条件： 取指请求在 transfers 队列中。 内存系统可以接受新的请求。 操作： 将请求发送到内存系统。 ##（3）取指响应返回 条件： 内存系统返回取指响应。 操作： 将响应放入 transfers 队列。 ##（4）处理取指响应 条件： 取指响应在 transfers 队列中。 响应已完成（state == Complete）。 操作： 判断响应是否需要丢弃（如属于旧的指令流）。 如果不需要丢弃，则将取指结果传递给下一阶段（Fetch2）。 从 transfers 队列中移除已处理的响应。 fetch2 Fetch2 将 Fetch1 的一行接收到其输入缓冲区中。该缓冲区头行中的数据被迭代并分离成单独的指令，这些指令被打包成可以传递给Decode 的指令向量。如果在整个输入行或分解的指令中发现错误，则可以提前中止打包指令。\nbranch predictor Fetch2 包含分支预测机制。这是 gem5 (cpu/pred/…) 提供的分支预测器接口的包装器。\n预测找到的任何控制指令的分支。如果尝试预测某条指令，则 在该指令上设置MinorDynInst::triedToPredict标志。\n当预测分支将执行时，MinorDynInst::predictedTaken标志将被设置，MinorDynInst::predictedTarget将被设置为预测的目标 PC 值。然后，预测的分支指令将被打包到 Fetch2 的输出向量中，预测序列号将递增，并将分支传送给 Fetch1。\n在发出预测信号后，Fetch2 将丢弃其输入缓冲区内容，并拒绝任何具有与该分支相同的流序列号但具有不同预测序列号的新行。这样就可以拒绝后续顺序获取的行，而不会忽略由 Execute 的“真实”分支指示的流更改生成的新行（它将具有新的流序列号）。\nFetch1 数据包提供给 Fetch2 的程序计数器值仅在流发生变化时更新。Fetch2::havePC 指示是否将从下一个处理的输入行中获取 PC。Fetch2::havePC 是必需的，以便通过解码跟踪换行指令。\nExecute 处理的分支（以及预测会分支的指令）将生成 BranchData ( pipe_data.hh ) 数据，解释分支的结果，该数据将转发给 Fetch1 和 Fetch2。Fetch1 使用此数据更改流（并更新其流序列号和新行的地址）。Fetch2 使用它来更新分支预测器。Minor 不会将提交途中丢弃的指令的分支数据传达给分支预测器。\nBranch enum val. In Execute Fetch1 reaction Fetch2 reaction No Branch(无分支) (output bubble data) - - CorrectlyPredictedBranch（预测正确） Predicted, taken - Update BP as taken branch UnpredictedBranch（未预测的分支） Not predicted, taken and was taken New stream Update BP as taken branch BadlyPredictedBranch（预测的跳转错误） Predicted, not taken New stream to restore to old Inst. source Update BP as not taken branch BadlyPredictedBranchTarget（预测的目标地址错误） Predicted, taken, but to a different target than predicted one New stream Update BTB to new target SuspendThread（暂停取指） Hint to suspend fetch Suspend fetch for this thread (branch to next inst. as wakeup fetch addr - Interrupt（中断） Interrupt detected New stream - Fetch2 阶段的核心功能 输入： 从 Fetch1 阶段接收指令行数据（ForwardLineData）。 从 Execute 阶段接收分支信息（BranchData），用于更新分支预测器。 输出： 将分解后的指令（ForwardInstData）传递给 Decode 阶段。 将分支预测结果（BranchData）传递给 Fetch1 阶段。 主要任务： 从指令行数据中提取指令。 进行分支预测。 更新分支预测器。 管理线程的取指状态，fetchinfo fetchinfo.inputIndex 是 相对于cache line 的 偏移,\n// 102a4 // 10280 // 10 0100 // 24 // 36 , 所以偏移是36 // icache 64 Byte // 1010 0100 struct Fetch2ThreadInfo { unsigned int inputIndex = 0; // 当前处理的指令行中的偏移量 std::unique_ptr\u0026lt;PCStateBase\u0026gt; pc; // 当前线程的程序计数器（PC） bool havePC = false; // PC 是否有效 InstSeqNum lastStreamSeqNum; // 上一个指令流的序列号 InstSeqNum fetchSeqNum; // 取指序列号 InstSeqNum expectedStreamSeqNum; // 预期的指令流序列号 InstSeqNum predictionSeqNum; // 预测序列号 bool blocked = false; // 线程是否被阻塞 }; fetch2::evaluate 功能： Fetch2 阶段的核心函数，负责处理输入数据并生成输出。 逻辑： 将 Fetch1 的输入数据放入输入缓冲区。 根据 Execute 的分支信息更新分支预测器。 如果指令流改变，清空指令缓冲区inputBuffer . 如果下一阶段的输入缓冲区没有空间会阻塞线程。 从输入缓冲区中提取指令行数据，在while遍历，并将其分解为单独的指令。如果发生fault 之类的，可能需要把整行丢了，然后结束遍历 控制是否pipline activate fetch2::updateBranchPrediction 它的主要作用是处理来自 Execute 的分支反馈（如分支是否被正确预测、分支目标是否正确等），并根据这些反馈调整分支预测器的状态，以提高未来分支预测的准确性。\n在未预测分支，正确预测分支，错误预测分支 ， 错误预测分支目标的时候都会去更新分支预测器。\nbranchPredictor.squash()\nbranchPredictor.update(),\n在 Minor CPU 中，stash 操作用于在分支指令的取指（Fetch）或译码（Decode）阶段临时存储分支预测的结果和相关上下文信息。这些信息会被保存到分支预测历史记录（predHist）中，以便在后续阶段使用。\n在 Minor CPU 中，update 操作用于在分支指令的提交（Commit）阶段根据实际执行结果更新分支预测器的状态。它的主要目的是修正预测器的内部状态，使其能够学习历史分支行为，从而提高未来的预测准确性。\nbpu::squash // 现在我们知道某个分支预测错误了，我们需要撤销从该分支之后的所有已见分支， // 并修复所有相关状态。 // 注意：这个函数可能在两种场景下被调用： // (1) 当一个分支执行后，它会更新其在 ROB（重排序缓冲区）中的状态。 // 提交阶段会检查 ROB 的更新，并向取指阶段发送信号， // 以清除该错误预测分支之后的历史记录。 // (2) 在译码阶段，你可以提前发现一个无条件 PC 相对分支是否被错误预测。 // 如果是，则向取指阶段发送信号，以清除该错误预测分支之后的历史记录。 目的：\n处理分支预测错误的情况。 清除错误的分支预测历史。 更新分支预测器的状态。 输入参数：\nsquashed_sn：被错误预测的分支的序列号（InstSeqNum）。 corr_target：正确的分支目标地址（PCStateBase）。 actually_taken：分支是否实际跳转（bool）。 tid：线程 ID（ThreadID）。 from_commit：是否来自提交阶段（bool）。 squash(squashed_sn, tid)：\n清除序列号大于 squashed_sn 的所有分支预测历史。 确保分支预测器恢复到错误预测之前的状态。 关键点：\n通过 squash(squashed_sn, tid) 清除错误的分支预测历史。 通过 update() 更新分支预测器的状态。 通过 iPred-\u0026gt;update() 更新间接分支预测器。 通过 ras-\u0026gt;pop() 和 ras-\u0026gt;push() 更新返回地址栈（RAS）。 通过 btb-\u0026gt;update() 更新分支目标缓冲器（BTB）。 通过 BPredUnit::squash，分支预测单元能够动态调整其状态，确保在分支预测错误时能够快速恢复，并提高未来分支预测的准确性。\nbpu::update 略\nfetch2::predictbranch 负责预测分支指令的行为（是否跳转、目标地址等），并更新相关的状态信息。\n如果是分支指令，调用分支预测器得到相应的结果，如果预测为跳转的话生成新的BranchData , 此时predictionSeqNum 会+1\ndecode 解码从Fetch2（通过其输入缓冲区）获取指令向量并将这些指令分解为微操作（如有必要）并将它们打包到其输出指令向量中。类型都是forwardInstData , 但是\n参数executeInputWidth设置每个周期可以打包到输出中的指令数量。如果参数decodeCycleInput为真，则 Decode可以尝试在每个周期从其输入缓冲区中的多个条目中获取指令。\n它会去更新 forwardInst 的 execSeqNum\n同样，也需要去更新流水线的状态\nExecute 输入从Decode 接收的指令流 ForwardInstData\n输出向Fetch1 发送的分支信息 BranchData , 负责指令流的更新\nExecute 提供所有指令执行和内存访问机制。通过 Execute 的指令通道可能需要多个周期，其精确时间由功能单元管道 FIFO 建模。\n指令向量（可能包括错误“指令”）由解码提供给执行，并可在执行输入缓冲区中排队后再发出。设置参数executeCycleInput允许执行检查多个输入缓冲区条目（多个指令向量）。可以使用executeInputWidth设置输入向量中的指令数量，可以使用参数executeInputBufferSize设置输入缓冲区的深度。\n将输入推送到inputbUffer 设置对输入输出数据slot 和分支slot的 step dcache 的接口队列 如果有中断，执行中断 否则，提交指令 ， issue 新的指令 advance 功能module pipline reactivate execute if the unit is still active 如果数据没有全部使用，则commit the push to the input Buffer execute\n输入/输出端口： inp：接收来自 Decode 阶段的指令数据。 out：发送分支信息到 Fetch1 阶段。 功能单元（FU）： funcUnits：功能单元池，每个 FU 处理特定操作类（如 ALU、FPU）。 noCostFUIndex：标记无成本指令（如 NOP）的虚拟 FU 索引。 访存队列（LSQ）： lsq：管理 Load/Store 请求，处理内存访问和缓存交互。 记分牌（Scoreboard）： scoreboard：跟踪寄存器的写后读（RAW）依赖，确保指令按序发射。 线程状态： executeInfo：每个线程的状态信息，包括飞行中的指令队列（inFlightInsts）和访存指令队列（inFUMemInsts） executeInfo 的关键成员 inFlightInsts：未提交的指令队列，按执行顺序排列。 inFUMemInsts：功能单元中待处理的访存指令队列。 drainState：流水线排空状态（如正常、排空当前指令、暂停取指等） 3. 指令发射（issue 函数） 3.1 发射流程 获取输入指令：从输入缓冲区（inputBuffer）中取出待发射指令。 检查线程状态：若线程挂起或指令流序号不匹配，则丢弃指令。 选择功能单元： 遍历所有 FU，寻找支持当前指令操作类（OpClass）的单元。 检查 FU 是否空闲且无结构冒险。 依赖检查：调用 scoreboard.canInstIssue 检查源寄存器是否就绪。 发射指令： 无成本指令：直接标记为完成，更新记分牌。 访存指令：推入 inFUMemInsts 队列，等待 LSQ 处理。 常规指令：推入 FU 管道，记录预计完成周期。 4. 指令提交（commit 函数） 4.1 提交流程 处理访存响应：从 LSQ 获取完成的 Load/Store 响应，更新寄存器或内存状态。 提交非访存指令： 检查 FU 头部指令是否与 inFlightInsts 队列头部一致。 执行指令（如 ALU 操作），更新 CPU 状态（寄存器、PC）。 处理异常：若指令执行中发生异常（如页错误），触发中断处理。 更新记分牌：清除已提交指令的依赖标记（clearInstDests）。 4.2 关键逻辑 访存指令提交：需等待 LSQ 响应，确保数据返回后才提交。 内存屏障：确保屏障后的指令按序执行，更新 LSQ 状态。 中断处理：若检测到中断，暂停当前指令流，更新分支信息。 6. 流水线排空（Drain） 6.1 排空状态机 NotDraining：正常执行。 DrainCurrentInst：排空当前宏指令的所有微指令。 DrainHaltFetch：停止取指，等待飞行中的指令完成。 DrainAllInsts：丢弃所有未提交指令，准备关闭流水线。 6.2 排空逻辑 drain()：触发排空流程，设置线程状态为 DrainCurrentInst 或 DrainHaltFetch。 isDrained()：检查 LSQ 和指令队列是否为空，确认排空完成。 commit 通过检查 Execute::inFlightInsts 队列的头部（该队列标有发出指令的功能单元编号）来提交指令。然后，可以在其功能单元中找到的指令将被执行并从 Execute::inFlightInsts 中弹出。\n内存操作指令被提交到内存队列（如上所述）并退出其功能单元管道，但不会从 Execute::inFlightInsts 队列中弹出。Execute::inFUMemInsts 队列在内存操作通过功能单元时为其提供排序（保持发出顺序）。进入 LSQ 时，指令会从 Execute::inFUMemInsts 中弹出。\n如果设置了参数 executeAllowEarlyMemoryIssue，内存操作可以在到达 Execute::inFlightInsts 的头部之前但满足其依赖关系之后从其 FU 发送到 LSQ。MinorDynInst ::instToWaitFor 标记了内存操作进入 LSQ 所需提交的最新依赖指令 execSeqNum。\n一旦内存响应可用（通过测试 Execute::inFlightInsts 的头部与LSQ::findResponse），提交将处理该响应（ExecuteContext::completeAcc）并从 Execute::inFlightInsts 中弹出指令。\n任何分支、故障或中断都会导致流序列号发生变化，并向 Fetch1/Fetch2 发出分支信号。只有具有当前流序列号的指令才会被发出和/或提交。\ncommit 的核心目标\n完成指令生命周期：将指令从功能单元（FU）或访存队列（LSQ）中提交，更新 CPU 状态（如寄存器、PC）。 处理依赖与冲突：通过记分牌（Scoreboard）管理寄存器依赖，确保指令按序提交。 处理异常与中断：响应指令执行中的异常（如缺页）和外部中断，更新流水线状态。 多线程调度：按策略选择线程提交指令，确保公平性和效率。 处理访存响应\nissue 发出指令涉及迭代输入缓冲区指令和功能单元的头部，以尝试按顺序发出指令。每个周期可以发出的指令数量受参数 executeIssueLimit、executeCycleInput 的设置方式、可用性的限制\n管道空间以及用于选择可以发出指令的管道的策略。\n目前，唯一的问题策略是严格按照给定的顺序循环访问每个管道。为了获得更大的灵活性，需要制定更好的（和更具体的）策略。\n内存操作指令遍历其功能单元以执行其 EA 计算。在“提交”时，执行ExecContext ::initiateAcc 执行阶段，并向[LSQ发出任何内存访问（通过 ExecContext::{read,write}Mem 调用LSQ::pushRequest）。\n请注意，故障的发出就像指令一样，并且（当前）可以发送给任何功能单元。\n每条发出的指令也被推送到 Execute::inFlightInsts 队列中。内存引用指令被推送到 Execute::inFUMemInsts 队列中。\nissue 的时候会去更新inFlightInst , 和scoreboard\nisNoConstInst , 可以issue\nfu不可用或者满\nfu 阻塞\n!fu-\u0026gt;canInsert()\nscoreboard 依赖未解决\n遍历function unit 找个一个有效的去issue , 然后inflight inst 和 inFUMemInsts（如果是访存指令） 都会增加\n相应的指令也会推送到fu的queue去\nscoreboard 记分板 ( Scoreboard ) 用于控制指令的发出。它包含将写入每个通用 CPU 整数或浮点寄存器的运行中指令的数量。只有当记分板包含 0 条将写入指令源寄存器之一的指令时，才会发出指令。\n一旦发出指令，指令的每个目标寄存器的记分板计数将会增加。\n通过将发出的 FU 的长度添加到当前时间，在记分板上标记指令结果的预计交付时间。每个 FU 上的计时参数提供了用于计算交付时间的附加规则列表。这些记录在 MinorCPU.py 中的参数注释中。\n在提交时（对于内存操作、内存响应提交），指令源寄存器的记分板计数器将减少。将减少。\nstd::vector\u0026lt;Index\u0026gt; numResults //个寄存器有多少条in-flight的指令没有修改 std::vector\u0026lt;Index\u0026gt; numUnpredictableResults; // 记录每个寄存器有多少条不可预测结果的指令正在修改它 fuIndices : //当前正在修改该寄存器的功能单元（FU）的索引。用于判断结果是否可以转发（Forwarding） std::vector\u0026lt;Cycles\u0026gt; returnCycle://计该寄存器的结果将在哪个周期可用。用于计算指令发射时间。 std::vector\u0026lt;InstSeqNum\u0026gt; writingInst; //最近一次修改该寄存器的指令的执行序列号（execSeqNum），用于确定依赖顺序。 bool findIndex(const RegId\u0026amp; reg, Index \u0026amp;scoreboard_index);// RegId 转换为 Scoreboard 内部索引（如整数寄存器映射到 intRegOffset + reg.index()）。 void markupInstDests(MinorDynInstPtr inst, Cycles retire_time, ThreadContext *thread_context, bool mark_unpredictable);//在指令发射时，标记其目的寄存器的依赖关系。 遍历指令的所有目的寄存器。 更新 numResults 和 numUnpredictableResults。 记录 returnCycle（预计结果可用周期）和 writingInst（最近写入指令的序列号）。 void clearInstDests(MinorDynInstPtr inst, bool clear_unpredictable); //在指令提交后，清除其目的寄存器的依赖标记。 减少 numResults 和 numUnpredictableResults，若归零则重置 returnCycle 和 writingInst InstSeqNum execSeqNumToWaitFor(MinorDynInstPtr inst, ThreadContext *thread_context);//返回当前指令需要等待的最大的 execSeqNum（即其源寄存器最近一次被修改的指令序列号） bool canInstIssue(MinorDynInstPtr inst, const std::vector\u0026lt;Cycles\u0026gt; *src_reg_relative_latencies, const std::vector\u0026lt;bool\u0026gt; *cant_forward_from_fu_indices, Cycles now, ThreadContext *thread_context); //检查指令的源寄存器是否全部就绪（无未完成依赖 所有源寄存器的 returnCycle \u0026lt;= now + 相对延迟。 无不可预测结果（numUnpredictableResults == 0） func_unit MinorOpClass 与 MinorOpClassSet 功能：描述功能单元支持的操作类（OpClass），如 IntAlu、MemRead 等。 实现： MinorOpClass 包装单个操作类，通过参数配置。 MinorOpClassSet 管理多个操作类集合，生成能力列表（capabilityList），用于快速检查功能单元是否支持某类操作 MinorFUTiming 功能：为特定指令类型提供额外的时序控制，例如调整源寄存器的依赖延迟或添加提交延迟。 关键字段： mask 和 match：通过指令的 ExtMachInst 匹配特定指令。 srcRegsRelativeLats：源寄存器的相对延迟（允许指令提前发射）。 extraCommitLat：指令提交时的额外延迟。 应用场景：为某类指令（如浮点乘除）设置更高的延迟。 MinorFU 功能：描述单个功能单元的基本属性。 关键参数： opClasses：支持的 OpClass 集合。 opLat：指令在 FU 中的执行延迟（周期数）。 issueLat：两次指令发射的最小间隔周期。 cantForwardFromFUIndices：禁止结果转发的 FU 索引列表。 timings：附加的时序规则（MinorFUTiming 列表）。 MinorFUPool 功能：管理多个功能单元的集合，通常在 CPU 配置中定义多个 FU 实例。 FUPipeline 功能：实现功能单元的流水线行为，继承自 SelfStallingPipeline，支持自我阻塞。 核心机制： 流水线推进：通过 advance() 方法逐步推进指令。 发射间隔控制：nextInsertCycle 记录下次允许发射的周期。 时序匹配：findTiming() 根据指令的 ExtMachInst 匹配附加时序规则。 lsu 附录 参考文献 ","date":"2025-03-11T21:20:03+08:00","permalink":"https://VastCircle.github.io/2025/gem5_minor_learning/","title":"Gem5_minor_learning"},{"content":" launch.json文件是VSCode启动程序的配置文件，着重关注以下几个参数：\nprogram：代表要运行的二进制文件（也就是你的C代码编译出来的程序）所在路径 miDebuggerPath：代表调试器（GDB）所在路径 preLaunchTask：在运行program前要做的前置任务，比如编译，task.json就是用于定义前置任务 tasks.json是前置任务的配置文件，有几个重要参数：\nlabel：指定前置任务（比如：“C/C++: gcc 生成活动文件”）名称 command：任务执行命令，一般来说执行编译命令：gcc args：用于command后面的参数，比如：-g（debug选项），-f等\n先会执行task.json 来做一些前置准备 ，\ncd options.cwd command args 然后就会执行launch.json\nfind label preLaunchTask in tasks.json\t# 在task.json定义中找到label为preLaunchTask的前置任务 bash preLaunchTask\t# 执行前置任务 cd cwd\t# 切换到用户定义的当前目录 program args\t# 执行命令 task.json 更像是在生成一些可执行文件 ， launch.json 就是运行这些文件 ，所以gdb 实际也是在launch.json 中设置的\n附录 参考文献 https://blog.csdn.net/weixin_44465434/article/details/126379978\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-10T22:18:16+08:00","permalink":"https://VastCircle.github.io/2025/vscode_task_json_and_launch_json/","title":"Vscode_task_json_and_launch_json"},{"content":"阅读gem5 o3 cpu 的相关代码\ngem5 的启动流程 gem5- c++/python co-binding 仿真前的初始化 src/sim/main.cc: importer() -\u0026gt; importInit()-\u0026gt; initAll() src/python/embedded.cc: initAll() src/sim/init.cc: initAll()-\u0026gt; pybind_init_event() src/python/pybind11/event.cc: pybind_init_event() -\u0026gt; simulate() src/sim/simulate.cc: simulate() -\u0026gt; doSimloop() -\u0026gt; serviceOne() src/sim/eventq.cc: serviceOne() -\u0026gt; eventq.hh:event-\u0026gt;process() 计算指令 Rename::tick()-\u0026gt;Rename::RenameInsts() IEW::tick()-\u0026gt;IEW::dispatchInsts() IEW::tick()-\u0026gt;InstructionQueue::scheduleReadyInsts() IEW::tick()-\u0026gt;IEW::executeInsts() IEW::tick()-\u0026gt;IEW::writebackInsts() Commit::tick()-\u0026gt;Commit::commitInsts()-\u0026gt;Commit::commitHead() 重命名（Rename::renameInsts()）。顾名思义，就是将寄存器重命名，并将指令推送到 IEW 阶段。它会检查 IQ/LSQ 是否可以容纳新指令。 Dispatch（IEW::dispatchInsts()）。此函数将重命名的指令插入到 IQ 和 LSQ 中。 调度（InstructionQueue::scheduleReadyInsts()） IQ 管理就绪列表中的就绪指令（操作数就绪），并将它们调度到可用的 FU。FU 的延迟在这里设置，当 FU 完成时，指令将被发送执行。 执行（IEW::executeInsts()）。此处execute()调用计算指令函数并将其发送至提交。请注意execute()将把结果写入目标寄存器。 Writeback( IEW::writebackInsts())。这里InstructionQueue::wakeDependents()调用。相关指令将被添加到就绪列表中以供调度。 提交（Commit::commitInsts()）。一旦指令到达ROB的头部，它将被提交并从ROB中释放。 访存指令 load 指令 加载指令与计算指令共享相同的路径直到执行。 Rename::tick()-\u0026gt;Rename::RenameInsts() IEW::tick()-\u0026gt;IEW::dispatchInsts() IEW::tick()-\u0026gt;InstructionQueue::scheduleReadyInsts() IEW::tick()-\u0026gt;IEW::executeInsts() -\u0026gt;LSQUnit::executeLoad() -\u0026gt;StaticInst::initiateAcc() -\u0026gt;LSQ::pushRequest() -\u0026gt;LSQUnit::read() -\u0026gt;LSQRequest::buildPackets() -\u0026gt;LSQRequest::sendPacketToCache() -\u0026gt;LSQUnit::checkViolation() DcachePort::recvTimingResp()-\u0026gt;LSQRequest::recvTimingResp() -\u0026gt;LSQUnit::completeDataAccess() -\u0026gt;LSQUnit::writeback() -\u0026gt;StaticInst::completeAcc() -\u0026gt;IEW::instToCommit() IEW::tick()-\u0026gt;IEW::writebackInsts() LSQUnit::executeLoad()将通过调用指令的函数来启动访问initiateAcc()。通过执行上下文接口， initiateAcc()将调用initiateMemRead()并最终定向到LSQ::pushRequest()。\nLSQ::pushRequest()将分配一个LSQRequest来跟踪所有状态，并开始转换。转换完成后，它将记录虚拟地址并调用LSQUnit::read()。\nLSQUnit::read() 将检查该负载是否与任何先前的存储有别名。\n如果可以转发，那么它将安排WritebackEvent下一个周期。 如果它是别名但不能转发，它会调用 InstructionQueue::rescheduleMemInst()和LSQReuqest::discard()。 否则，它会将数据包发送到缓存。 LSQUnit::writeback()将调用StaticInst::completeAcc()，它将把加载的值写入目标寄存器。然后该指令被推送到提交队列。IEW::writebackInsts() 然后将其标记为完成并唤醒其依赖项。从这里开始，它与计算指令共享相同的路径。\nstore 指令 IEW::tick()-\u0026gt;IEW::executeInsts() -\u0026gt;LSQUnit::executeStore() -\u0026gt;StaticInst::initiateAcc() -\u0026gt;LSQ::pushRequest() -\u0026gt;LSQUnit::write() -\u0026gt;LSQUnit::checkViolation() Commit::tick()-\u0026gt;Commit::commitInsts()-\u0026gt;Commit::commitHead() IEW::tick()-\u0026gt;LSQUnit::commitStores() IEW::tick()-\u0026gt;LSQUnit::writebackStores() -\u0026gt;LSQRequest::buildPackets() -\u0026gt;LSQRequest::sendPacketToCache() -\u0026gt;LSQUnit::storePostSend() DcachePort::recvTimingResp()-\u0026gt;LSQRequest::recvTimingResp() -\u0026gt;LSQUnit::completeDataAccess() -\u0026gt;LSQUnit::completeStore() 与LSQUnit::read()不同，LSQUnit::write()只会复制存储数据，但不会将数据包发送到缓存，因为存储尚未提交。 存储提交后，LSQUnit::commitStores()将标记 SQ 条目，以便canWB将LSQUnit::writebackStores()存储请求发送到缓存。 最后，当响应返回时，LSQUnit::completeStore()将释放 SQ 条目。 memory order fail InstructionQueue具有跟踪内存顺序依赖性的的功能MemDepUnit。如果 MemDepUnit 声明存在依赖性，IQ 将不会调度指令。\n在LSQUnit::read() 中，LSQ 将搜索可能的别名存储并转发（如果可能）。否则，将阻止加载，并通过通知 MemDepUnit 重新安排，直到阻止存储完成。\nLSQUnit::executeLoad/Store()两者都将调用LSQUnit::checkViolation() 来搜索 LQ 以查找可能的错误推测。如果发现，它将设置 LSQUnit::memDepViolator并IEW::executeInsts()稍后启动以消除错误推测的指令。\nIEW::tick()-\u0026gt;IEW::executeInsts() -\u0026gt;LSQUnit::executeLoad() -\u0026gt;StaticInst::initiateAcc() -\u0026gt;LSQUnit::checkViolation() -\u0026gt;IEW::squashDueToMemOrder() 32 54 10 32 76\n35 23 43 33 02 6\n附录 参考文献 https://www.icfgblog.com/index.php/riscv/351.html\nhttps://jianyue.tech/posts/gem5/\nhttps://blog.csdn.net/ivy_reny/article/details/54289190\ngem5 c++/python co-binding\nhttps://deep-learning.feishu.cn/wiki/YAmkwBlzkiTGlnkQQXMctS1bnse\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-10T21:38:17+08:00","permalink":"https://VastCircle.github.io/2025/gem5_o3_learning/","title":"Gem5_o3_learning"},{"content":"MP_IPDOM （来自知乎） 本文的MP_IPDOM机制在先前DWS和DPS研究的基础上，通过将SIMT Stack解耦成Warp Split Table和Warp Reconvergence Table，用前者用于tracking分化的可以并行执行的控制流，用后者用于tracking并行执行的控制流何时重新汇聚。该机制弥补了DWS和DPS不能对嵌套分化的路径并行执行的缺点：对嵌套分支路径执行并行的支持意味着更多数量的warp splits可以同时执行，根据论文实验数据显示，如果将该数量从2增大至4或者更大，可以同时运行的标量线程的数量还会有一定程度的增加。（注：无论怎样增加Fraction of running scalar threads也没有达到100%是因为T分支路径执行时间和NT分支路径耗费的执行时间不相等所致，总有一个warp split的线程需要在IPDOM处stall以实现分化线程的重汇聚。）\n本身SIMT stack 对分支做串行的操作 ， 但是 MP_IPDOM可以做并行操作 ， 即在同一时间执行不同的分支block , 但是又确保可以重新汇聚\n补充（PDOM) 对于基本块B,如果基本块D出现在所有从B到程序出口的新路径，那么D是B的PDOM , 最近的一个PDOM 就是 IPDOM\n补充（SIMT堆栈） 算法原理和实现 把per-warp SIMT Stack解耦成per-warp Split Table（ST）和per-warp Reconvergence Table（RT）两张表并按照warp split的粒度修改记分牌reserve/release/checkCollision的逻辑\nsimt stack 只能执行栈指针指向的线程 ， 但是Multi-Path IPDOM通过分成两张表，在ST表中的是可以并行进行执行的，然后再利用RT表进行重新汇聚，达到那种穿插的效果。\nPending Mask 的更新就是在某一部分分支执行完到达分支点之后，相应的1就会变成0,如果全部变成0了，代表已经聚合了，就可以把RT的表项移动到ST\n具体实现 Branch Unit 附录 参考文献 https://www.zhihu.com/question/612490213/answer/3122138352\nhttps://hackmd.io/@lzydaphne/HyMn5IcYT\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-09T20:39:08+08:00","permalink":"https://VastCircle.github.io/2025/a_scalable_multi_path_microarchitecture_for_efficient_gpu_control_flow/","title":"A_scalable_multi_path_microarchitecture_for_efficient_GPU_Control_Flow"},{"content":"一个大核，两个小核\ncore jum_unit 的返回的一些信号会接入到rob\nval gh_effective_jalr_target_reg = RegInit(0.U(xLen.W)) gh_effective_jalr_target_reg := jmp_unit.io.brinfo.jalr_target // 跳转目标 rob.io.gh_effective_rob_idx := jmp_unit.io.iresp.bits.uop.rob_idx // rob rob.io.gh_effective_valid := jmp_unit.io.iresp.valid // 是否有效 rob.io.gh_effective_jalr_target := gh_effective_jalr_target_reg rob rob\nrob共添加了4步 ，\ncan_commit 添加了\u0026amp;\u0026amp; !gh_stall 的条件\n多了一个can_commit_noGC,这个感觉像是正常的commit\n多了一个gh_stall , 衍生出了一组 can_commit , 原本的commit 变成了commit_noGC\ngh_effective_alu_out_reg , 在rob中加入了一列表项， 把 跳转指令的跳转目标保留了下来\nlsu lsu唯一增加的是这部分的代码\nval ldq_head_delay = Reg(Vec(coreWidth, UInt((2*xLen).W))) val stq_head_delay = Reg(Vec(coreWidth, UInt((2*xLen).W))) val zeros_24bits = WireInit(0.U(24.W)) // debug_wb_data 就是dcache 返回的数据 ， 所以这个就是以 data 0 addr 的形式 把sdq 和 ldq 头部的那一条指令输出出来 // ldq_head 和 stq_commit_head 都是将要commit的load 或者store for (i \u0026lt;- 0 to coreWidth - 1){ ldq_head_delay(i) := Cat(ldq(ldq_head+i.U).bits.debug_wb_data, zeros_24bits, ldq(ldq_head+i.U).bits.addr.bits) stq_head_delay(i) := Cat(stq(stq_commit_head+i.U).bits.data.bits, zeros_24bits, stq(stq_commit_head+i.U).bits.addr.bits) } for (i \u0026lt;- 0 to coreWidth - 1){ io.ldq_head(i) := ldq_head_delay(i) io.stq_head(i) := stq_head_delay(i) } front fetch-target-queue ftq是一个ram , 出入队是fifo，但是在一些情况下是需要修改表项的\n这里多加入了3组信号，两输入一输出，主要是要对输出的jal_or_jalr_target进行更新\ngh_mispredict：标记每个核心宽度（coreWidth）的指令是否发生分支预测错误。 gh_mispredict_ooo：标记乱序执行（Out-of-Order, OOO）场景下的分支预测错误。 gh_ptr：指向下一个待处理的FTQ（Fetch Target Queue）条目索引。 gh_mispredict_ooo_idx/val：记录乱序执行中需要重定向的FTQ索引和目标地址。 gh_deq_valid_delay/ptr_delay：延迟一周期后的出队有效信号和指针，用于时序同步。 for (i \u0026lt;- 0 until coreWidth) { gh_mispredict(i) := (io.brupdate.b2.mispredict) \u0026amp;\u0026amp; (io.gh_ftq_idx(i) === io.redirect.bits) \u0026amp;\u0026amp; (io.redirect.valid) // 当前指令的FTQ索引等于记录的乱序错误索引时 gh_mispredict_ooo(i) := io.gh_ftq_idx(i) === gh_mispredict_ooo_idx gh_ptr(i) := Mux(io.gh_ftq_idx(i) === (ftqSz-1).U, 0.U, io.gh_ftq_idx(i) + 1.U) } //分支预测错误：使用重定向的目标地址 io.gh_redirect_pc。 //乱序错误：使用记录的乱序目标地址 gh_mispredict_ooo_val。 //正常情况：使用FTQ中下一个条目的地址 pcs(gh_ptr(i))。 for (i \u0026lt;- 0 until coreWidth) { jal_or_jlar_target_reg(i) := MuxCase(pcs(gh_ptr(i)), Array((gh_mispredict(i) === true.B) -\u0026gt; io.gh_redirect_pc, (gh_mispredict_ooo(i) === true.B) -\u0026gt; gh_mispredict_ooo_val, ((gh_mispredict(i) === false.B) \u0026amp;\u0026amp; (gh_mispredict_ooo(i) === false.B)) -\u0026gt; pcs(gh_ptr(i)) ) ) io.jal_or_jlar_target(i) := jal_or_jlar_target_reg(i) } tile tile 里有大量的代码 ， 主要还是大量接口的互联\n包括rocc\n大核的内容基本就是这么多了\ncore 在\nR_RSU 主要就是把32个架构寄存器打包传输出去\n通过arfs_merge信号\n寄存器快照捕获：在特定事件（如异常/中断）发生时保存处理器状态 状态合并控制：协调安全模块（GHT）进行状态验证 跨时钟域处理：支持CDC（Clock Domain Crossing）场景下的安全数据传输 调试支持：提供状态追踪打印功能 标准模式：32周期完成数据传输 CDC模式：64周期（双倍同步周期）多了个分频 // 常规数据包 merge_cnt \u0026lt;= 32 | 127:64 | 63:0 | |--------|-------| | FP Reg | IntReg| // merge_cnt = 32 | 127:72 | 71:64 | 63:40 | 39:0 | |--------|-------|-------|------| | Zero | FCSR | Zero | PC | io.r_arfs(w) := Cat(rsu_master.io.arfs_index(w), rsu_master.io.arfs_merge(w)) io.r_arfs_pidx(w) := rsu_master.io.arfs_pidx(w) r_arfs : 按照格式合并的寄存器包 r_arfs_pidx arfs_index : 包的 index , 具体就是 merge_conter R_IC 多核中断控制器\n中断调度管理：协调多核系统中的中断请求分配 状态监控：跟踪各核心的执行计数器与状态 安全检查机制：集成GuardianCouncil安全框架 性能分析：提供详细的调试性能计数器 输入信号（Inputs） 信号名称 位宽 功能描述 ic_run_isax 1 启动冗余执行模式（1=启动） ic_exit_isax 1 退出冗余执行模式（1=退出） ic_syscall 1 系统调用触发信号（1=触发） ic_syscall_back 1 系统调用完成信号（1=完成） rsu_busy 1 恢复单元忙状态（1=忙，0=空闲） ic_threshold params.width_of_ic-1 指令计数阈值，当 ic_counter 达到该值时触发检查 icsl_na Vec[1]（每个核心） 各核心的“不可用”状态（1=不可用） ic_incr 3 指令计数器每次递增的步长值（例如 1 表示每次+1） if_ready_snap_shot 1 快照保存就绪信号（1=就绪） clear_ic_status Vec[1]（每个核心） 清除核心状态（1=清除对应核心的 ic_status 和 ic_counter） if_correct_process 1 当前处理流程正确性标志（1=流程正常） num_of_checker 8 当前启用的检查器数量 changing_num_of_checker 1 检查器数量正在变更（1=变更中） core_trace 1 核心跟踪调试使能（1=启用调试输出） ic_trace 1 模块内部状态跟踪调试使能（1=启用调试输出） debug_perf_reset 1 性能计数器复位（1=复位） debug_perf_sel 3 性能计数器选择信号（0-7选择不同计数器） 输出信号（Outputs） 信号名称 位宽 功能描述 crnt_target 5 当前目标核心的掩码（用于指示正在检查的核心）(ctrl , crnt_target) if_filtering 1 指令过滤使能（1=启用过滤，0=禁用） if_pipeline_stall 1 流水线暂停信号（1=暂停） if_dosnap 1 快照保存触发信号（1=触发保存） ic_counter Vec[width_of_ic] 各核心的指令计数器（记录已执行指令数） ic_status Vec[1]（每个核心） 各核心的运行状态（0=空闲，1=运行中） debug_perf_val 64 性能计数器值（根据 debug_perf_sel 选择输出不同统计项） debug_maincore_status 4 主核心状态编码（0=空闲，1=调度中，2=检查中，3=异常） shared_CP_CFG 13 共享配置信息（包含当前调度核心和掩码，用于多核协同） fsm_reset：复位所有寄存器和状态。 fsm_presch：预调度阶段，等待启动信号。ic_run_isax fsm_sch：调度阶段，选择下一个目标核心。赋值nex_target,如果不行就会一直在这个阶段调度 fsm_cooling：冷却阶段，等待资源释放。if_cooled 拉高之后，状态转变且赋值crnt_target fsm_snap：快照阶段，保存当前状态。if_dosnap 会拉高的 ，保存寄存器状态 fsm_trans：状态传输阶段，处理退出或系统调用。end信号和ctrl 信号会进行相应的变化 ， 在end 为0 ， ic_exit_isax 为1 并且 rsu_busy 为 0 的时候会将end 置为1 ，ctrl 同理会变成3 ，意思就是检测到退出信号的时候就退出调度 fsm_check：检查阶段，验证指令计数与阈值。 fsm_postcheck：后检查阶段，更新计数器并返回调度。 ctrl 的含义 值（十进制） 二进制 控制模式 功能描述 0 00 正常调度模式 默认模式，允许调度器选择新核心。 1 01 强制调度模式 忽略核心状态，强制选择下一核心（用于错误恢复或紧急任务）。 2 10 初始化/复位模式 复位阶段或未启动状态，禁止所有调度操作。 3 11 终止/退出模式 终止当前操作，触发系统复位或清理流程。 ctrl 在 初始的时候会初始化为 2 ， 在fsm_trans 会转变为 3 或者保持不变\n在 fsm_check 的时候会转变为3 or 1 or 0\nic_exit_isax -\u0026gt; 3 , is_syscall || if_t_and_na -\u0026gt; 1 , if_t_and_a -\u0026gt; 0\nctrl 控制 if_donsap 和 crnt_mask 和 state trans\nend 的含义 end 信号只有在fsm_trans 和 fsm_reset 的时候会进行改变 ，fsm_trans 在满足 条件\nMux(!end.asBool \u0026amp;\u0026amp; (ic_exit_isax_buffer.asBool || io.ic_exit_isax.asBool), Mux(!io.rsu_busy.asBool, 1.U, end), end) 会置为1 ， 在reset 的时候会返回为 0 ， 这样其实说明如果fsm_trans 赋值为1 了 ， 除非reset 了 ， end 就一直会是1 ，如果要跳转到 fsm_postcheck 状态 ， end 就一定会是1\nGHT GHT（Global History Tracker）是一个 全局历史跟踪与调度模块，主要用于多核处理器的 错误检测、冗余执行协调和状态同步。其核心功能包括：\n指令过滤与转发：筛选有效指令并转发至目标核心。 多核调度：通过调度引擎分配任务至可用核心。 错误恢复：检测分支预测错误并触发恢复机制。 调试与监控：提供性能计数器和状态信号。 模块名称：GHT（可能是 Guardian Hardware Tracker 的缩写） 关键子模块： 过滤器（GHT_FILTERS_PRFS）：过滤输入的指令和数据。 映射器（GHT_MAPPER）：将指令映射到特定的事件或规则。 调度引擎（GHT_SE）：根据规则调度事件到不同的检查器（Checker）。 输入信号（Inputs） 信号名称 功能描述 ght_mask_in 屏蔽信号（1=屏蔽当前指令流）。 ght_cfg_in 配置字（动态调整过滤、映射规则）。 core_na 各核心的“不可用”状态。 ght_inst_in 当前周期处理的指令流。 ght_pcaddr_in 指令对应的程序计数器（PC）地址。 new_commit 指令提交标志（标记指令是否完成）。 debug_bp_reset 调试计数器复位信号。 输出信号（Outputs） 信号名称 功能描述 ght_packet_out 发送至其他核心的数据包（包含指令历史或状态）。 ght_packet_dest 数据包的目标核心掩码。 core_hang_up 触发核心暂停信号（检测到错误时挂起流水线）。 debug_bp_checker 分支预测错误计数器（用于调试）。 ght_filters_ready 过滤器就绪状态（1=可接收新指令）。 GHT_FILTERS_PRFS 功能： 作为多核指令过滤器，负责并行处理多个核心的指令流，合并过滤结果并通过统一接口输出数据包。 关键组件： 多个 GHT_FILTER_PRFS 实例：每个实例处理一个核心的指令。 FIFO 缓冲区：临时存储过滤后的数据包，解决处理速度不匹配问题。 状态机（FSM）：控制数据包的加载和发送顺序，支持多核合并（rsu_merging）。 GHT_FILTER_PRFS 功能： 作为单核指令过滤器，解析指令的操作码和功能码，生成规范化数据包，并控制数据转发逻辑。 关键组件： 指令解析逻辑：提取操作码（opcode）、功能码（func）和指令类型（inst_index）。 查找表（GHT_FTABLE）：根据配置匹配指令类型，确定数据处理方式（dp_sel）。 故障注入（Fault Injection）：模拟硬件故障，用于测试或调试。 输入信号： 信号名称 位宽 方向 功能描述 ght_ft_cfg_in 32-bit 输入 配置输入，包含指令映射规则（操作码、功能码、索引和选择信号）。 ght_ft_cfg_valid 1-bit 输入 配置有效信号，高电平时写入配置。 ght_ft_inst_in 32-bit 输入 当前指令的二进制编码。 ght_ft_pc_in 32-bit 输入 当前指令的程序计数器（PC）地址。 ght_ft_newcommit_in 1-bit 输入 指令提交信号，高电平时触发处理逻辑。 ght_ft_alu_in 2*xlen 输入 ALU 计算结果，包含目标寄存器和内存操作数据。 ght_ft_is_rvc_in 1-bit 输入 标记当前指令是否为压缩指令（RVC）。 ght_prfs_rd xlen-bit 输入 物理寄存器文件（PRF）的读取数据。 ic_crnt_target 5-bit 输入 当前目标核心或线程的标识符。 gtimer 62-bit 输入 全局计时器，用于同步和故障注入。 gtimer_reset 1-bit 输入 计时器复位信号。 use_fi_mode 1-bit 输入 故障注入模式使能信号。 输出信号： 信号名称 位宽 方向 功能描述 ght_ft_inst_index 8-bit 输出 指令索引，用于标识指令类型（如加载、存储、跳转等）。 packet_out 可变 输出 规范化的数据包，包含指令信息、ALU结果或故障数据。 ght_prfs_forward_ldq 1-bit 输出 转发到加载队列（LDQ）的控制信号。 ght_prfs_forward_stq 1-bit 输出 转发到存储队列（STQ）的控制信号。 ght_prfs_forward_ftq 1-bit 输出 转发到跳转队列（FTQ）的控制信号。 ght_prfs_forward_prf 1-bit 输出 转发到物理寄存器文件（PRF）的控制信号。 输入信号 (Inputs) 信号名称 位宽 方向 功能描述 cfg_ref_inst_func 4-bit 输入 配置阶段的目标功能码（Func），用于写入内存地址的高4位。 cfg_ref_inst_opcode 7-bit 输入 配置阶段的目标操作码（Opcode），用于写入内存地址的低7位。 cfg_ref_inst_index 5-bit 输入 配置阶段的索引值，仅低2位被写入内存数据的高2位。 cfg_ref_inst_sel_d 4-bit 输入 配置阶段的选择信号，仅低3位被写入内存数据的低3位。 cfg_ref_inst_valid 1-bit 输入 配置有效信号，高电平时执行写入操作。 inst_newcommit 1-bit 输入 指令提交信号，高电平时触发查表操作。 inst_is_rvc 1-bit 输入 标记当前指令是否为压缩指令（RVC），参与生成查表地址。 inst_in_func 3-bit 输入 当前指令的功能码（Func），参与生成查表地址。 inst_in_opcode 7-bit 输入 当前指令的操作码（Opcode），参与生成查表地址。 输出信号 (Outputs) 信号名称 位宽 方向 功能描述 inst_index 5-bit 输出 查表得到的指令索引，高3位固定为0，有效位为低2位（来自内存数据的高2位）。 inst_sel_d 3-bit 输出 数据选择信号，直接取自内存数据的低3位。 就是一个sram , 把index 和 sel 合并写入 地址为 io.cfg_ref_inst_func, io.cfg_ref_inst_opcode的 sram 里去\nis_rvc 是否有用\nght_sch ght_sch_anyaviliable 信号 方向 位宽 功能描述 core_na 输入 1-bit x N 核心不可用指示信号（低有效） core_s 输入 4-bit 可调度核心起始索引 core_e 输入 4-bit 可调度核心结束索引 sch_dest 输出 4-bit 最终调度的核心索引 rst_sch 输入 1-bit 复位调度状态信号 逻辑挺简单的，就是选择在 core_s 到 core_e 之间空闲的核心，优先序号小的\nlittle LazyRocc 这个文件进行了很多的修改\nrocc补充 xd , xs1 , xs2 表示对应的寄存器是否被使用到了\nRoCC 主要通过如下接口和 CPU 进行交互：\nCPU 通过 Cmd 接口将指令和相关寄存器的值发送给 RoCC 加速器 RoCC 加速器通过 Resp 接口将计算结果（要写入的寄存器号和值）返回到 CPU RoCC 通过 busy 标记加速器是否处于忙状态 RoCC 自身也可以访问内存、引发中断等 csr 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-08T21:51:42+08:00","permalink":"https://VastCircle.github.io/2025/meek%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/","title":"MEEK代码阅读"},{"content":" 死锁，大核有锁，但需要小核心去 校验 ， 小核心需要教研， 等待大核释放锁\n最大的motivation是\n可靠性 ， npu 的可靠性没法做\n寄存器的翻译\ni\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-03-02T15:06:54+08:00","permalink":"https://VastCircle.github.io/2025/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB3.2/","title":"论文分享——3.2"},{"content":"lsu Load Store Unit class LDQEntry(implicit p: Parameters) extends BoomBundle()(p) with HasBoomUOP { val addr = Valid(UInt(coreMaxAddrBits.W)) val addr_is_virtual = Bool() // Virtual address, we got a TLB miss val addr_is_uncacheable = Bool() // Uncacheable, wait until head of ROB to execute val executed = Bool() // load sent to memory, reset by NACKs , 发送给cache val succeeded = Bool() // 成功获得cache的数据 ，包括forward及cache 返回的 val order_fail = Bool() // load-load 或者 store-load 错误 val observed = Bool() // 被cache release 的addr 会 置位 val st_dep_mask = UInt(numStqEntries.W) // list of stores older than us， 第i位为1,即stq_idx为i的store 是老于load的 val youngest_stq_idx = UInt(stqAddrSz.W) // index of the oldest store younger than us，比load 早的最新的一条store val forward_std_val = Bool() val forward_stq_idx = UInt(stqAddrSz.W) // Which store did we get the store-load forward from? val debug_wb_data = UInt(xLen.W) } class STQEntry(implicit p: Parameters) extends BoomBundle()(p) with HasBoomUOP { val addr = Valid(UInt(coreMaxAddrBits.W)) val addr_is_virtual = Bool() // Virtual address, we got a TLB miss val data = Valid(UInt(xLen.W)) val committed = Bool() // committed by ROB val succeeded = Bool() // D$ has ack\u0026#39;d this, we don\u0026#39;t need to maintain this anymore val debug_wb_data = UInt(xLen.W) } sfence sfence 是一种store barrier 写屏障 ，sfence 之后发出的任何写入指令都不会启动，直到sfence 之前发出的写入指令完成为止\n在sfence的时候，会把整个exe_req都赋值成sfence的指令\nfor (i \u0026lt;- 0 until memWidth) { when (io.core.exe(i).req.bits.sfence.valid) { exe_req := VecInit(Seq.fill(memWidth) { io.core.exe(i).req }) } } 多个fire\n// Can we fire a incoming load val can_fire_load_incoming = widthMap(w =\u0026gt; exe_req(w).valid \u0026amp;\u0026amp; exe_req(w).bits.uop.ctrl.is_load) // Can we fire an incoming store addrgen + store datagen // val can_fire_stad_incoming = widthMap(w =\u0026gt; exe_req(w).valid \u0026amp;\u0026amp; exe_req(w).bits.uop.ctrl.is_sta \u0026amp;\u0026amp; exe_req(w).bits.uop.ctrl.is_std) // Can we fire an incoming store addrgen val can_fire_sta_incoming = widthMap(w =\u0026gt; exe_req(w).valid \u0026amp;\u0026amp; exe_req(w).bits.uop.ctrl.is_sta \u0026amp;\u0026amp; !exe_req(w).bits.uop.ctrl.is_std) // Can we fire an incoming store datagen val can_fire_std_incoming = widthMap(w =\u0026gt; exe_req(w).valid \u0026amp;\u0026amp; exe_req(w).bits.uop.ctrl.is_std \u0026amp;\u0026amp; !exe_req(w).bits.uop.ctrl.is_sta) // Can we fire an incoming sfence val can_fire_sfence = widthMap(w =\u0026gt; exe_req(w).valid \u0026amp;\u0026amp; exe_req(w).bits.sfence.valid) // Can we fire a request from dcache to release a line // This needs to go through LDQ search to mark loads as dangerous val can_fire_release = widthMap(w =\u0026gt; (w == memWidth-1).B \u0026amp;\u0026amp; io.dmem.release.valid) io.dmem.release.ready := will_fire_release.reduce(_||_) // Can we retry a load that missed in the TLB val can_fire_load_retry = widthMap(w =\u0026gt; ( ldq_retry_e.valid \u0026amp;\u0026amp; ldq_retry_e.bits.addr.valid \u0026amp;\u0026amp; ldq_retry_e.bits.addr_is_virtual \u0026amp;\u0026amp; !p1_block_load_mask(ldq_retry_idx) \u0026amp;\u0026amp; !p2_block_load_mask(ldq_retry_idx) \u0026amp;\u0026amp; RegNext(dtlb.io.miss_rdy) \u0026amp;\u0026amp; !store_needs_order \u0026amp;\u0026amp; (w == memWidth-1).B \u0026amp;\u0026amp; // TODO: Is this best scheduling? !ldq_retry_e.bits.order_fail)) // Can we retry a store addrgen that missed in the TLB // - Weird edge case when sta_retry and std_incoming for same entry in same cycle. Delay this val can_fire_sta_retry = widthMap(w =\u0026gt; ( stq_retry_e.valid \u0026amp;\u0026amp; stq_retry_e.bits.addr.valid \u0026amp;\u0026amp; stq_retry_e.bits.addr_is_virtual \u0026amp;\u0026amp; (w == memWidth-1).B \u0026amp;\u0026amp; RegNext(dtlb.io.miss_rdy) \u0026amp;\u0026amp; !(widthMap(i =\u0026gt; (i != w).B \u0026amp;\u0026amp; can_fire_std_incoming(i) \u0026amp;\u0026amp; stq_incoming_idx(i) === stq_retry_idx).reduce(_||_)) )) // Can we commit a store val can_fire_store_commit = widthMap(w =\u0026gt; ( stq_commit_e.valid \u0026amp;\u0026amp; !stq_commit_e.bits.uop.is_fence \u0026amp;\u0026amp; !mem_xcpt_valid \u0026amp;\u0026amp; !stq_commit_e.bits.uop.exception \u0026amp;\u0026amp; (w == 0).B \u0026amp;\u0026amp; (stq_commit_e.bits.committed || ( stq_commit_e.bits.uop.is_amo \u0026amp;\u0026amp; stq_commit_e.bits.addr.valid \u0026amp;\u0026amp; !stq_commit_e.bits.addr_is_virtual \u0026amp;\u0026amp; stq_commit_e.bits.data.valid)))) // Can we wakeup a load that was nack\u0026#39;d val block_load_wakeup = WireInit(false.B) val can_fire_load_wakeup = widthMap(w =\u0026gt; ( ldq_wakeup_e.valid \u0026amp;\u0026amp; ldq_wakeup_e.bits.addr.valid \u0026amp;\u0026amp; !ldq_wakeup_e.bits.succeeded \u0026amp;\u0026amp; !ldq_wakeup_e.bits.addr_is_virtual \u0026amp;\u0026amp; !ldq_wakeup_e.bits.executed \u0026amp;\u0026amp; !ldq_wakeup_e.bits.order_fail \u0026amp;\u0026amp; !p1_block_load_mask(ldq_wakeup_idx) \u0026amp;\u0026amp; !p2_block_load_mask(ldq_wakeup_idx) \u0026amp;\u0026amp; !store_needs_order \u0026amp;\u0026amp; !block_load_wakeup \u0026amp;\u0026amp; (w == memWidth-1).B \u0026amp;\u0026amp; (!ldq_wakeup_e.bits.addr_is_uncacheable || (io.core.commit_load_at_rob_head \u0026amp;\u0026amp; ldq_head === ldq_wakeup_idx \u0026amp;\u0026amp; ldq_wakeup_e.bits.st_dep_mask.asUInt === 0.U)))) // Can we fire an incoming hellacache request val can_fire_hella_incoming = WireInit(widthMap(w =\u0026gt; false.B)) // This is assigned to in the hellashim ocntroller // Can we fire a hellacache request that the dcache nack\u0026#39;d val can_fire_hella_wakeup = WireInit(widthMap(w =\u0026gt; false.B)) // This is assigned to in the hellashim controller is_sta is_std是在exe阶段进行赋值的 ， is_sta \u0026amp;\u0026amp; is_std 说明 此时 addr 和 data 的值都是准备好的 ， is_sta说明此时addr是准备好的\n虽然store 指令被分成多个uop , 但是 可以根据 stq_idx来跟踪具体的load , store 指令\n3个数据来源， exe ,ldq ,stq\nload retry w = memWidth - 1\nsta_retry w = memWidth - 1\nstore_commit w = 0\nload_wakeup w = memWidth - 1\nrelease w = memWidth - 1\n选择的时候按照age , 越老的应该会越早进行 retry 等操作\n在 load incoming 和 load_retry 的时候 会进行 load queue 的赋值 ， 包括addr 的valid , 修改 vaddr 为 paddr , 写入 pdest , addr_is_virtual , uncacheable\n在 sta_incoming stad _incoming sta_retry 的时候更新 store queue , 包括addr 的valid， addr还是转化为物理地址 ， addr_is_virtual 赋值 ， 为什么这里会更新 pdst\nstq data 需要判断是浮点数还是 int , 然后选择相应的数据写入相应的store queue ,此时data.valid 会拉高 ， 浮点貌似只有在w = 0 这一路才能够输入进来\n发现br_mask需要随时通过 新的core.brupdata来更新\nload_coming , stad_coming , sta_coming , sfence , hella_incoming , load_retry , sta_retry 不会同时拉高 且按照优先级\n如果在s0周期data.valid 了 ， 第s1周期由于是把s0周期的表项进行打拍，正常来说此时data是没有valid的 ，就是说在上个周期赋值的data 是没办法clr_busy_valid的 ，错了 ， 它是在 sta_incoming 的时候判断data有没有valid,，意思就是判断data 和 addr都valid , sta_incoming 代表上一个周期已经把data写入了\ns0 在exe resp 的时候 会判断 will_incoming 等一系列的，发起tlb访问 ， 发起dcache 访问 ， 同一拍可以返回tlb 的值 ， 更新 store queue 和 load queue\n首先发起tlb的访问 ，在同一个周期返回是否tlb miss , 如果没有miss 且 uncache 的话， 发起dcache 访问\ndcache 有多个数据来源 ，\nload incoming , exe 发起的 load 请求 ， 需要查找tlb loadd retry , load queue 发起的 retry 请求 ， 需要 查找tlb store commit , load_wakeup hella_incomig hella_wakeup dcache 有一个总体的ready 信号\n位向量 s0_executing_loads 记录送到cache 执行的 load_index\nstq有一个stq_execute_head 队列指针 ， 指向需要commit 的 store\n如果exe 发起的时候 dcache 没有ready 好 ， 这个周期就无法访问dcache , 此时会怎么样 ？\n对于store , 本身就没有在incoming执行的选项，是根据execute指针进行执行的\n对于load ,在后续通过ldq_wakeup来向dcache发送req\ns1 具体需要做以下的事情\n向rob 发起 clr_bsy的信号 ， 针对store 需要store 的data 和 addr都就绪 ，此时就可以把rob_bsy给清空了 ，当然valid 还需要在当前周期，前一个周期，前两个周期都没有出现异常 （浮点数也需要另做处理，貌似浮点数只在最后一个口输出给rob）\n计算可能可以forward的 load queue index , valid , addr ， lcam_addr包含store 和 load 的addr , lcam_ldq_idx只有load 的index , 还有一个store_index ，\n设置observe位，在遍历load queue时，如果load_queue 的 addr 和 do_release 的addr block_match , 设置observe\n遍历load queue , 1.如果load没有forward_std_val (没有做forward), 2.如果load queue的数据是forward得到的，但是当周期的store指令有和这个load地址一致并且这个store要比forward的store年轻一点，说明之前forward的store是错误的. 需要 置位 ldq_order_fail , 并标记fail_load(会产生异常) 。 （store - load 违例）\n如果当前流水的load 比较老 ，load queue 对应的load 已经执行了 ， 并且load queue的load observe为1 ， 则发生了 order failure, 如果此时load queue 没有执行的话 ， 更新 s1_set_execute, 暂停cache 访问(就是直接停止访问cache)， 设置can_forward （不太懂）\n根据execute_mask表设置load queue 的 execute位 （发送给cache ）\n遍历store queue , 如果有地址和store queue地址一致的load , 需要向cache 发起kill 信号 ，并且可以设置相应的forward（因为此时从cache中取数据是错误的，可以直接forward）， addr_match 标志位 , 获取到mem_forward_valid 和 mem_forward_stq_idx(即和load 地址匹配并且最年轻的store(貌似有可能在load后面)) ， store-load 冲突 , 还有更新s1_set_execute\n更新clr_unsafe, (不过貌似这个clr_unsafe是保持为0的)\n推测唤醒 ， 只要 fire_load_incoming (向cache 发送了请求)，可以直接把目的寄存器唤醒\ns2 需要做\n在 nack_valid 了 之后， lsu 需要 re-execute this ,当 nack uses_ldq时 ， 把ldq 的executed 重新置为0 ， nacking_loading 相应位置1 ， 如果 used_store_ldq的时候，如果stq_idx 比目前的 stq_execute_head 和 stq_head 都要老的话 ， 更新 stq_execute_head , 相当于要重新commit store 了 、 ​ 在resp_valid 了 之后，如果是load, 通过core.exe.iresp 或者 fresp 返回对应的数据,后面就是写回相应的寄存器了，如果没有异常的话指令周期就结束了 ， ldq.success 会拉高 ， 如果是store , stq.successed 会拉高 ， 如果是amo指令 ， 需要返回data , uop 等值\n如果!dmem_resp_fire 并且 forward_fire , 可以做store data 的forward , 根据上一周期选择的forward_stq_idx等值 ，此时也会把load_queue的success拉高， 同时更新ldq 的 forward_std_val和 forward_stq_idx 判断ld_miss ， 上周期做了推测唤醒 ， 如果这周期发现spec_ld_succeed 为 0 的话 ， ld_miss 就为 true 了 ， 具体判断条件为 1. 上周期做了推测唤醒，2. 这周期iresp.valid 且 ldq_idx 为 上周期incoming的idx ,有一路失败了，ld_miss就为1 了 forward的store 只有 sta_incoming stda_incoming sta_retry 这3个选项（刚获得物理地址）, load 有 load_incoming , load_wakeup , load_retry 这3个选项\ndcache 的访问和 lsu 的流水线是并行的两条流水线\nload_wake 和 store commit 的特殊处理 ， 本身优先级是 load_wakeup高于 store_commit , 但是如果can_fire_store_commit了 但是一直无法will_fire_store_commit的话 ， 当累计15个周期，会 强行 block load_wakeup一个周期，让store_commit\ndcache 如果命中的话 ， s0 发起请求 tag 和 data，s1 返回tag 并比较 ， s2 周期会返回data(data返回需要两周期) 包含data 和 nack , data就是返回的一些数据 ， nack 是 s2_req ， 或者说就是把请求重新发回给 lsu , s2_send_resp 和 s2_send_nack是互斥的 ， 不能够同时为1\n每周期都需要遍历一次store表，更新表中的br_mask信息， 一旦发现br_mask 中所指的某一条分支出现分支错误，把当前条目的valid , addr.valid , data.valid 都 置为false ， 更新live_store_mask的位\n同理，每个周期都会遍历也会遍历load 表， 更新 br_mask ,如果发现分支预测错误，复位valid , addr.valid 信号\n出现mispredict 的时候，也会直接将 stq_tail 和 ldq_tail 更新为 mispredict的那一个uop 对应的值 ， 另外说一下 ， 即使不是load , store 指令 ， 也会分配对应的load_idx 和store_idx ， 确实方便\n然后就是commit , 这是和rob的交互 ， 如果 commit_valid , 并且是 uses_stq 或者 uses_ldq , 如果 commit_store , 把stq.commit 拉高 ， commit_load ， 把load的所有valid , addr.valid , executed , succeeded , order_fail , forwar_std_val 清空 ，然后更新 stq_commit_head 和 ldq_head , 逻辑很简单 ， 这里说一下就是 stq 是有3个指针的 ，包括 stq_head 和 stq_commit_head ，stq_execute_head , 但是load只有一个ldq_head, stq_commit_head会快于stq_execute_head 快于 store_head , 因为在commit了之后还需要找机会写入cache , 才能清空表项\nstq_commit_head 在 rob发起commit信号的时候 store.commit 之后后增加\nstq_execute_head 在发起dcache 访问的时候会增加\nstq_head 在commit 且 success 的时候会增加\ncommit_head \u0026gt; execute_head \u0026gt; head , 因为 commit 了之后才能发起execute , execute 成功了之后拉高success ,才能够增加stq_head\n在load-load 冲突的时候，如果loadB 经历过 cache.release且已经被执行了 , 执行loadA的时候会出现 order-fature ,\n在执行loadB的时候，发现loadA 没有执行会打断loadB的执行\nstore-load 冲突就是 order-fail\n在stq_head的指令又commit 又 successed (写入cache)之后 ， clear_store会拉高 ， 此时才清空stq_head 对应的store queue ， 另外 clear_store 还会清空 live_store_mask ， 和 load, queue 对应的 st_dep_mask 位 ， 这样load 就不会通过这条store 来forward 了\n发生异常的时候，清空所有的load queue , 把store queue 回退到 commit_head , 清空没有commit 且 successed 的 store queue , 更新live_store_mask 的相应位\n最后就是hellacache ，一个状态机\n主要实现的是和ptw的交互\ndcache clientMetadata\nstate : Dirty(有脏数据但是可读可写) , Trunk（可读可写） , Branch（可读不可写）， nothing (不可读不可写)\nprivate def growStarter(cmd: UInt): (Bool, UInt) = { import MemoryOpCategories._ import TLPermissions._ import ClientStates._ val c = categorize(cmd) // wr 11 wi 01 rd 00 Cat(is(Write),iswriteintend) MuxTLookup(Cat(c, state), (Bool(false), UInt(0)), Seq( //(effect, am now) -\u0026gt; (was a hit, next) Cat(rd, Dirty) -\u0026gt; (Bool(true), Dirty), Cat(rd, Trunk) -\u0026gt; (Bool(true), Trunk), Cat(rd, Branch) -\u0026gt; (Bool(true), Branch), Cat(wi, Dirty) -\u0026gt; (Bool(true), Dirty), Cat(wi, Trunk) -\u0026gt; (Bool(true), Trunk), Cat(wr, Dirty) -\u0026gt; (Bool(true), Dirty), Cat(wr, Trunk) -\u0026gt; (Bool(true), Dirty), //(effect, am now) -\u0026gt; (was a miss, param) Cat(rd, Nothing) -\u0026gt; (Bool(false), NtoB), Cat(wi, Branch) -\u0026gt; (Bool(false), BtoT), Cat(wi, Nothing) -\u0026gt; (Bool(false), NtoT), Cat(wr, Branch) -\u0026gt; (Bool(false), BtoT), Cat(wr, Nothing) -\u0026gt; (Bool(false), NtoT))) } s0 请求来源 lsu_req , wb_req , prober_req , prefetch_req , mshr_read_req , 主要就是赋值 s0_type , s0_valid , s0_send_resp_or_nack\n发起meta , data read ,需要在多个源中选出一个，包括 mshr.replay , mshrs_meta_read , wb_mata_read , probe_meta_read , mshrs.prefetch , lsu ,因为lsu是多路选择，所以其它源实际上只有一路是有效的\ns1\nregnext(s0_req) , 更新 br_mask(s2更新完成) ， s1_valid 需要综合考虑 是否发生分支预测错误，是否发生lsu异常（要是load异常），是否s2_store_fail ,\n获取地址 ， 是否nack (probe发起)\n只有lsu 需要对比tag 选择对比tag选择对应的路 ， 其它源可以直接获取 way_en , 得到tag_match_way\n通过replacer 得到需要替换的 way 比较tag s2\n更新 br_mask ,\n判断是否命中, 命中的条件包括 ， s2_has_permission 在读写nothing 和 写branch 的时候 为0 ， 唯一有满足permission 又会改状态的是（wr, trunk) , 会由trunk 转为Dirty ， 这样也认为是没命中吗 ， mshrs.block_hit , 命中了mshr （命中了mshr说明此时数据还不在cache中） 如果是t_replay和t_wb 就直接命中\nval s2_hit = widthMap(w =\u0026gt; (s2_tag_match(w) \u0026amp;\u0026amp; s2_has_permission(w) \u0026amp;\u0026amp; s2_hit_state(w) === s2_new_hit_state(w) \u0026amp;\u0026amp; !mshrs.io.block_hit(w)) || s2_type.isOneOf(t_replay, t_wb)) 处理lr/sc指令 ， lr/sc指令需要在sc和lr之间，没有其他指令改变lr的地址 , 所以在s2_lr的时候会记录lrsc_addr , 同时把计数器值设为最高， 如果发现sc的时候addr和lrsc_addr不一致，sc_fail\n得到相应的data (如果是lsu的话应该是所有路的data都会读取出来)，然后根据tag选择对应路的tag\n赋值s2_nack , s2_send_resp ,s2_send_nack\n// nack because of incoming probe // 翻译：因为传入的探测而否决 val s2_nack_hit = RegNext(VecInit(s1_nack)) // Nack when we hit something currently being evicted // 翻译：当我们命中当前正在被驱逐的东西时，我们会否决 val s2_nack_victim = widthMap(w =\u0026gt; s2_valid(w) \u0026amp;\u0026amp; s2_hit(w) \u0026amp;\u0026amp; mshrs.io.secondary_miss(w)) // MSHRs not ready for request val s2_nack_miss = widthMap(w =\u0026gt; s2_valid(w) \u0026amp;\u0026amp; !s2_hit(w) \u0026amp;\u0026amp; !mshrs.io.req(w).ready) // Bank conflict on data arrays val s2_nack_data = widthMap(w =\u0026gt; data.io.nacks(w)) // Can\u0026#39;t allocate MSHR for same set currently being written back val s2_nack_wb = widthMap(w =\u0026gt; s2_valid(w) \u0026amp;\u0026amp; !s2_hit(w) \u0026amp;\u0026amp; s2_wb_idx_matches(w)) s2_nack := widthMap(w =\u0026gt; (s2_nack_miss(w) || s2_nack_hit(w) || s2_nack_victim(w) || s2_nack_data(w) || s2_nack_wb(w)) \u0026amp;\u0026amp; s2_type =/= t_replay) val s2_send_resp = widthMap(w =\u0026gt; (RegNext(s1_send_resp_or_nack(w)) \u0026amp;\u0026amp; !s2_nack(w) \u0026amp;\u0026amp; (s2_hit(w) || (mshrs.io.req(w).fire \u0026amp;\u0026amp; isWrite(s2_req(w).uop.mem_cmd) \u0026amp;\u0026amp; !isRead(s2_req(w).uop.mem_cmd))))) val s2_send_nack = widthMap(w =\u0026gt; (RegNext(s1_send_resp_or_nack(w)) \u0026amp;\u0026amp; s2_nack(w))) 返回resp 和 nack 给 lsu 向mshr发送请求 ， 请求有效的条件如下 mshrs.io.req(w).valid := s2_valid(w) \u0026amp;\u0026amp; !s2_hit(w) \u0026amp;\u0026amp; !s2_nack_hit(w) \u0026amp;\u0026amp; !s2_nack_victim(w) \u0026amp;\u0026amp; !s2_nack_data(w) \u0026amp;\u0026amp; !s2_nack_wb(w) \u0026amp;\u0026amp; s2_type.isOneOf(t_lsu, t_prefetch) \u0026amp;\u0026amp; !IsKilledByBranch(io.lsu.brupdate, s2_req(w).uop) \u0026amp;\u0026amp; !(io.lsu.exception \u0026amp;\u0026amp; s2_req(w).uop.uses_ldq) \u0026amp;\u0026amp; (isPrefetch(s2_req(w).uop.mem_cmd) || isRead(s2_req(w).uop.mem_cmd) || isWrite(s2_req(w).uop.mem_cmd)) 另外，如果源是mshr,本周期也会返回meta_read的结果（实际上上周期就有结果了，需要打一拍）\n给probe 发 s3\n只对s3_req和s3_valid 进行了赋值 ， s3_valid 拉高是针对hit的store 的 向cache 行中写数据 s4 , s5 , 设置的目的是为了旁路 ， 是为s2服务的 ， 如果出现 store -\u0026gt; load , 此时还没有\n有关tilelink edge.addr_inc 用来按照节拍传输数据的\ndef firstlastHelper(bits: TLChannel, fire: Bool): (Bool, Bool, Bool, UInt) = { val beats1 = numBeats1(bits) // 数据传输的节拍数 val counter = RegInit(UInt(0, width = log2Up(maxTransfer / manager.beatBytes))) val counter1 = counter - UInt(1) val first = counter === UInt(0) // 一开始 val last = counter === UInt(1) || beats1 === UInt(0) // 只剩下最后一个节拍 val done = last \u0026amp;\u0026amp; fire // 最后一个节拍都传输完成了，或者说本周期正在传输最后一个节拍 // counter = 4 , coutner1 = 3(011) , beats1 = 6(110) ,(100) = 4 , counter = 3 , counter1(010) = 2 , count = 100 val count = (beats1 \u0026amp; ~counter1) when (fire) { counter := Mux(first, beats1, counter1) // 在counter为0的时候,下一周期赋值为beats1,之后在fire的时候-1 } (first, last, done, count) } 有关meta state 的状态 ： Dirty Trunk Nothing Branch\nshrinkHelper 根据probe param决定要变成什么状态 , probe pram 包括 toT toB toN 就是变成后面的几种状态 ， probe是降权限的， 所以不会出现升权限的\nMuxTLookup(Cat(param, state), (Bool(false), UInt(0), UInt(0)), Seq( //(wanted, am now) -\u0026gt; (hasDirtyData resp, next) Cat(toT, Dirty) -\u0026gt; (Bool(true), TtoT, Trunk), Cat(toT, Trunk) -\u0026gt; (Bool(false), TtoT, Trunk), Cat(toT, Branch) -\u0026gt; (Bool(false), BtoB, Branch), Cat(toT, Nothing) -\u0026gt; (Bool(false), NtoN, Nothing), Cat(toB, Dirty) -\u0026gt; (Bool(true), TtoB, Branch), Cat(toB, Trunk) -\u0026gt; (Bool(false), TtoB, Branch), // Policy: Don\u0026#39;t notify on clean downgrade Cat(toB, Branch) -\u0026gt; (Bool(false), BtoB, Branch), Cat(toB, Nothing) -\u0026gt; (Bool(false), NtoN, Nothing), Cat(toN, Dirty) -\u0026gt; (Bool(true), TtoN, Nothing), Cat(toN, Trunk) -\u0026gt; (Bool(false), TtoN, Nothing), // Policy: Don\u0026#39;t notify on clean downgrade Cat(toN, Branch) -\u0026gt; (Bool(false), BtoN, Nothing), // Policy: Don\u0026#39;t notify on clean downgrade Cat(toN, Nothing) -\u0026gt; (Bool(false), NtoN, Nothing))) onAccess (growStarter套壳) 确定此命令是否缺失，和新的状态（命中时）或者要发送的参数（缺失时）\nprivate def growStarter(cmd: UInt): (Bool, UInt) = { import MemoryOpCategories._ import TLPermissions._ import ClientStates._ val c = categorize(cmd) // (isWriite, isWriteIntend) MuxTLookup(Cat(c, state), (Bool(false), UInt(0)), Seq( //(effect, am now) -\u0026gt; (was a hit, next) Cat(rd, Dirty) -\u0026gt; (Bool(true), Dirty), Cat(rd, Trunk) -\u0026gt; (Bool(true), Trunk), Cat(rd, Branch) -\u0026gt; (Bool(true), Branch), Cat(wi, Dirty) -\u0026gt; (Bool(true), Dirty), Cat(wi, Trunk) -\u0026gt; (Bool(true), Trunk), Cat(wr, Dirty) -\u0026gt; (Bool(true), Dirty), Cat(wr, Trunk) -\u0026gt; (Bool(true), Dirty), //(effect, am now) -\u0026gt; (was a miss, param) Cat(rd, Nothing) -\u0026gt; (Bool(false), NtoB), Cat(wi, Branch) -\u0026gt; (Bool(false), BtoT), Cat(wi, Nothing) -\u0026gt; (Bool(false), NtoT), Cat(wr, Branch) -\u0026gt; (Bool(false), BtoT), Cat(wr, Nothing) -\u0026gt; (Bool(false), NtoT))) } onGrant (growFinisher套皮) 根据grant param 决定在miss后是什么状态\n如果是预测写，就无法转到Dirty\nprivate def growFinisher(cmd: UInt, param: UInt): UInt = { import MemoryOpCategories._ import TLPermissions._ import ClientStates._ val c = categorize(cmd) //assert(c === rd || param === toT, \u0026#34;Client was expecting trunk permissions.\u0026#34;) MuxLookup(Cat(c, param), Nothing, Seq( //(effect param) -\u0026gt; (next) Cat(rd, toB) -\u0026gt; Branch, Cat(rd, toT) -\u0026gt; Trunk, Cat(wi, toT) -\u0026gt; Trunk, Cat(wr, toT) -\u0026gt; Dirty)) } onSecondaryAccess0 /** Does a secondary miss on the block require another Acquire message */ // 翻译：块的二次缺失是否需要另一个获取消息 def onSecondaryAccess(first_cmd: UInt, second_cmd: UInt): (Bool, Bool, UInt, ClientMetadata, UInt) = { import MemoryOpCategories._ val r1 = growStarter(first_cmd) // ._1返回的是是否命中， ._2 返回的是此次操作之后的下一次状态 val r2 = growStarter(second_cmd) val needs_second_acq = isWriteIntent(second_cmd) \u0026amp;\u0026amp; !isWriteIntent(first_cmd) // 第二次是写，第一次不是写 val hit_again = r1._1 \u0026amp;\u0026amp; r2._1 // 第一次命中并且第二次命中 val dirties = categorize(second_cmd) === wr // 第二次一定要写 , is_write 一定是true val biggest_grow_param = Mux(dirties, r2._2, r1._2) // 第二次是写就选第二次 val dirtiest_state = ClientMetadata(biggest_grow_param) val dirtiest_cmd = Mux(dirties, second_cmd, first_cmd) // 第二次是写就选第二次 (needs_second_acq, hit_again, biggest_grow_param, dirtiest_state, dirtiest_cmd) } // needs_second_acq : 是否需要第二次获取消息 // hit_again , 两次访问是否都命中 // bigest_grow_param: 两次访问后缓存块的最终状态参数 // dirtiest_state: 最终确定的clientMetadata // dirtiest_cmd : 最终确定的访问命令 一些参数的意义 blockOffBits : 一个block的位宽 ， 比方说 log(64) = 6 ,\nwordBytes: coreDataBytes , 就是8Byte\nwordBits : 8 * 8 = 64 bit\ncoreDataBits: 64 bit\nrowOffBits : 4 , 一次传输的位宽 ， 128bit / 8 = 16 log (16) = 4\nrowWords : 2 , rowBits / wordBits , wordBits : 64 , 8byte , 超过64bit 需要 ， word_idx就是专门用来选择 第几个rowWord的\nrowBits: 128 , 指一个cacheline 128bit\nencDataBits : 64bit ,\nuntagBits :不是tag 的位宽， tag = addr \u0026raquo; untagBits , 12\nlgCacheBlockByres : 6\ncacheBlockBytes: 64 , 应该指的是一个cache block 是 64 Byte\nmshr // s_refill_req : 请求一个新的缓存行 // s_refill_resp : 将填充响应存储到我们的缓冲区 // s_drain_rpq_loads : 从 rpq（加载请求队列）中排出加载操作 // : 如果缺失是预测错误，则转到 s_invalid 状态 // s_wb_req : 写回被逐出的缓存行 // s_wb_resp : 完成写回被逐出的缓存行 // s_meta_write_req : 写入新缓存行的元数据 // s_meta_write_resp : 完成写入新缓存行的元数据 req 是每一个mshr 都有的，具体保存 req_index 和 req_tag,\nrpq 放的是req , 主要包含 req_addr , mem_size ,mem_signed 等 ， req 的粒度是比较大的 ， 涉及到一整个cache block 了 （比方说64Byte）， rpq 的粒度比较小，涉及到block里具体的地址\nmshr 是一个大的状态机\n在in_valid 状态 ， 如果发生了首次缺失，判断出\n在 s_refill_req状态，通过a通过发起acquireblock事件 ， 如果成功发起 跳转到s_refill_resp 状态 （从内存把数据拿回来)\n在s_refill_resp状态 ，通过lb_write转发mem_grant返回的数据,在数据接受完成之后，根据是否返回data 决定是跳转到 s_drain_rpq_loads或者 s_drain_rpq (把数据放在load queue里)\n在s_drain_rpq_loads状态，会向lb发起读请求，然后返回相应的数据通过io.resp 接口\n在meta_read状态，用req去读取meta ,成功发起读取请求之后转换到s_meta_resp_1\n在s_meta_resp_1状态 ，直接跳转到s_mrta_resp_2状态\n在s_meta_resp_2状态，如果此时meta_resp没有valid , 说明没读出来 （这个没读出来应该是由于一些外力中断了（比方说prober），不是因为没有成功握手），重新回到s_meta_read重发 ， 如果没出现前面的情况,如果发现需要写回（即有脏数据），进入s_meta_clear 状态， 反之，进入s_commit_line状态\n在s_meta_clear状态，将nothing 作为 coh 写入meta ,成功发起(fire)之后，进入wb_req\n在wb_req ，发起wb_req ,还是使用req的一些信息 ， 如果fire , 转化到 wb_resp ,如果 wb_resp ， 转化到s_commit_line\n在s_commit_line状态， 通过refill_ctr 读取 lb 连续的 内存 128 * a , 通过refill转发出去 应该总共refill了64个字节 ，refill 是把数据从lb 读取到 dcache 的data\n在s_drain_rpq状态 ， 需要和replay交互 ， 如果replay握手成功并且是store的话，更新new_coh , 如果rpq空了，转到s_meta_write_req\n在meta_write_req状态， 写入req的meta , 如果成功握手，转入s_mem_finish_1\n在s_mem_finish_1 状态，将grantack的数据转到mem_finish ,如果mem_finish_fire , 或者就没有data(grantack.valid), 转到s_mem_finish_2\n在s_mem_finish_2 状态，如果是从s_drain_rpq_loads -\u0026gt; mem_finish_1 的，转到s_prefetch , 反之转到s_invalid\n在s_prefetch状态，如果是二次缺失且命中，转到s_meta_read , 如果不是二次缺失，转到s_invalid\nmshrfile 在req.fire 并且是iswrite的时候会把数据写入store queue , sdq\nmshrs 有一个统一的存放数据的地方，就是lb , lb通过id 和 offset进行索引 ， id就是发起事件的id , offset是应该会遍历 beats , offset 的位宽就是 log2(beats)\nlb , load buffer , 内存的数量是 mshr_number * beats , 大小是 128 , 即 tilelink一次交互的数据 ，每一个mshr 都有专门的一块 lb , 大小为 128 * beats , 用 (mshr_id , offset)来寻址\nlb由mshr 进行读取和写入， 每次只能响应一个请求，所以需要仲裁\nlb_write 是把内存里的数据读出来写到lb里去 ， lb_read 有两种情况，一种是从lb中读取数据refill ,一种是从lb读数据resp 给dcache\nidx_match (w)(i) , 第w路的访问和第i个mshr 是否idx_match , 对于mshr ,只要 state =/= s_invalid 就是 idx_valid 和 tag_valid , way_valid还需要不是s_prefetch, idx_match 拉高的条件是 valid 并且 mshr的idx 要 和req 的 idx 相同\npri_val : 所有mshr中没有一个idx值是和req_idx (addr的一部分)匹配上的\nmshr 有一个 head , 会去选择一个大于head 并且 pri_rdy 的 mshr ,state === in_valid 的 mshr 是pri_rdy的， 就是没有任何数据的\nmshr的sec_val 已经是针对于特定的mshr 了，或者说需要有这个mshr使得idx_match 并且 tag_match , sec_rdy\nval sec_rdy = (!cmd_requires_second_acquire \u0026amp;\u0026amp; !io.req_is_probe \u0026amp;\u0026amp; !state.isOneOf(s_invalid, s_meta_write_req, s_mem_finish_1, s_mem_finish_2))// Always accept secondary misses 然后每一个mshr都需要连接接口 brupdate , exception , wb_resp ,meta_resp,lb_resp, 返回的数据只要直连就可以了，不需要经过仲裁，因为mshr内部会通过ready决定是不是需要这些数据， 然后从mshr 返回的接口需要通过仲裁器输出，wb_req , meta_write,meta_read , lb_read , lb_write , resp, mem_grant 虽然是io连接到mshr的，但需要mem_grant的source和mshr符合\nmmio是另一个mshr 就是!cacheable的数据的mshr ,\n通过TLArbiter.lowestFrowSeq选择优先级最低的源发出消息 ，\nmem_acquire是a通道，mem_grant是D通道，mem_finish是e通道\n多个mshr的resp 经过仲裁后输入到一个队列里 ，然后再连接io.resp\nfor (w \u0026lt;- 0 until memWidth) { io.req(w).ready := (w.U === req_idx) \u0026amp;\u0026amp; Mux(!cacheable, mmio_rdy, sdq_rdy \u0026amp;\u0026amp; Mux(idx_match(w), tag_match(w) \u0026amp;\u0026amp; sec_rdy, pri_rdy)) // 在sec_rdy 需要让tag_match io.secondary_miss(w) := idx_match(w) \u0026amp;\u0026amp; way_match(w) \u0026amp;\u0026amp; !tag_match(w) // 二次缺失，本身已经找到了一个mshr, 但是tag不匹配 io.block_hit(w) := idx_match(w) \u0026amp;\u0026amp; tag_match(w) } sdq_alloc_id会在mshr_req中传递过去 ，如果是load是没有用的 ， 但是如果是store 的话就方便取数据\n后续可以进行replay\n如果是一个store被replay , 那就可以释放相应的sdq表项了， sdq表项是越小的会被优先分配\n对于一个miss的load , 在mshr 那边首先会出现首次缺失 ， 从 in_valid(0) -\u0026gt; s_refill_req(1) ,\n然后发起mem_acquire,成功发起之后跳转到 s_refill_resp (2) , 此时通过lb_write将mem_grant的数据写到lb去，这里需要传送4个128bit , 即64字节 ,\n在传输完成之后，进入s_drain_rpq_loads(3)状态，这个阶段会向lb发起读请求，具体的请求是 rpq里存放的req , 然后通过resp返回对应的结果 ，resp的结果会放在resp queue里 ，可以看到rpq.ready的条件，如果commit_line是false 的话，说明deq没有fire , 说明lb_read没有ready 或者 resp.ready , 如果rpq 中全都是 load 的请求，那会直接把rpq清空，相当于可以响应所有load的请求，但是如果中间有一个store的话，会暂停 ，\n然后都会进入下一个阶段 ， s_meta_read (4) , meta_read 需要提供req_tag req_idx 和 way_en 是需要去读取特定路的 ， 所以miss 的时候其实会分配特定路，写入对应的tag 和 coh , 然后再给mshr ，\n然后会进入s_meta_resp_1(5) 状态，然后会进入s_meta_resp_2(6)状态, 不知道为什么要打一拍，在这个状态会根据coh 判断是否需要wb(其实主要是看state 是否是dirty) ,是dirty就需要写回 ， 跳转到meta_clear(7)状态,反之跳转到s_commit_line状态（B)，\n在s_commit_line(B)状态, 主要做的是refill ,做lb_read , 就是把通过lb_write写入的数据通过refill端口 data_write ，写入到对应的data 里去，那后面就不需要从mshr取了 ， refill 的地址是 req_block_addr | (refill_ctr \u0026laquo; rowOffBits), 总共需要refill 64 Byte , 一次传输128bit , 即 16Byte , 所以refill传输的地址实际上去原始地址，是地址的[11:0]位 ，即 index 这一部分 ， 读data的时候是读[11:4], 16Byte对齐，12 = 6 + 6 ，实际上是分成 2^8 sets的\n// resp.ready 需要mshrfile xu rpq.io.deq.ready := io.resp.ready \u0026amp;\u0026amp; io.lb_read.ready \u0026amp;\u0026amp; drain_load 完成后，跳转到drain_rpq(C), 这是是让rpq.deq和replay相连，一般没有replay_fire主要是由于deq.valid没拉高，即rpq.empty,目前看下来replay都是replay store,对于load 来说，会跳到s_meta_write_req(D)\n在s_meta_write_req（D)上，把new_coh写入就行了，new_coh主要是在s_refill_resp的时候更新的,就是把coh_on_grant更新过去\n然后跳转到s_meta_finish_1 (e), 是需要通过e端口传递的信息 ， 然后跳转到s_mem_finish_2(f), 如果不是预取的话，就可以跳转到 s_invalid , mshr 对当前缺失的处理就结束了\n对于一个mshr 的store , 首先还是从invalid 起， 到s_refill_req , 然后到s_drain_rpq_load , 因为不是load , 所以什么都没有发生，此时应该会跳转到s_meta_read , 然后到s_meta_resp_1 ， 到 s_meta_resp_2 , 到s_commit_line 或者s_meta_clear (写回) ， 感觉和load是一样的 ， 之后到s_drain_rpq的时候出现区别， 此时会进行replay ,它是借助replay把数据写到data 里去 ， 其中的data 就是 借助sdq中保存的数据，然后把req 的 请求都清空之后 ， 然后就是D-\u0026gt; E-\u0026gt;F ，store 就结束了\n会出现rpq 是 store ， load 交替出现的情况吗\n附录 参考文献 ","date":"2025-02-17T22:54:00+08:00","permalink":"https://VastCircle.github.io/2025/boom-lsu/","title":"Boom Lsu"},{"content":"我们在这项工作中的目标是通过减轻负载数据依赖性和资源依赖性来改善ILP。为此，我们提出了一种称为Constable的纯粹微体系技术，可以安全地消除执行负载指令。 Constable动态标识了从同一负载地址反复获取相同数据的负载指令。我们称这种负载可能稳定。对于每个可能稳定的负载，Constable（1）通过轻巧的硬件结构跟踪对其源体系结构寄存器和内存位置进行修改，并且（2）消除执行加载指令的后续实例，直到将其写入其源寄存器或其源寄存器或商店或Snoop请求到其加载地址。\n我们使用多种90个工作负载进行的广泛评估表明，在强大的基线系统中，核心动态动力消耗量平均将MRN和其他动态指导优化（例如，移动和零消除量）降低了核心动态功耗3.4％，而警官的性能则提高了3.4％（例如，移动和消除零的消除，我们的广泛评估（降低了3.4％） ，恒定和分支折叠）。在有2条同时多线程（SMT）的情况下，Constable的性能提高比基线系统增加到8.8％。当与最先进的负载值预测器（EVES）结合使用时，Constable分别在没有2-Way SMT的基线系统中，与单独的负载值预测变量相比，平均绩效益处相比，平均绩效益处相比。\nintroduction Constable背后的关键洞察力是，当满足以下两个条件时，静态load指令的动态负载实例I2 I势必从与同一静态load指令的先前的动态load实例I1相同的内存位置获取相同的值。\n条件1：在I1和I2之间没有写入I的任何源寄存器。\n条件2：在I1和I2的出现之间，没有存储或窥探请求到达I1的内存地址。\n满足条件1确保I2具有和I1相同的加载地址 ， 满足条件2确保I2将从内存获取和I1相同的值\nbackground 负载值预测（LVP）[32、42、42、71、98、107、114、139-143、151、151、153-155、159、160]通过预测负载指令的值并使用，从而破坏了负载数据依赖性负载数据依赖于预测值。后来通过执行加载指令来验证预测值。正确的预测增加了ILP，但是错误的预测导致重新执行负载依赖指令，从而产生了性能和电源开销。\nperformance headroom of constable (a)中load 指令从内存中获取对象指针 s_rng . s_rng 在workload 开始时只初始化一次 ， 因此s_rng 实际上充当常量 。 编译器无法优化，因为无法在全局范围内保留一个寄存器 ， 后续的get_Rng还是会重复去获取相同的地址和数据 。\n(c)中 out_pos （地址） ， *out_pos（数据）是不变的 ，out 和 *out也是不变的(out是个二重指针) ， 是两个稳定的load\n6. Constable: Microarchitecture Design 稳定负载检测器 （SLD）。SLD 是一个程序计数器 （PC） 索引表，有三个主要用途。首先，SLD 通过分析其过去的动态实例来识别给定的 load 指令是否可能稳定。其次，SLD 决定是否可以消除加载指令的执行。第三，SLD 提供给定的可能稳定的加载指令的最后计算的加载地址和最后获取的数据。\n寄存器监视器表 （RMT）\nRMT 是一个 architectural register indexed 表，其主要目的是监视对 architecture registers 的修改，并避免在其源 architectural register被修改时消除 load 指令。每个 RMT 条目都存储了当前正在消除的负载 PC 列表，这些 PC 使用相应的架构寄存器作为其源。在 rename 阶段，每条指令都使用其目标架构寄存器查找 RMT，并从 SLD 中的相应 RMT 条目中重置任何加载 PC 的消除状态，以确保该加载指令的任何未来实例都不会被消除。从本质上讲，RMT 强制执行条件 1 以消除负载指令 （§5）\n类似于组相连的cache\n地址监视器表 （AMT）\nAMT 是一个物理地址索引表，其主要目的是监视内存中的修改，并避免在它从中获取数据的内存位置被修改时消除加载指令。每个 AMT 条目都存储当前正在消除的访问相应物理内存地址的负载 PC 的列表。每个存储或窥探请求都使用其物理地址查找 AMT，并从 SLD 中的相应 AMT 条目重置任何负载 PC 的消除状态，以确保不会进一步消除该负载的任何后续实例。实质上，AMT 强制执行条件 2 以消除负载指令 （§5）。\nAMT和RMT不太一样，RMT是不需要分配表项的，只需要往条目中加pc , 因为architecture address 32个，应该是提前根据id分好了 ， 但是 address是不确定的，只能在后面分配表项 ，这样的话AMT的第一层寻址就需要进行全匹配 ，就要把所有表项都列一遍\n6.2 identifying likely-stable loads SLD 采用基于置信度的学习机制，根据其过去的动态实例的执行结果来识别可能稳定的加载指令。\n每个 SLD 条目存储四个关键信息：（1） 最后计算的加载地址，（2） 最后获取的值，（3） 5 位稳定性置信度和 （4） 表示是否可以消除此加载指令的实例的 can _ eliminate 标志。\n当未消除的加载指令在写回阶段完成执行时，Constable 使用加载 PC 检查 SLD，将上次计算的加载地址和最后获取的值与当前加载地址和值进行比较。如果地址和值都匹配，则 Constable 将稳定性置信度水平增加 1;否则，它会使置信度减半。如果稳定性置信度超过阈值（在我们的评估中设置为 30），Constable 会将来自同一台 PC 的后续负载实例识别为可能稳定。\n6.3. Eliminating Load Execution 在重命名阶段，加载指令首先使用加载 PC（图 8 中的 1）检查 SLD。如果在相应的 SLD 条目中设置了 can _ eliminate 标志，则 Constable 将使用存储在 SLD 条目中的最后获取的值中断加载数据依赖性，并消除其执行 （ 2 ）。如果未设置 can _ eliminate 标志，Constable 将检查 SLD 条目中存储的稳定性置信度。如果置信度高于阈值，则 Constable 将加载指令标记为可能稳定，并将其作为基线 （ 3 ） 正常执行。只有标记为 likely-stable 的 load 指令才能在其执行的 writeback 阶段设置 can _ eliminate 标志.\n重命名阶段检测是否能够消除load\nMicroarchitecture for breaking load data dependence.\n打破负载数据依赖性需要将load value提供给所有依赖的in-flight指令。通过将值写入物理寄存器文件（PRF）或单独的值表[159]来实现这一目标。由于写信给PRF需要将昂贵的写入端口添加到PRF [134、141、143]，或者需要对现有写入端口的延迟敏感仲裁[139，159]，因此Constable使用一个小的额外寄存器文件实现负载数据依赖性（仅是32个条目），称为xPRF，该条目致力于保存in-flight的值消除了负载指令。\n如果SLD决定去消除load execution , ，Constable 将 SLD 提供的最后获取的值存储在可用的 xPRF 寄存器中, 将load 指令转化为three-operand register move instruction , the source is the xPRF register , the destination is the destination architectural register of the load , and the third operand is the last-computed load address provided by the SLD . 在rename 阶段 ， 转换后的寄存器移动指令只需要将目标寄存器映射到源xPRF寄存器就可以完成执行 。 in the allocation stage , 在 allocation 阶段，转换后的 register move 指令分配一个 reorder buffer （ROB） 条目和一个 load buffer （LB） 条目。LB 条目中的 address 字段将更新为 move 指令中嵌入的最后计算的加载地址作为第三操作数。稍后需要 LB 条目中的这个地址字段，以正确消除来自动态存储 [70] 的消除负载的歧义，如 §6.5 中所述。由于转换后的寄存器移动指令的执行已经在重命名阶段完成，因此该指令会绕过剩余的管道阶段和资源，直接根据按顺序停用逻辑进行停用。(貌似还是要调度的)\n会直接将load指令进行转化成另一条指令（硬件指令），这样就没有对load的数据通路有任何影响 。\n好奇address有什么用 . 懂了，用来放到 load buffer 里面去\n更新constable结构 6.4.1 当可能稳定但未消除的负载完成执行时进行更新。 在管道的writeback阶段，当可能稳定但未消除的负载完成执行时，Constable 会更新其结构以消除相同加载指令的后续实例。这分三个步骤进行。\nConstable 使用其源架构寄存器查找 RMT。对于每个源寄存器，Constable 将加载 PC 插入相应的 RMT 条目 （ 4 ）。\nConstable 使用 load 指令的物理地址查找 AMT。如果找到加载地址，Constable 将加载 PC 插入相应的 AMT 条目 （ 5 ）。如果未找到该地址，Constable 将为加载地址插入一个新的 AMT 条目，并将加载 PC 插入到新的 AMT 条目中。\nConstable 使用加载 PC 查找 SLD，并set 相应条目 （ 6 ） 的 can _ eliminate 标志。设置can _ eliminate 标志允许 Constable 消除相同加载指令的后续实例的执行。\n当可能稳定但未消除的load 再执行一次后，后续的执行就可以去消除了 （写回阶段）,所以此时会将指令的pc写入RMT和AMT进行记录 。\n**6.4.2.在寄存器重命名期间更新。**在重命名阶段，Constable 检查每条指令的目标架构寄存器并更新其结构，以避免消除使用目标寄存器作为其源的任何加载指令的后续实例。首先，Constable 使用每条指令的架构目标寄存器 （ 7 ） 查找 RMT 。如果相应的 RMT 条目中有任何加载 PC，Constable 使用每个加载 PC 查找 SLD，并重置 SLD （ 8 ） 中相应条目中的 can _ eliminate 标志。\n在重命名阶段如果发现稳定load 的源寄存器要被更新，那就把can_eliminate = 0 , 方法就是每一条指令的目标寄存器去找RMT , 找到的条目里的所有PC都去更新SLD , 重置SLD中的can_eliminate标志\n6.4.3.存储指令上的更新。 当生成store指令的地址时，Constable 会更新其结构，以避免消除从与store相同的内存地址获取数据的任何加载指令的后续实例。这分两个步骤进行。\nConstable 使用物理存储地址 （ 9 ） 查找 AMT 。如果在 AMT 中找到地址，Constable 将使用 AMT 条目中的每个加载 PC 查找 SLD，并从 SLD （ 8 ） 的相应条目中重置 can _ eliminate 标志。 在重置后可以消除 AMT 条目中所有负载 PC 的标志，Constable 驱逐AMT条目。 6.4.4.Snoop 上的更新 Request. .为了安全地消除多核系统中的负载，Constable 监控进入核心的 snoop请求并更新其结构，以避免消除从与 snoop 相同的内存地址获取数据的任何加载指令的后续实例。Constable 处理 snoop 请求的方式与 store 请求类似。当snoop请求到达核心时，Constable 使用 snoop 地址 （ 10 ） 查找 AMT。如果找到地址，Constable 将使用 AMT 条目中的每个加载 PC 查找 SLD，并从 SLD （ 8 ） 的相应条目中重置 can _ eliminate 标志。最后，Constable 驱逐 AMT 条目。\n和6.4.3 类似 。 snoop 应该是其他核修改了内存的值 ， 需要向核心广播 ， 所以很显然也是需要处理的\n6.5. 消除 In-Flight store 中 Removed Loads 的歧义 当store指令计算其地址时，Constable 访问 AMT 并重置访问同一内存位置的所有加载指令的 can_eliminate 标志（参见 §6.4.3）。这可以防止 Constable 消除这些加载指令的任何后续出现。但是，在主动无序发出 loads 的处理器中 [67,70,119]，pipeline 中可能会有比 store 指令更年轻的 load 被消除，并且其地址与 store 地址匹配。我们观察到这种情况很少发生（参见扩展版本 [39] 中的附录 A.2），因为 Constable 认为只有当负载指令满足稳定性置信度阈值时，它才有资格被消除。在这种不常见的情况下，Constable 利用现有的内存消歧逻辑 [48\\u201270]，该逻辑将存储地址与 LB 中每个加载的地址相匹配。如果捕获到违规，Constable 会刷新管道并重新执行所有较年轻的指令，包括错误消除的负载（参见 §6.8 中的示例）。\n就是现有的逻辑消歧义逻辑，所以需要在load buffer 中保存地址，方便在出现歧义的时候重新执行load\n6.6. 在多核系统中保持一致性 Constable 依靠监控 snoop 请求来跟踪其他处理器内核对内存的修改，以安全地消除多核系统中的负载。但是，监控 snoop 请求会带来以下两个关键挑战。\n由于干净驱逐而失去淘汰机会(Loss of elimination opportunity due to clean eviction)\n在具有基于目录的一致性协议的多核系统中 [45]，当缓存行从内核私有缓存中被驱逐时，对应于该内核（即own\u0026rsquo;s core）的内核有效位（CV 位）将在该缓存行的目录条目中重置 [22,23,74,152]。由于重置 CV 位会阻止目录向该缓存行发送任何进一步的snoop request到核心，因此在每次核心私有缓存驱逐时，Constable 需要避免消除任何访问被驱逐的缓存行的加载指令。这带来了两个主要缺点。首先，如果被驱逐的缓存行是干净的（例如，由于缓存容量有限或缓存冲突而被驱逐），Constable 就会失去消除机会（我们在 [39] 的附录 A.3 中量化了这种消除机会损失的影响）。其次，对于每个核心私有缓存驱逐，Constable 都需要查找相应的 AMT 条目并使之无效，这增加了设计复杂性。\n为了解决这些缺点，我们建议固定 cacheline 的own\u0026rsquo;s core 的 CV-bit，该 cacheline 由消除的 load 指令访问。当可能稳定但未消除的 load 的内存请求从 cache 层次结构返回时，Constable 将自己的内核的 CV-bit 固定在该 cacheline 的目录条目中。固定 CV 位可确保 （1） 一致性协议会将任何snoop request发送到该缓存行到own\u0026rsquo;s core，即使该缓存行从core-private cache中被完全驱逐，并且 （2） Constable 不需要在每次内核私有缓存驱逐时查找 AMT。一旦 snoop 请求被传送到内核，CV 位就会被重置，就像正常的基于目录的一致性协议一样。\n奇怪，如果因为其他核导致缓存行被清楚，拿到不是因为其他核心污染了内存吗 ？ 它的意思是设计激进一点，只要当前核心的cache行被驱逐了，访问当前行的load 都不能进行消除load , 貌似是有一些架构不一定用了基于目录的一致性协议。所以后面就建议不管是不是用基于目录的协议，都加一个CV-bit。\n看不懂，尤其是那句（由于重置CV位会阻止目录向该缓存行发送任何进一步的窥探请求到核心）\n懂了， 第一次发送snoop request 到core , CV位会清除，后续由于CV位清除了，后面的snoop requeset 是无法发送到core 的 ，这会造成第一次可能\n以 cacheline 地址粒度跟踪 snoop 请求\n与包含完整内存地址的 store 指令不同，snoop 请求包含 cacheline 地址。因此，为了支持使用 snoop 地址进行 AMT 查找，**Constable 使用物理地址以缓存行粒度为 AMT 编制索引。**这可能会导致由于错误的地址冲突而失去消除机会（例如，存储到 cacheline 可能会重置 load 指令的 can _ eliminate 标志，该指令访问存储访问的同一 cacheline 的不同字节）。但是，我们发现，这种消除机会损失对性能的影响可以忽略不计。具有 cacheline-address-indexed AMT 的 Constable 的平均性能仅比具有完整地址索引 AMT 的 Constable 低 0.4%。这主要是因为编译器倾向于将 like-stable 加载指令访问的内存地址放在一起（例如，一组函数参数布置在堆栈内存段的同一 cacheline 中），这减少了错误地址冲突的开销。\n就是虽然访问的是一个cache line , 但是不一定是同一个字节\n6.7. Other Design Decisions 6.7.1.构建 SLD 设计具有足够读/写端口的 SLD 对于实现 Constable 的性能优势至关重要。Constable 读取每个加载指令的 SLD，以识别重命名阶段中可能稳定的负载（图 8 中的 1）。因此，SLD 需要支持一组指令中预期数量的 load 指令的读取带宽，在每个周期中一起重命名（我们称之为 rename group）。我们观察到，一个重命名组在所有工作负载中平均包含 1.93 个负载，并且 98.3% 的重命名组的负载少于或等于两个。**因此，我们使用三个读取端口对 SLD 进行建模。如果重命名组中有三个以上的加载，我们将停止重命名阶段，直到 Constable 完成该组中的每个加载的 SLD 查找。**Constable 可能需要在每次 RMT 更新时更新 SLD 中的 can _ eliminate 标志，重命名组（ 7 和 8 ）中的每条指令都会发生这种情况。由于每个 RMT 条目可能包含可能稳定的负载 PC 列表，因此每个周期的预期 SLD 更新次数可能会有很大的变化。图 9（a） 以盒须图的形式显示了每个工作负载每个周期观察到的 SLD 更新的平均数量。10正如我们所看到的，我们观察到所有工作负载平均每个周期只有 0.28 个 SLD 更新。所有工作负载中 98.23% 的平均周期有两个或更少的 SLD 更新。这是因为，在任何时间点，所有负载 PC 中只有一小部分（平均 14.7%）满足稳定性置信度阈值，以便被 RMT 条目跟踪。因此，我们使用两个写入端口对 SLD 进行建模。如果一个周期中有两个以上的 SLD 更新，我们将停止重命名阶段，直到 Constable 完成该重命名组中每个加载指令的 SLD 更新。\n6.7.2.处理执行错误的路径 在存在分支预测的情况下，Constable 的结构可能会得到错误的更新（尤其是7,8)，这可能导致不必要的消除机会损失，除非在分支错误预测恢复时恢复结构。为了了解恢复 Constable 结构的必要性，我们测量了 Constable 在结构仅由正确路径上的指令更新时的性能变化，而不是当它们被所有指令更新时，没有分支错误预测恢复的更新机制，并将其显示为图 9（b）。关键的观察结果是，90 个工作负载中有 82 个显示性能的绝对变化小于 1%，而平均性能变化仅为 0.2%。因此，我们在分支错误预测恢复中对其结构没有任何更新机制的 Constable 进行建模。\n就是不处理\n6.7.3.处理物理地址映射的变化 AMT 监控物理地址空间中所有已删除的加载指令所访问的内存位置。这带来了一个挑战：当物理内存映射更改时，AMT 条目跟踪的物理内存地址可能不再与相应的已消除负载相关联。在这种情况下，为避免错误地消除加载执行，Constable 会重置所有 SLD 条目的 can _ eliminate 标志，并在物理内存映射更改时（例如，上下文切换）使所有 RMT 和 AMT 条目失效。\n6.8 一个说明性的例子 略\n6.9 storage overhead 表 1 显示了 Constable 的存储开销。Constable 的每个处理器内核只需要 12.4 KB 的存储空间（参见 §8.1）。\nSLD是组相联cache , 应该是用一部分pc做index , 一部分作tag 了， 表项内容 1） 最后计算的加载地址(addr : 32)，（2） 最后获取的值(val : 64)，（3） 5 位稳定性置信度(confidence level: 5b) 和 （4） 表示是否可以消除此加载指令的实例的 can _ eliminate 标志(1b)。 (5) pc值 ： tag : 24b\nRMT 由于寄存器号没几位，直接用全索引，没做成cache\nAMT是组相连cache , 32 sets(5b) ， 8 ways , entry : 物理地址作为tag（32b) , load pc (4*24b）\n所以实际上也不敢做成全相连cache ，一次性遍历512个表项相当恐怖，所以还是遍历1 set ,\n看AMT,貌似是一个表项存放了4个pc值， 还以为是多重索引的那种\n附录 参考文献 见标题\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-16T23:45:47+08:00","permalink":"https://VastCircle.github.io/2025/constable_improving_performance_and_power__execution/","title":"Constable_improving_performance_and_power__execution"},{"content":"内存重命名应用寄存器访问技术来加载和存储指令，以加快内存流量的处理速度。该方法的工作原理是在 pipeline 的早期准确预测 memory communication ，然后将 communication 重新映射到 fast physical registers 。\noperations 我们通过使用内存依赖性预测器（ 3 ）实现了对存储/加载依赖关系的准确和早期识别，如图 1a 所示。内存依赖性预测器使用负载的程序计数器 （PC） 来预测其sourcing store。由于 stores 和 loads 的程序计数器在管道的第一阶段就知道，因此我们可以在管道的早期启动内存依赖性预测，足够早，不会影响调度延迟。预测器通过利用存储和负载之间通信中的简单位置来实现准确性。预测要通信的 store 和 loads 绑定到 value 文件中的同一 physical register 。访问值文件条目可以在没有 load 或 store 指令的有效地址的情况下执行（推测性地）。\n图 1b 详细介绍了内存重命名器的作用。执行 store 时，memory dependence predictor 与 store 的 PC 一起建立索引，以在数组中定位其条目。如果store不在内存依赖性预测器中，则将其插入到数组中。还会分配值文件中的entry，并将其index插入到内存依赖性预测器的store条目中。值文件中的条目使用 LRU、random 或其他合适的策略进行分配。但是，任何新分配的值文件条目都应该是近期不太可能使用的条目。最后，存储数据（如果可用）将存入与存储关联的值文件条目中。\n在 load 指令上，memory dependence predictor 与 load 的 PC 一起索引，以在数组中定位其条目。如果加载不在预测器中，则会分配一个条目，并将加载的源存储的值文件索引插入到新分配的条目中。有多种方法可以识别源存储的值文件条目，从使用值文件条目索引标记数据存储（我们实验中使用的方法）到通过存储转发机制传播值文件索引。最后，与加载关联的值文件条目将推测性地返回为加载的值。\n如果 load 指令没有明显的 source-store，例如，它是常量的 load 或不经常存储的变量，则从内存中加载的结果也会插入到 value 文件中。\ndependence predictor , 通过对应的 pc 索引 store 条目， 条目含有 value file 的 index ,\nvalue file 是一个cache 结构 ， 含有store 的 data ， 在store 的时候分配\n对于load, 通过 对应的pc索引load 条目 ， 如果不在entry中，分配一个条目，并且将 load 的 源store value file index 插入到新分配的条目\n识别load的源store value fiele index 的方法 可以使用 value file index 标记 数据store , 通过store forward 传播值文件索引\n程序地址 A 和 B 上的两个存储可能会在程序地址 C 处获取负载，具体取决于 q 的值。如果 p 的值不等于 q，如图 2b），重命名器会将 *p 的定义和 *p 的使用映射到相同的值文件条目。但是，如果 p 等于 q，如图 2c） 所示，重命名器会将 *q 的定义和 *p 的使用映射到相同的值文件条目。\n3.EXPERIMENTAL PIPELINE DESIGN memory dependence predictor 集成到处理器 pipeline 的前端。在解码过程中，会探测内存依赖性预测器（对于存储和加载）以查找分配给内存依赖性边缘的值文件条目的索引。如果访问命中内存依赖性预测器，则返回的值文件索引将传播到重命名阶段。否则，将在 predictor 和 value 文件中为指令分配一个条目。此外，解码阶段可以保存重命名加载的置信度计数器 （ 5 ）。当正确预测这些计数器的采购存储时，这些计数器会因负载而递增，而当预测不正确时，这些计数器会递减（或 reset ）。当负载达到预定义的阈值时，允许进行推测。\n在管道的重命名阶段，加载使用从 decode 阶段传入的值文件索引来访问值文件中的条目。值文件返回最后存储到预测依赖性边中的值，或者如果该值正在计算中（即正在进行），则返回预订站索引。如果返回预留站索引，则加载将停止，直到将源存储数据写入存储的预留站。当重命名的加载完成时，它会将其结果广播到依赖指令;register 和 memory scheduler 像以前一样对 speculative load 结果进行作，无需修改。重命名的存储完成后，它会将其在值文件中的预留索引替换为 stored 的值。通过允许值文件条目包含预订站引用，可以正确重命名同一通信边沿的多个活动实例。为了说明这种情况，请考虑图 2a） 中的示例，其中代码嵌入在一个紧密循环中。如果 value 文件条目仅包含值，则将 store values 正确转发到 loads 将要求循环的所有迭代都执行而不交错。如果不是这种情况，则 load 可以从循环的另一次迭代中看到 store，具体取决于 store 和 loads 的顺序。通过存储预订站引用，我们可以正确处理这种情况。每个无法立即执行的 store 将在 value 文件中插入一个新的 reservation station 索引，并且引用此 store 值的下一个加载将等待该 reservation station 生成其结果± ±请记住，在管道的这个阶段，指令仍然按顺序处理。每次迭代都会看到来自同一迭代的正确存储，并且来自不同迭代的存储和加载可以使用任何交错执行，而不会影响计算的正确性。 所有加载，无论是推测的还是其他的，都会访问内存系统。当重命名的加载的非推测值从内存系统返回时，会将其与预测值进行比较。如果值不匹配，则发生了加载数据错误推测，并启动管道恢复。\n与 loads 不同，store 指令在停用之前不会访问值文件。那时，store 将其 store 数据存储到 value 文件（覆盖其 reservation station 索引）和内存系统中。任何稍后引用此值的重命名加载都将能够直接从值文件访问它。没有尝试保持值文件和主内存之间的一致性。如果它们的内容不同（例如，由于外部 DMA 或内存一致性作），管道将继续正常运行。将重命名的 load 值与实际内存内容进行比较时，将检测到任何不连贯性。\n当未重命名的 load 引用重命名的 store 生成的数据时，将创建 stores 和 loads 之间的初始绑定。我们探索了两种检测这些新依赖性边缘的方法。最简单的方法寻找重命名的 store，这些 store 转发到 load/store 队列转发网络中的 load（即，动态指令之间的通信）。当检测到这些边缘时，内存依赖性预测器会相应地更新。一种功能稍强的方法是将 value file indices 附加到重命名的 store data，并将这些索引传播到 memory hierarchy 中。这种方法性能更好，因为它可以检测寿命更长的依赖性边，但是，值文件索引的额外存储使该方法的成本更高。\n3.2 Recovering from Mis-speculations 当重命名的加载将不正确的值注入程序计算时，正确的程序执行至少需要重新执行使用错误值的所有指令和相关指令。为此，我们探索了两种从数据错误猜测中恢复管道的方法：squash 和 re-execution recovery。这两种方法在错误推测时表现出不同的性能下降以及不同的实现复杂性。 Squash 恢复虽然成本高昂，但却是最简单的实施方法。该方法的工作原理是在错误推测的 load 指令之后丢弃所有指令。由于所有依赖指令都将遵循 load 指令，因此确实会满足所有依赖指令都被重新执行的限制。不幸的是，这种方法可能会丢弃许多独立于错误推测的 load 结果的指令，需要许多不必要的重新执行。这种方法的优点是，与目前实现的方法相比，它需要的支持非常少。错误推测的 load 可能与错误推测的分支相同。 重新执行恢复虽然更复杂，但恢复性能明显优于 squash 恢复。该方法利用存储在尚未停用的指令的预留站中的依赖性信息，仅允许重新执行那些依赖于推测负载值的指令。这种方法的成本是增加了管道复杂性。 我们通过将错误推测的 loads 的正确结果注入到结果总线上来实现重新执行± ±所有接收正确 load 结果的依赖指令都将重新执行，并重新广播它们的结果，强制依赖指令重新执行，依此类推。由于一条指令知道有多少个作数将通过重新执行重新生成并非易事，因此一条指令可能会多次重新执行，每个重新生成的作数一次。此外，通过内存的依赖项可能需要重新执行加载指令。为了适应这些依赖关系，load/store 队列还会重新检查任何重新执行的 store 的内存依赖关系，重新发出任何依赖的 load 指令。此外，如果加载通过指令重新执行收到新地址，则可能会强制重新执行。在停用时，任何重新执行的指令都将是机器中最早的指令，因此它无法接收更多重新生成的值，并且该指令可以安全地停用。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-13T22:44:11+08:00","permalink":"https://VastCircle.github.io/2025/memory_renaming_fast_early_and_accurate_processing_of_memory_communication/","title":"Memory_renaming_fast_early_and_accurate_processing_of_memory_communication"},{"content":"3. motivation 3.1 no speculation 所有load 指令等到所有先前的store 指令都发出后才能被允许发出\n3.2 naive speculation 在寄存器依赖项准备就绪时就执行load,而与内存依赖项无关 。\n这样会涉及到流水线的冲刷和load及其依赖指令的重新执行\nmemory trap penalty: the number of cycles between the first time a load is fetched to the next time the load is fetched after a memory-order violation has been detected.内存陷阱惩罚表明未获取有用指令的平均周期数。\nload-\u0026gt; 发现内存顺序错误 -\u0026gt; 重新load , 这一段时间 ， 无效实现\n3.3 perfect memory dependence prediction 完美依赖性预测\n5 . Store sets store sets 的概念基于两个基本假设。首先，内存顺序冲突的历史行为可以很好地预测未来的内存依赖关系。第二个是预测加载的依赖关系非常重要，其中一个加载依赖于多个存储或多个加载依赖于同一存储。\n5.1 concept 我们将正在运行的程序中的每个 load 指令定义为具有一组关联的 store 指令，称为其 store set。负载的存储集由它曾经依赖的所有存储（由其 PC 标识）组成。\n当程序开始执行时，所有加载都有空的 store set，并且处理器允许对 store 周围的 load 进行naive speculation。当 load 和 store 以错误的顺序执行，导致违规时，store PC 将被添加到 load 的 store set，例如，set A。如果另一个 store 与相同的负载冲突，则该 store PC 也会添加到设置 A。当处理器下次看到该 load 时，它要求该 load 在store set A 中最近获取的任何存储之后执行。当获取 load 时，processor 将确定 load 的 store set 中的哪些 store 是最近获取的但尚未发出的，并创建对这些 store 的依赖关系。永远不会导致 memory-order 冲突的加载将没有强加的内存依赖项，并且会尽快执行。导致内存顺序冲突的 load 将仅依赖于它们过去所依赖的那些先前的 store。如果存储集 A 中的一个存储也导致另一个加载的内存顺序冲突，则它也将成为该加载的存储集的一部分。负载和存储由其 PC 标识。\n这种多个加载依赖于同一存储的情况相当常见，当一个值有一个写入器和多个读取器时，就会发生这种情况. 依赖于多个 store 的 One load 在某种程度上更加模糊。发生这种情况的三种情况是：1） 负载可能取决于来自不同路径的 store，例如，if （expr） then x = a;否则 x = b;. . . . .c = x;2） 加载可以依赖于对数据字中打包的结构字段的多个存储，这些字段都一起读取，例如，写入颜色结构的红色、绿色和蓝色分量;3） 假设内存先写后写风险被视为依赖关系，则负载可能依赖于对同一位置的一系列存储;例如，多次泄漏到同一位置。\n3种配置\n其中程序中的每个加载都有自己的存储集，并且该存储集可以包含任意数量的存储，但一个存储只能驻留在一个存储集中,当存储导致内存顺序冲突时，它将从它所在的任何存储集中消除，并放置在最后与之冲突的负载的存储集中（禁止多个load依赖于同一个store)。 将 store 集的大小限制为 1，允许程序中的每个加载最多指定一个 store 依赖项,这禁止一个load依赖于多个store 没有前面的限制 ，infinite 5.2 performance 四种load : not predicted , correct predictions , false dependencies ,memory order violations\n因为是基于store 的pc进行预测的 ， 对load来说还是可能出现 false dependencies (错误依赖，本身没有依赖的但是预测为依赖)，violation(内存顺序违规，有内存依赖但是没有预测出来)\nimage-20250212210408090 将2位饱和计数器和store set memory dependence predictor 耦合 ， 一个两位计数器被附加到load的store set中的每个store . 当发生违规时，counter设置为max, 当load被store set中的store 阻止时，可以比较load和store的地址，如果相同，说明是真的依赖，counter + 1 , 反之 counter - 1 , 仅当 counter 的高位set ， load才会等待store set中的store .\n6. store set implementation 在硬件实现中，限制store pc 最多存在在一个store set中(为什么说是配置2)， 提出合并store sets的算法，允许依赖于同一store 的两个load 共享一个store\nstore sets 允许 load 依赖与多个 store , 需要一种机制延迟 load,直到store set中的所有store 都执行完 。构建这样的机制比较麻烦，因此可以强制store set中的store是按顺序执行的 ，这是通过使得每一个store 依赖于store set 中最后获取的store 实现（?)\n6.1 components store set identifier table(SSIT) , pc indexed table(PC索引表), using a common tag for each load and the stores in its store set\nLast fatched store table (LFST) , 维护每个store sets 中最近获取的store的动态信息 。信息是store 的 inum , 是一个硬件指针，用来标识每个正在运行的指令的实例。\n最近获取的load 根据pc访问SSIT 获取store set identifier (SSID), 储存集标识符， 如果一个load有有效的SSID,则它具有有效的store set . 它将访问第二个表LFST,获取最近获取的store指令的inum\nssid就是store sets 的id号， pc 通过ssit索引 store set id , 然后再获取最近的一条store指令的 inum\n最近获取的store 也会访问SSIT,如果找到有效的SSID,则它属于有效的store sets . 然后，store 需要执行 1） 访问LFST并获取store sets中最近获取的store指令。 新的store 将依赖于它在LFST中找到的store .2) 更新LFST,插入自己的inum , 因为它是现在store sets中最后的store\n当store issues后，会访问LFST,如果仍然引用自身，则使得该条目无效。可以确保load和store只依赖于未issue的store(?) 如果store来自不同的代码路径，并且不是每次执行load时都执行，则只有获取的store将访问 SSIT 并修改 LFST。load将始终依赖于适当的 store，并且 store 永远不会被迫相互load，因为它们在不同的时间执行。\nstore issue确实无所谓了，代笔地址会在后几个周期就计算出来, 好像不太对\n在 dispatch的时候访问ssid表， 在store commit 的时候如果发生冲突，会在SSIT中创建store sets\nSSID pc经过 hash 作为 索引 ， SSID 是分配的 ，冲突的load ,store 具有相同的 ssid ,\n在 store 访问 SSIT,如果能够发现有效的SSID , 就会进一步通过SSID去将store 的 inum 写入 LFST\n随后的load 指令因为和store 指令具有相同的SSID,所以可以得到store指令的inum,进而在后续issue的时候就能够得到相应的依赖关系，在依赖的store未issue的时候，就无法issue load\nSSID是lfst的 index\n如果之后load 和另外的store 发生冲突，load有SSID, store 没有，那此时store 直接继承load的SSID ,并且将inum更新为现在的store , 这样的话load ,\nSSIT和LFST的更新应该是在发生冲突的时候\n在程序开始时，假设 SSIT 中的所有条目都是无效的。最初，存储和加载指令将访问该表，并且不会获得有效的内存依赖性信息。如果store commit内存顺序冲突，则会在 SSIT 中创建一个store sets 。冲突中涉及的 load 和 store 指令将被分配一个SSID，例如 SSID X。我们在负载的 PC 上选择了 exclusive-or 哈希。SSID X 将被写入 SSIT 中的两个位置;第一个位置将由load PC 编制索引，第二个位置将由store PC 编制索引。下次获取该store PC 时，它将读取由其 PC 索引的 SSIT 条目。由于 SSID 有效，因此它使用该存储集的 SSID 访问 LFST，在那里它没有从存储集 X 中找到有效的最近获取的指令。因此，它不会依赖于其他store。store 继续将自己的 inum 写入 LFST。当随后获取 load 指令时，它访问 SSIT，然后访问 SSID 为 X 的 LFST。LFST 向指令调度器传达 load 取决于它在那里找到的 store 指令。这一次，指令调度器将在 load 和 store 之间施加依赖关系，其方式类似于它施加 register 依赖关系约束的方式。\n如果稍后加载与其他存储冲突，则会通知 SSIT 新的内存顺序冲突。SSID X 被复制到由新load的 PC 编制索引的 SSIT 条目中。现在 SSIT 中有三个指向 SSID X 的条目。下次获取两个存储和负载时，第二个存储将取决于第一个存储，而负载将取决于第二个存储。？ 怎么做到的\n请注意，存储被限制为一次只能位于一个存储集中，以保持 SSIT 和 LFST 的简单性。如果我们允许 SSIT 在每个条目中保存多个 SSID，则一个存储可以是多个存储集的一部分。然后，多个 SSID 必须访问 LFST，从而增加所需的读取端口数量。此外，每个加载将依赖于最多两个存储，从而为需要施加依赖关系的指令调度硬件增加更多的大小和复杂性。\n6.2 store set 分配 发生内存顺序冲突时，将在 SSIT 中创建条目。当加载的 SSID 和存储的 SSID 均无效时，将创建一个 SSID 并将其分配给两者。如果加载的 SSID 有效而存储的 SSID 无效，则存储将继承加载的 SSID，并成为加载的存储集的一部分。我们尚未讨论如果store已经拥有有效的 SSID 会发生什么情况。覆盖store的旧 SSID 将有效地从旧store集中删除该store，并将其放入新的store集中。这会产生不良效果，即限制 store 一次只能位于一个 store 集中。为了控制在确定是否用一个有效 SSID 覆盖一个有效 SSID 时所做的决策，我们建立了一些存储集分配规则。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-12T16:24:37+08:00","permalink":"https://VastCircle.github.io/2025/memory_dependence_prediction_using_store_sets/","title":"Memory_dependence_prediction_using_store_sets"},{"content":"内存访问 一般来说可以认为，Load 是没有副作用的（实际上，Load 会导致 Cache 加载数据，这也引发了以 Meltdown 为首的一系列漏洞），因此可以很激进地预测执行 Load。但是，Store 是有副作用的，写出去的数据就没法还原了。因此，Store 指令只有在 ROB Head 被 Commit 的时候，才会写入到 Cache 中。\n当load的地址计算出来之后，可以去取数据，首先从store queue找，如果有地址和load地址相等，在store数据准备好之后，可以做数据转发。\n如果没有找到，需要从cache中取\n如果store慢到还没有写如store queue,load就完成了，就会出现错误，此时需要重新执行load指令和依赖与load指令的其余指令\n加载存储单元 最简单的方法是顺序执行，pipline会清空，store/atomic/uncached load 会有副作用\n需要读写乱序， 需要提前执行load, 一种思路是等待所有的store执行完毕，另一种思路是用地址搜寻store,看看是否出现同一个地址的store和load,但是这样相当于做了一个全相连的buffer,面积大，延迟高。\nA high-bandwidth load-store unit for single-and multi-threaded processors 的解决思路是，把 Store 指令分为两类，一类是需要转发的，一类是不需要的，那么可以设计一个小的相连存储器，只保存这些需要转发的 Store 指令；同时还有一个比较大的，保存所有 Store 指令的队列，因为不需要相连搜索，所以可以做的比较大。\n修复load-store相关性可以在store提交的时候，检查是否有地址冲突的load指令（ Boom LSU ),\n可以在commit的时候重新执行load指令，如果结果不一致，把后面依赖冲刷掉，但是这样每条load需要执行两次 。Store Vulnerability Window (SVW): Re-Execution Filtering for Enhanced Load Optimization 属于重新执行 Load 指令的方法，通过 Bloom filter 来减少一些没有必要重复执行的 Load。还有一种办法，就是预测 Load 指令和哪一条 Store 指令有依赖关系，然后直接去访问那一项，如果不匹配，就认为没有依赖。Scalable Store-Load Forwarding via Store Queue Index Prediction 把 Load 指令分为三类，一类是不确定依赖哪条 Store 指令（Difficult Loads），一类是基本确定依赖哪一条 Store 指令，一类是不依赖 Store 指令。这个有点像 Cache 里面的 Way Prediction 机制。\n具体到 Load/Store Queue 的大小，其实都不大：\nZen 2 Store Queue 48 Intel Skylake Store Buffer 56 Load Buffer 72 POWER 8 Store Queue 40 Load Queue 44 (Virtual 128+128) Alpha 21264 Store Queue 32 Load Queue 32 load pipline\n下面来举例分析 LSU 中 Load Pipeline 每一拍需要做些什么。\n以香山雁栖湖微架构为例，它的 Load Pipeline 分为三级流水线：\n第一级：计算虚拟地址（基地址 + 立即数偏移），把虚拟地址送进 DTLB 和 L1 DCache（因为 VIPT，虚拟地址作为 index 访问 L1 DCache），从 DTLB 读取物理地址，从 L1 DCache Tag Array 读取各路的 Tag 第二级：从 DTLB 得到了物理地址，根据物理地址计算出 Tag，和 L1 DCache 读出的 Tag 做比较，找到匹配的 Way，从 L1 DCache 的 Data Array 读取对应 Way 的数据；把物理地址送到 Store Queue，查找匹配的 Store 第三级：根据从 L1 DCache 读取的数据和 Store to Load Forwarding 得到的数据，得到最终的读取结果，写回 以香山南湖微架构为例，它的 Load Pipeline 分为四级流水线：\n第一级：计算虚拟地址（基地址 + 立即数偏移），把虚拟地址送进 DTLB 和 L1 DCache（因为 VIPT，虚拟地址作为 index 访问 L1 DCache），从 DTLB 读取物理地址，从 L1 DCache Tag Array 读取各路的 Tag 第二级：从 DTLB 得到了物理地址，根据物理地址计算出 Tag，和 L1 DCache 读出的 Tag 做比较，找到匹配的 Way，从 L1 DCache 的 Data Array 读取对应 Way 的数据；把物理地址送到 Store Queue，查找匹配的 Store 第三级：由于 L1 DCache 容量较大，需要的延迟比较高，在这一级完成数据的读取和 Store to Load Forwarding 第四级：根据从 L1 DCache 读取的数据和 Store to Load Forwarding 得到的数据，得到最终的读取结果，写回 以香山昆明湖微架构为例，它的Load Pipline 分成\n未完\n为了减少额外的 1 个周期对 pointer chasing 场景的性能影响，南湖架构针对 pointer chasing 做了优化：pointer chasing 场景下，读取的数据会成为后续 load 指令的地址。为了优化它，南湖架构在流水线的第四级上做了前传，直接传递到下一条 load 指令的由虚拟地址计算出的 index，这样的话可以做到 3 cycle 的 load to use latency。为了优化时序，前传的时候，假设基地址加上 imm 以后，不会影响 index，这样预测的时候就不用加上 imm，时序上会好一些，不过这也限制了优化可以生效的 imm 范围。\n苹果的专利就是读寄存器的一个前递，苹果的专利 Reducing latency for pointer chasing loads 提到了它的 LSU 流水线设计以及前传的做法：\n和香山南湖类似，它的 Load Pipeline 也是四级流水线（对应图中 Stage 3-6），功能也类似。不过它的 3 周期 load to load 前传的实现方法则不同。\n这个专利的前传是从第三级前传到读寄存器的阶段，这样也可以实现 3 周期的的 load to load latency。这样的好处是，AGU 阶段保留，这对于 AGU 阶段比较复杂的 ARM 架构是比较好的，因为 ARM 架构下 AGU 阶段可能涉及到加法和移位，而 RISCV 只有立即数加法。不过这样也要求 Load 不命中 Store Queue，而是从 L1 DCache 获得，因为 Store to Load Forwarding 的合并操作是在第四级流水线，为了能在第三级流水线前传，只能预测它不命中 Store Queue，数据完全从 L1 DCache 中取得。\n图中把 AGU 和 DTLB Lookup 并着画可能有一些问题，应该是先由 AGU 计算出虚拟地址，再走 DTLB Lookup。\nMemory Dependence Predictor 解决store-load依赖的，如果有依赖，等待依赖的store完成，如果没有依赖，可以直接load .为了保证正确性，Store 执行的时候，也要去看是否破坏了提前执行的 Load。\nalpha 21264 load wait table , 对于那些出现过顺序违例的 Load 指令，打上一个标记，那么未来这个 Load 都要等到在它之前的所有 Store 执行才能执行。这个标记的方法也很简单，维护 Load 指令的 PC 到单 bit 的映射。 香山实现\nval data = RegInit(VecInit(Seq.fill(WaitTableSize)(0.U(2.W)))) // 2bit的计数器 val resetCounter = RegInit(0.U(ResetTimeMax2Pow.W)) resetCounter := resetCounter + 1.U // read ports for (i \u0026lt;- 0 until DecodeWidth) { // raddr : pc(vaddr-1:1) io.rdata(i) := (data(io.raddr(i))(LWTUse2BitCounter.B.asUInt) || io.csrCtrl.no_spec_load) \u0026amp;\u0026amp; !io.csrCtrl.lvpred_disable } // write port when(io.update.valid){ data(io.update.waddr) := Cat(data(io.update.waddr)(0), true.B) } store set , 一个load 依赖过的所有store 的集合 ， 如果一个 Load 的 Store Set 内的所有的 Store 都执行完了，那么这个 Load 就可以提前执行了，不用考虑别的 Store 指令。当然了，一开始并不知道 Load 依赖哪些 Store，所以 Store Set 是空的，此时 Load 可能会提前执行。当发现执行顺序错误，需要回滚时，就把导致回滚的 Store 添加到对应 Load 的 Store Set 当中。\n每个 Store 只能出现在一个 Store Set 当中，这个 Store Set 可以由多个 Load 共享。 执行 Load 之前，为了保证 Store Set 中的 Store 指令都完成执行，要求这些 Store 指令按照一定的顺序完成，那么 Load 只用等待 Store Set 内的最后一条 Store 指令，而不用考虑 Store Set 内所有 Store 指令完成。 首先是 Store Set Identifier Table (SSIT)，这个表实现了 Load/Store 指令 PC 到 Store Set ID 的映射。通过 SSIT，就可以知道 Load 的 Store Set 是哪个 ID，哪些 Store 在这个 Store Set 当中。第二个表是 Last Fetched Store Table (LFST)，它记录了这个 Store Set 中最晚被取指的 Store 指令。\n前面提到，为了简化依赖的检查，同一个 Store Set 内的 Store 指令需要按照顺序执行，那么 Load 只需要依赖 Store Set 的最后一条 Store 指令。这个就是通过 LFST 来实现的：\n每个 Store 首先根据 SSIT 找到自己的 Store Set ID，再用 Store Set ID 访问 LFST，如果里面已经有更早的 Store，那就要依赖这个更早的 Store；同时也会更新 LFST，把自己写进去。 同理 Load 也会根据 SSIT 找到 Store ID，用 Store Set ID 反问 LFST，去依赖最晚的 Store。 如果 Store 已经被执行（准确地说，Issue），自然后续的 Load 也不用等待它了，如果 LFST 记录的还是这条 Store，它就可以从 LFST 中清除掉。 store to load forwarding 对于那些依赖之前的 Store 的 Load 指令，如果 Store 还没有写进缓存，那么 Load 在执行的时候，就需要从 Store 要写入的数据里获取数据，这就是 Store to Load Forwarding。但实际情况可能会比较复杂，例如 Load 和 Store 只有一部分的重合，不重合的部分要从缓存中获取；或者 Load 和多个 Store 重合，要从多个 Store 分别取数据合并起来；或者前后有对同一个地址的 Store，那么要选取最晚的那一个。\n首先来看看 Intel 在 Intel® 64 and IA-32 Architectures Optimization Reference Manual 中对 Core（不是 Core 系列 CPU）微架构的表述：\n尽量通过寄存器传递函数参数，而不是栈；虽然通过栈传参数，比较容易享受到 Store to Load Forwarding 的优化，但浮点的转发还是比较慢。 转发时，Load 的起始地址和 Store 相同。Load 的读取范围要包含在 Store 的写入范围之内。 如果要从 Store 写入范围的中间而不是开头读取数据，直接从中间开始读无法享受 Store to Load Forwarding，想要更好的性能，需要先从头开始读，满足转发条件，再通过位运算提取出想要的部分。 ARM公版核： Load的起始地址等于store的起始地址或者正好中间，大于 8 字节的 Load 最多可以从两个 Store 中转发数据，此时每个 Store 分别贡献一半，例如两个 Store 分别写入 8 个字节，然后 Load 把 16 个字节读出来。小于或等于 4 字节的 Load 只能从一个 Store 中获取数据。\n下面是在几款处理器上实测 Store to Load Forwarding 在各种访存模式下能否转发以及转发的条件：\nuArch 1 ld + 1 st 1 ld + 2 st 1 ld + 4 st 1 ld + 8 st AMD Zen5 Yes [1] No No No ARM Neoverse V2 Yes [2] Yes [3] No No Qualcomm Oryon Yes [4] Yes [5] No No Apple Firestorm Yes Yes [6] Yes [6] Yes [6] Intel Golden Cove Yes [7] No No No Intel Gracemont Yes [8] No No No [1]: 要求 st 完全包含 ld [2]: 要求 ld 和 st 地址相同或差半个 st 宽度 [3]: 要求 ld 和 st 地址相同 [4]: 要求不跨越 64B 边界 [5]: 要求 ld 对齐到 4B 边界且不跨越 64B 边界 [6]: 要求不跨越 64B 边界 [7]: 要求 st 完全包含 ld；特别地，在 st 和 ld 访问相同地址时，无 Forwarding 性能损失 [8]: 要求 st 完全包含 ld，ld 和 st 地址相同，不跨越 64B 边界；特别地，64b st 到 32b ld 转发允许 ld 地址和 st 地址差半个 st 宽度 memory renaming Register Renaming 把物理寄存器重命名为架构寄存器，那么 Memory Renaming: Fast, Early and Accurate Processing of Memory Communication 类似地把内存重命名为寄存器。具体地，如果发现某个 Load 的数据总是来自于某个 Store，按照先前的做法，要等 Store 先执行，然后 Load 从 Store Queue 中拿到 Store 的结果，更进一步，不如直接把 Load 的目的寄存器复制为 Store 的源数据寄存器，相当于把内存重命名成了寄存器，Load 变成了简单的寄存器的 Move。\n具体做法是，在 Memory Dependency Predictor 的基础上，还把 Store 写入的数据保存到 Value File 当中。当预测 Load 会从某个 Store 取数据时，就从 Value File 中取出对应的数据，提早执行依赖 Load 结果的指令。\nload address prediction 把数据预取到寄存器上\n在 1993 年的论文 A load-instruction unit for pipelined processors 提出了类似的想法：预测 Load 指令的地址，提前把数据从缓存中读取，如果命中了，把数据存到 Load Queue 中，当 Load 指令被执行，计算出实际地址时，如果实际地址和预测的匹配，就直接从 Load Queue 中取数据，而不用读取缓存，可以节省一个周期；如果缓存缺失了，就相当于进行了一次缓存的预取。为了实现地址的预测，需要维护一个 Load Delta Table，根据 Load 指令的地址来查询，Entry 记录了最后一次访问的地址以及每次访存地址的偏移 Delta，当 Delta 为 0 时，对应 Constant Address；当 Delta 不等于 0 时，对应 Stride Address。这个设计比较简单和保守，因为它要等到 Load 的地址实际计算出来才能 Bypass。\n提前用预测的地址向cache发起请求，等结果计算出来后，如果相同，直接将数据返回 ， 本身是load 指令计算出来之后再发起访存 ， 差了一拍\n下面来分析一个来自苹果公司的专利：Early load execution via constant address and stride prediction，它实现的优化是，当一条 load 指令的地址是可预测的，例如它总是访问同一个地址（constant address），或者访问的地址按照固定的间隔（constant stride）变化，那就按照这个规律去预测这条 load 指令要访问的地址，而不用等到地址真的被计算出来，这样就可以提前执行这条 load 指令。\n既然是一个预测算法，首先就要看它是怎么预测的。专利里提到了两个用于预测的表：\nLoad Prediction Table，给定 PC，预测 Load 指令要访问的地址 Load Prediction Learning Table，用于跟踪各个 PC 下的 Load 指令的访存模式以及预测正确率 一开始，两个表都是空的，随着 Load 指令的执行，首先更新的是 Load Prediction Learning Table，它会跟踪 Load 指令的执行历史，训练预测器，计算预测器的准确率。\n当 Load Prediction Learning Table 发现能够以较高的准确率预测某条 Load 指令时，就会在 Load Prediction Table 中分配一个 entry，那么之后前端（IFU）再次遇到这条 Load 指令时，通过检查 Load Prediction Table，就可以预测要访问的地址。\n当 Load Prediction Learning Table 发现某条 Load 指令的预测错误次数多了，就会把对应的表项从 Load Prediction Table 和 Load Prediction Learning Table 中删除，此时就会回退到正常的执行过程，Load 指令需要等待地址计算完成才可以执行。\n为了避免浪费功耗，如果 Load 指令的地址很快就可以算出来，那么预测也就没有必要了，此时即使做了预测，也不会带来很高的性能提升。判断的依据是，计算从预测地址到计算出地址耗费的周期数，如果超过一个阈值，那么优化就有效果；如果没有超过阈值，那就不预测。\n那么，如果 Load 的地址需要比较长的时间去计算，但实际上又是可以预测的，那就可以通过 Load Address Prediction 的方法，来提升性能。\n感觉这个和stride prediction 就只相差了一个load prediction learning table , 先通过预测确保正确率，然后再通过prefetch去预测 ， 但是它做的是寄存器级的，就是已经要从cache取到寄存器了，所以得尽量的去保证正确率，不像从l2取到dcache 错误的惩罚其实不多\nway prediction 组相连结构在处理器的很多地方都有，例如各种缓存，那么在访问组相连结构的缓存的时候，首先需要用 Index 取出一个 Set，再进行 Way 的匹配。但缓存在硬件中通常是用 SRAM 实现的，读取有一个周期的延迟，因此读取的过程并没有这么简单，下面分析几种读取组相连缓存的设计：\n第一种最简单的办法是，第一个周期根据 Index 把整个 Set 所有 Way 的 Tag 和数据都读出来，第二个周期就可以拿到所有的 Tag 和数据，比较 Tag 后得到结果。这个方法比较简单，缺点是功耗比较大，实际只命中最多一个 Way，却要把所有的 Way 和 Tag 和数据都读出来。\n既然只有一个 Way 的数据需要用，一个直接的想法是把读取拆成两步：第一个周期根据 Index 把整个 Set 所有 Way 的 Tag 都读出来，只读 Tag 不读数据，比对 Tag 后，第二个周期再把 Tag 正确的那一个 Way 的数据读出来。这样省下了很多数据 SRAM 的读取功耗，Tag 的读取没有省，同时付出了多了一个周期的代价。\n有没有什么办法改进呢？能否只读一个 Way 的 Tag 和数据？这就需要引入 Way Prediction，这在论文 Way-Predicting Set-Associative Cache for High Performance and Low Energy Consumption 中提出，它的思路是，引入一个预测器，预测这次访问会命中哪个 Way，然后第一个周期只读这一个 Way 的 Tag 和数据，如果 Tag 命中了，数据也有了，这样功耗和性能都是比较好的。不过如果预测错了，第二个周期就需要把其他几个 Way 的 Tag 和数据读出来，再比较一次\n预测第一周期只读一路 tag 和 data , 如果预测错误了 ， 下一周期把其他路的data 和 tag 读出来 , 如果预测对了就是净赚一周期， 预测错误其实也需要两周期， 第一周期需要做到 读取tag 和 data , 虚实转化 ， 比较tag 是否匹配 ， 如果不匹配需要发起请求\nimg 对于 VIPT 的 cache 来说，它的 tag 来自于物理地址，意味着如果要做 way 比对，判断哪一个 way 命中，需要等到虚实地址转换，得到物理地址以后，才能知道实际的 tag，才能去比对 Zen 5 为了避免等待虚实地址转换，基于虚拟地址计算出一个 8-bit 的 microtag(utag)，在一个类似缓存的 way predictor 结构里，保存每个 set 的每个 way 的 utag，同一个 set 内不同 way 的 utag 互不相同，way predictor 的 way 和 data cache 的 way 一一对应 访存的时候，读出那个 set 的所有 way 的 utag（12 路，每路 8 bit），用 utag 进行比对： 因为 utag 互不相同，所以最多只有一个 way 命中 如果有且仅有一个 way 命中，下一个周期就去读取出这一个 way 对应的数据以及用物理地址算出来的 tag 如果没有 way 命中，则认为 miss 由于 utag 完全用的是虚拟地址，它可能会出错，分两种情况： 把 miss 的预测为 hit，比如出现了 hash 冲突，有两个 way 的 tag 不同，但是 utag 一样，只能预测其中一个 way，访问另一个的时候就会 miss 把 hit 的预测为 miss，比如两个虚拟页映射到同一个物理页，用物理地址算出来的 tag 相同，但用虚拟地址算出来的 utag 不同，这两个 utag 就会抢同一个 way 的位置（注：这个问题是可以解决的，比如不要求 way predictor 的 way 与 data cache 的 way 一一对应，在 way predictor 每个 entry 里面加上一个 data cache 的 way index，不过考虑到概率和开销，好处不明显） 等虚实地址转换完成，再用物理地址验证访问是否正确 对于一般的cache , f0 发起req , f1 得到根据index 获取set 的 tag ， 同时进行虚实转化 ， 进行tag的比较 ，并发起data 的读取 ， f2 得到读取的data\nzen5 , 会基于虚拟地址计算一个utag , 一个set中的way的utag不同 ，然后获取对应的way ,如果命中了，下一个周期读取对应的数据和计算出来的tag\nutag不经过虚拟化， 这个感觉就是先用虚拟地址的tag比较出来，获取结果之后，然后用物理tag进行验证 ，可以提前一点虚实转化的时间 ， 这样主频会高一点， 本身有个周期需要虚实转化 + tag 比较 ， 现在可以单纯进行tag比较 ， 虚实转化可以这周期发起，下一周期得到 ，然后在比较物理tag , 那周期就会短一点 ， 并且这样读取多路的tag 和 读取 多路的utag + 一路的tag , 相比应该是前者功耗更低 (utag的位数很少)\n顺便说一下，boom 是同时去读取data 和 tag 的\nload value prediction 对load 得到的值进行预测 。 设计了一个load value predictio , 根据load 的地址来索引 ，\nload addr prediction 是根据pc 去预测地址， 然后提前向 cache 发起访问 ， load value prediction 是根据 addr 去预测 load 的值 ， 提前把预测的值写入寄存器\nValue Locality and Load Value Prediction 提出了 Load Value Prediction，就是对 Load 得到的值进行预测。它设计了一个 Load Value Prediction Table，根据 Load 指令的地址来索引，得到预测的读取的值。然后设计一个 Load Classification Table 来记录预测准确与否的历史，记录了 saturating counter，以此来判断是否要进行预测。预测时，可以提前把结果写入到目的寄存器内，但还要验证预测的正确性。验证的方式有两种：第一是依然完成正常的访存，把读出来的数据和预测的数据做比较；第二是针对预测正确率很高的 Load，从一个小的 Constant Verification Unit 确认这个值没有变过。\n如果要拿分支预测来类比，BTB 记录分支的目的地址，对应这里的 Load Value Prediction Table，记录 Load 指令得到的值；BHT 记录分支的跳转方向，对应这里的 Load Classification Table，判断 Load 的可预测性。\n预测算法的一脉相传嘛\nConstant Verification Unit 类似一个小的针对 Load Value Prediction 的 L0 Cache，只记录那些预测正确率很高的 Load 的地址 - 值映射关系，可以在地址计算出来后查询，判断访存是否正确预测，如果正确，就不用访问缓存了。\n根据论文 FLOP: Breaking the Apple M3 CPU via False Load Output Predictions，苹果在 M3/M4/A17 等处理器的 P 核上实装了 Load Value Prediction 预测器，它会观察 Load 指令的访存的规律，如果一条 Load 总是读出来相同的数据，那就会预测它未来读出来还是相同的数据。它的各项参数如下：\n只支持 Constant value，即 load 指令读出来的数据不变 不支持 Striding value，即 load 指令读出来的数据构成等差数列 大概 240 次 load 相同的值后使能值预测以提升性能 对于 1/2/4 字节 load，可以预测出所有可能的值，意味着这最多 4 字节的值会记录在预测器内部 对于 8 字节 load，只能预测值等于 0 的情况，没有做 8 字节 load 的通用场景，背后的考虑可能是： 8 字节比较长，开销大 8 字节且非零的 constant load 相对少见 指针也是 8 字节，避免预测的 8 字节的值被当成指针来用 观察到可以预测最多 72 个 Load 的 Value，可能是 4 路组相连 用 load 指令的地址做 full tag，不能跨越上下文共享 前面提到，苹果也实装了 Load Address Prediction，意味着在 M3/A17 及之后的处理器的 P 核上，既有 Load Address Prediction，又有 Load Value Prediction，分别对 Load 的地址和读出来的数据做预测。为此，苹果专利 Shared Learning Table for Load Value Prediction and Load Address Prediction 设计了一种机制来同时支持两种预测，并且共享 Learning Table：\n前面分析苹果的 Load Address Prediction 专利时提到，硬件实现中会用到两个表，一个用来跟踪训练的状态（Learning Table），另一个用来进行实际的预测（Prediction Table） 类似地，Load Value Prediction 也会有类似的设计：一个 Learning Table 寻找潜在的可以被预测的 Load，一个 Prediction Table 跟踪正在被预测的 Load 既然两种预测都是针对 Load 进行的，就要考虑应用哪种预测，避免冲突，提升性能 具体的实现方法就是，用一个 Learning Table 解决 Value 和 Address 两种预测的训练，再分别给 Value 和 Address 设置各自的 Prediction Table 对于learning table , 感觉确实是常规字段 ，pc索引, 保存地址 ， 一些判定标志位， 置信度 ， 这种是不是就是cam 结构， pc是并行的去访问所有表项然后进行判断的 ， value 的优先级更高 ， 诶， 其实这种应该相当于全相联的cache\nvalue prediction 也分配pc表项，确保它也能够被直接读取\n专利中给出了一种可能的 Learning Table 的 Entry 的字段：\nStatus: 状态，比如 Valid，Age，Priority 等等 PC tag: 区分不同 Load，Full Tag Predicted address：预测的访存地址 Stride or value：适用 Address 还是 Value Prediction Predicted stride/hash of value：预测的 Stride 或者 Value 的哈希 Striding load indicator: 是否是 Striding Load Confidence level：预测的信心 Allocated in prediction table?：是否在 Prediction Table Number of consecutive mis-predictions：连续的错误预测次数 接下来讨论一条 Load 指令的训练过程：\n当一条 Load 指令第一次进入 Prediction Table 时，还不知道它是否能够被预测，它的 Address 还是 Value 能够被预测，此时它的地址和数据会记录在 Prediction Table 当中\n当这条 Load 再次被执行时，如果它的值和上一次相同（使用哈希判断，节省开销，当然也可能出错），则标记为 Value 预测模式；如果值不相同，那就把这次 Load 的地址减去上一次 Load 的地址作为 Stride 保存下来，标记为 Address 预测模式\n在 Value 预测模式下，持续跟踪 Load 的值是否预测正确：\n如果 Value 预测正确，则累积 Confidence 当 Confidence 超过阈值时，在 Value Prediction Table 中分配，启动 Value 预测 如果 Value 预测失败，则结束 Value 预测，切换到 Address 预测模式 在 Address 预测模式下，持续跟踪相邻两次 Load 的地址的差值：\n如果发现连续两次访问的 Stride 相同，则标记为 Striding Load 反过来，如果两次访问的 Stride 不同，则取消 Striding Load 标记，重新识别 Load 的类型 如果 Striding Load 的 Stride 预测正确，则累积 Confidence 当 Confidence 超过阈值时，在 Address Prediction Table 中分配，启动 Address 预测 接下来分析 Value Prediction Table，专利中给出了一种可能的 Value Prediction Table 的 Entry 的字段：\nStatus: 状态 PC tag：区分不同 Load，Full Tag Value acquired：数据是否已经保存到 Data 字段，如果没有，需要发送一个 Probing load 去把数据取进来 Probe Sent：标记是否已经发送 Probing load，避免重复发送 Data：记录了预测的数据 LRU：维护 LRU 信息 接下来分析 Address Prediction Table，专利中给出了一种可能的 Address Prediction Table 的 Entry 的字段：\nStatus: 状态 PC tag：区分不同 Load，Full Tag Predicted Address：预测要访问的地址 Predicted Stride：预测的地址跨步 Striding load indicator：标记是否为 Striding Load Intermittent striding loads：记录跨步访存的进度 stable load 论文 Constable: Improving Performance and Power Efficiency by Safely Eliminating Load Instruction Execution 指出，很多 Load 指令总是从相同的地址取出相同的值，对于这种 Load 指令（称为 Stable Load），可以通过硬件的扩展来优化，提升性能。它是这么做的：\n检测这样的 Stable Load：Load 执行的时候，判断这次的 Load 地址和数据，与同一个 PC 的上一次 Load 是否相同，如果相同，就增加置信度 如果一段时间内地址和数据都不变（通过置信度判断），认为这是一个可以消除的 Stable Load 消除的方法是，直接把 Load 的数据复制给目的寄存器，跳过了地址计算，也不用访存 在 Register Monitor Table 中记录 Stable Load 使用的源寄存器，如果这些寄存器被修改了，那么大概率地址会发生变化，不再消除这条 Stable Load 在 Address Monitor Table 中记录 Stable Load 访问的地址，如果对这个地址有写入操作，或者被其他核心访问，那么大概率数据会发生变化，不再消除这条 Stable Load 这篇论文可以认为是 Load Value Prediction 的变体：缩小 Load 指令优化的范围，只考虑数据 Constant 且源地址寄存器不变的 Load，此时不再需要去读缓存来验证正确性，同时也省去了地址的重复计算（Load Value Prediction 中，因为没有跟踪寄存器的变化，所以预测时，还是需要重新计算地址，去查询缓存或者 Constant Verification Unit）。\n感觉挺难满足要求的， 对于一个pc值，又要address 相同，又要data 相同 ，如果置信度够高 ， 直接进行数据复制 ， 访存和地址计算都不用了 ，条件挺苛刻的\ndata prefetch 数据预取的目的是预测程序的访存模式，提前把数据准备到缓存当中，提升缓存的命中率。以 AMD Zen 5 为例，它实现了这些预取器（来源：Processor Programming Reference (PPR) for AMD Family 1Ah Model 24h, Revision B0 Processors）：\nL2 Up/Down Prefetcher: uses memory access history to determine whether to fetch the next or previous line into L2 cache for all memory accesses. L2 Stream Prefetcher: uses history of memory access patterns to fetch additional sequential lines into L2 cache. L1 Region Prefetcher: uses memory access history to fetch additional lines into L1 cache when the data access for a given instruction tends to be followed by a consistent pattern of other accesses within a localized region. L1 Stride Prefetcher: uses memory access history of individual instructions to fetch additional lines into L1 cache when each access is a constant distance from the previous. L1 Stream Prefetcher: uses history of memory access patterns to fetch additional sequential lines into L1 cache. 简单来说，Stream Prefetcher 就是取一段连续的 Cache Line，Stride Prefetcher 则是根据 Stride 去预取数据，未必是连续的 Cache Line，Up/Down Prefetcher 更好理解，就是取相邻的一个 Cache Line。Region Prefetcher 则比较复杂，属于 Spatial Prefetcher 的一种。\nIntel 的处理器通过 MSR 1A4H 可以配置各个预取器：\nthe L2 hardware prefetcher, which fetches additional lines of code or data into the L2 cache. the L2 adjacent cache line prefetcher, which fetches the cache line that comprises a cache line pair (128 bytes). 这和 AMD 的 Up/Down Prefetcher 应该是一个意思 the L2 Adaptive Multipath Probability (AMP) prefetcher. 根据专利 Systems and methods for adaptive multipath probability (amp) prefetcher 的描述，这个应该属于 Spatial Prefetcher the L1 data cache prefetcher, which fetches the next cache line into L1 data cache. 这个应该属于 Next Line Prefetcher the L1 data cache IP prefetcher, which uses sequential load history (based on instruction pointer of previous loads) to determine whether to prefetch additional lines. Spatial Prefetching 的思想是这样的：程序经常会访问数组，那么对数组每个元素的访问模式，应该是类似的。比如访问数组前十个元素有某种规律，那么访问接下来的十个元素应该也有类似的规律，只是地址变了而已。如果这个数组的元素的结构比较复杂，这个访存模式（例如从 0、256 和 320 三个偏移分别读取数据）可能既不满足 Stride 又不满足 Stream，此时就需要 Spatial Prefetcher 来介入。例如程序在同一个物理页内，总是会从 A、B、C 和 D 四个页内偏移读取数据，那么当程序从页内偏移 A 读取一个新的物理页的数据时，大概率新的物理页内 B、C 和 D 偏移处的数据将来会被读取，那就预取进来。\n一种 Spatial Prefetcher 实现是 Spatial Memory Streaming (SMS)。它的做法是，把内存分成很多个相同大小的 Region，当缓存出现缺失时，创建一个 Region，记录这次访存指令的 PC 以及访存的地址相对 Region 的偏移，然后开始跟踪这个 Region 内哪些数据被读取了，直到这个 Region 的数据被换出 Cache，就结束记录，把信息保存下来。以上面的 0、256 和 320 为例子，访问 0 时出现缓存缺失，那就创建一个 Region，然后把 256 和 320 这两个偏移记下来。当同一条访存指令又出现缺失，并且偏移和之前一样时，根据之前保存的信息，把 Region 里曾经读过的地址预取一遍，按上面的例子，也就是 256 和 320。这里的核心是只匹配偏移而不是完整的地址，忽略了地址的高位，最后预取的时候，也是拿新的导致缓存缺失的地址去加偏移，自然而然实现了平移。从 AMD 的专利 DATA CACHE REGION PREFETCHER 来看，AMD 的 L1 Region Prefetcher 应该采用的是 SMS 的思想，缓存缺失时，创建一个 Region，记录这个 Region 中哪些数据被访问了。\n另一种 Spatial Prefetcher 实现是 Variable length delta prefetcher (VLDP)，它的思路是，对访存序列求差分，即用第 k 次访存地址减去第 k-1 次访存地址，得到 Delta 序列，然后对当前的 Delta 序列，预测下一个 Delta，那么预取的地址，就是 Delta 加上最后一次访存的地址。从 Intel 的专利 Systems and methods for adaptive multipath probability (amp) prefetcher 来看，它的 AMP Prefetcher 实现思路和 VLDP 类似，专利中给出了一个例子：\n假如程序对某个物理页的访存模式是：0, 2, 4, 16, 15 求差分，得到：+2, +2, +12, -1 那么 AMP 预测器要做的就是： 无历史时，预测第一个差分值：N/A -\u0026gt; +2 第一个差分是 +2 时，预测第二个差分值：+2 -\u0026gt; +2 已知前两个差分时，预测第三个差分值：+2, +2 -\u0026gt; +12 已知前三个差分时，预测第四个差分值：+2, +2, +12 -\u0026gt; -1 sms 根据某一个物理页的访存模式去预测其他区域的 ， VLDP根据差值预测\n不过 Spatial Prefetcher 遇到动态分配的不连续的数据结构就犯了难（比如链表和树），因为数据在内存里的分布比较随机，而且还有各种指针，要访问的数据之间的偏移大概率是不同的。这时候就需要 Temporal Prefetcher，它的思路是跟踪缓存缺失的历史，如果发现当前缺失的地址在历史中曾经出现过，那就预取在历史中紧随其后的几次缓存缺失。比如链表节点按顺序是 A、B 和 C，第一次访问时，按照 A B C 的顺序出现缓存缺失，这些缺失被记录在历史当中；未来如果再次访问 A，预取器在历史中找到 A 的位置，发现其后的缓存缺失为 B 和 C，那就对它们进行预取。就好像预取器自己存了一份链表，提前去查后继的节点，也可以说是 Record and Replay 思想的实践。\n附录 参考文献 浅谈乱序执行\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-11T21:45:42+08:00","permalink":"https://VastCircle.github.io/2025/%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/","title":"乱序访存单元"},{"content":"还是想好好理解一下分支预测\n可以先看一下现代分支预测——从学术界到工业界\n分支预测的历史 gShare预测器 全局分支预测器\nGShare 预测器将分支的 PC 与一个全局历史寄存器 XOR 以后作为 index 来选择 PHT 中的一个饱和计数器，然后使用这个计数器给出预测方向，更新时同样也通过同样的方式索引到同一个饱和计数器并更新。\n这种方式将不同全局分支历史下的同一条分支的预测分给了不同的饱和计数器，使得 GShare 预测器能够区分不同的历史。这样做带来的第一个好处是能够正确预测循环退出了。另一个好处是，分支之间的相关性可以得到有效利用，\n锦标赛预测器 由局部历史和全局历史的两个预测器分别独立预测，然后再由一个饱和计数器构成的选择结构选择使用哪个子预测器提供的方向预测。\n现代的分支预测器算法只有一种——TAGE，几乎所有的学术研究和商业高性能处理器都使用 TAGE 或者 TAGE 的变种。TAGE 预测器是最早在 2006 年由 Andre Seznec 提出的，提出当时即获得当届分支预测锦标赛冠军。然后接下来直到 2016 年的所有分支预测锦标赛都由TAGE预测器的变种获得。\nTage分支预测器 附录 参考文献 现代分支预测——从学术界到工业界\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-10T20:34:57+08:00","permalink":"https://VastCircle.github.io/2025/%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B/","title":"分支预测"},{"content":"摘要 应用程序广泛使用具有规则且固定布局的数据对象，这导致内存区域访问模式的重复出现。空间数据预取技术利用这一现象来预取未来的内存引用，并隐藏DRAM访问的长延迟。尽管当前最先进的空间数据预取器在减少数据未命中的数量上是有效的，但我们观察到仍有显著的改进空间。为了选择预取的访问模式，现有的空间预取器将观察到的访问模式与高重复概率的短事件或低重复概率的长事件关联。因此，预取器要么提供低准确性，要么错失重要的预测机会。我们发现，将观察到的空间模式仅与单一事件关联会显著限制空间数据预取器的有效性。本文主张将观察到的空间模式同时与短事件和长事件关联，从而在不失去预测机会的同时实现高准确性。我们提出了Bingo空间数据预取器，在其中短事件和长事件用于选择最佳的预取访问模式。我们提出了一种高效的Bingo设计，仅需一个历史表来维护访问模式与长短事件之间的关联。通过对一组大数据应用程序的详细评估，我们展示了Bingo比没有数据预取器的基线系统提高了60%的性能，并比最好的现有空间数据预取器提高了11%的性能。\nintroduction 长延迟的外部内存访问是许多大数据应用的一个众所周知的性能瓶颈。由于处理器与外部内存之间速度不匹配，每次DRAM访问时，处理器可能会因停滞而延迟数百个周期，导致显著的性能损失。如今，高度推测性和深度流水线化的乱序处理器最多只能容忍一级数据缓存未命中，并且在进行外部内存访问时会遭遇相当大的性能惩罚[1]，[2]，[3]，[4]，[5]，[6]，[7]。\n传统上，处理器设计师通过增加片上缓存的容量来提高命中率，从而减少外部内存访问的次数。然而，这种方法在今天的处理器上应用越来越少，因为它会导致缓存命中延迟的增加[3]，[8]，[9]，[10]。此外，使用硅片资源增加核心数量比扩大缓存更具优势[3]，[8]，[9]。最后，应用程序数据集的持续增长（例如图形处理和机器学习）导致数据集达到数百GB甚至几个TB，这比当前活动芯片上最大可能的缓存大几个数量级。\n为了弥合处理器与内存之间的性能差距，系统架构师使用了各种工具。数据预取就是其中之一，已证明它在减缓缓存未命中的延迟方面具有巨大的潜力[11]，[12]，[13]。数据预取是预测未来内存访问并在处理器明确请求之前将那些不在缓存中的数据提前加载，以隐藏外部内存访问的长延迟。如今，几乎所有高性能处理器都使用数据预取（例如Intel Xeon Phi [14]、AMD Opteron [15]和UltraSPARC III [16]），以应对规则和/或不规则的内存访问模式。\n空间数据预摘要通过依靠空间地址相关性来预测未来的内存访问：多个内存1页之间访问模式的相似性。也就是说，如果一个程序访问了第A页的位置{x，y，z}，则可能会在将来触摸{x，y，z}位置的{x，y，z}位置。访问模式证明了空间相关性，因为应用程序使用带有常规和固定布局的数据对象，并且当数据结构遍历数据时访问[17]，[18]。\n每当应用程序请求页面时，空间数据预摘要（例如[18]，[19]，[20]，[21]）会观察到页面的所有访问，并记录一个足迹，指示页面的哪些块由页面使用。应用程序。然后，它将足迹与一个事件关联，并将〈事件，足迹〉对存储在历史表中，以便未来事件再次发生时使用记录的足迹。事件通常从触发访问中提取，即访问页面的第一次访问[2]。当相同的事件发生时，空间预取器使用记录的足迹来预取当前请求页面的未来内存引用。\n与其他类型的数据预取器（例如时间数据预取器[22]，[23]，[24]，[25]，[26]，[27]，[28]）相比，空间数据预取器对元数据的存储需求低得多。此外，空间预取器通过将从相似页面学到的访问模式推广到新的未观察到的页面，可以预取性能关键的强制未命中（即未曾见过的缓存未命中），从而显著提高系统性能。最后，正如最近的研究所显示[29]，空间预取器不仅通过减少外部内存访问的次数提高了性能，还通过减少能耗高的DRAM行激活次数提高了内存系统的能效。\n传统上，未命中覆盖率（即预取器消除的缓存未命中的比例）是预取器设计中的主要考虑因素。因此，预取器在消除缓存未命中的能力上不断提高，而存储效率和预取准确性等其他因素则被边缘化。然而，随着多核处理器的广泛应用，存储需求和预取准确性等其他因素变得越来越重要。硬件优化器（如预取器）的存储开销应该尽可能小；否则，可能需要消除该优化器并将其硅片资源用于增加核心数量[30]。预取准确性也变得至关重要，因为高核心数量已将设计推向内存带宽瓶颈，主要是由于引脚数量扩展性差[31]，[32]，[33]，[34]，[35]，[36]。因此，预取器应具有很高的准确性，以高效利用有限的DRAM模块带宽[37]，[38]，[39]，[40]，[41]。在这两者中，预取准确性比存储效率更为重要，因为设计通常首先遇到带宽瓶颈[8]，[9]，[42]，[43]。\n受TAGE[44]（一种最先进的分支预测器）启发，许多近期的研究通过使用多个级联历史表提高了基于预测器的硬件优化器的效率。在这种策略中，预取器不是依赖单个历史表来预测未来事件（如图1-(a)所示），而是使用多个具有特定信息的历史表来进行预测（如图1-(b)所示）。这些表存储长短事件的历史。长事件指的是几个特定事件的同时发生。例如，“使用指令I5访问页面P2的第3个缓存块”可以被视为一个长事件（多个事件的共同发生）。另一方面，短事件指的是少数特定事件的同时发生。例如，“执行指令I5”可以视为一个短事件（仅一个事件）。\n每个级联历史表在TAGE类似预测器中存储特定长度的事件历史，并对存储的事件之后的发生进行预测。基于长事件做出的预测预计准确性较高，但长事件再次发生的概率较低。因此，如果一个预测器仅依赖长事件的历史，它很少能做出预测（但当做出预测时，准确性很高）。相反，短事件的重复发生几率较高，但基于这些事件的预测不如基于长事件的预测准确。为了兼得两者，TAGE类似的预测器记录长短事件的历史。每当需要预测时，它们依次检查历史表，从最长的历史表（最准确但最少发生）开始做预测。如果无法做出预测，则切换到下一个最长的历史表，重复此过程。这一过程使得预测器能够尽可能准确地进行预测，同时不会错失预测机会。\n许多先前的工作通过使用TAGE类似策略提高了各种基于预测器的硬件优化器的效率。TAGE类似策略被用于分支预测[46]，[47]，[48]，数据预取[28]，[49]，[50]，数据值预测[51]，[52]，[53]，内存依赖预测[54]，[55]，缓存命中/未命中预测[56]，近似计算中的质量预测[57]，基于预测的DRAM调度[58]，以及指令类型预测[59]等。\n本文在空间数据预取的背景下借鉴了这一思想，并提出了Bingo，一个高效的机制来识别并预取空间相关的数据访问。Bingo像先前的方法（例如[17]，[18]，[19]，[20]，[21]）一样，将每个页面的足迹存储为元数据，但不同的是，它将每个足迹与多个事件关联。每当需要进行预取时（即触发访问发生时），Bingo找到与最长发生事件关联的足迹。因此，Bingo发出准确的预取请求而不失去预取机会，主动为处理器提供所请求的数据。\nBingo的朴素实现需要为预取器分配多个历史表来存储元数据。在这种实现中，每当需要存储一个足迹时，它会被插入到所有元数据表中，并在每个表中将其分配给不同长度的事件。这种方法，如图1-(b)所示，已经被先前的TAGE类似预测器采用，但它会带来显著的面积开销。我们观察到，在空间数据预取的背景下，级联TAGE类似表中存储的大部分元数据是冗余的。为了有效消除这些冗余，我们提出了一种优雅的解决方案，将所有历史表的元数据合并为一个统一的表。通过这一实现，单个历史表将被多次查找，每次使用不同的事件查找与最长事件相关的预测（如图1-(c)所示）。通过在一个历史表中组织元数据，我们大大减少了Bingo的存储需求。本文的贡献如下： • 我们证明了仅依赖单个事件来发出预取请求是当前空间数据预取器低效的主要来源。 • 我们提出了一个TAGE类似的预测器，以准确地最大限度地提取空间相关的数据访问模式。 • 我们建议了一种将多个历史表合并为一个统一元数据表的方案，从而显著减少了存储需求。 • 综合以上，我们提出了一种名为Bingo的空间数据预取器，并对其在各种大数据应用中的表现进行了细致评估。我们显示，Bingo在没有预取器的基准系统上提高了60%的平均性能，最高提升了285%，同时比最好的现有空间数据预取器提高了11%的平均性能，最高提升67\nII. 背景 现代大数据应用处理的数据集远远超过了容量有限的缓存，因此这些数据集存储在内存中。因此，执行这些工作负载的处理器会遇到频繁的缓存未命中，导致核心停顿，从而造成显著的性能损失 [3]，[4]，[28]，[34]，[60]，[61]。空间数据预取器 [18]，[19]，[20]，[21]，[50]，[62]，[63]，[64]，[65]，[66] 通过根据内存页面之间访问模式的相似性来预取未来的内存引用，从而减少缓存未命中的数量。空间数据预取由于其固有的独特优势，长期以来被认为是有效的。\n首先，与其他类型的数据预取器（如时间数据预取器 [22]，[23]，[24]，[25]，[26]，[27]，[28]）相比，空间数据预取器需要的元数据存储空间要少几个数量级。与时间预取器不同，空间预取器仅需要存储一个偏移量（即块地址与页面开始位置的距离）或一个增量（即两个连续访问之间的距离），而不需要存储完整的地址。因此，它们在存储元数据时需要显著更少的存储空间。此外，在空间预取中，页面边界内的访问顺序不太重要，因此无需记录页面内的访问顺序，这进一步减少了存储需求。由于空间预取器训练和预取的内存页面通常小于或等于一个DRAM行（例如，1-2 KB，相比2-8 KB），所有随触发访问一起发送的预取请求都能享受行缓冲区命中，因此它们都会迅速被提取并缓存到最后一级缓存（LLC）中，从而减轻了提取顺序的影响 [29]。\n空间数据预取器的另一个同样显著的优点是它们能够消除强制缓存未命中。强制缓存未命中是某些应用程序中性能下降的主要来源，例如扫描主导的工作负载，在这些工作负载中，扫描大量数据会产生大量未曾缓存的内存访问。通过利用在过去页面中观察到的模式来推测新的未观察页面的访问，空间预取器可以缓解强制缓存未命中，显著提升系统性能。\n最后，一个准确的空间数据预取器不仅能提高性能，还能改善内存子系统的能耗。空间数据预取器通过精确预测即将使用的缓存块，并在一次DRAM行激活中提取所有有用的缓存块，增加了DRAM行缓冲区命中率。通过这种方式，它们避免了如果没有空间预取器的话，可能会发生的多次能量消耗大的DRAM行激活 [29]。\n先前的工作：按页面历史（PPH）与共享历史（SHH） 先前关于空间数据预取的研究大致分为两类：按页面历史（PPH）方法和共享历史（SHH）方法。PPH方法为每个页面记录一个访问历史（通常是页面足迹），然后将记录的历史与某个事件相关联，最后将历史存储在元数据表中。另一方面，SHH方法在全局级别上观察所有访问，并将历史信息（通常是增量）存储在共享的元数据结构中。SHH方法优先考虑存储效率，通常维持一个单一的元数据结构来记录所有页面观察到的模式。也就是说，它们不为每个页面存储模式，而是将各个页面中观察到的访问模式融合为一个统一的组织。例如，一个基于增量的SHH预取器（例如 [50]）可能会观察到页面P1中的三个连续访问：A1、A2和A3，并生成两个连续的增量d1和d2（d1 = A2 − A1，d2 = A3 − A2）。在这种情况下，它不会记录“在页面P1中观察到A1、A2和A3”，而是将“d2跟随d1”记录在全局元数据历史中。SHH策略显著减少了预取器的存储需求，但也显著降低了预取器在使用〈d1，d2〉相关条目时，若该页面的行为与P1不同，消除缓存未命中的能力。\nSHH方法中的另一个重要挑战是预取程度：预取器一次发出的请求数量。在PPH方法中，如我们稍后讨论的，每当触发预取器时，它会一次性获取所有根据页面足迹确定的预期使用的块。然而，在SHH方法中，由于没有这样的详细信息，预取器不知道应该发出多少预取请求，以确保及时接收到所需的块。例如，基于SHH的方法SPP [62] 提出了自适应限制预取程度的技术：只有当该预测的估计准确性超过某个阈值时，才会发出预取请求。虽然这样的启发式方法在控制预取程度方面可能是有用的，但它们使得预取器的未命中覆盖率和及时性变得越来越依赖于这些限制决策的准确性。\nPPH方法 PPH方法在应用程序首次请求页面时（即触发访问）开始观察并记录该页面的后续访问，只要该页面仍被应用程序使用。当该页面不再使用时（即页面居住期结束），这些方法会将记录的访问模式与某个事件相关联，并将〈事件，模式〉对存储在它们的历史表中。记录的历史通常是一个位向量，称为页面足迹，其中每个位代表页面中的一个块：位为‘1’表示该块在页面居住期间已被访问，而‘0’则表示未被访问。与页面足迹相关联的事件通常是从触发访问中提取的。例如，Kumar和Wilkerson [17] 提出了使用触发访问的‘PC+地址’作为事件：触发指令的‘PC’与触发指令请求的‘地址’相结合。作为另一个例子，Somogyi等人 [18] 评估了几种启发式方法作为事件，经过实验证明，‘PC+偏移量’比其他方法更有效：触发指令的‘PC’与请求的缓存块距离页面开头的‘偏移量’结合。稍后，在相同事件（例如，对于‘PC+偏移量’，具有相同‘PC’的指令请求位于页面中偏移量位置的缓存块）再次出现时，这些预取器将存储的足迹应用于预测并预取当前请求页面的未来内存引用。\n与这些方法相关的挑战之一是如何找到最佳的事件，将页面的足迹与之关联。每种启发式方法都有其优缺点。例如，在提到的两种事件中，‘PC+地址’ [17] 非常准确，因为它会保守地等待相同的指令重新执行并访问相同的地址。尽管准确，但这种方法无法覆盖强制缓存未命中，因为必须请求相同的页面才能使用存储的足迹。另一方面，‘PC+偏移量’ [18] 是一种激进的方法，可以通过将一个页面的足迹信息应用到另一个页面来覆盖强制未命中，但基于它的预测并不十分准确。本文提出，单纯依赖其中一种启发式方法是次优的，应该采用一种机制，将每个足迹与多个事件相关联，并选择最匹配的事件进行预取。\nIII. 动机 计划设计一个高性能的空间数据预取器，我们将 Bingo 的设计空间缩小到基于 PPH 的方法。图 2 显示了将页面足迹与不同事件关联时，各种启发式方法的准确性和匹配概率，数据是对所有应用的平均值。准确性是指所有预取的缓存块中，在被驱逐之前已被处理器使用的百分比，而匹配概率是指在历史表中找到事件的比例。随着事件长度的增加，预测的准确性提高，而匹配概率通常下降。在评估的启发式方法中，‘PC+地址’是最长的事件（即同一指令和同一地址应该同时发生），它提供了最高的预测准确性，但由于该事件重新发生的概率低，因此预测的机会较少。因此，如果预取器仅依赖此事件，其预测准确，但无法频繁做出预测。另一方面，随着事件变短，预测的准确性降低，但预测的机会通常增加。‘偏移量’作为事件，是评估方法中最短的事件（即一个块距离页面开始的偏移量应该重新出现），它具有较高的预测机会，但预测的准确性不如较长事件。因此，如果预取器仅使用此事件，它将能够频繁发出预取请求，但预取的准确性将不令人满意。这个观察结果促使我们提出了一种机制，使用多个事件来做出预测。一旦记录了页面足迹，它将与多个事件相关联，然后存储在历史表中。也就是说，页面足迹会与‘PC+地址’、‘PC+偏移量’和‘PC’等事件相关联，并存储在历史表中。每当预取时机到来（即触发访问发生），预取器首先查找最长事件（即‘PC+地址’）的历史记录：如果找到匹配，预取器将基于匹配的足迹发出预取请求；否则，它将递归地查找下一个最长的事件（即‘PC+偏移量’）。通过这种方式，预取器能够兼顾高准确性和高预测机会，克服了先前提出的空间预取器的局限性。\n为了证明使用多个事件的重要性，图 3 显示了一个空间预取器的失效覆盖率和准确性，当关联页面足迹的事件数从一个增加到五个时的表现。当事件数为一个时，预取器始终将页面足迹与最长的事件（即‘PC+地址’）关联。随着事件数的增加，预取器能够将页面足迹与更短的事件关联。当事件数为五个时，预取器能够将页面足迹与所有事件关联，包括最短的事件（即‘偏移量’）。如图 3 所示，增加事件数使得预取器能够覆盖更多的缓存未命中，同时保持较高的预取准确性。我们观察到，当事件数从一个增加到两个时，预取器的失效覆盖率显著提高，获得了最大的改进。然而，增加事件数超过两个，并未带来显著的提升；因此，为了简化设计，我们为提出的空间预取器 Bingo 使用了两个事件。\nIV. Bingo空间预取器 像先前的工作[18]一样，Bingo使用一个小型辅助存储来记录空间模式，在处理器访问空间区域时。当访问到一个新页面（即触发访问）时，Bingo为该页面分配一个条目并开始记录其足迹。在页面的驻留期结束时（即当页面中的一个块被使无效或从缓存中驱逐时[18]），Bingo将记录的模式转移到其历史表中，并释放辅助存储中的相应条目。与先前的工作不同，Bingo使用‘PC+地址’和‘PC+偏移量’这两个事件进行预取。Bingo的一个简单实现需要两个不同的历史表，就像之前的TAGE类方法一样。一个表维护在每次‘PC+地址’之后观察到的足迹历史，另一个表则存储与‘PC+偏移量’相关联的足迹元数据。在查找要预取的模式时，逻辑上，首先使用触发访问的‘PC+地址’来查找长历史表。如果找到匹配，则利用对应的足迹发出预取请求。否则，使用触发访问的‘PC+偏移量’来查找短历史表。如果找到匹配，则使用匹配条目的足迹元数据进行预取。如果没有找到匹配条目，则不发出预取请求。然而，这样的实现会带来显著的存储开销。\n我们观察到，在空间数据预取的背景下，级联的TAGE类历史表中存储的元数据中有相当一部分是冗余的。冗余是指两张元数据表（长事件和短事件相关联的表）提供相同预测的情况。图4展示了TAGE类历史表在空间预取中的冗余。在这个实验中，每次空间预取器需要做出预测时，我们都会确定长事件和短事件是否提供相同的预测。如图所示，冗余性相当高，从SAT Solver中的26%到Mix2中的93%不等。\n为了有效地消除元数据存储中的冗余，我们提出了不使用多个历史表，而是使用单一历史表并多次查找，每次查找使用不同的事件。图5详细说明了我们为Bingo设计的实际方案，它只使用一个历史表。其主要思想基于短事件是由长事件所承载的事实。也就是说，通过获取长事件，我们可以知道短事件是什么，只需要忽略长事件的部分内容。对于Bingo来说，‘PC+偏移量’的信息被承载在‘PC+地址’中；因此，通过知道‘PC+地址’，我们也知道‘PC+偏移量’是什么。\n为了利用这一现象，我们提出只使用一个历史表，该表只存储长事件的历史，但使用长事件和短事件多次查找它。对于Bingo来说，历史表存储的是每个‘PC+地址’事件后观察到的足迹，但使用触发访问的‘PC+地址’和‘PC+偏移量’来查找，以在不失去预取机会的同时提供高准确性。为了实现这一点，我们发现该表应仅使用短事件的哈希来索引，而用最长事件进行标记。\n具体而言，在Bingo中，每当新的足迹要存储到元数据组织中时，它会与相应的‘PC+地址’相关联。为了在历史表中找到新条目的位置，只使用‘PC+偏移量’的哈希来索引表。通过知道集合，基线替换算法（如LRU）被用来选择一个牺牲者，为存储新条目腾出空间。确定位置后，条目存储在历史表中，但所有的‘PC+地址’位被用来标记该条目。\n每当需要进行预测时，历史表首先用最长事件进行查找；如果找到匹配，则会用它来做出预测。否则，表应该使用下一个较长的事件进行查找。由于长事件和短事件都映射到同一个集合中，因此无需检查新集合；相反，只需测试同一集合中的条目，以找到与短事件匹配的条目。对于Bingo，表首先用触发访问的‘PC+地址’进行查找。如果找到匹配，则使用对应的足迹元数据发出预取请求。否则，表应使用触发访问的‘PC+偏移量’进行查找。由于我们知道‘PC+地址’和‘PC+偏移量’都映射到同一个集合，因此不需要检查新集合。也就是说，所有对应的‘PC+偏移量’条目应该都在同一个集合中。因此，我们测试同一集合中的条目，以找到匹配项。然而，在这种情况下，并不是所有存储在条目中的标签位都是必需的匹配位；只有‘PC+偏移量’位需要匹配。\n通过这种方式，我们将每个足迹与多个事件（即‘PC+地址’和‘PC+偏移量’）相关联，但仅使用其中一个（较长的）来存储足迹元数据，从而减少存储需求。这样，冗余性就自动消除了，因为元数据足迹只与‘PC+地址’标签一起存储。在我们提出的设计中，每当表使用较短事件查找时，可能会找到多个匹配项。对于Bingo来说，可能没有任何条目与触发访问的‘PC+地址’匹配，同时，多个条目与访问的‘PC+偏移量’匹配。这种情况给Bingo带来了挑战，它应根据可能不同的多个足迹信息发出预取请求。在这种情况下，可以采用多种启发式方法：例如，基于最近性信息选择最新的足迹，或者为所有匹配条目的足迹中指出的块发出预取请求。我们评估了许多这样的启发式方法，并通过实验证明，考虑所有匹配的足迹信息在发出预取请求时可以获得最佳性能：如果至少20%的匹配条目中包含一个缓存块，则会对该块进行预取。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-06T21:30:21+08:00","permalink":"https://VastCircle.github.io/2025/bingo_spatial_data_prefetcher/","title":"Bingo_Spatial_Data_Prefetcher"},{"content":"摘要 先前的研究表明，应用程序的内存访问模式存在较大的空间变化。然而，现代内存系统使用小的固定大小的缓存块，因此无法利用这些变化。增加缓存块大小不仅会极大地增加引脚和互连带宽的需求，还会增加在共享内存多处理器中发生虚假共享的可能性。本文表明，商业工作负载中的内存访问通常表现出跨越大内存区域（例如，几kB）的重复布局，并且这些访问以可以通过基于代码的关联来预测的模式重复出现。我们提出了一种称为空间内存流的实用片上硬件技术，该技术识别代码相关的空间访问模式，并在需求缺失之前将预测的块流式传输到主缓存中。通过对商业和科学应用进行周期精确的全系统多处理器仿真，我们展示了空间内存流平均可以预测58%的L1缓存缺失和65%的芯片外缓存缺失，平均性能提高37%，最佳性能提升可达到307%。\n1.引言 糟糕的内存系统表现限制了高端服务器中商业应用的性能。在商业在线事务处理（OLTP）、决策支持系统（DSS）和Web服务器工作负载中，一半到三分之二的执行时间都花费在与内存系统相关的停顿上[2, 3, 13, 21, 26, 30]。这些工作负载对系统设计师提出了挑战，因为它们依赖于复杂的算法和数据结构，具有较大的代码占用，操作的数据集远超物理内存，并使用精密的细粒度同步来最大化并发性。\n微架构创新，如乱序执行、非阻塞缓存和预执行[19]，通过增加芯片外内存级并行性（MLP）来提高内存系统性能。然而，为了发现并行缺失，这些方法必须正确预测和执行指令流，这限制了它们可以探索的指令窗口的深度。在OLTP和Web应用中，由于频繁且长时间的依赖内存访问链条，这些创新带来的好处有限[21, 30]。尽管现代服务器提供了丰富的内存带宽[7]，但由于这些依赖链条严重限制了可用的内存级并行性，内存系统仍然未被充分利用——有研究报告称，在当前一代乱序系统上，这些应用的平均并行芯片外缺失仅为1.3[6]。增强并行性并隐藏内存访问的延迟是服务器性能提升的关键。\n尽管计算机架构师在通过内存预取或流式传输提高桌面和科学应用的内存级并行性和隐藏内存延迟方面取得了巨大成功（例如，[18, 20, 24, 25, 29]），但很少有研究成功地改善商业应用的内存系统性能。指令流缓冲器减少了主指令缓存的停顿[21]。软件预取可以加速某些数据库操作，如哈希连接[5]。时间流式传输通过流式传输重复的、时间相关的协同缺失序列来减少一致性停顿[30]。然而，这些方法都仅针对有限类别的内存访问，仍有相当一部分内存停顿未被消除。\n尽管复杂，商业应用程序仍然使用具有重复布局和访问模式的数据结构——例如数据库缓冲池页或网络数据包头。当这些应用遍历数据集时，访问数据的相对偏移中会出现重复的模式。不幸的是，这些访问通常是非连续的，并且不遵循常数步幅（例如，B树中的二分查找）。由于稀疏模式可能跨越大区域（例如操作系统页），我们使用“空间相关性”而非“空间局部性”来描述访问之间的关系。增加缓存块大小以捕获空间相关性会导致存储和带宽利用效率低下。\n过去关于单处理器系统的研究表明，可以通过将模式与启动模式的代码和/或数据地址关联来预测空间相关性[4, 17]。尽管现有的空间模式预取设计对于桌面/工程应用有效[4]，但在服务器工作负载上进行评估的唯一实际实现提供的缺失率减少不到20%[17]。\n在本文中，我们重新考虑了空间相关访问模式的预测和流式传输，以提高内存级并行性（MLP）并隐藏二级缓存和芯片外内存访问的长延迟。我们的设计——空间内存流（SMS）——以商业服务器应用为目标，可以减少多处理器服务器中主缓存和芯片外缺失。SMS利用重复的访问模式来预测并在需求缺失之前将块流式传输到主缓存中。我们通过基于追踪和周期精确的全系统仿真，评估了SMS在科学和商业应用中的表现。该工作证明了以下几点：\n有效的空间相关性与预测。与之前的研究结果[17]相反，基于地址的相关性并不是预测商业工作负载访问流的必要条件。相反，我们展示了代码与访问模式之间的强相关性，SMS利用这一点来预测即使是之前未访问的地址的模式。由于独立代码序列远少于数据地址，SMS在存储相当的情况下提供了约四倍于基于地址的预测器的预测覆盖率。 精确的空间相关性跟踪。我们展示了在之前的研究中使用的与缓存耦合的结构（[4, 17]）对于观察空间相关性并不理想。对多个独立模式的访问通常是交错的，这会在之前的检测结构中引发冲突行为。相反，我们提出了一种解耦的检测结构，它识别较少且更密集的模式，从而将预测器存储需求减少一半，并且覆盖率提高了最多20%。 性能提升。对于商业工作负载，我们展示了SMS平均预测了55%，最佳可预测78%的芯片外读取缺失，提供了1.22倍的平均加速，最佳为1.48倍，相较于没有SMS的系统。相比之下，全球历史缓冲区（GHB）[20]，对于桌面/工程应用最有效的预取器，平均仅消除了30%的芯片外缺失，最佳为62%。在科学应用中，SMS与GHB的覆盖率相当，平均消除了81%的芯片外缺失，并提供了从1.26倍到4.07倍的加速。 本文其余部分的组织结构如下：第二部分描述了空间内存流（SMS），第三部分介绍了我们的硬件实现细节。第四部分评估了我们的设计并展示了性能结果。第五部分讨论了相关工作，第六部分给出了结论。\n2. 空间内存流（Spatial Memory Streaming） 空间内存流（SMS）通过利用数据之间的空间关系，超越单一缓存块，提升科学和商业服务器应用的性能。\n在选择缓存块大小时，系统设计师必须在空间局部性、传输延迟、缓存存储利用率、内存/处理器引脚带宽利用率和虚假共享等方面进行平衡。通常，最佳的缓存块大小会牺牲对密集数据结构的空间局部性利用机会，以避免对稀疏数据结构造成过度的带宽开销。对于简单数据结构（如数组），可以通过简单的预取方案，如步幅预取[24]，来利用空间关系。\n商业应用通常表现出复杂的访问模式，这些模式不适合简单的预取或流式传输方案。然而，这些应用中的数据结构常常会在缓存块之间表现出空间关系。例如，在数据库中，缓冲池中的页面共享常见的结构元素，如页面头部的日志序列号和页面底部的插槽索引，这些元素总是在扫描或修改页面之前被访问。在Web服务器中，数据包头部和尾部具有任意复杂但固定的结构。更多的示例如图1（左）所示。尽管这些结构内的访问可能是非连续的，但它们仍然在相对地址上表现出重复的模式。我们将这些访问之间的关系称为空间相关性。\nSMS在运行时提取空间相关的访问模式，并利用这些模式预测未来的访问。然后，SMS将预测的缓存块根据可用的资源和带宽尽可能快速地流式传输到处理器的主缓存中，从而增加内存级并行性，并隐藏较低级缓存和芯片外访问的延迟。\n2.1 空间模式与生成 我们将空间相关性的概念形式化，类似于先前关于空间足迹的研究[4, 17]。我们将一个空间区域定义为系统地址空间中的一个固定大小的部分，包含多个连续的缓存块。一个空间区域生成是指SMS在一个空间区域内记录访问的时间间隔。我们称空间区域生成中的第一次访问为触发访问（trigger access）。一个空间模式是一个位向量，表示在空间区域生成过程中访问的区域内的块集合。因此，空间模式捕获了在时间上相互接近的缓存块的布局。\n在触发访问时，SMS预测在空间区域生成过程中将被访问的空间模式。定义空间区域生成的精确时间间隔会显著影响空间模式的准确性和覆盖率[17]。必须定义一个生成间隔，以确保当SMS在未来的触发访问时将块流式传输到缓存中时，任何预测的块都不会在使用之前被逐出或失效。**因此，我们选择从触发访问开始，直到在生成过程中访问的任何块被替换或失效并从处理器的主缓存中移除为止。**对该区域中任何块的后续访问将作为新生成的触发访问。这个定义确保了在一个生成过程中访问的块是同时存在于缓存中的。\n某一个区域，第一次访问是触发访问， 如果该区域有内存块被移除，这个空间模式就结束了，下一次访问就是另一个空间模式的触发访问\n图1（右）展示了三个空间区域生成及其对应的模式的示例。\n2.2 识别重复的空间模式 在触发访问时，SMS预测区域内的块子集，这些块在空间上是相关的，因此可能会被访问**。因此，SMS中的一个关键问题是找到与重复空间模式强相关的预测索引。**空间相关性是由于数据结构的布局和访问模式中的重复性和规律性引起的。例如，空间相关性可能是因为多个变量或字段的聚合经常一起被访问。在这种情况下，空间模式与触发访问的地址相关，因为该地址标识了数据结构。空间相关性也可能是因为数据结构的遍历是重复的，或者具有规律的结构。在这种情况下，空间模式将与执行遍历的代码（程序计数器值）相关。\n文献中已研究了多种预测索引。所有先前的研究发现，结合地址和程序计数器来构造一个索引，能够在没有限制的关联表存储情况下，始终提供最准确的预测[4, 17]。通过结合这两个量，我们称之为PC+address索引，当多个代码序列导致同一数据结构的不同遍历时，预测器会生成不同的模式。然而，这种预测索引需要的预测器存储随着数据集大小的增加而扩展，在实际存储限制下，预测器的覆盖率会急剧下降。\n对于SPEC CPU 2000应用，PC+address索引可以通过将程序计数器与空间区域偏移量结合来近似[4, 17]。数据地址的空间区域偏移量是该地址距离空间区域起始位置的缓存块距离。空间区域偏移量允许预测器区分由相同代码片段生成的重复模式，这些模式仅在相对于空间区域边界的对齐方式上有所不同。\nPC+offset索引显著减少了预测表的存储需求，因为应用程序的不同缺失程序计数器比缺失地址要少得多。我们观察到，除了存储节省外，PC+offset索引本质上比基于地址的索引更强大，因为它可以消除冷启动缺失。当一个代码序列在一个大型数据集上重复相同的访问模式时，在访问序列开始时学习到的与程序计数器相关的空间模式将为从未访问过的数据提供准确的预测。数据库扫描和连接操作是决策支持查询执行中占主导地位的操作[23]，它们包含长时间的重复访问模式，这些模式仅访问一次数据。在这些应用中，PC+offset索引显著优于基于地址的方案。\n3. 设计 现在我们描述Spatial Memory Streaming (SMS)的设计。与先前的提案不同，我们的设计针对的是多处理器环境下的高性能商业服务器应用。我们设计的一个重要区别在于，先前的设计针对的是解耦的分区缓存[22]或子块缓存。将空间模式预测与这类缓存集成可以简化硬件设计，因为空间区域访问的训练结构可以与子块缓存的标签数组集成。然而，对不同空间区域的交替访问会在子块标签中引起冲突行为，导致空间区域生成的碎片化，从而降低观察到的模式的准确性**。因此，我们设计SMS以与传统的缓存层级结构集成。**\nSMS由两个硬件结构组成。**活动生成表（active generation table）记录空间模式，随着处理器访问空间区域并训练预测器。模式历史表（pattern history table）存储先前观察到的空间模式，并在每次空间区域生成的开始时访问，以预测未来的访问模式。**接下来的两个小节将描述这些结构及其操作。\n3.1. 观察空间模式 Spatial Memory Streaming (SMS)通过记录在空间区域生成过程中访问了哪些块来学习空间模式，这些记录存储在活动生成表（AGT）中。当一个空间区域生成开始时，SMS会在AGT中分配一个条目。随着缓存块的访问，SMS会更新AGT中的记录模式。在生成结束时（即在生成过程中访问的任何块被逐出/失效时），AGT将空间模式转移到历史表中，并释放AGT条目。\n**尽管AGT在逻辑上是一个单一的表格，但我们将其实现为两个内容可寻址存储器（CAM）：积累表（accumulation table）和过滤表（filter table），以减少每个存储器中的关联搜索大小以及结构的整体大小。**由于AGT处理每个L1数据访问，因此两个表必须能够匹配L1数据访问带宽。AGT不在L1数据访问的关键路径上，因此不会影响缓存访问延迟。\n空间模式记录在积累表中。积累表中的条目由空间区域标签标记，即区域基地址的高位。每个条目存储触发访问的PC和空间区域偏移量，以及一个空间模式位向量，指示在生成过程中访问了哪些块。新的空间区域生成最初在过滤表中分配。过滤表记录空间区域标签以及触发访问的PC和空间区域偏移量，适用于在当前生成中只有一次访问的空间区域。少数空间区域生成从未有第二个块被访问；预测这些生成没有意义，因为唯一的访问就是触发访问。通过将这些生成限制在过滤表中，SMS减少了对积累表的压力。\nAGT的详细操作如图2所示。每个L1访问首先搜索积累表。如果找到匹配的条目，则对应访问块的空间模式位被设置。否则，访问会在过滤表中查找其标签。如果没有找到匹配项，则该访问是新空间区域生成的触发访问，并且会在过滤表中分配一个新条目（图2中的第1步）。如果访问在过滤表中匹配，则会将其空间区域偏移量与记录的偏移量进行比较。如果偏移量不同，则该块是生成过程中 访问的第二个不同的缓存块，此时过滤表中的条目将转移到积累表中（图2中的第2步）。对该区域的其他访问将设置模式中的相应位（图2中的第3步）。空间区域生成以逐出或失效结束（图2中的第4步）。发生这些事件时，将搜索过滤表和积累表以查找对应的空间区域标签。（请注意，即使被替换的块是干净的，这个搜索也需要读取被替换缓存块的标签。）如果在过滤表中找到匹配项，则会丢弃该条目，因为它表示一个只有触发访问的生成。在积累表中找到匹配项时，则将该条目转移到模式历史表中。如果两个表中任意一个已满，需要分配新条目时，会选择一个受害条目并终止相应的生成（即，将条目从过滤表中丢弃或从积累表转移到模式历史表）。在第4.5节中，我们观察到，较小的（例如32条或64条）积累表和过滤表使这种情况变得非常少见。\n3.2. 预测空间模式 SMS使用模式历史表（PHT）进行空间模式的长期存储，并预测在每个空间区域生成过程中将访问的块模式。PHT的实现和地址流预测过程如图3所示。PHT组织为类似缓存的集合关联结构。PHT通过使用从触发访问的PC和空间区域偏移量构造的预测索引进行访问。PHT中的每个条目存储了在AGT中累积的空间模式。\n在触发访问时，SMS查询PHT来预测在生成过程中将访问哪些块。如果在PHT中找到条目，则将空间区域的基地址和空间模式复制到多个预测寄存器之一。随着SMS将每个由模式预测的块流入主缓存，它会清除预测寄存器中相应的位。当寄存器中的整个模式被清除时，该寄存器会被释放。如果多个预测寄存器处于活动状态，SMS将按轮询方式从每个预测寄存器请求块。SMS流请求的行为类似于缓存一致性协议中的读请求。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-06T20:42:37+08:00","permalink":"https://VastCircle.github.io/2025/spatial_memory_streaming/","title":"Spatial_Memory_Streaming"},{"content":"在其传统的图形渲染角色中，GPU 访问数据集，例如详细的纹理图，这些数据集太大而无法完全缓存在芯片上。实现在图形中所期望的高性能可编程性，既可以随着图形模式数量的增加而降低验证成本，也可以使游戏开发人员更容易区分他们的产品 [Lindholm et al., 2001]，为此我们有必要采用能够维持大的片外 (off-chip) 带宽的架构。因此，今天的 GPU 会同时执行数万个线程。虽然每个线程的片上内存存储量很小，但缓存仍然可以有效地减少大量的片外内存访问。例如，在图形工作负载中，可以由片上缓存捕获的相邻像素操作之间存在显著的空间局部性。\n图 3.1 展示了本章讨论的 GPU 流水线的微架构。该图说明了图 1.2 中所示的单个 SIMT 核心的内部组织。流水线可以分为 SIMT 前端和 SIMD 后端。流水线由三个调度“循环 (loop)”组成，它们在一个流水线中共同作用：一个取指循环、一个指令发射 (issue) 循环和一个寄存器访问调度 (scheduling) 循环。取指循环包括标记为 Fetch、I-Cache、Decode 和 I-Buffer 的块。指令发射循环包括标记为 I-Buffer、Scoreboard、Issue 和 SIMT 堆栈的块。寄存器访问调度循环包括标记为 Operand Collector、ALU 和 Memory 的块。在本章的其余部分，我们通过考虑依赖于每个循环的架构的关键方面，帮助您全面了解图中的各个块。\nimg 3.1 单循环近似 为了提高效率，线程被组织成 NVIDIA 称为 \u0026ldquo;warp\u0026rdquo; 和 AMD 称为 \u0026ldquo;wavefronts\u0026rdquo; 的组。因此，调度的单位是一个 warp。**在每个周期中，硬件选择一个 warp 进行调度。**在单循环近似中，warp 的程序计数器 (pc) 用于访问指令存储器以查找要为 warp 执行的下一条指令。获取指令后，对指令进行解码并从寄存器堆中获取源操作数寄存器。在从寄存器堆中获取源操作数的同时，确定 SIMT 执行掩码 (execution mask) 值。以下小节描述了如何确定 SIMT 执行掩码值并将它们与现代 GPU 中也使用的谓词 (predication) 进行对比。\n在执行掩码和源寄存器可用后，执行以单指令、多数据 (SIMD) 的方式进行。如果设置了 SIMT 执行掩码，则每个线程都在与通路 (lane) 关联的功能单元上执行。与现代 CPU 设计一样，功能单元通常是异构的，这意味着给定的功能单元仅支持指令的子集。例如，NVIDIA GPU 包含一个特殊功能单元 (Special Function Unit, SFU)、加载/存储单元、浮点功能单元、整数功能单元，以及从 Volta 开始的 Tensor Core。\n**所有功能单元 (function unit) 名义上包含的通路数与 warp 中的线程数一样多。**然而，一些 GPU 使用了不同的实现，其中单个 warp 或 wavefront 在多个时钟周期内执行。这是通过以更高的频率为功能单元提供时钟来实现的，这可以以增加能耗为代价实现更高的单位面积性能。为功能单元实现更高时钟频率的一种方法是将它们的执行流水线化或增加它们的流水线深度。\n3.2 双循环近似 为了帮助减少每个核心必须支持以隐藏长执行延迟的 warp 数量，能够在早期指令尚未完成时从 warp 发出后续指令是有帮助的。然而，前面描述的单循环微架构阻止了这种情况，因为该设计中的调度逻辑只能访问线程标识符和下一条要发出的指令的地址。具体来说，它不知道为 warp 发出的下一条指令是否依赖于尚未完成执行的较早指令。为了提供这样的依赖信息，有必要首先从内存中获取指令，以确定存在哪些数据和/或结构冒险 (hazard)。为此，GPU 实现了一个指令缓冲区，指令从缓存被取出之后被放置在这里。一个单独的调度程序用于决定指令缓冲区中的几条指令中的哪一条应该被发射到流水线的其余部分。\n指令内存被实现为一级指令缓存，由一级或多级二级（通常是统一的）缓存支持。指令缓冲区还可以结合指令未命中状态保持寄存器 (MSHR) [Kroft, 1981] 帮助隐藏指令缓存未命中延迟。在缓存命中或缓存未命中填充 (fill) 后，指令信息被放入指令缓冲区。指令缓冲区的组织可以采取多种形式。一种特别直接的方法是为每个 warp 存储一个或多个指令。\n译者注：我们把 buffer 翻译为缓冲区，cache 翻译为缓存，memory 翻译为内存，scratchpad 翻译为暂存器，storage 翻译为存储（暂未用到），以作区分。\n接下来，让我们考虑如何检测同一 warp 中指令之间的数据依赖关系。它们是检测传统 CPU 架构中指令之间依赖关系的两种传统方法：记分板 (scoreboard) 和保留站 (reservation station)。保留站用于消除名称依赖性并引入对在面积和能源方面昂贵的关联逻辑的需求。记分板可以设计为支持顺序执行或乱序执行。支持乱序执行的记分板（如 CDC 6600 中使用的记分板）也相当复杂。另一方面，单线程顺序 CPU 的记分板非常简单：记分板中的每个寄存器都用 1 bit 表示，只要发射将写入该寄存器的指令，就会置位该 bit。任何想要读取或写入在记分板上置位了相应 bit 的寄存器的指令都会停止 (stall)，直到该 bit 被写入寄存器的指令清除。这可以防止先写后读 (RAW) 和先写后写 (WAW) 冒险。当与顺序指令问题结合使用时，这个简单的记分板可以防止先读后写 (WAR) 冒险，前提是寄存器堆的读取被限制为顺序发生，这通常是顺序 CPU 设计中的情况。鉴于它是最简单的设计，因此将消耗最少的面积和能量，GPU 实现了顺序记分板。然而，正如接下来所讨论的，在支持多个 warp 时使用顺序记分板存在挑战。\n上述简单顺序记分板设计的第一个问题是现代 GPU 中包含大量寄存器。每个 warp 最多 128 个寄存器，每个核心最多 64 个 warp，每个核心总共需要 8192 bit 来实现记分板。\n上面描述的简单顺序记分板设计的另一个问题是遇到依赖的指令必须在记分板中重复查找其操作数，直到它所依赖的前一条指令将其结果写入寄存器堆。对于单线程设计，这没怎么引入复杂性。然而，在顺序发射的多线程处理器中，来自多个线程的指令可能正在等待更早的指令完成。如果所有此类指令都必须探测 (probe) 记分板，则需要额外的读取端口。最近的 GPU 支持每个核心最多 64 个 warp，并且最多支持 4 个操作数，允许所有 warp 在每个周期探测记分板，这将需要 256 个读取端口，这将非常昂贵。一种替代方法是限制每个周期可以探测记分板的 warp 数量，但这限制了可以考虑被调度的 warp 数量。此外，如果检查的指令都没有依赖关系，则即使其他无法检查的指令碰巧没有依赖关系，也不会发射指令。\n这两个问题都可以使用 Coon [2008] 等人提出的设计来解决。该设计不是在每个 warp 的每个寄存器中保留 1 bit，而是在每个 warp 中包含少量（在最近的一项研究 [Lashgar 等人，2016 年] 中估计约为 3 或 4 个）表项，其中每个表项指示的是已发射但尚未完成执行的指令写入的寄存器。常规的顺序记分牌在发射指令和写回指令时都会被访问。相反，Coon 等人的记分板是在将指令放入指令缓冲区以及将其结果写入寄存器堆时访问的。\n当从指令缓存中取出一条指令并将其放入指令缓冲区时，相应 warp 的记分板表项将与该指令的源寄存器和目的寄存器进行比较。这会产生一个短的位向量 (bit vector)，相应 warp 的记分板上的每个表项对应一个 bit（例如，3 或 4 bit）。如果记分板中的相应表项与指令的任何操作数匹配，则置位相应 bit。然后将该位向量与指令缓冲区中的指令一起复制。在所有 bit 都被清除之前，指令调度程序没有资格考虑发射这条指令，这可以通过将向量的每个 bit 送入或非门 (NOR) 来确定。指令缓冲区中的相关 bit 在指令将其结果写入寄存器堆时被清除。如果一个给定的 warp 的所有表项都用完了，那么要么停止所有 warp 取指，要么该指令被丢弃并且必须再次取指。当一条已执行的指令准备好写入寄存器堆时，它会清除记分板中分配给它的表项，并清除存储在指令缓冲区中的来自同一 warp 的任何指令的相应依赖 bit。\n常规的计分牌在发射阶段访问是否存在依赖，去比较相应源寄存器 （目标寄存器也要比较（避免waw冲突））， 在写回阶段更新目标寄存器，将相应的目标寄存器复位\n优化后的记分牌在将指令写入指令缓存区的时候就会被访问，去比较源寄存器和目的寄存器和记分牌条目，将比较的结果和指令一起放入指令缓冲区，\n个人感觉在指令发射时还是会将目标寄存器写入scoreboard，和常规记分牌一样\n在执行的指令写入寄存器堆时，会清除记分牌中分配的表项，并清除指令缓存区来自同一warp任何指令的依赖bit\n区别之处就在于直接将比较的掩码写入指令缓存区，后续通过清除掩码来确认指令是否能够发射，而不是再去访问scoreboard\n在warp的条目用完了之后，因为无法在将目的寄存器写入表项，所以需要停止所有warp取指或丢弃指令，直到又有空余表项\n思想其实就是没必要将每一个寄存器都预留一位，而是直接加法式的加入依赖\n在双循环架构中，第一个循环选择在指令缓冲区中有空间的 warp，查找其程序计数器并执行指令缓存访问以获得下一条指令。第二个循环在指令缓冲区中选择一条没有突出依赖关系的指令并将其发射到执行单元。\n3.3 三循环近似 如前所述，为了隐藏较长的内存延迟，有必要支持每个核心上有多个 warp；为了支持 warp 之间的逐周期切换，必须有一个大的寄存器堆，其中包含每个正在执行的 warp 的单独物理寄存器。例如，在 NVIDIA 最近的 GPU 架构（例如，Kepler、Maxwell 和 Pascal 架构）上，此类寄存器包含 256 KB。现在，SRAM 内存的面积与端口数成正比。寄存器堆的简单实现要求每周期、每条被发射的指令、每个操作数都拥有一个端口。减少寄存器堆面积的一种方法是使用多个单端口内存 bank 来模拟大量端口。虽然可以通过将这些 bank 暴露于指令集架构来实现这种效果，但在某些 GPU 设计中，它出现了一种称为操作数收集器 (operand collector) 的结构 [Coon et al., 2009, Lindholm et al., 2008b, Lui et al.。 , 2008] 用于以更透明的方式实现这一目标。操作数收集器有效地形成第三个调度循环，如下所述。\n通过分bank可能会出现非常多的储存体冲突的现象\n为了更好地理解操作数收集器解决的问题，首先考虑图 3.12，它显示了一个简单的微架构，用于提供增加的寄存器堆带宽。此图显示了 GPU 指令流水线的寄存器读取阶段，其中寄存器堆由四个单端口逻辑寄存器 bank 组成。在实践中，由于寄存器堆非常大，每个逻辑 bank 可以进一步分解为更多的物理 bank（未示出）。逻辑 bank 通过 crossbar 连接到 staging 寄存器（标记为“pipeline 寄存器”），这些 staging 寄存器在将源操作数传递给 SIMD 执行单元之前对其进行缓冲。仲裁器控制对各个 bank 的访问，并通过 crossbar 将结果路由到适当的 staging 寄存器。\nimg 图 3.13 显示了每个 warp 的寄存器到逻辑 bank 的简单布局。在该图中，warp 0 (w0) 中的寄存器 r0 存储在 Bank 0 的第一个位置，warp 0 中的寄存器 r1 存储在 Bank 1 的第一个位置，依此类推。如果计算所需的寄存器数量大于逻辑 bank 的数量，则分配回绕 (wrap around)。例如，warp 0 的寄存器 r4 存储在 Bank 0 的第二个位置。\nimg 图 3.14 展示了一个时序示例，突出显示了此微架构如何影响性能。该示例涉及顶部显示的两条指令。第一条指令 i1 是一个多重加法运算，它从寄存器 r5、r4 和 r6 中读取，这些寄存器分配在存储区 1、0 和 2 中（图中用下标表示）。第二条指令 i2 是一条加法指令，它从分配在 bank 1 中的寄存器 r5 和 r1 中读取。图中的中间部分显示了指令发射的顺序。在第 0 周期，warp 3 发出指令 i1，在第 1 周期，warp 0 发出指令 i2，在第 4 周期，warp 1 在由于 bank 冲突而延迟后发出指令 i2，如下所述。该图的底部说明了不同指令访问不同 bank 的时序。在周期 1，warp 3 中的指令 i1 能够在周期 1 读取其所有三个源寄存器，因为它们映射到不同的逻辑 bank。但是，在周期 2，来自 warp 0 的指令 i2 只能读取其两个源寄存器之一，因为它们都映射到 bank 1。在周期 3，该指令的第二个源寄存器读取与来自 warp 3 指令 i1 的写回并行。在周期 4，来自 warp 1 的指令 i2 能够读取其第一个源操作数，但不能读取第二个，因为两者都映射到 bank 1。在周期 5，来自 warp 的指令 i2 的第二个源操作数 1 被阻止从寄存器堆中读取，因为该 bank 已经被 warp 0 较早发出的指令 i2 的较高优先级写回访问。最后，在周期 6 中，来自 warp 1 的 i2 的第二个源操作数从寄存器堆中读取。总之，三个指令需要六个周期才能完成对其源寄存器的读取，并且在此期间，许多 bank 都没有被访问。\nimg 3.3.1 操作数收集器 操作数收集器微架构 [Lindholm et al., 2008b] 如图 3.15 所示。关键的变化是 staging 寄存器已被收集器单元 (collector unit) 取代。每条指令在进入寄存器读取阶段时都会分配一个收集器单元。有多个收集器单元，因此多个指令可以重叠读取源操作数，这有助于在各个指令的源操作数之间存在 bank 冲突的情况下提高吞吐量。每个收集器单元包含执行指令所需的所有源操作数的缓冲空间。鉴于多条指令的源操作数数量较多，仲裁器更有可能实现增加的 bank 级并行性，以允许并行访问多个寄存器文件 bank。\nimg 当 bank 冲突发生时，操作数收集器使用调度来容忍它。这留下了如何减少 bank 冲突数量的问题。图 3.16 说明了 Coon 等人修改的寄存器布局，描述了如何减少 bank 冲突。这个想法是从不同 bank 中的不同 warp 分配等效寄存器。例如，在图 3.16 中，warp 0 的寄存器 r0 分配给 bank 0，但 warp 1 的寄存器 r0 分配给 bank 1。这并不能解决单个指令的寄存器操作数之间的 bank 冲突。然而，它确实有助于减少来自不同warp的指令之间的 bank 冲突。特别是，每当 warp 取得相对平稳的进展时（例如，由于轮询调度或两级调度 [Narasiman et al., 2011]，其中 fetch group 中的各个 warp 以轮询顺序调度）。\nimg 图 3.17 显示了一个时序示例，顶部显示了一系列的加法和乘加指令。中间显示了发射顺序。在周期 0 到 2 上发出来自 warp 1 到 3 的三个 i1 实例。来自 warp 0 的指令 i2 的实例在周期 3 上发出。请注意，加法指令写入寄存器 r1，对于任何给定的 warp，该寄存器都分配在作为源寄存器 r5 的同一 bank。然而，与图 3.13 中使用寄存器布局的情况不同，这里不同的 warp 访问不同的 bank，这有助于减少一个 warp 的写回和读取其他 warp 中的源操作数之间的冲突。底部显示了由于操作数收集器而导致的访问的 bank 级别时序。在周期 1 中，寄存器 r2 从 warp 1 读取 Bank 3。在周期 4，注意从 warp 1 写回寄存器 r1、从 warp 3 读取寄存器 r5 和从 warp 0 读取寄存器 r3 并行进行。\nimg 到目前为止所描述的操作数收集器的一个微妙问题是，由于它不会在准备发射不同指令的时间之间施加任何顺序，因此它可能会出现先读后写 (WAR) 冒险 [Mishkin et al., 2016]。如果来自同一 warp 的两条指令存在于操作数收集器中，并且第一条指令读取第二条指令将写入的寄存器，则可能会发生这种情况。如果第一条指令的源操作数访问遇到重复的 bank 冲突，则可以想象第二条指令可能在第一条寄存器读取（正确的）旧值之前将新值写入寄存器。防止这种 WAR 冒险的一种方法是简单地要求来自同一 warp 的指令按照程序顺序将操作数收集器留给执行单元。米什金等人 [2016] 探索了三种具有低硬件复杂性的潜在解决方案，并评估了它们对性能的影响。第一个是提交时释放 (release) 的 warpboard，每个warp最多允许执行一条指令。不出所料，他们发现这会对性能产生负面影响，在某些情况下，性能几乎会降低两倍。他们的第二个提议是读取时释放 warpboard，它每次只允许一个指令在操作数收集器中收集操作数。该方案导致他们研究的工作负载最多降低 10%。最后，为了在操作数收集器中实现指令级并行性，他们提出了一种布隆板 (bloomboard) 机制，该机制使用小型布隆过滤器来跟踪未完成的寄存器读取。相比于（错误地）允许 WAR 冒险，这导致的影响小于百分之几。另外，Gray 进行的一项分析表明，NVIDIA 的 Maxwell GPU 引入了一个“读取依赖屏障”，该屏障由特殊的“控制指令”管理，可用于避免某些指令的 WAR 冒险（参见第 2.2.1 节）。\n虽然说发射是第一个指令提前于第二条指令发射的，但是由于储存体冲突，有可能第二条指令先于第一条指令将数据写入了，scoreboard已经解决了raw和waw\n3.3.2 指令重放：处理结构冒险 GPU 流水线中存在许多潜在的结构冒险的原因。例如，寄存器读取阶段可能会用完操作数收集器单元。许多结构冒险的来源与内存系统有关，我们将在下一章更详细地讨论。一般来说，一个 warp 执行的单个内存指令可能需要分解成多个单独的操作。这些单独的操作中的每一个都可以在给定的周期中充分利用流水线的一部分。\n当一条指令在 GPU 流水线中遇到结构冒险时会发生什么？在单线程顺序 CPU 流水线中，标准解决方案是停止较年轻的指令，直到遇到停止条件的指令可以继续执行。至少有两个原因，这种方法在高多线程吞吐量架构中不太理想。首先，考虑到寄存器堆的大尺寸以及支持完整图形流水线分配停止信号所需的许多流水级，可能会影响关键路径。流水线停顿周期分布导致需要引入额外的缓冲增加区域。其次，停止来自一个 warp 的指令可能会导致来自其他 warp 的指令在它后面停止。如果这些指令不需要导致停顿的指令所需的资源，则吞吐量可能会受到影响。\n为了避免这些问题，GPU 实现了一种指令重放 (replay) 形式。在一些 CPU 设计中发现了指令重放，当根据具有可变延迟的较早指令推测性地 (speculatively) 调度依赖指令时，它被用作恢复机制。例如，负载可能在一级缓存中命中或未命中，但时钟频率较高的 CPU 设计可能会在多达四个时钟周期内流水线式访问一级缓存。一些 CPU 会根据负载推测唤醒指令，以提高单线程性能。相比之下，GPU 避免推测，因为它往往会浪费能源并降低吞吐量。相反，在 GPU 中使用指令重放以避免阻塞流水线和电路区域和/或因停顿导致的时序开销。\n为了实现指令重放，GPU 可以将指令保存在指令缓冲区中，直到知道它们已完成或指令的所有单独部分都已执行 [Lindholm et al., 2015]。\n参考文献 https://zhuanlan.zhihu.com/p/510961793\nhttp://b.7dell.com/index.php/article/95.html\n","date":"2025-02-04T23:43:57+08:00","permalink":"https://VastCircle.github.io/2025/general-purpose_graphics_processor_architecture-simt%E6%A0%B8%E5%BF%83/","title":"General Purpose_graphics_processor_architecture SIMT核心"},{"content":"现代 GPU 采用广泛的 SIMD (单指令多数据)硬件来利用 GPU 应用程序中的数据级并行。 CUDA 和 OpenCL 等 GPU 计算 API 不是直接将 SIMD 硬件暴露给程序员，而是具有类似 MIMD（多指令多数据） 的编程模型，允许程序员在 GPU 上启动大量标量线程。这些标量线程中的每一个都可以遵循其独特的执行路径，并且可以访问任意内存位置。在运行时，GPU 硬件在 SIMD 硬件上执行称为 warp（或 AMD 术语中的 wavefront）的标量线程组，以利用它们的规律性和空间局部性。这种执行模型称为单指令、多线程 (SIMT) [Lindholm et al., 2008a, Nickolls and Reusch, 1993]。\n2.1 执行模型 GPU 计算应用程序开始在 CPU 上执行。对于分离式 GPU，应用程序的 CPU 部分通常会分配内存用于 GPU 上的计算，然后将输入数据传输到 GPU 内存，最后在 GPU 上启动计算内核。对于集成式 GPU，只需要最后一步。计算内核（通常）由数千个线程组成。每个线程执行相同的程序，但可能会根据计算结果遵循通过该程序的不同控制流\nsaxpy, single-precision scalar value A times vector value X pulus vector value Y . SAXPY 是著名的基本线性代数软件 (BLAS) 库 [Lawson 等人，1979 年] 的一部分，可用于实现更高级别的矩阵运算，例如高斯消元法 [McCool 等人，2012 年]。鉴于其简单性和实用性，在教授计算机架构时经常将其用作示例 [Hennessy and Patterson, 2011]。图 2.2 中的示例演示了 CUDA 和相关编程模型（例如，OpenCL [Kaeli et al., 2015]）提供的抽象。\n主机端——cpu上执行的代码 设备端——GPU执行的代码 h - host (主机) ， d-device (设备端)\n一个计算内核通常由数千个线程组成，每个线程都从运行相同的函数开始。在我们的示例中，CPU 在第 17 行使用 CUDA 的内核配置语法在 GPU 上开始计算。内核配置语法看起来很像 C 中的函数调用，其中包含一些附加信息，指定三尖括号 (\u0026laquo;\u0026lt;\u0026raquo;\u0026gt;) 之间包含的线程数。构成计算内核的线程被组织成一个层次结构，该层次结构由一个由线程块 (thread blocks) 组成的网格 (grid) 组成，这些线程块由线程束 (warp) 组成，多个线程块被分配到多个核心上。在 CUDA 编程模型中，各个线程执行操作数为标量值（例如 32 位浮点）的指令。为了提高效率，典型的 GPU 硬件以锁步 (lock-step) 方式一起执行多组线程。这些组被 NVIDIA 称为 warp，AMD 称为 wavefront。 NVIDIA 一个 warp 由 32 个线程组成，而 AMD 一个 wavefront 由 64 个线程组成。多个 warp 被组合成一个更大的单元，被称为协作线程阵列 (cooperative thread array, CTA) 或被 NVIDIA 称为线程块 (thread block)。第 17 行表示计算内核应该启动由 nblocks 个线程块组成的单个 grid，其中每个线程块包含 256 个线程。 CPU 代码传递给内核配置语句的参数被分发到 GPU 上正在运行的线程的每个实例。\n在第 3 行，threadIdx.x 的值标识线程在其线程块内的 x 坐标，而 blockIdx.x 指示线程块在其网格内的 x 坐标(第几个线程块)。值 blockDim.x 表示 x 维度上的最大线程数（一个线程块多大）。\nthread -\u0026gt; warp -\u0026gt; thread block -\u0026gt; grid 一个线程块包含多少线程，是软件概念，由内核配置语法决定；而一个 warp 包含多少线程，是硬件概念，warp 是硬件调度的最小粒度。\n**CTA（被 NVIDIA 称为 thread block）中的线程可以通过每个计算核心暂存器 (scratchpad) 内存有效地相互通信。**这个 scratchpad 被 NVIDIA 称为共享内存 (shared memory)。每个流式多处理器 (SM) 都包含一个共享内存。共享内存中的空间在该 SM 上运行的所有 CTA 之间分配。 AMD 的下一代图形核心 (GCN) 架构 [AMD, 2012] 包括一个类似的暂存器内存，AMD 称之为本地数据存储 (local data store, LDS)。这些暂存器内存很小，每个 SM 为 16-64 KB，并作为不同的内存空间向程序员公开。程序员使用源代码中的特殊关键字（例如，CUDA 中的 \u0026ldquo;shared\u0026quot;）将内存分配到暂存器内存中。暂存器存储器用作软件控制的高速缓存。虽然 GPU 还包含硬件管理的缓存，但通过此类缓存访问数据可能会导致频繁的缓存未命中。当程序员可以以可预测的方式识别频繁重用的数据时，应用程序将从使用暂存器存储器中受益。与 NVIDIA 的 GPU 不同，AMD 的 GCN GPU 还包括由 GPU 上的所有内核共享的全局数据存储 (global data store, GDS) 暂存器内存。 Scratchpad 内存用于图形应用程序中以在不同的图形着色器之间传递结果。例如，LDS 用于在 GCN [AMD，2012] 中的顶点和像素着色器之间传递参数值。\n**CTA (thread block) 中的线程可以使用硬件支持的屏障指令有效地同步。不同 CTA 中的线程可以通信，但需要通过所有线程都可以访问的全局地址空间进行通信。**就时间和精力而言，访问这个全局地址空间通常比访问共享内存更昂贵。\n线程块内的线程通过 shared memory 进行通信，线程块内的线程通过 barrier 进行同步。\n共享内存通过软件来加载数据，不会被硬件踢出或驱逐\n每个 SM 上可以跑多个线程块。\n不同线程块间线程的通信，需要经由 global memory。\n2.2 GPU指令集架构 当 NVIDIA 在 2007 年初推出 CUDA 时，他们决定走类似的道路，并为 GPU 计算引入了自己的高层次虚拟指令集架构，称为并行线程执行 (Parallel Thread eXecution) ISA，或 PTX [NVI，2017]。\nNVIDIA 在每个 CUDA 版本中都完整地记录了这种虚拟指令集架构，以至于本书的作者很容易开发出支持 PTX 的 GPGPU-Sim 模拟器 [Bakhoda et al., 2009]。 PTX 在很多方面类似于标准精简指令集计算机 (RISC) 指令集架构，如 ARM、MIPS、SPARC 或 ALPHA。它还与优化编译器中使用的中间表示具有相似性。一个这样的例子是使用无限组的虚拟寄存器。图 2.3 显示了图 2.2 中 SAXPY 程序的 PTX 版本。\nld.param 加载参数\nmov.u32 %r3 , 计算网格中的位置\n25-33是实际的saxpy程序\n在 GPU 上运行 PTX 代码之前，有必要将 PTX 编译为硬件支持的实际指令集架构。 NVIDIA 将此级别称为 SASS，它是 \u0026ldquo;Streaming ASSembler\u0026rdquo; 的缩写 [Cabral，2016]。从 PTX 转换为 SASS 的过程可以通过 GPU 驱动程序或 NVIDIA 的 CUDA 工具包提供的名为 ptxas 的独立程序来完成。NVIDIA 没有完整记录 SASS。虽然这使得学术研究人员更难开发能够捕获所有编译器优化效果的架构模拟器，但它使 NVIDIA 从客户需求中解放出来，在硬件级别提供向后兼容性，从而能够从一代到下一代完全重新设计指令集架构。不可避免地，希望了解底层性能的开发人员开始创建自己的工具来反汇编 SASS。由 Wladimir Jasper van der Laan 完成并命名为 \u0026ldquo;decuda\u0026rdquo; [van der Lann] 的第一个此类努力于 2007 年底推出，用于 NVIDIA 的 GeForce 8 系列 (G80)，当时是在第一个支持 CUDA 的硬件发布后的大约一年内。decuda 项目对 SASS 指令集有了足够详细的了解，因此可以开发汇编程序。这有助于在 GPGPU-Sim 3.2.2 [Tor M. Aamodt 等人] 中开发对 SASS 的支持，直至 NVIDIA 的 GT200 架构。 NVIDIA 最终推出了一个名为 cuobjdump 的工具，并开始部分记录 SASS。 NVIDIA 的 SASS 文档 [NVIDIA Corporation, c] 当前（2018 年 4 月）仅提供了汇编操作码名称的列表，但没有提供有关操作数格式或 SASS 指令语义的详细信息。最近，随着在机器学习中使用 GPU 的爆炸式增长以及对性能优化代码的需求，其他人已经为后续架构开发了类似于 decuda 的工具，例如 NVIDIA 的 Fermi [Yunqing] 和 NVIDIA 的 Maxwell 架构 [Gray]。\n图 2.4 展示了我们为 NVIDIA 的 Fermi 架构 [NVI, 2009] 编译并使用 NVIDIA 的 cuobjdump（CUDA 工具包的一部分）提取的 SAXPY 内核的 SASS 代码。图 2.4 中的第一列是指令的地址。第二列是汇编，第三列是编码指令。如上所述，NVIDIA 仅部分记录了他们的硬件组装。比较图 2.3 和图 2.4，可以看出虚拟和硬件 ISA 级别之间的相似之处和不同之处。在高层次上存在重要的相似之处，例如都是 RISC（都使用加载和存储来访问内存）和都使用谓词 [Allen et al., 1983]。更细微的区别包括： (1) PTX 版本具有基本上无限的可用寄存器集，因此每个定义通常使用一个新寄存器，很像静态单一分配 [Cytron 等人，1991]，而 SASS 使用有限的一组寄存器； (2) 内核参数通过存储在 SASS 中的非加载/存储指令可以访问的常量内存进行传递，而参数在 PTX 中分配到它们自己单独的“参数”地址空间中。\nimg 图 2.5 展示了 SAXPY 的 SASS 代码，该代码由相同版本的 CUDA 但针对 NVIDIA 的 Pascal 架构生成并使用 NVIDIA 的 cuobjdump 提取。比较图 2.5 和图 2.4，很明显 NVIDIA 的 ISA 发生了显着变化，包括指令编码方面。图 2.5 包含一些没有反汇编指令的行（例如，在第 3 行的地址 0x0000 处）。这些是在 NVIDIA Kepler 架构中引入的特殊“控制指令 (control instructions)”，以消除使用记分板 [NVIDIA Corporation, b] 进行显式依赖性检查的需要。 Lai 和 Seznec [2013] 探索了 Kepler 架构的控制指令编码。正如 Lai 和 Seznec [2013] 所指出的，这些控制指令似乎类似于 Tera 计算机系统上的显式依赖前瞻 [Alverson et al., 1990]。 Gray 描述了他们能够为 NVIDIA 的 Maxwell 架构推断出的控制指令编码的大量细节。根据 Gray 的说法，Maxwell 中每三个常规指令就有一个控制指令。这似乎也适用于 NVIDIA 的 Pascal 架构，如图 2.5 所示。根据 Gray 的说法，Maxwell 上的 64 位控制指令包含三组 21 位，为以下三个指令中的每一个编码接下来的信息：a stall count；yield hint flag；以及 write, read, and wait dependency barriers。 Gray 还描述了寄存器重用标志 (register reuse flags) 在常规指令上的使用，如图 2.5 所示（例如，R0.reuse 用于第 8 行的整数短乘加指令 (Integer Short Multiply Add instruction) XMAD 中的第一个源操作数）。这似乎表明从 Maxwell 开始在 NVIDIA GPU 中添加了“操作数重用缓存 (operand reuse cache)”（参见第 3.6.1 节中的相关研究）。这种操作数重用缓存似乎能够为每个主寄存器文件访问多次读取寄存器值，从而降低能耗和/或提高性能。\nimg 2.2.2 AMD 显卡核心下一代指令集架构 与 NVIDIA 相比，AMD 推出了他们的 Southern Islands 架构，他们发布了完整的硬件级 ISA 规范 [AMD, 2012]。 Southern Islands 是 AMD 的第一代 Graphics Core Next (GCN) 架构。 AMD 硬件 ISA 文档的可用性帮助学术研究人员开发了在较低级别上工作的模拟器 [Ubal et al., 2012]。 AMD 的编译流程还包括一个称为 HSAIL 的虚拟指令集架构，作为异构系统架构 (HSA) 的一部分。\nAMD 的 GCN 架构和 NVIDIA GPU（包括 NVIDIA 最新的 Volta 架构 [NVIDIA Corp., 2017]）之间的一个关键区别是单独的标量和向量指令。图 2.6 和 2.7 再现了 AMD [2012] 的高级 OpenCL（类似于 CUDA）代码示例和 AMD Southern Islands 架构的等效机器指令。在图 2.7 中，标量指令以 s_ 开头，向量指令以 v_ 开头。在 AMD GCN 架构中，每个计算单元（例如 SIMT 核心）都包含一个标量单元和四个向量单元。向量指令在向量单元上执行，并为 wavefront 中的每个单独线程计算不同的 32 位值。相反，在标量单元上执行的标量指令计算 wavefront 中所有线程共享的单个 32 位值。在图 2.7 所示的示例中，标量指令与控制流处理有关。特别是， exec 是一个特殊寄存器，用于预测 SIMT 执行的各个向量通路 (lane) 的执行。在第 3.1.1 节中更详细地描述了在 GPU 上使用掩码 (masking) 进行控制流处理。 GCN 架构中标量单元的另一个潜在好处是，SIMT 程序中计算的某些部分经常会计算相同的结果，而与线程 ID 无关（参见第 3.5 节）。\nimg img AMD 的 GCN 硬件指令集手册 [AMD, 2012] 提供了许多关于 AMD GPU 硬件的有趣见解。例如，为了对长延迟操作启用数据依赖性解析，AMD 的 GCN 架构包括 S_WAITCNT 指令。对于每个 wavefront，有三个计数器：向量内存计数、本地/全局数据存储计数和寄存器导出计数。这些中的每一个都指示给定类型的未完成操作的数量。编译器或程序员插入 S_WAITCNT 指令以使 wavefront 等待，直到未完成的操作数减少到指定阈值以下。\n参考文献 https://zhuanlan.zhihu.com/p/510756136\n","date":"2025-02-04T21:43:57+08:00","permalink":"https://VastCircle.github.io/2025/general-purpose_graphics_processor_architecture-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/","title":"General Purpose_graphics_processor_architecture 编程模型"},{"content":"前端流水线 最新版的BOOM前端共有五个阶段，在取指过程中同时进行分支预测，一旦发现预测错误马上重定向指令流，在后端中遇到分支预测错误也会将重定向指令地址给到前端进行取指，前端从指令存储器中以Fetch Packet为单位进行取指，一个Fetch Packet中包含多条指令，取到的指令会放到Fetch Buffer中传给后面的流水线，指令的PC和分支预测信息则储存在Fetch Target Queue中。\nF0阶段\n选择PC,然后将PC向Icache发送请求，并且将PC送到分支预测器进行预测\nF1阶段\nf0阶段到f1阶段 是 RegNext，无条件的\n访问TLB,将虚拟的PC值翻译成物理地址，并且将翻译的物理地址传递给icache .当TLB发生了miss或者F1阶段需要被冲刷时，需要中止对Icache的访问。\nF1阶段可以得到单周期分支预测器的预测结果（这个要看f1_do_redirect），如果预测结果为跳转，则将预测的目标跳转地址给到PC(即给到s0_pc,f0阶段)，反之，则正常指向下一个PC值。\nF2阶段\nf1阶段到f2阶段，需要s1_valid \u0026amp;\u0026amp; !f1_clear ,大部分数据都是f1阶段打拍过来的，比方说 ppc, vpc , tlb_resp, tlb_miss\n该阶段可以得到Icache的响应结果，当Icache的响应无效或者F3阶段传来的握手信号没有准备就绪时，需要将该阶段的PC值重定向回F0阶段，重新访问Icache，并且需要清除此时F1阶段中的内容(反正都有重发了，那f1的结果就没有意义了,f1_clear)。标记为s0_replay的条件是s2有效并且icache是返回数据的但是s3那边没有就绪\n该阶段还会得到两周期分支预测器的预测结果，需要先判断F2阶段分支预测的目标跳转地址与此时F1阶段的PC值是否一样，预测跳转方向与之前F1阶段的预测是否一样，如果是则证明两个阶段的分支预测器的预测结果相同，不需要进行PC的重定向，只需要更新F2阶段的全局历史寄存器即可；反之，则需要清除F1阶段的内容，将F2阶段预测的目标地址给到F0阶段重定向PC。 如果f1_clear = 1，是没有办法访问TLB等操作的\n插一嘴：其实可以看到流水线的每一个阶段都是以s0作为起点，因为每一个新的数据都必须经历完整的一条流水线才能够得到正确的结果\nF3阶段\nf2和f3之间可能不止相差了一拍，所以在f3没有ready的时候需要重发， s3_valid或者说是 enq_fire 依赖于 f3_deq_ready (queue = 1), 依赖于 f4_enq_ready (quene = 1), 依赖于 f4_deq_ready , 依赖于fb_enq_ready和ftq_enq_ready , 意思是说需要确保fetch buffer和fetchtargetqueue是有空位的\n在F3阶段中使用了IMem Response Queue（源码中名称为f3）和BTB Response Queue（源码中名称为f3_bpd_resp）两个队列，两个队列项数均为1，这两个队列可以防止F4阶段对F3阶段的反压。其中IMem Response Queue在F2阶段入队，在F3阶段出队，主要传递Icache响应的指令、PC、全局历史等信息；而BTB Response Queue则设置成“flow”的形式（即输入可以在同一周期内“流”过队列输出），所以它的入队出队均在F3阶段完成，主要传递分支预测器的预测信息。\n补充： flow能够在队列空的时候提前1周期拉高deq_valid,只要enq_fire , pipe能够在队列满的时候提前1周期拉高enq_ready,只要deq_fire，不使用flow , 输入输出起码差一拍， 使用pipe,可以对后级的响应速度快一拍\n该阶段可以得到TAGE分支预测器（下文会对该分支预测器进行介绍）的预测结果，此外该阶段还有一个快速译码单元，通过快速译码逻辑可以判断指令是否为分支跳转指令，若是分支跳转指令则：\n对于jal指令，该指令为无条件跳转指令，即一定会发生跳转，且可以通过译码得到直接跳转的地址，将译码得到的地址与之前预测的地址进行比较，若不一致或者之前的预测的跳转方向为不跳则需要重定向PC，刷掉前两个阶段取到的错误指令。\n对于jalr指令，该指令也为无条件跳转指令，但跳转地址不能通过译码获得，所以只判断跳转方向是否预测正确，跳转地址仍使用预测的跳转地址，若之前的跳转方向预测错误，还是需要重定向PC，刷掉前两个阶段取到的错误指令，最终的跳转地址还需要考虑该指令类型是否是return指令，若是则需要从ras中取出跳转地址，不是return指令才从预测结果中取出。\n对于branch指令，该类指令为有条件跳转指令，无法通过译码得到跳转方向，因此跳转方向采用分支预测器预测的结果，但可以通过译码得到跳转地址，所以需要判断跳转地址是否预测正确，若跳转地址预测不正确则需要重定向PC，刷掉前两个阶段取到的错误指令。\n对于jal指令和branch指令，由于它们的跳转地址是以立即数的形式存在指令中，通过译码再加上偏移量即可获得跳转地址，所以在该阶段可以得到正确的跳转地址，与之前的预测结果进行比较，如果不相同则需要更新分支预测器中对应的项。\nF4阶段\n该阶段会处理short-forwards branch（该技术的具体原理见参考资料[2]），同时在该阶段会将指令的相关信息传到Fetch Buffer中，将分支预测信息传到Fetch Target Queue中。\n上文具体介绍了BOOM前端每一个阶段的任务，下面将对BOOM中所有需要重定向PC的情况做一个总结。\nPC需要进行重定向的情况主要有以下几种：（下面按从高到低的优先级列举，当多种情况同时发生时，选择优先级最高的重定向地址作为最终的PC）\n1、当执行SFENCE.VMA指令时，代表软件可能已经修改了页表，因此此时的TLB里的内容可能是错误的，那么此时正在流水线中执行的指令也有可能是错误的，因此需要刷新TLB和冲刷流水线，也需要重新进行地址翻译和取指，所以此时需要重定向PC值。\n2、当执行级发现分支预测失败、后续流水线发生异常或者发生Memory Ordering Failure时（Memory Ordering Failure的相关介绍见参考资料[1])，需要冲刷流水线，将处理器恢复到错误执行前的状态，指令也需要重新进行取指，所以此时也需要重定向PC值。\n3、当发生以下三种情况时，需要将PC重定向为F3阶段分支预测器预测的目标跳转地址：\nF2阶段的指令有效且F3阶段的分支预测结果与此时处于F2阶段的指令的PC值不相同；\nF2阶段的指令无效且F3阶段的分支预测结果与此时处于F1阶段的指令的PC值不相同；\nF2阶段和F1阶段的指令均无效。\n4、当Icache的响应无效或者F3阶段传来的握手信号没有准备就绪时，需要将PC值重定向为此时处于F2阶段的指令的PC值。\n5、当F1阶段的指令有效且F2阶段的分支预测结果与此时处于F1阶段的指令的PC值不相同或者F1阶段的指令无效时，需要将PC重定向为F2阶段分支预测器预测的目标跳转地址。\n6、当TLB没有发生miss且F1阶段的分支预测器预测结果为跳转时，需要将PC重定向为预测的目标跳转地址。\nFetch Buffer Fetch Buffer本质上是一个FIFO，使用寄存器堆组成, 它可以将指令按照原来程序中的顺序存储起来，按照指令的顺序传到译码阶段进行译码，可以将取指阶段和后续流水线进行解耦。当发生 ICache 缺失时，Fetch Buffer中依然有指令供后续流水线使用，可以避免引起流水线的暂停，同时，由于有些指令需要译码成两条微指令进行执行，而Fetch Buffer的存在可以避免阻塞取指阶段。Fetch Buffer每次从F4阶段输入一个Fetch Packets，根据掩码将无效指令去掉后，从Buffer的尾部进入，每次从Buffer的头部输出coreWidth（后续流水线并行执行的宽度）个指令到译码级。\nFetch Target Queue 分支指令到达执行级的分支运算单元后，才能得到跳转结果，因此，分支预测的正确性也是要在执行级才能知道，所以需要将之前的预测结果保存跟随着流水线传到执行级，然后在执行级进行比较，发现预测失败的情况就需要重定向PC、刷新流水线、恢复流水线错误执行前的状态。因此，需要在取指阶段结束后将分支预测信息储存起来传到后续流水线，Fetch Target Queue（下文简称为FTQ）就是充当一个这样的缓存功能，其中包含了分支指令的PC以及相关联的分支预测信息，这些信息可以供流水线在执行阶段时引用，一旦指令被提交就会退出ROB，同时也会告诉FTQ, 将该指令也移出FTQ。同时，FTQ还有一个作用是可以接收执行级分支指令的执行信息，用来更新各个分支预测器。\n附录 参考文献 https://zhuanlan.zhihu.com/p/379874172\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-03T16:37:52+08:00","permalink":"https://VastCircle.github.io/2025/boom%E5%89%8D%E7%AB%AF/","title":"Boom前端"},{"content":"TAGE设计原理 TAGE设计思路与优势 TAGE全名为Tagged Geometric History Branch Predictor，在2006年Journal of Instruction Level Parallelism上发表的一篇工作中被提出，并且连续赢下了两年的Competition Branch Predictor比赛。TAGE作为一种混合式预测器，其优势在于可以同时根据不同长度的分支历史序列，对某一个分支指令分别进行分支预测，并且对在该分支指令在各个历史序列下的准确率进行评估，并且选择历史准确率最高者作为最终分支预测的判断标准。然而，相较于传统的混合式预测器，TAGE兼具下两个新的设计特性，使得其预测准确率得到可观的提升：\n对于每个预测表中的表项添加了tag数据。在传统的优先分支预测器中，往往仅采用分支历史以及当前分支指令的PC值作为依据来对预测表进行取指。这种情况会导致多条不同的分支指令指向同一个预测表表项的情况(aliasing)产生，而这种情况对混合式预测器中采取的分支历史长度较短的部分预测表所给出的分支预测准确率影响尤为显著。因此，在TAGE的设计中，通过partial tagging的方法，可以更好地将当前指令与预测表中的表项进行实际的匹配，从而较大程度地避免上述情况的产生。 采用几何级数变化的分支历史长度来索引不同的预测表，从而使得在分支预测过程中对各个预测表中的表项选择过程的粒度得到了很大的提升。除此之外，在每个表项中还添加了一个usefulness计数器，用于记录该表项对于分支预测的有用程度。通过这种设计，各类分支指令都有更高的几率藉由预测准确率最高的分支历史长度进行索引来做出最终的分支预测。 总的来说，出于上述两种设计创新，在TAGE预测器中，既大大降低了aliasing产生的可能性，同时也通过usefulness计数器的使用，在很大程度上缓冲了大历史长度预测表的有效表项填充时间。**也就是说，TAGE预测器既不会因为所选取的历史分支长度过短而使得某个预测表中的表项同时映射到多条不同的指令从而降低表项的信息有效程度，也不会因为选取的历史长度分支过大而使得整个TAGE需要经过很长时间的更新之后才能够发挥有效的预测功能。因此，TAGE所可采用的分支历史长度范围非常大，可以用于判断各种代码语境下的分支指令。**在2006年的工作中尝试了8个预测表的TAGE，分支历史长度为从1至128的指数序列；而在BOOM 中，则为从2至64的指数序列。\nTAGE的硬件架构与更新准则 在2006年的工作中，所提出的TAGE原理图如下所示：\n除去T1-T4这四个局部tag预测表之外，该结构还提供了一个基准预测器T0，用于在四个预测表的tag均不匹配时提供预测结果（该预测器通过一个简单的PC取指的2比特BIM来实现）。每个预测表的表项由一个3比特的预测计数器pred（通过最高位来给出预测结果），一个局部tag构成。同时，每个预测表配备一2比特的usefulness计数器。\n在每次进行预测时，首先在每个预测表中使用pc值以及各自的分支历史进行两个不同的哈希函数计算，计算结果分别用于计算该运算的最终tag以及对预测表的索引。若T1-T4中索引所得到的tag与tag哈希函数得到的结果匹配，则该预测表中给出的pred最高位被加入最终的分支预判序列。最终，通过多级MUX，可以从所有tag匹配的分支预判中选择历史长度最长者作为最终预测结果。若T1-T4无匹配，则采用T0为最终的预测结果。\n而TAGE的预测表更新策略如下所示：\n首先，定义所有产生tag匹配的预测表中所需历史长度最长者为provider，而其余产生tag匹配的预测表（若存在的话）被称为altpred。\n当provider产生的预测被证实为一个正确的预测时，首先将产生的正确预测的对应provider表项的pred计数器自增1。其次，若此时的provider与altpred的预测结果不同，则provider的userfulness计数器自增1。 当provider产生的预测被证实为一个错误的预测时，首先将产生的错误预测的对应provider表项的pred预测器自减1。其次，若存在产生正确预测的altpred，则provider的usefulness计数器自减1。接下来，若该provider所源自的预测表并非所需历史长度最高的预测表，则此时执行如下的表项增添操作。首先，读取所有历史长度长于provider的预测表的usefulness计数器，若此时有某表的u计数器值为0，则在该表中分配一对应的表项。当有多个预测表（如Tj,Tk两项）的u计数器均为0，则将表项分配给Tk的几率为分配给Tj的2^(k-j)倍（这一概率分配在硬件上可以通过一个LFSR来实现）。若所有TAGE内预测表的u值均不为0，则所有预测表的u值同时减1。 除了在得到真正的分支结果之后进行更新之外，由于在之前的一些使用tag匹配的分支预测器中存在某些预测表的usefulness保持恒定，几乎不更新的情况，导致存在一些永远被假定为有效的预测表，故在TAGE中在处理了固定数目的分支预测之后会对所有预测表的usefulness计数器进行重置。在论文中提出的重置策略为：每256K个分支预测后重置所有计数器的高位为0；而再过256K个分支预测后重置所有计数器的低位为0。\n最后，在初始化时，所有的表项中的pred计数器均设置为4，即弱taken状态，而所有的usefulness计数器均设置为0。\nboom中的tage 分支预测 tage采取的是全局分支预测\n相应的文件在tage.scala中\ntageTable就是独立的表，T1,T2等等\nboom总共就6张表 ，每张表有其特有的 nrows , tagsize , histlength , nrows指的是一张表有多少表项， 索引时通过idx来索引\n在f0的时候，相应的pc会传入 预测器， 在f1的时候，分支历史 ghist会传入预测器\n在f1周期，需要做哈希处理 ,得到经由 pc和 ghist 处理的 s1_hashed_idx和s1_tag\ndef compute_folded_hist(hist: UInt, l: Int) = { val nChunks = (histLength + l - 1) / l val hist_chunks = (0 until nChunks) map {i =\u0026gt; hist(min((i+1)*l, histLength)-1, i*l) } hist_chunks.reduce(_^_) } // def compute_tag_and_hash(unhashed_idx: UInt, hist: UInt) = { val idx_history = compute_folded_hist(hist, log2Ceil(nRows)) val idx = (unhashed_idx ^ idx_history)(log2Ceil(nRows)-1,0) val tag_history = compute_folded_hist(hist, tagSz) val tag = ((unhashed_idx \u0026gt;\u0026gt; log2Ceil(nRows)) ^ tag_history)(tagSz-1,0) (idx, tag) } val (s1_hashed_idx, s1_tag) = compute_tag_and_hash(fetchIdx(io.f1_req_pc), io.f1_req_ghist) 同时，s1周期还会通过得到的s1_hashed_idx去读取tag表（包含tag valid ctr），u标志位 , 具体的值会在s2时返回， 并且u标志位还分成两个存储mem (提高时序？),\n在s2 周期能够得到读取的tag表，u,此时也会去比较tag是否匹配\n在s3 周期的时候才将相应的数据传回给上层 ，包括是否匹配， u, ctr ， ctr就是表项中的3bit 饱和计数器\ntage还是分bank的，bank是与icache相关的 ，每一个bank都会得到一个分支预测的结果，但是分支预测的全局历史是共享的，tage表是独立的，相当于是在通过全局分支并行的更新\nval hi_us = SyncReadMem(nRows, Vec(bankWidth, Bool())) val lo_us = SyncReadMem(nRows, Vec(bankWidth, Bool())) val table = SyncReadMem(nRows, Vec(bankWidth, UInt(tageEntrySz.W))) val mems = Seq((f\u0026#34;tage_l$histLength\u0026#34;, nRows, bankWidth * tageEntrySz)) val s2_tag = RegNext(s1_tag) val s2_req_rtage = VecInit(table.read(s1_hashed_idx, io.f1_req_valid).map(_.asTypeOf(new TageEntry))) val s2_req_rhius = hi_us.read(s1_hashed_idx, io.f1_req_valid) val s2_req_rlous = lo_us.read(s1_hashed_idx, io.f1_req_valid) val s2_req_rhits = VecInit(s2_req_rtage.map(e =\u0026gt; e.valid \u0026amp;\u0026amp; e.tag === s2_tag \u0026amp;\u0026amp; !doing_reset)) for (w \u0026lt;- 0 until bankWidth) { // This bit indicates the TAGE table matched here io.f3_resp(w).valid := RegNext(s2_req_rhits(w)) io.f3_resp(w).bits.u := RegNext(Cat(s2_req_rhius(w), s2_req_rlous(w))) io.f3_resp(w).bits.ctr := RegNext(s2_req_rtage(w).ctr) } 在s3周期得到结果之后， 在tage预测器的顶模块，就会去遍历所有表项，当发现ctr不是3或者4的时候，比方说 5 6 7 101 110 111， 应该是预测为跳转，3 ，4 属于不上不下的值，所以要去选择其他的表项， 具体是前面的一些表项 ， hislen比较短的 ， 最终选择出来的应该是hislen最长的\nfor (i \u0026lt;- 0 until tageNTables) { val hit = f3_resps(i)(w).valid val ctr = f3_resps(i)(w).bits.ctr when (hit) { // 当tag命中的时候 io.resp.f3(w).taken := Mux(ctr === 3.U || ctr === 4.U, altpred, ctr(2)) final_altpred := altpred // final_altpred应该正好保存第二长的 } provided = provided || hit // provided是否命中 provider = Mux(hit, i.U, provider) // provider选择的是hit的最长的id altpred = Mux(hit, f3_resps(i)(w).bits.ctr(2), altpred) // altpred在命中时会进行更新 } 分支预测更新 从 io.updatepc 到 传入 table 表 ，经历了2个周期 ， 即实际传入的是 s2_updatepc\n// 更新table表 for (i \u0026lt;- 0 until tageNTables) { for (w \u0026lt;- 0 until bankWidth) { tables(i).io.update_mask(w) := RegNext(s1_update_mask(i)(w)) tables(i).io.update_taken(w) := RegNext(s1_update_taken(i)(w)) tables(i).io.update_alloc(w) := RegNext(s1_update_alloc(i)(w)) tables(i).io.update_old_ctr(w) := RegNext(s1_update_old_ctr(i)(w)) tables(i).io.update_u_mask(w) := RegNext(s1_update_u_mask(i)(w)) tables(i).io.update_u(w) := RegNext(s1_update_u(i)(w)) } tables(i).io.update_pc := RegNext(s1_update.bits.pc) tables(i).io.update_hist := RegNext(s1_update.bits.ghist) } 在s1阶段，会根据传入的br_mask , 等信息 更新 s1_update_mask u, taken, old_ctr, u_mask ,mask, 等信息\ns1_update_meta这些信号应该是在 f3阶段 通过 f3_meta（分支预测阶段）输出出去，然后跟随着分支指令，在分支指令得到结果之后通过io_update_bits_meta对应回来（分支预测表项更新）\nmeta里有是否命中 (valid,)，proder_index (provider的编号)，provider_u , provider_ctr， alt_differ () 等信息\nu的增加是在顶层文件中通过inc_u实现的，s1阶段 , 逻辑和理论一致，如果 和 alter 预测一致，就不变，不一致，如果预测错误（这也说明alter是预测正确的），u - 1 ，否则 u - 1\n// 得到分支为更新 val update_was_taken = (s1_update.bits.cfi_idx.valid \u0026amp;\u0026amp; (s1_update.bits.cfi_idx.bits === w.U) \u0026amp;\u0026amp; s1_update.bits.cfi_taken) when (s1_update.bits.br_mask(w) \u0026amp;\u0026amp; s1_update.valid \u0026amp;\u0026amp; s1_update.bits.is_commit_update) { when (s1_update_meta.provider(w).valid) { // 在hit的条件下,更新选择的provider val provider = s1_update_meta.provider(w).bits s1_update_mask(provider)(w) := true.B s1_update_u_mask(provider)(w) := true.B val new_u = inc_u(s1_update_meta.provider_u(w), s1_update_meta.alt_differs(w), s1_update_mispredict_mask(w)) s1_update_u (provider)(w) := new_u s1_update_taken (provider)(w) := update_was_taken s1_update_old_ctr(provider)(w) := s1_update_meta.provider_ctr(w) s1_update_alloc (provider)(w) := false.B } } } def inc_u(u: UInt, alt_differs: Bool, mispredict: Bool): UInt = { Mux(!alt_differs, u, Mux(mispredict, Mux(u === 0.U, 0.U, u - 1.U), Mux(u === 3.U, 3.U, u + 1.U))) } 在table表中，会进行相应数据的写入，使用的是 write(index,data,mask)这个api ,mask和bank相关，它没用write_en,主要就是通过mask来控制的， 应该是在s2时发起了写入的请求 ， 在s2期间还做了update_wdata的一些数据的更新， 比方说\n另外就是数据的旁路了 ，主要是写数据的旁路\nval update_wdata = Wire(Vec(bankWidth, new TageEntry)) table.write( Mux(doing_reset, reset_idx , update_idx), Mux(doing_reset, VecInit(Seq.fill(bankWidth) { 0.U(tageEntrySz.W) }), VecInit(update_wdata.map(_.asUInt))), Mux(doing_reset, ~(0.U(bankWidth.W)) , io.update_mask.asUInt).asBools ) val update_hi_wdata = Wire(Vec(bankWidth, Bool())) hi_us.write( Mux(doing_reset, reset_idx, Mux(doing_clear_u_hi, clear_u_idx, update_idx)), Mux(doing_reset || doing_clear_u_hi, VecInit((0.U(bankWidth.W)).asBools), update_hi_wdata), Mux(doing_reset || doing_clear_u_hi, ~(0.U(bankWidth.W)), io.update_u_mask.asUInt).asBools ) val update_lo_wdata = Wire(Vec(bankWidth, Bool())) lo_us.write( Mux(doing_reset, reset_idx, Mux(doing_clear_u_lo, clear_u_idx, update_idx)), Mux(doing_reset || doing_clear_u_lo, VecInit((0.U(bankWidth.W)).asBools), update_lo_wdata), Mux(doing_reset || doing_clear_u_lo, ~(0.U(bankWidth.W)), io.update_u_mask.asUInt).asBools ) for (w \u0026lt;- 0 until bankWidth) { update_wdata(w).ctr := Mux(io.update_alloc(w), Mux(io.update_taken(w), 4.U, 3.U ), Mux(wrbypass_hit, inc_ctr(wrbypass(wrbypass_hit_idx)(w), io.update_taken(w)), inc_ctr(io.update_old_ctr(w), io.update_taken(w)) ) ) update_wdata(w).valid := true.B // 目前只要是写入的表项 valid都是有效的 update_wdata(w).tag := update_tag update_hi_wdata(w) := io.update_u(w)(1) update_lo_wdata(w) := io.update_u(w)(0) } 同时boom也增加了旁路机制 , 具体需要比较 index 和 tag , 然后在更新ctr的时候可以使用 旁路的数据进行更新 ，暂时没看出来，这是性能的优化还是如果没有的化会报错 ， 优先级是wrbypass_hit比较高，那就代表，如果是bypass_hit,那么update_wdata会写入bypass的值，然后bypass的值会更新为update_wdata ,意思是和 io.update_old_ctr无关了\n如果没有命中bypass 表，此时会利用 io.update_old_ctr进行变化写入table,并且将 io.update_old_ctr经过变化的值赋值bypass,那后面如果再次出现的话，就会一直使用bypass的值而不使用update_old_ctr直到被替代\nval wrbypass_tags = Reg(Vec(nWrBypassEntries, UInt(tagSz.W))) val wrbypass_idxs = Reg(Vec(nWrBypassEntries, UInt(log2Ceil(nRows).W))) val wrbypass = Reg(Vec(nWrBypassEntries, Vec(bankWidth, UInt(3.W)))) val wrbypass_enq_idx = RegInit(0.U(log2Ceil(nWrBypassEntries).W)) // 遍历所有的wrBypassEntries，看是否有命中 val wrbypass_hits = VecInit((0 until nWrBypassEntries) map { i =\u0026gt; !doing_reset \u0026amp;\u0026amp; wrbypass_tags(i) === update_tag \u0026amp;\u0026amp; wrbypass_idxs(i) === update_idx }) val wrbypass_hit = wrbypass_hits.reduce(_||_) // 找到命中的wrBypassEntries的索引 val wrbypass_hit_idx = PriorityEncoder(wrbypass_hits) when (io.update_mask.reduce(_||_)) { when (wrbypass_hits.reduce(_||_)) { // 如果命中 wrbypass(wrbypass_hit_idx) := VecInit(update_wdata.map(_.ctr)) // 用update_wdata更新 } .otherwise { // 如果没有命中,增加新的wrBypassEntries wrbypass (wrbypass_enq_idx) := VecInit(update_wdata.map(_.ctr)) wrbypass_tags(wrbypass_enq_idx) := update_tag wrbypass_idxs(wrbypass_enq_idx) := update_idx wrbypass_enq_idx := WrapInc(wrbypass_enq_idx, nWrBypassEntries) } } 最后就是在新增表项的操作 ,操作和理论如出一辙， 在进行分支预测的时候实际上已经把这条分支指令如果预测错误需要分配表项的 valid 和 entry都确定好了\n有点不一样，就是如果在预测错误分配表项失败的时候，直接强制把比provider长的分支表的u全部置为0,而不是减1\n// Create a mask of tables which did not hit our query, and also contain useless entries // and also uses a longer history than the provider // masklower是把最高位的1前面的全部变成1 , 0010010 -\u0026gt; 0011111 // allocatable_slots长度是tageNTables // 把provider前面的全部变成1,取反 // 有多个预测表（如Tj,Tk两项）的u计数器均为0，则将表项分配给Tk的几率为分配给Tj的2^(k-j)倍（这一概率分配在硬件上可以通过一个LFSR来实现）。 // k \u0026gt; j, 分配给Tk的几率大，即分配给长分支历史的表项的几率大 // 读取所有分支历史长度长于provider的且不匹配的表项，则将表项分配给u计数器为0的表项。 val allocatable_slots = ( // 枚举的是table表 , 没valid说明不匹配 VecInit(f3_resps.map(r =\u0026gt; !r(w).valid \u0026amp;\u0026amp; r(w).bits.u === 0.U)).asUInt \u0026amp; ~(MaskLower(UIntToOH(provider)) \u0026amp; Fill(tageNTables, provided)) ) // 随机,概率选择 val alloc_lfsr = random.LFSR(tageNTables max 2) val first_entry = PriorityEncoder(allocatable_slots) val masked_entry = PriorityEncoder(allocatable_slots \u0026amp; alloc_lfsr) val alloc_entry = Mux(allocatable_slots(masked_entry), masked_entry, first_entry) // 重新分配表项 f3_meta.allocate(w).valid := allocatable_slots =/= 0.U f3_meta.allocate(w).bits := alloc_entry 附录 参考文献 https://www.sunnychen.top/archives/tage#%E5%90%8E%E6%97%A5%E8%B0%88%EF%BC%9Atage%E5%9C%A8%E5%BE%AE%E6%9E%B6%E6%9E%84%E7%9A%84%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0\n分支预测算法（一）：TAGE\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-03T15:19:09+08:00","permalink":"https://VastCircle.github.io/2025/tage%E9%A2%84%E6%B5%8B%E5%99%A8/","title":"TAGE预测器"},{"content":"摘要 硬件预取（Hardware prefetching）是隐藏长数据访问延迟最常用的技术之一。为了解决硬件预取面临的挑战，架构师提出在空间区域（spatial region）的粒度上检测并利用空间局部性。当一个新的区域被激活时，他们尝试基于系统级环境特征（如触发指令或数据地址）查找类似的先前访问区域，以进行足迹预测。然而，我们发现这种基于上下文的预测无法捕捉访问模式的本质特征，导致灵活性和实用性受限，并使预取性能次优。在本文中，我们受到存储访问的时间特性的启发，注意到空间足迹内部的时间相关性是空间模式的关键特征。为此，我们提出了一种简单高效的硬件空间预取器——Gaze，它巧妙地利用足迹内部的时间相关性来高效表征空间模式。同时，我们发现利用由空间流（spatial streaming）生成的空间足迹时，存在一个独特但未解决的挑战，即这些足迹表现出极高的访问密度。因此，我们进一步为 Gaze 设计了一个专门的两阶段方法，以缓解传统方案中常见的过度预取（over-prefetching）问题。我们进行了全面且多样化的实验，结果表明 Gaze 能够在更广泛的场景中有效提升性能。具体而言，与最新的低成本方案 PMP 和 vBerti 相比，Gaze 在单核环境下分别提升 5.7% 和 5.4%，在八核环境下分别提升 11.4% 和 8.8%。\nintroduction 在过去的几十年里，主存的容量经历了指数级增长；然而，主存与CPU之间的延迟差距（即“存储墙”）并未得到显著改善[36]、[57]、[89]。此外，随着大数据[53]和深度学习[54]等内存密集型应用的激增，这种性能差距正变得越来越严重。\n硬件预取是一种广泛使用且被深入研究的方法，旨在弥合这一差距[27]、[36]。通过推测并在CPU明确请求之前主动将数据块预取到缓存，数据预取可以隐藏长数据访问延迟，并缓解存储子系统的压力[59]。硬件预取器通过观察内存请求来提取内存访问模式。当检测到模式可能重复时，它们会尝试预取未来可能访问的数据[27]。因此，准确刻画程序行为对预取性能至关重要。然而，在实际应用中，多样化的访问行为以及乱序调度等干扰因素，使得在保持硬件简洁性的同时实现高效预取变得极具挑战性。\n为了解决这些挑战，架构师提出了检测和利用空间局部性的方法[13]、[17]–[19]、[21]、[22]、[29]、[48]、[51]、[52]、[58]、[65]、[67]、[70]、[75]、[78]、[79]、[83]。一种有效的策略是利用存储区域（如4KB物理页）粒度上的空间模式[13]、[17]、[19]、[22]、[29]、[48]、[52]、[78]、[79]、[83]。存储区域的空间模式通常表示为其空间足迹的位向量[22]。基于空间模式的预取器通过跟踪多个活动内存区域来学习空间模式，并利用这些模式预测新激活区域的可能足迹。已有大量研究表明，空间足迹预测可以有效减少强制性缺失（compulsory misses）[13]、[22]、[27]、[48]、[52]，并适用于相似循环[48]、重复数据布局[13]、[27]、[47]、[78]，以及数据结构遍历[13]、[78]。此外，它还可以在乱序调度环境下保持稳健性[17]。\n为了准确识别相似区域进行足迹预测，许多研究人员提出使用系统级环境特征（如触发指令或数据地址）来表征空间模式[52]。这是因为当系统在访问新区域时表现出相似特征时，模式很可能会再次出现。例如，在PC+地址（PC+Address）方案中，相同指令访问相同地址意味着可能会重现相同的足迹[13]。尽管这种基于上下文的表征方法在微架构技术（如分支预测[74]、值预测[55]和缓存替换策略[41]）中被广泛使用，但在空间模式预测中并不如预期那样高效。\n图1绘制了几种空间模式预取表征方案的性能表现（详细方法见§IV-A）。“-opt”表示最近文献中的优化版本。横轴显示了来自CloudSuite[30]的scale-out服务器工作负载，其中包含大量不规则访问。纵轴则呈现了SPEC17[11]的实验结果。结合PC和数据地址进行精细化表征的预取器确实能实现较高加速比，但需要大量硬件资源。而采用较粗粒度表征的方法虽然更具硬件友好性，但在复杂工作负载中会产生大量误预测。此外，即使是优化方案也未能完全解决这些问题，严重限制了灵活性和实用性。\n在本文中，我们重新思考如何从本质上刻画空间模式。由于访问行为本身通常表现出时间相关性[84]，因此由这些行为生成的空间模式也应具有类似的特性。受此启发，我们观察到，当空间模式重复出现时，其内部的时间相关性往往也会以相似方式重现。也就是说，足迹内部的访问顺序在表征空间模式方面起着至关重要的作用。\n基于这一观察，我们提出了一种名为Gaze2的空间预取器，该预取器创新性地利用足迹内部的时间相关性来高效刻画空间模式。然而，充分利用这一时间特性在实际中并不可行。相反，我们的研究表明，仅关注前几个初始访问即可实现高效预测。因此，Gaze 选择利用足迹内部的一小部分时间相关性，以保持简洁性。此外，传统基于空间模式的预取器使用位向量表示足迹，未能捕捉访问顺序的任何时间信息。与其引入额外的元数据，Gaze 直接将时间信息无缝融入经验搜索过程，从而增强了硬件设计的简洁性和兼容性。\n此外，我们发现由空间流（spatial streaming）生成的足迹通常表现出极高的访问密度。如果误用此模式，可能导致严重的过度预取（over-prefetching），因为它可能指示预取几乎整个区域。然而，过于保守的策略又可能错失大量预取机会。为了解决这一独特挑战，我们进一步为Gaze设计了一种专门的两阶段策略，以在整个区域的需求和过度激进性之间动态平衡预取力度。\n我们使用涵盖各种真实应用的基准测试对Gaze进行评估。实验包括单核、多核和带宽受限环境等多个场景。通过与七种最先进的预取器进行广泛对比，我们表明Gaze可以在更广泛的场景下有效提升性能。具体而言，在整个单核评估集中，Gaze 相比 PMP 和 vBerti [65] 分别提升了 5.7% 和 5.4%；在八核仿真中，分别提升了 11.4% 和 8.8%。此外，Gaze 的存储开销几乎与 PMP 相同，比 Bingo [13] 低 31 倍。同时，其面积和能耗开销远低于 PMP 和 vBerti。\n本论文的主要贡献如下：\n我们指出基于空间模式的预取器的薄弱环节在于其基于环境上下文的模式表征方法，这极大限制了其灵活性和实用性。 通过利用足迹内部的时间相关性来表征空间模式，所提出的 Gaze 可以更准确地预测即将访问的足迹。此外，Gaze 将这一时间信息直接集成到经验搜索过程中，从而保持了硬件的简洁性。 我们进一步针对空间流优化 Gaze，提出了一种两阶段策略，以在整个区域需求和过度激进性之间取得平衡。 我们评估了 Gaze 以及七种最新的预取器，覆盖了来自 SPEC06、SPEC17、Ligra、PARSEC 和 CloudSuite 基准测试套件的 201 条不同的真实应用轨迹。实验结果表明，Gaze 能够在各种场景下有效提升性能。 II. 相关工作与研究动机 A. 近期基于空间模式的机制 基于空间模式的预取通过直接记录某一区域的足迹来学习该区域的空间模式，并尝试找到其他相似区域以利用所学的经验进行预取 [22], [52]。这一潜力已被许多前期工作所证明 [13], [17], [19], [22], [29], [48], [52], [78], [79], [83]。\n空间足迹预测器（SFP）[52]首次示范了基于空间模式的预取的常见结构和逻辑。SFP提议使用程序计数器（PC）以及一些数据地址的位来表征模式，从而提高预取准确性，并使预取器能够消除强制缺失。空间模式预测 [22] 在SFP的基础上进行了改进，使用了更大的区域大小和缓存行大小。\n细粒度空间预取通常通过几个环境上下文来表征模式，如激活的指令和数据地址。空间内存流（SMS）[78]提议使用PC+偏移量（Offset3）。SMS还使用一个过滤表（FT）来过滤掉单一比特的空间足迹。批量内存访问预测与流式传输 [83] 进一步减少了SMS的能量消耗。\n长触发事件（PC+地址）携带（PC+偏移量）。受TAGE [74] 分支预测器的启发，Bingo首次尝试使用较长的触发事件来找到精确匹配。如果没有找到匹配，则使用较短的事件来找到近似匹配。因此，与SMS相比，Bingo通过更多的失配覆盖了相似的准确度（由精确匹配维持）。\n结合触发指令和数据地址，能够准确捕获模式开始时的上下文特征。因此，匹配区域的预测通常会获得很高的准确性。然而，由于微小的上下文差异，相似的模式通常与不同的事件相关联，导致严重的数据冗余 [13], [48]。因此，为了实现可观的覆盖率，需要大量的存储开销和较长的学习周期 [17], [48]，这使得预取器不切实际。SMS和Bingo在实现最佳性能时都需要超过100KB的存储 [13], [78]。\n**粗粒度空间预取。**到目前为止，几项最近的研究尝试采用更简化的方式。它们选择更适合硬件的粗粒度事件，并采用各种方法来缓解由此带来的低准确度。粗粒度方法仅通过触发指令或数据地址的几位来表征模式。\n双重空间模式预取器（DSPatch）[17]在指令粒度上表征空间模式（即使用PC）。同时，它为每个PC保持两个最新的模式，并且可以通过预取同时/任一模式中出现的数据块来进一步提高准确性/覆盖率。\n模式合并预取器（PMP）[48]通过仅使用偏移量进一步简化了表征，确保在短时间内几乎总能找到匹配。这几乎消除了由于执行新指令或访问未见过的地址而丢失预取机会的可能性。此外，对于每个偏移量，PMP合并了最近的32个模式，意味着它们的共同特征得以保留和利用。\nB. 现有局限性与研究动机 传统的基于上下文的方法在捕获关键访问特征时存在重大局限性。如图 1 所示，低成本方案难以适用于复杂工作负载，而引入更多的环境上下文信息又会导致难以接受的硬件成本。尽管已有研究提出了基于带宽利用率的动态调整 [17]、模式合并 [48] 和长短事件联合关联 [13] 来缓解这一问题，但这些方法的缺陷仍然未能彻底解决，严重限制了基于空间模式的预取的灵活性和实用性。因此，我们的研究进一步探索模式本身，以开发更高效的表征方法。\n内存访问通常表现出时间局部性，即已访问的数据在短时间内可能会被再次访问 [27]。时间相关性（Temporal Correlation）类似于时间局部性，指的是一组地址倾向于按相同的顺序被重复访问 [84]。它被广泛应用于识别指针追踪和图处理等不规则模式 [12], [40], [49], [66], [79], [85], [87], [88]。由于空间模式是由内存访问产生的，它们自身也应该表现出类似的时间特性。这意味着，模式复现可能与内部访问的顺序一致。\n图 2 上半部分展示了从 fotonik3d_s 负载中提取的几个空间区域的详细访问足迹。其中：\nRegion A 和 Region C 具有相同的空间足迹和访问顺序，即它们的被访问块是对齐的，且访问顺序相同。 Region A 和 Region B 之间的空间足迹和访问顺序差异较大，因此它们属于不同模式。 由于足迹内部的时间相关性是由访问行为本身决定的，利用这一特性进行精细粒度模式表征可能是一个可行的方向。\n假设我们观察图 2 所示的场景：\nt0 时刻（见下半部分），Region A、B 和 C 先前的模式已被学习，而 Region D 此刻刚刚被激活。四个区域的触发访问（红色标记）是对齐的，因此它们在定义上是相似的。然而，Region A、B 和 C 之间的模式存在冲突，因此难以确定 Region D 的最佳预取模式。 仅依赖触发偏移量是不够的，而引入附加的上下文信息（如 PC 或完整地址）会导致不可接受的元数据开销。 t2 时刻，在额外观察了两次内存访问之后，Region B 和 Region D 之间的相似性变得明显。因此，在 t2 时刻，我们可以做出高置信度的预测。 这种方法能够在不大幅增加元数据开销的情况下，实现细粒度模式表征。\n然而，这一思想并不能直接应用于基于空间模式的预取，主要原因有两点： ➊ 它与传统的硬件设计不兼容； ➋ 它引入了额外的复杂性。\n第一个挑战在于，传统方法是基于触发访问（trigger access）进行预测的，而要获取时间相关性，需要额外的观察。 第二个挑战在于，存储和利用时间信息的成本较高。\n因此，为了保持方法的简单性和高效性，我们需要进行精心设计，否则其效果可能还不如现有的细粒度方法。\nIII. Gaze空间预取器 我们提出了Gaze，据我们所知，它是第一个利用足迹内部时间相关性来高效表征空间模式的空间预取器。为了平衡硬件复杂度和性能，Gaze利用区域的前两个访问信息（§III-B）。这种简化使得Gaze能够将时间特征提取无缝集成到现有硬件设计中，而无需额外的元数据存储。同时，Gaze引入了一种专用的双阶段方法，以减轻在常规方案中，当利用由空间流生成的高密度足迹时，常常出现的过度预取问题（§III-C）。Gaze被设计并主要评估为L1D预取器。然而，它也可以放置在L2C，与现有的商业L1D预取器IP-stride一起工作。\nA. 设计概述 图3展示了Gaze的设计。中间的子图（图3b）显示了设计概览，而左侧子图（图3a）和右侧子图（图3c）分别展示了详细的学习和预取过程。图3b突出了关键创新，包括使用来自前两个访问的时间信息（细节在§III-B中讨论）以及专用的激进性控制路径（§III-C）。\n如图3b所示，Gaze在缓存加载时进行训练。与传统的基于空间模式的预取器[13]，[48]，[78]类似，Gaze由三个主要组件组成：过滤表（FT）、累积表（AT）和模式历史模块（PHM）。FT用于过滤掉单比特空间模式，表示在跟踪期间区域内只有一个块被需求。AT用于跟踪所有活动区域。PHM用于学习访问模式，并基于学习到的经验发出预取。任何新激活的区域首先会在FT中记录，并且只有在到达第二次不同的加载访问后，才会被AT跟踪。Gaze还采用了一个预取缓冲区（PB），高效存储预取地址，因为单个位向量通常包含多个具有相同起始地址（即区域编号）的请求。此外，PB还帮助平滑预取的发出。\n访问流程。加载到达时，Gaze首先检查AT，以查看所访问的区域是否正在跟踪（➊），如果是，Gaze将更新相应的足迹。否则，Gaze会查找FT（➋）。如果找到该区域，表示它曾经激活过，Gaze将开始在AT中跟踪它（➌）。与以前的提案不同，Gaze还会将触发偏移、第二个偏移以及触发PC发送到PHM进行预取（➍）。这是因为Gaze选择结合前两个访问之间的时间相关性，这在此时可用。如果需要更多访问，则该步骤将被延迟。传统方法[13]，[17]，[48]，[78]通过触发访问而不是第二次访问唤醒预取过程。在接收到这些信息后，PHM决定是否触发该区域的预取。如果触发，则相应的预取模式将被发送到PB，准备预取（➎）。对于每个正在跟踪的区域，一旦它被停用（例如，其中一个缓存块被从缓存中驱逐，或者其相关的跟踪条目因不活动而被LRU策略从AT中驱逐），累积结束，并将位向量发送到PHM（➏）进行模式学习。\nAT中的每个条目用于跟踪一个活动区域，我们引入了两个额外的6位字段来存储该区域最后两个访问的偏移，这些偏移与新访问一起，将共同计算最后两个步长。AT根据这两个步长（➐）决定是否执行基于区域的步长预取（作为备份预取）和激进性提升。\nB. 模式表征 为了识别足迹内部特征，Gaze需要等待几个初始访问。因此，最关键的设计选择是用于提取时间相关性的访问次数。这要求Gaze在强干扰（如乱序调度）存在的情况下，保持并观察所有最近激活的区域，通过它们最近访问的块来区分空间模式。此外，这也意味着会错失一些预取机会。因此，等待过多的访问会带来负面影响。为了在性能和成本之间找到良好的平衡，我们首先探讨了使用的时间信息量与加速、准确性和覆盖率等效率之间的关系。当两个区域的初始访问在空间足迹和时间顺序上对齐时，我们认为它们是相似的。图4展示了将所需对齐的初始访问次数从一个扩展到最多四个的效果。结果是整个评估集的平均值。我们依次连接这些访问的偏移量来形成索引事件。当仅使用触发偏移时，模式历史表（PHT）的大小为64，因为在一个4KB区域内有64个不同的偏移且没有包含指令信息。然而，当考虑更多的访问时，完整的PHT变得不切实际且低效。因此，在这些情况下，为了简化，我们使用了256条入口的全关联历史表，其消耗不到3KB。如图4所示，如果我们要求前四个需求块在空间和时间上都必须对齐，预取准确性从56%提高到90%，这表明访问行为的成功表征。然而，预取机会显著丧失，导致IPC和覆盖率下降。当我们选择仅使用前两个访问时，达到了理想的平衡，这在IPC上提供了3%的提升，在准确性上提供了35%的提升，同时覆盖率的减少几乎可以忽略不计。当使用的偏移数量再次增加时，准确性的边际提升是以IPC和覆盖率的显著下降为代价的。\n基于这一见解，我们决定利用前两个访问之间的时间相关性来表征空间模式。这一选择带来了三个主要优势。首先，与传统的依赖多样化程序上下文的细粒度方法相比，这种方法显著减少了存储开销。其次，它平衡了性能、准确性和覆盖率，确保及时的预取并最小化乱序调度带来的干扰。第三，它可以无缝集成到近期的硬件设计中。Gaze利用现有逻辑来捕捉前两个偏移，并以不增加额外元数据开销的方式存储模式，保持简洁性和兼容性。具体而言，最近的方法使用FT来使仅访问一次的区域无效，这使我们能够在FT将有效区域发送到AT时获取这两个偏移（图3b中的➋）。此外，我们将第一个偏移作为索引，第二个偏移作为标签来存储模式，在表查找过程中本质上验证它们的顺序。\n此外，为了保持高准确性，Gaze采用了严格的匹配机制，当只有一个访问匹配而另一个不匹配时，防止唤醒预取。这与Bingo [13]、TAGE [74]和Domino [12]中采用的机制略有不同，这些机制即使在部分匹配的情况下也能进行预测。我们限制这种能力，主要是因为前两个访问之间的时间相关性是一个关键特征。然而，当候选区域未能找到匹配时，尽管其即将到来的模式可能很容易跟随，我们可能会错失预取机会。为了弥补这一点，我们通过备用预取器增强了跟踪结构。具体细节将在与我们专用的双阶段激进性控制一起在§III-C中进一步讨论。\nC. 向空间流式处理的增强 空间流式处理指的是长期的空间跨越访问现象 [27]。尽管过去几十年对空间流式处理进行了广泛的研究 [37]–[39]，[50]，[71]，[91]，我们仍然观察到在利用其空间足迹时存在一个独特的未解决挑战。具体来说，我们发现，由空间流式处理生成的足迹通常表现出极高的访问密度，尤其是当跨越为1时，这意味着在用于预取时，几乎会为候选区域中的所有块发出推测性预取。显然，空间流式处理可以从这种高激进性中大大受益。然而，实际上，各种访问模式往往以交错的方式表现出来，如果过度使用这种高密度的足迹，产生的大量无效预取可能会导致显著的缓存污染和外部带宽瓶颈。例如，图5提供了Ligra中基于BFS的图处理算法的伪代码。该算法分配一个临时空间，称为Frontier，用于存储当前级别中将被处理的稀疏分布的顶点。因此，遍历Frontier（在函数BFS_forward中）会产生同时包含不规则访问和空间流式处理的访问模式。\n为了解决这个挑战，像许多之前的方法 [38]，[71]，[91]，我们使用基于PC的机制。具体来说，我们部署了一个密集PC表（DPCT）来记录最近的密集PC，一个密集计数器（DC）来跟踪最近密集足迹的频率。我们使用这两个结构进行双重检查，并采用两阶段方法来逐步增加预取激进性。\n学习阶段。空间流式处理检测如图3a上部所示。当我们跟踪完一个区域，其初始两个访问的块是块0和块1（即图中的r）时，我们检查它是否是高度密集的，即它的所有块是否都已被访问。如果是，我们将其触发指令记录到DPCT中，并增加DC。否则，我们减少DC，其中较大的值促使快速减少。\n**预取阶段。**我们采用两阶段方法来调整预取的激进性，尝试将此密集模式应用于候选区域。在第一阶段，对于候选区域，我们检测其展示空间流式处理的信心级别，并相应地分配初始预取激进性。在第二阶段，我们根据随后的访问动态调整预取的激进性，逐步增加激进性。\n阶段1。如图3c上部所示，当为可能被空间流式处理完全需求的区域p发出预取时，如果触发指令最近被标记为密集PC或DC已饱和，我们分配适中的激进性：将前16个块预取到L1D，将剩余的块预取到L2C。我们经验性地将具有较高激进性的初始块数设置为16（即区域的四分之一），以避免错失预取机会，同时不至于过于激进。否则，如果DC饱和度为一半，表示p成为密集区域的概率较低，我们只将前16个块预取到L2C。如果触发指令未被标记或DC不够大，我们则不进行预取。同时，在将该区域插入AT时，我们设置stride_flag标记。这使得AT在该区域后续展示流式处理行为时，能够预取其余块。\n阶段2。AT将跟踪所有标记的区域。对于每个区域，我们计算最后三个访问的两个跨越。如果这两个跨越都等于1，我们将若干后续块提升到L1D（见图3c上部）。图3b下部显示了PB如何合并提升模式和原始预取模式。这种基于跨越的方法还可以作为当我们的严格匹配机制（见§III-B）未能预测时的备选预测器。如图3c下部所示，如果未找到匹配，则在跟踪时也会设置该区域的stride_flag。一般来说，对于标记的区域，一旦最后两个跨越匹配，就会激活基于区域的跨越预取。\n我们基于区域的跨越预取与其他基于跨越的机制之间的差异如下。首先，它具有双重目的：促进激进性并捕捉潜在的错失机会（图3b中的➐）。其次，它利用现有结构，例如AT，并在区域级别操作，而不是全局或每个PC视图，这避免了需要新的跟踪结构。因此，为了保持简洁性，不处理诸如多个跨越之类的复杂场景。\nD. 模式历史模块 如图3b所示，除了负责处理§III-C中提到的大规模空间流式处理的DPCT和DC（简化表示为案例1）之外，PHM还包括一个模式历史表（PHT），用于处理典型场景（简化表示为案例2）。如前所述，如果一个区域的前两个访问是空间相邻并且发生在区域的开头，那么DPCT和DC将学习到该模式。否则，将使用PHT来学习该模式。同样，对于候选区域的足迹预测，PHM根据其前两个访问的块来调用相应的结构。此外，PHT会将所有块预取到L1D中。\nE. 硬件开销 **存储开销。**Gaze将区域大小设置为4KB（与典型的物理页面相同）。表I展示了每个组件的详细划分以及总存储开销。FT和AT都有64个条目，允许同时跟踪64个页面。PB使用32个条目存储最多32个页面的预取模式，每个偏移量有四个状态：不预取、预取到L1D、L2C和LLC（未使用）。PHT采用4路组相联方式。DPCT包含8个条目。我们忽略了DC的开销，因为它只占用3个比特。最后，Gaze的总硬件开销为4.46KB（比Bingo [13]低31倍，比PMP [48]少0.54KB，比Berti [65]多1.91KB）。\n**面积和能量开销。**我们使用CACTI [60]、[86]的22nm配置来估算Gaze（PHT和DPCT）和PMP（OPT和PPT）的模式历史模块所消耗的面积和访问能量。与PMP相比，Gaze消耗的面积约为29%（0.0034 mm² vs. 0.0117 mm²）。这是因为Gaze中的每一行仅需要64b来存储一个比特向量，而PMP则需要320b（或160b）来存储一个计数器向量（粗计数器向量）。此外，Gaze的模式历史模块的读写访问消耗的能量不到PMP的46%。Gaze的每个表可以在一个CPU周期内被访问。与Berti相比，Gaze的面积和能量消耗要低得多，因为Berti将每个L1D行扩展12个比特来容纳获取延迟。这种扩展导致其面积和访问能量比Gaze的PHM增加超过10倍。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-02T22:53:52+08:00","permalink":"https://VastCircle.github.io/2025/gaze_into_the_pattern__for_hardware_prefetching/","title":"Gaze_into_the_Pattern__for_Hardware_Prefetching"},{"content":" 在dispatch 的时候派遣指令到store IQ上 ，ROB标记为可提交状态 ，这样这两条指令就从ROB中消失了，然后是store Queue把数据写入dcache里面\nstore 指令和 load指令的物理地址一致， 但是load提前store发出了\n只要能够检测到load是提前store发射的，那重新执行一遍load就可以了\nstore检测load queue里有没有新的load,然后直接重新执行load\ndcache需要写的时候是抢不到读口的\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-02-02T16:33:38+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E9%82%80%E8%AF%B7%E6%8A%A5%E5%91%8A%E4%B9%B1%E5%BA%8F%E8%AE%BF%E5%AD%98%E5%8D%95%E5%85%83/","title":"香山邀请报告——乱序访存单元"},{"content":"在boom的代码中看到挺多var的使用，来记录一下\nvar类型:在处理过程中可以多次重写\nval类型:在处理过程中只能分配一次\n例如，在表搜索中，考虑存储为 ID 和值对的类似散列的结构，并搜索与散列值匹配的地址值。 如果同一个ID在表中多次存在，则表中地址较大的值优先。\nval entry_id = Reg(Vec(8, UInt(8.W))) val entry_value = Reg(Vec(8, UInt(32.W))) val is_hit = Wire(Vec(8, Bool())) // 检查条目是否与id值匹配 val hit_value = Wire(Vec(8, UInt(32.W))) // 如果命中，选择条目i的值，否则继承前一个条目的结果 for (i \u0026lt;- 0 until 8) { is_hit(i) := (entry_id(i) === io.addr) hit_value(i) := Mux(is_hit(i), entry_value(i), if(i==0) { 0.U} else { hit_value(i-1) }) } io.id_out := hit_value(7) io.id_hit := is_hit(7) 因此，为了保留前面的条目，hit_value有多少条目就准备多少条目，并且只有在索引为0时才添加特殊处理，有点麻烦。var解决方案是使用可以像过程类型一样编写的类型（即可以被覆盖） 。\n首先，is_hit和hit_value不需要有多个条目。当然，在硬件上生成时，val硬件数量保持不变（因为它相当于使用），但源代码数量减少了。\n尽管两种情况下生成的硬件数量相同，但此表示法也可用于减少 Chisel 描述的数量。\nval entry_id = Reg(Vec(8, UInt(8.W))) val entry_value = Reg(Vec(8, UInt(32.W))) var is_hit = false.B var hit_id = 0.U for (i \u0026lt;- 0 until 8) { is_hit = (entry_id(i) === io.addr) hit_id = Mux(is_hit, entry_value(i), hit_id) } io.id_out := hit_id io.id_hit := is_hit when (io.w_en) { entry_id(io.w_addr) := io.w_id entry_value(io.w_addr) := io.w_value } 附录 参考文献 var的使用\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-30T23:55:06+08:00","permalink":"https://VastCircle.github.io/2025/scala_var/","title":"Scala_var"},{"content":"Introduction 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-25T23:47:50+08:00","permalink":"https://VastCircle.github.io/2025/a_primer_on_hardware_prefetching%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/","title":"A_Primer_on_Hardware_prefetching读书笔记1"},{"content":" local history 局部信息 , ret call\nglobal history 跳和不跳历史的整合\npath history 历史上执行数据的信息\n如果推测路径都是错误，只恢复栈顶项要出问题\n分支预测发生阻塞，对icache也会阻塞 ， 反之亦然\n34byte为了保证万一最后有4Byte的指令，确保其也能取出\nicache是sram结构\n预译码：分支类型，指令边界之类的\nimage-20250125215358388 这个和fetch的第一级流水是一样的\n= 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-25T20:04:28+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E9%82%80%E8%AF%B7%E6%98%86%E5%89%8D%E7%AB%AF%E8%AE%BE%E8%AE%A1/","title":"香山邀请昆前端设计"},{"content":"在大核里\nstride load\nRPT : ( pc : 40 addr : 40 stride : 16 state : 2 最内层检测位 : 1)\n当发现检测位为1，可以去清空VTT和FLR ，重新开始\n每当重新遇到启动discoder mode 的pc时， 会清空所有的检测位\nTaint Tracker\nVTT ： 依赖链的建立 ,污点向量记录\nFLR : 记录最后一个load ，更新FLR时，清空SBB和LCR\nloop bound detector\nSBB:是否处理过分支\nLCR:保存上一个比较指令的源和目标寄存器的ID (x86是这样的) ， riscv的话，累加指令？\nbne s0,s4 ,1031a\nbeqz s2,10362\n小核的执行单元和访存单元 ，写回单元（） ， 需不需要写小核的寄存器 ？\n发一条小核执行一条 ？\n什么时候发送?\n找到 stride load 和 loop bound , 再次进入前一个stride load 的时候\nPCv 来记录 stride load pc ，在发现检测位为1时可以去更新PCv, 并且清空VTT和 FLR\n下一轮会把所有标记为脏的指令全部都发送到一个结构里去 ， 然后再用一个结构向量化转发给多个小核（可以在标记的时候就发送吗 ？）\n发送给某个结构的内容？\n能使得小核成功执行指令的 部分\nstride load addr step ， 可能不止一条stride load ,\n只有stride load 需要电路控制 step\n一些算数运算 rs1 rs2 rdata1 rdata2 op , 要放寄存器序号需要重命名， 可以不放寄存器号，可以直接映射到id去 （1）in-order核加一部分寄存器 （2）小核维护一个freeReg 表 ， 完成之后需要恢复\njar ?\ndepend load rs1 imm\nboom Uop -\u0026gt; rocket decode , 大部分可以去除\n提取 ？\ndispatch -\u0026gt; uop\n中间数据都需要通过 exe 读取 ， 最快的应该是从 iregister_read的时候读取 ，\n需要提取的中间数据 ： 没有被VTT标记的寄存器值\n// rocket decode def default: List[BitPat] = // jal renf1 fence.i // val | jalr | renf2 | // | fp_val| | renx2 | | renf3 | // | | rocc| | | renx1 s_alu1 mem_val | | | wfd | // | | | br| | | | scie s_alu2 | imm dw alu | mem_cmd | | | | mul | // | | | | | | | | | zbk | | | | | | | | | | | | div | fence // | | | | | | | | | | zkn | | | | | | | | | | | | | wxd | | amo // | | | | | | | | | | | zks | | | | | | | | | | | | | | | | | dp List(N,X,X,X,X,X,X,X,X,X,X,X, A2_X, A1_X, IMM_X, DW_X, aluFn.FN_X, N,M_X, X,X,X,X,X,X,X,CSR.X,X,X,X,X) // frs3_en wakeup_delay // is val inst? | imm sel | bypassable (aka, known/fixed latency) // | is fp inst? | | uses_ldq | | is_br // | | is single-prec? rs1 regtype | | | uses_stq | | | // | | | micro-code | rs2 type| | | | is_amo | | | // | | | | iq-type func unit | | | | | | | is_fence | | | // | | | | | | | | | | | | | | is_fencei | | | is breakpoint or ecall? // | | | | | | dst | | | | | | | | | mem | | | | is unique? (clear pipeline for it) // | | | | | | regtype | | | | | | | | | cmd | | | | | flush on commit // | | | | | | | | | | | | | | | | | | | | | | | csr cmd // | | | | | | | | | | | | | | | | | | | | | | | | List(N, N, X, uopX , IQT_INT, FU_X , RT_X , DC2 ,DC2 ,X, IS_X, X, X, X, X, N, M_X, DC2, X, X, N, N, X, CSR.X) 附录 参考文献 ","date":"2025-01-25T18:38:54+08:00","permalink":"https://VastCircle.github.io/2025/big-small-runahead/","title":"Big Small Runahead"},{"content":"b站学习 分支预测块\n把每个周期的数据都发送到一个结构里去\n使用FTQ存放分支预测后的数据\n设置redirect 通道， 如果s2 预测的结构和s1不一样， 用redirect把结果覆盖掉 ，直接去修改FTQ的内容 ，因为有s1了，已经能够做到每一个周期预测一个结果了 ， 那s2,s3，实际上也是每一个周期出一个数据 ，但是实际上如果0x8的是预测错误的，那0xc实际上是白白预测的，因为根本不会跳到0x8这个块\nFTQ收集后端的反馈信息，然后可以通过重定向通道发送给BPU\n需要得知各种信息来训练分支预测\n一个FTB项有3个槽 ，FTB项用PC索引 ，3个槽有两个条件分支槽，1个无条件分支槽\nBPU只和Composer交互就可以了， composer集成了5个子预测器\n会有一个valid信号来无效前面预测器的输出，初始pc0, 比方说 ， T0 s1 预测 pc0-\u0026gt; pc1， T1 s2发现pc0-\u0026gt; pc1预测错误的实际是pc3 ，T1阶段所有预测器通过pc1去预测pc2,那么此时需要把所有预测器的valid都拉低，因为这个pc1是错误的，这个阶段没必要对pc1做预测 ， 对预测器2而言它没必要在下一周期得到pc1的预测结果，换言之，在T2阶段时，预测器2的流水线2是没必要工作得到结果的，在T2,T3阶段，预测器3的流水线2,3是没必要去工作的 。\n如果发生了redirect,那所有的target就都不去听\n这些信号也会直接输出给ftq\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-25T15:13:03+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81%E5%89%96%E6%9E%90%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B%E5%8D%95%E5%85%83/","title":"香山源代码剖析——分支预测单元"},{"content":"标量向量运行前 （SVR） 通过搭载处理器上执行的现有指令，在简单的有序内核上提取高内存级并行性，从而导致将来的不规则内存访问。SVR 执行多个瞬态、独立、并行的内存访问实例及其链，这些实例从预测的归纳变量的不同值启动，以将相互独立的内存访问彼此相邻移动，以隐藏依赖的停顿。SVR 的硬件开销仅为 2 KiB，性能比基准 3 宽的有序内核高 3.2× 比完全无序内核高 1.3× 倍，同时能耗减半。将开销增加到 9 KiB 以应对更大的寄存器文件，SVR 可以将相对于乱序内核的加速比扩展到 1.7×。\n1.引言 我们能否通过依赖内存访问链为这些具有挑战性的工作负载实现高性能，同时仍能获得按顺序处理的能效优势？\n我们的目标是采用 Vector Runahead 的原理并将其应用于小的有序超标量核心。这需要重新构建方法。保留重叠未来的内存访问可以利用 MLP，但无需支持向量 ISA 或单独的超前运行上下文。我们的技术称为Scalar Vector Runahead (SVR)，它通过机会生成多个标量副本来同步“搭载”处理器中执行的现有指令，每个标量副本都具有独立的输入和依赖项集。它使用自己的小型 SRAM 池跟踪所有新交错的指令，同时从执行的动态属性中学习，以有效地发现准确的循环边界，而不依赖于乱序执行来计算未来工作的属性。它在做到这一点的同时保留了简单、严格按顺序的执行模型。\n2.background A. 稀疏内存访问 许多类别的现代工作负载都具有难以预测的非顺序内存访问，这些访问基于索引查找，例如，稀疏矩阵（在图形和 HPC 中）或表数据结构（例如数据库工作负载中的哈希表）。虽然这些工作负载理论上在算法级别具有较高的内存级并行性 （MLP），但这很难利用。大数据量和低时态位置性使现代缓存层次结构未得到充分利用。由于访问是间接的或指针追逐的，因此无法轻松地将它们预取到更靠近 cache 层次结构中的核心的位置。\n例如，由于其稀疏性质，图形应用程序通常以压缩的稀疏行 （CSR） 格式存储，以实现高存储效率。如图 2 所示，这包括清单 1：PageRank 中热循环的 C++ 代码。三个数组：offset、neighbor 和 vertex data [35]。对偏移数组的访问是顺序的，而对相邻和顶点数据数组的访问是间接的。清单 1 显示了从 GAP 基准测试套件 [11] 访问 PageRank 的三个数组的 C++ 代码。第 1 行迭代节点，如图 2 中的 Offset 数组表示，第 3 行迭代每个节点的邻居，如图 2 中的 Neighbor 数组表示，第 4 行将每个邻居的贡献添加到当前节点排名中，这是对图 2 中 Vertex 数据的访问。\n对 g.in_neigh（u） 的访问遵循规则的顺序，因此它们可以被步幅预取器拾取，而对 outgoing_contrib[v] 的访问，基于存储在 g.in_neigh（u） 中的非顺序值，是不规则的并且高度依赖于数据，这意味着它们在缓存中持续缺失。尽管乱序内核可以在其 reorder buffer 中同时容纳一些循环迭代，以从多个依赖链中提取 MLP，但它在使内存带宽饱和之前很快就会停滞。对于 in-order 内核，问题甚至更严重。即使我们假设 inorder 内核是 stall-on-use 而不是 stall-on-load，使用 cache-missing load 也会导致内核暂停执行，直到完成对主内存的高延迟访问。这有效地抑制了任何类型的 MLP，从而导致性能不佳。\nB. In-Order 内核上的内存延迟 图 3 报告了 in-order 和 OoO 内核的每指令周期数 （CPI）。如图所示，间接内存访问对 in-order 内核的性能影响的严重性比其 OoO 对应项高出许多倍。虽然 OoO 内核在 DRAM 内存访问上停滞在 3.6 CPI 上，但按顺序排列的内核停滞不前，CPI 要高得多。这会导致 in-order 相对于 out-of-order 内核的速度减慢 2.5×。因此，解决具有间接内存访问的应用程序的性能瓶颈对于按顺序内核至关重要。\nC. 向量超前 Vector Runahead （VR） [38]， [40] 是一种用于乱序内核的微架构技术，用于为稀疏内存访问生成高 MLP。VR 保留一个参考预测表 [17] 来查找具有跨步访问模式的负载，用于预测未来循环的归纳变量。如果这些步幅负载在其计算链上生成依赖的内存访问，则 VR 会创建与从许多不同的索引开始的链对应的指令，同时瞬态地发出许多独立的未来迭代。VR 将这些多个标量指令副本组合成向量，以提高后端吞吐量。尽管从属访问仍会在缓存中丢失，但现在许多独立的丢失发生在很近的地方，从而导致非常高的 MLP，并且一旦处理器恢复正常执行，缓存命中率就会很高。解耦矢量超前 （DVR） [39]、[43] 构建在 VR 之上。当 ROB 填满时触发 VR，因此 OoO 内核无法进一步进行，而 DVR 通过在同一内核上的第二个简单按顺序同步子线程中发出推测性矢量化指令流，实现“解耦”或独立于微架构结构的大小。此外，DVR 在运行时检测循环边界以提高预取准确性，包括同时跨多个嵌套的内循环和外循环。DVR 还使用 GPU 样式的重新收敛堆栈处理控制流发散。 这两种技术都广泛使用了仅在大型无序超标量内核中可用或真实的资源，这意味着直接转换为节能的有序内核是不可能的。但是，两者都提供了对设计机制的见解，这些机制可以消除在 inorder 内核上观察到的更紧迫的 latencybound 行为。\n3.SVR的设计理念 标量向量，而不是向量：VR 和 DVR 都将未来迭代的独立组的数据打包到宽 SIMD 寄存器中，并利用其相应的 SIMD 向量指令（例如 AVX512）。较小的内核根本不可能支持向量运算，或者只支持较小的向量宽度（例如，128 位 [21]）。尽管如此，即使使用 512 位数据路径，VR 和 DVR 也必须同时发出多个矢量指令（VR 同时发出 64 次迭代，而 DVR 最多发出 128 次迭代）。如果底层内核受内存限制，我们仍然可以通过将对许多独立数据项的计算作为标量运算而不是向量指令来实现加速，因此称为“标量向量”。即使在按顺序排列的内核中，只要内核支持使用时停顿而不是未命中时停顿（即，内核在使用加载的值时停顿，而不是在缓存未命中时立即停顿），我们仍然可以利用数据级并行性，通过将许多独立的内存访问打包在一起来实现高 MLP。甚至 DVR 的子线程也不使用乱序执行，因为通道之间的并行性很充足，而且由于间接链，单个通道几乎没有指令级并行性。因此，我们可以看到瞬态矢量化的 MLP 优势，而无需实际使用乱序执行或任何显式向量运算，因此提出了标量向量 Runahead。\n4.SVR微架构 SVR 建立在“使用时停顿”的有序内核之上 [26]。该内核监控数据加载流的跨步内存访问模式，生成跨步加载的多个标量副本，每个副本具有不同的未来地址。在 taint tracker 的帮助下跟踪跨步负载的传递依赖指令，并且还为每个依赖指令生成多个副本。为单个指令生成的数据标量副本组称为标量向量 （SV），指令将自身复制一个集体标量向量指令 （SVI）。一个 SV 包含 N 个标量（或向量有 N 个元素）;除非另有说明，否则 N = 16**。SVI 和矢量指令之间的主要区别在于，组成 SVI 的标量指令是在处理器后端独立发出和执行的。**SVI 在主线程旁边的现有功能单元上瞬态执行（意味着它们不会影响架构状态），SVI 的目的是预取主线程的未来内存访问。由于按顺序内核中没有备用物理寄存器，因此 SVI 读取和写入称为推测寄存器文件 （SRF） 的小型物理矢量寄存器文件。 在检测到具有跨步内存访问模式的负载指令时，内核进入捎带式超前模式 （PRM） 并为跨步负载生成 SVI，另请参见图 4。SVI 背负在处理器执行的现有实际指令流上，因为在发出实际指令时，也会为直接或间接依赖于跨步负载的任何指令生成 SVI。 从跨步负载开始的依赖指令链称为间接链。当内核遇到相同跨步负载的另一个实例时，生成 SVI 的过程将终止，内核进入等待模式。这标志着间接链的一次迭代的执行。等待模式可防止内核重新进入背负式超前模式，并避免为重叠迭代生成 SVI。当负载超出预取范围时，负载可以重新进入 piggyback runahead 模式。 在检测到具有跨步内存访问模式的负载指令时，内核进入捎带式超前模式 （PRM） 并为跨步负载生成 SVI，另请参见图 4。SVI 背负在处理器执行的现有实际指令流上，因为在发出实际指令时，也会为直接或间接依赖于跨步负载的任何指令生成 SVI。 从跨步负载开始的依赖指令链称为间接链。当内核遇到相同跨步负载的另一个实例时，生成 SVI 的过程将终止，内核进入等待模式。这标志着间接链的一次迭代的执行。等待模式可防止内核重新进入背负式超前模式，并避免为重叠迭代生成 SVI。当负载超出预取范围时，负载可以重新进入 piggyback runahead 模式。\nA.微体系结构 图 5 显示了对基线 in-order 内核的 SVR 微架构修改。为了支持 SVR，我们使用以下结构（绿框）来增强基线：（1） 一个步幅检测器，用于跟踪具有跨步内存访问模式的负载，（2） 一个污点跟踪器，用于识别跨步负载的间接链，（3） 一个名为头部跨步负载寄存器 （HSLR） 的寄存器（蓝色），用于保存启动（和终止）跨步负载的指令指针， （4） 最后一个预取寄存器 （LP），用于跟踪 SVR 为每个跨步加载生成的最后一个地址，以避免重叠的预取，（5） 由间接链内的 runahead 指令访问的推测寄存器文件 （SRF），最后，（6） 修改发出单元以适应标量向量单元 （SVU），该标量向量单元复制当前指令并创建/发出最多 N 个标量副本。在预测 SVR 必须预取的即将到来的迭代次数时，会使用循环绑定检测器 （LBD）（橙色）和最后一个比较寄存器 （LC）（粉红色）。以下部分介绍了每个结构的详细信息。 1） 步幅检测器：步幅检测器使用类似于步幅预取器 [17] 中的参考预测表;它与加载指令的 PC 进行索引。图 6 显示了 stride 检测器每个条目的字段。在 SVR 中，步幅检测器具有多个角色。首先，步幅检测器负责识别具有步幅内存访问模式的加载指令。步幅计算为“Previous Address”和当前地址之间的差值，并存储在“Stride”字段中。当新计算的步幅与已存储的步幅相同时，“饱和度计数器”会增加以表示更高的置信度。其次，步幅检测器中的“Last Prefetch”字段可防止内核在上一轮获取的范围内（等待模式）进入 piggyback runahead 模式，以避免为消耗计算资源的冗余预取生成重复地址。第三，“Seen”位用于在存在多个（嵌套）跨步负载的情况下检测内部循环如果在遇到头部冲刺负载之前已经看到了另一个撞击负载。最后，步幅探测器还跟踪链中的“最后一个间接负载（LIL）”。\n每个负载指令都到达问题队列的头部时访问步幅检测器，并在执行后更新检测器。到达头部后，会按正常发出负载指令。但是，如果将负载检测到跨过，则使用负载的PC更新HSLR，并且核心进入Piggyback Runahead模式。问题单位发出了负载的n副本，其地址基于原始负载和检测到的大小。仅在所有SVIS的所有SVI签发后，就发布了以下计划订单中的指令。\n2)检测间接负载：使用污点跟踪器来识别间接链，该污点跟踪器使用架构寄存器标识符进行索引。图 8 显示了污点跟踪器条目的字段。当指令是间接链的一部分时，“污染”位被设置。跨步加载设置与其目标寄存器相对应的位。任何读取在污点跟踪器中设置了其污点位的寄存器的未来指令也会设置与其目标寄存器相对应的位。为读取带有污染位集的寄存器的所有指令生成 SVI，并且当内核离开捎带运行模式时，污染跟踪器会重置。当架构寄存器映射到 SRF 中的推测寄存器时，“Mapped”位被设置，并且“SRF Reg.”位被设置。 ID’字段存储推测的SRF.reg\n3）寄存器映射和回收：SVR维护具有1,024位宽的投机寄存器的投机寄存器文件（SRF），而16个标量可以同时访问每个寄存器中的不同64位位置。从污点跟踪器中维护了从建筑物到投机寄存器的映射（图8）。通常，SRF登记处的SRF条目通常会少，因为SRF条目非常宽，因此，在硅区域方面的价格也很高。这意味着两者之间不可能进行一对一的映射，因此我们只能一次映射有限数量的建筑寄存器。在Piggyback Runahead模式下，建筑寄存器将在First Write1上分配一个免费的SRF条目（通过Strideload Generation或由于输入寄存器被污染），该寄存器在污染跟踪器中污染和映射建筑寄存器。取决于从此投机寄存器中读取的统计负载，以下标量。当映射的建筑寄存器被不属于间接链的指令所覆盖时，“污染”字段已重置并释放了SRF寄存器。\n相对于架构寄存器，SRF 条目被故意配置不足。为了在它们耗尽时尝试继续矢量化，我们使用 LRU 替换；分配给污点跟踪器中最近最少读取（但仍映射）的架构寄存器的 SRF 条目将被回收。此时，我们通过在污点跟踪器中将架构寄存器的 Mapped 位设置为 0 来指示旧映射的无效性，以防止使用输入寄存器的任何指令被标量向量化。 LRU替换状态是通过Offset字段实现的；它会在每次读取寄存器时更新自该轮捎带运行模式开始以来已执行的指令数。\n4)生成和执行标量向量：SVI 由附加到基线核心的发布单元的标量向量单元生成。在检测到跨步加载时，标量向量单元会根据跨步加载的内存地址和跨步大小创建一个 SVI：具有不同地址的负载的 N 个进一步副本，从而污染污点跟踪器中的目标寄存器。对于污点跟踪器中输入被污染的任何指令，它也会执行相同的操作。当我们从跨步加载（放置在 HSLR 中）启动捎带运行超前模式时，寄存器会跟踪返回到 HSLR 加载之前执行的最后一个间接加载的 16 个最低有效位。当我们终止时，它会被复制到步幅检测器 2 中 HSLR PC 的 LIL 条目中。当超过 LIL 中的指令数或达到 HSLR 负载（以先到者为准）时，我们将停止生成 SVI。\n在终止piggyback runahead mode的时候，最后一个load的后16位被复制到LIL , 但是 SVI本身是和 LIL同步判断的， 那 SVI不是肯定会超出吗，除非是先跑一遍确定LIL,然后进入piggyback runahead mode 生成SVI 这些副本与来自主线程的指令一起发送到功能单元，并根据相关单元的可用性执行。主程序的指令优先于副本。我们使用 ⌈log2(N + 1)⌉ 位返回计数器来扩充记分板的每个条目，以跟踪 N 个执行标量。当从间接链发出指令时，返回计数器设置为 N，并且返回计数器中的值 0 表示为该指令生成的所有标量已完成其执行。返回时，每个标量指令都会更新 SRF，并递减计数器。然后可以继续执行依赖于架构或推测目的地的指令。\n5)终止和启动: 当我们到达 HSLR 中的跨步负载 PC 或 256 条指令超时时，Piggyback runahead 模式终止。然后我们清除污点跟踪器。此时，核心进入等待模式，以避免对相同的跨步负载 PC 重复工作。只要观察到的地址位于步幅检测器条目的 Previous Address 和 Last Prefetch 字段之间，步幅加载就无法开始新一轮的提前运行。一旦在给定 PC 上观察到超出此范围的地址（由于不连续性或在上次预取后到达地址），我们就会重新启动 piggyback runahead 模式。 不懂 6)多个间接链：除了图4中的简单间接链之外，SVR还可以同时处理多个间接链。图 9 显示了三种情况，每种情况都有两个间接链，一种从跨步负载 A 开始，另一种从跨步负载 B 开始。这三种情况提供了通过为多个链生成预取或重新定位到具有更及时预取的链来提高性能的进一步机会（来自更内部的循环）。我们使用跨步检测器中的“Seen”字段来检测其他循环，每当核心检测到跨步负载时就会set。每当内核遇到 HSLR 负载或重新定位并重置 HSLR 时，除 HSLR 负载之外的seem位都会被清除。\nNested Loops.对于嵌套循环，内核在 t0 处对负载 A 进入 piggyback runahead 模式。设置负载的步幅检测器条目中的 Seen 位，并将 HSLR 设置为负载 A 的 PC。当内核在 t 1 处检测到另一个跨步负载 B 时，它将负载 B 的 Seen 位设置为 1，并启动负载 B 的背负超前模式。但是，如果内核在负载 A 之前检测到负载 B 的另一个实例（在 t 2 处）( 什么意思 ，通过检测已设置的负载 B 的 Seen 位，负载 B 是嵌套循环的一部分。因此，内核在 t 2 处中止负载 A 和负载 B 的捎带式超前模式，将 HSLR 设置为负载 B，并开始从负载 B 开始为内部环路生成 SVI。\nUnrolled Loops.对于具有两个间接链并行执行的展开循环，仅为一个链生成预取会使性能下降，因为错过了为另一个链预取内存访问的机会。因此，在为负载 A 生成预取时，如果发行单元发现另一个未设置 Seen 位的独立跨步负载 B，则它也会为从 B 开始的间接链生成标量。**当内核在 t 2 处再次检测到负载 A （HSLR 中的电流负载） 时，B 的 Seen 位被清除。**因此，与嵌套循环不同，当我们在 t 3 遇到另一个 B 实例时，我们不会完全切换到为 B 生成标量，同时为两条链生成预取。\ndependent Loops : 对于独立循环，我们已经完成了 HSLR 负载 PC A 的背负式超前模式，我们将 A 保留在 HSLR 中，并在每次到达 HSLR 时重置所有“Seen”位，无论内核是否处于负载 A 的背负式超前模式。如果我们看到不同的负载 PC B，而内核未处于等待模式，我们设置其 Seen 位，如果随后我们看到 B 设置了 Seen 位，则重定向，使用负载 B 的 PC 更新 HSLR，并开始负载 B 的捎带超前模式，无论内核是处于等待模式还是负载 A 的正常模式。HSLR 中对 PC 的这种偏向是为了防止在首次从外部循环进入内部循环时进行重定向，从而延迟内部循环的超前运行，降低外部循环的优先级，但仍允许重定向到我们两次看到的任何负载，防止在不同循环的新程序阶段出现匮乏。\n7)确定 SVR 何时有用： 为避免 SVR 对性能的损害大于其好处，我们使用 L1 缓存中的预取标签来监控 SVR 的准确性，以跟踪 SVR 带来的负载的首次使用以及使用前的逐出。如果在预热 100 次使用或驱逐后，准确率下降到 50% 以下，我们会阻止触发所有负载 SVR.To 防止这种情况成为永久性的，我们会重置每 100 万条指令，以便给 SVR 另一次执行机会。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-23T22:05:34+08:00","permalink":"https://VastCircle.github.io/2025/scalar_vector_runahead/","title":"Scalar_vector_runahead"},{"content":"DVR的思路 1.discover mode\nRPT : ( pc : 40 addr : 40 stride : 16 state : 2 最内层检测位 : 1)\nDVR是引入了一个子线程，线程是跑在同一个内核里的， 所以它多搞了一组寄存器 ，用来实现SIMT , 单指令多线程\n子线程的生成 ： 从跨步加载开始到存储在FLR 的 PC结束\n子线程使用与主线程相同的取指，解码，执行单元\n子线程指令从前端缓存区生成 ，前端缓冲区通过保持解码的微操作将取指阶段与pipline的其余部分解偶。子线程使用不同的向量发出寄存器（VIR),而不是乱序指令队列 ， 每当主线程没有为端口准备好指令（执行），就会发出子线程发出寄存器的指令\nSVR的思路 stride detector\nimage-20250124121204554 taint Tracket\n当指令是间接链的一部分时，“Tainted\u0026quot;位被set ,\n为读取带有Tainted 位的寄存器的所有指令生成SVI\n当内核离开piggyback runahead mode , taint is reset\nHSLR\n检测到stride load ,将load PC -\u0026gt; HSLR , 并且core 进入 Piggyback Runahead mode\nspeculative Register File\nSVI :\n在检测到stride load 时，SVU会根据内存地址和跨步大小创建一个SVI\n对于taint Tracket输入被污染的指令，也会执行相同操作 。\n当我们从stride load(HSLR中)启动piggyback runahead mode 是，a register keeps track of the 16 least significant bits of the last indirect load executed before we return to the HSLR load。When we terminate, this is copied into the HSLR PC’s LIL entry in the stride detector2.当超过 LIL 中的指令数或达到 HSLR 负载（以先到者为准）时，我们将停止生成 SVI。\n思考 在大核里\nstride load\nRPT : ( pc : 40 addr : 40 stride : 16 state : 2 最内层检测位 : 1)\n当发现检测位为1，可以去清空VTT和FLR ，重新开始\n每当重新遇到启动discoder mode 的pc时， 会清空所有的检测位\nTaint Tracker\nVTT ： 依赖链的建立 ,污点向量记录\nFLR : 记录最后一个load ，更新FLR时，清空SBB和LCR\nloop bound detector\nSBB:是否处理过分支\nLCR:保存上一个比较指令的源和目标寄存器的ID (x86是这样的) ， riscv的话，累加指令？\nbne s0,s4 ,1031a\nbeqz s2,10362\nRPT dispatch -\u0026gt; PC , exe -\u0026gt; addr\n不需要寄存器号\n小核的执行单元和访存单元 ，写回单元（） ， 需不需要写小核的寄存器 ？\nstride load imm , addr, step 寄存器号\n发一条小核执行一条 ？\n什么时候发送?\n找到 stride load 和 loop bound , 再次进入前一个stride load 的时候\nPCv 来记录 stride load pc ，在发现检测位为1时可以去更新PCv, 并且清空VTT和 FLR\n下一轮会把所有标记为脏的指令全部都发送到一个结构里去 ， 然后再用一个结构向量化转发给多个小核（可以在标记的时候就发送吗 ？）\n发送给某个结构的内容？\n能使得小核成功执行指令的 部分\nstride load addr step ， 可能不止一条stride load ,\n只有stride load 需要电路控制 step\n一些算数运算 rs1 rs2 rdata1 rdata2 op , 要放寄存器序号需要重命名， 可以不放寄存器号，可以直接映射到id去 （1）in-order核加一部分寄存器 （2）小核维护一个freeReg 表 ， 完成之后需要恢复\njar ?\ndepend load rs1 imm\nboom Uop -\u0026gt; rocket decode , 大部分可以去除\n提取 ？\ndispatch -\u0026gt; uop\n中间数据都需要通过 exe 读取 ， 最快的应该是从 iregister_read的时候读取 ，\n需要提取的中间数据 ： 没有被VTT标记的寄存器值\n// rocket decode def default: List[BitPat] = // jal renf1 fence.i // val | jalr | renf2 | // | fp_val| | renx2 | | renf3 | // | | rocc| | | renx1 s_alu1 mem_val | | | wfd | // | | | br| | | | scie s_alu2 | imm dw alu | mem_cmd | | | | mul | // | | | | | | | | | zbk | | | | | | | | | | | | div | fence // | | | | | | | | | | zkn | | | | | | | | | | | | | wxd | | amo // | | | | | | | | | | | zks | | | | | | | | | | | | | | | | | dp List(N,X,X,X,X,X,X,X,X,X,X,X, A2_X, A1_X, IMM_X, DW_X, aluFn.FN_X, N,M_X, X,X,X,X,X,X,X,CSR.X,X,X,X,X) // frs3_en wakeup_delay // is val inst? | imm sel | bypassable (aka, known/fixed latency) // | is fp inst? | | uses_ldq | | is_br // | | is single-prec? rs1 regtype | | | uses_stq | | | // | | | micro-code | rs2 type| | | | is_amo | | | // | | | | iq-type func unit | | | | | | | is_fence | | | // | | | | | | | | | | | | | | is_fencei | | | is breakpoint or ecall? // | | | | | | dst | | | | | | | | | mem | | | | is unique? (clear pipeline for it) // | | | | | | regtype | | | | | | | | | cmd | | | | | flush on commit // | | | | | | | | | | | | | | | | | | | | | | | csr cmd // | | | | | | | | | | | | | | | | | | | | | | | | List(N, N, X, uopX , IQT_INT, FU_X , RT_X , DC2 ,DC2 ,X, IS_X, X, X, X, X, N, M_X, DC2, X, X, N, N, X, CSR.X) 其实我看了这么多我感觉是只要遇到一个负载就认为是跨步负载 ， 要不然对于嵌套，肯定是内部的先检测出嵌套循环\nRPT肯定是要有的 ， RPT 应该是每一个load都会分配一个rpt ,\n动态迭代次数也要有\n迭代次数需要达到一定的数量，不能太少\n控制流\nfor (i = 0 to N ) {\n​\tA[i] load A[i]\n​\tfor (j = 0 to M ) {\n​\tB[j] ; load B[j]\n​\t}\n}\nfor (i = 0 to N) {\n​\tA[i] ; load A[i]\n​\tB[i]; load b[i]\n}\nfor (i = 0 to N) {\n​\tA[i] ; load A[i]\n}\nfor (i = 0 to N ) {\n​\tB[i]; load b[i]\n}\nmicroUop\nload a\nstore a -\u0026gt; b // store指令是可以不用关注的\nb -\u0026gt; c // 编译器是不是会直接优化成 a -\u0026gt; c\nload c //\nload a // stride load\na = a ^ b\nload a(imm)\n发送什么 ？\n顺序\n从stride load 到 depend load 的指令的\ndispatch 的时候进入队列 -\u0026gt; 重命名 ？\nROB + issue\n从哪里获取 ？\ndispatch uop + issue data , 专门加入一个队列来放置一些相关的数据 ，\nrob uop + issue data + dispatch\n发送给小核的寄存器号？\nstride load exe之后的结果 可以直接发送过去\n基于存放队列做重命名 -\u0026gt;\nstride load : addr step loop_bound\n后面的一些指令 :\n算数指令:\n顺序表 -\u0026gt; 每个条目\n按道理来说需要把从stride load -\u0026gt; depend load 的整个uop都发送给 小核\nuop 要发送\n小核不和大核共用寄存器堆\ndispatch 里 ， 顺序\ndecode里 发送 ，重命名之前的 ， 分支 ？\nRPT多余的位 最内层检测位可以用来更新 VTT和 FLR\n等传递链结束的时候可以就可以进行vector runahead ,\nDependent-Load Checking\nLCR : 2 src id + dest id x86 cmp eax, ebx\nSBB : 1bit\n架构相关 riscv : 累加 ,riscv通过判断累加值就可以判断stride,通过分支指令就可以判断循环边界 x86 通过比较指令\n比较指令 往前跳\n物理寄存器里\n能就只发送一次吗 ？\nstride +\n发送什么数据\n发送到一个buffer里，在buffer里做矢量化 ，在发送到小核里去\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-22T16:44:10+08:00","permalink":"https://VastCircle.github.io/2025/prefetch%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%80%9D%E8%80%83/","title":"Prefetch的一些小思考"},{"content":"dispatch 两种dispatch , BasicDispatch必须按照特定的标号来dispatch , CompactingDispather coreWidth的标号和dispatchWidth不需要完全对应\n/** * This Dispatcher assumes worst case, all dispatched uops go to 1 issue queue * This is equivalent to BOOMv2 behavior */ class BasicDispatcher(implicit p: Parameters) extends Dispatcher { issueParams.map(ip=\u0026gt;require(ip.dispatchWidth == coreWidth)) // 每一条发射队列对应端口的ready信号都要拉高 val ren_readys = io.dis_uops.map(d=\u0026gt;VecInit(d.map(_.ready)).asUInt).reduce(_\u0026amp;_) for (w \u0026lt;- 0 until coreWidth) { io.ren_uops(w).ready := ren_readys(w) } // io.dis_uops(i) 是第i条发射队列,第i条发射队列的0-coreWidth个端口分别和0-coreWidthren_uops连接 // dis_uops(0) mem dis_uops(1) int dis_uops(2) fp // 每个发射队列要做好最坏的打算，即所有的uop都要发射到这个队列 // dis(w).valid 信号是ren(w).valid信号和发射队列的iqType信号的与，即需要选择对应的发射队列 for {i \u0026lt;- 0 until issueParams.size // 对i条发射队列 w \u0026lt;- 0 until coreWidth} { // 遍历所有MicroOp val issueParam = issueParams(i) val dis = io.dis_uops(i) dis(w).valid := io.ren_uops(w).valid \u0026amp;\u0026amp; ((io.ren_uops(w).bits.iq_type \u0026amp; issueParam.iqType.U) =/= 0.U) dis(w).bits := io.ren_uops(w).bits } } /** * Tries to dispatch as many uops as it can to issue queues, * which may accept fewer than coreWidth per cycle. * When dispatchWidth == coreWidth, its behavior differs * from the BasicDispatcher in that it will only stall dispatch when * an issue queue required by a uop is full. * 尝试尽可能多的向发射队列派遣指令，可以忍受每个周期较低的coreWidth, 每个发射队列的 coreWidth \u0026gt;= dispatchWidth */ class CompactingDispatcher(implicit p: Parameters) extends Dispatcher { issueParams.map(ip =\u0026gt; require(ip.dispatchWidth \u0026gt;= ip.issueWidth)) // input io.ren_uops -\u0026gt; output io.dis_uops // ren_readys(w), 指的是第w条发射队列， val ren_readys = Wire(Vec(issueParams.size, Vec(coreWidth, Bool()))) // 遍历每条派遣队列，ip是参数 for (((ip, dis), rdy) \u0026lt;- issueParams zip io.dis_uops zip ren_readys) { val ren = Wire(Vec(coreWidth, Decoupled(new MicroOp))) ren \u0026lt;\u0026gt; io.ren_uops val uses_iq = ren map (u =\u0026gt; (u.bits.iq_type \u0026amp; ip.iqType.U).orR) // Only request an issue slot if the uop needs to enter that queue. // 修改ren.valid 为 valid \u0026amp; uses_iq， 即需要保证ip一致 (ren zip io.ren_uops zip uses_iq) foreach {case ((u,v),q) =\u0026gt; u.valid := v.valid \u0026amp;\u0026amp; q} // compactor是将n个输入的前k个有效输入连接到输出 // 在n输入里， 选择k个作为输出， 在coreWidth个输入里，选择ip.dispatchWidth个作为输出 // ren.ready应该是指被选中的几个端口 val compactor = Module(new Compactor(coreWidth, ip.dispatchWidth, new MicroOp)) compactor.io.in \u0026lt;\u0026gt; ren dis \u0026lt;\u0026gt; compactor.io.out // The queue is considered ready if the uop doesn\u0026#39;t use it. rdy := ren zip uses_iq map {case (u,q) =\u0026gt; u.ready || !q} } // r(i)实际就是 ren_readys(0,i) \u0026amp;\u0026amp; ren_readys(1,i) \u0026amp;\u0026amp; ren_readys(2,i) \u0026amp;\u0026amp; ren_readys(3,i)的结果 // 还是所有端口同时readyio.ren_uops才能ready (ren_readys.reduce((r,i) =\u0026gt; VecInit(r zip i map {case (r,i) =\u0026gt; r \u0026amp;\u0026amp; i})) zip io.ren_uops) foreach {case (r,u) =\u0026gt; u.ready := r} } issue-unit 定义了IssueUnit抽象类，issue-unit-age-ordered.scala和issue-unit-unordered.scala中定义的顺序/乱序发射单元类都由它派生。\n发射队列保存着已派遣但又未执行的微指令。当微指令的所有操作数都就绪时，保存该微指令的发射槽将把request位置为1。然后发射选择逻辑将选择一个发射槽进行发射。一条微指令被发射时，它将在发射队列中被删除，以腾出空间给更多派遣的指令。\nBOOM使用彼此不同的一组发射队列，对应不同的指令类型（整数、浮点数、访存）。\n尽管还没有实现，未来的设计可能会为了提高性能而发射推测状态的微指令（例如，推测一条加载指令会命中缓存，所以在假设加载的数据会通过旁路从而可用的情况下，选择发射有数据依赖的指令）。在这种情况下，发射队列将不能删除已发射的处于推测状态的微指令，直到其状态被确定。如果已发射的微指令的推测出错，所有从这个推测窗口发射的微指令都必须被清除，并从发射队列中重试。另外更多先进的技术也已经可用。\nissue-slot 微指令被派遣到发射队列中，它们将等待所有操作数准备就绪（“p”代表存在位，它表示操作数何时在寄存器堆中可用）。一旦准备就绪，发射槽将发出request信号，并等待发射。\n每个发射选择逻辑端口都是一个静态的优先编码器，用于选取发射队列中的第一个valid的微指令。每个端口（连接到某个执行单元）将只调度其可以处理的微指令（例如，浮点指令将只调度到拥有浮点单元的端口）。这将为端口创建级联的优先级编码器，这些端口可以彼此调度相同的微指令。\n如果检测到某个功能单元（发射槽中微指令需要的功能单元）不可用，发射槽将取消valid信号，并且不会向其该功能单元发出指令（例如，尝试发射到正在计算的一个非流水线化除法器）。\nstore(AMO)指令被分成两个uop , 但是存储在同一个发射槽中\n一个是状态的更新， 总共3个状态 in_valid , valid_1, valid_2 . 有两个状态变量， state 和 next_state ,state是一个reg,next_state是一个wire, state改变可以通过 in_uop.valid来改变，其他时候state的改变是通过next_state来改变的\n对于next_state , 在要发射了之后next_state 就会变成 s_invalid , 在state = s_valid_2的时候，就会变成 uopSTD的uop 然后转化为valid_2\nissue-unit-age-ordered 顺序发射单元。\n对于每个新派遣的指令，总是放到队列中尽可能靠后的位置（即“顺序”）。而在每个周期中，这些指令都会向前移动（即“紧密”）。 这样就使得最早的指令拥有最高的发射优先级。 这种设计代码显然更复杂，面积和功耗较大，但性能更好。\n在IssueUnit抽象类的基础上实现了以下功能：\n计算出发射后发射槽和派遣过来的每一条指令需要的移位数，然后进行移位。 移位完成后给派遣级正确的ready信号，并实现发射逻辑。 探究一下 io_iss_valid生成的verilog是怎么样的 可以看到它是由一堆的东西或起来\nassign io_iss_valids_0 = _T_1569 | _T_1530 | _T_1491 | _T_1452 | _T_1413 | _T_1374 | _T_1335 | _T_1296 | _T_1257 | _T_1218 | _T_1179 | _T_1140 | _T_1101 | _T_1062 | _T_1023 | _T_984 | _T_945 | _T_906 | _T_867 | _T_828 | _T_789 | _T_750 | _T_711 | _T_672 | _T_633 | _T_594 | _T_555 | _T_516 | _T_477 | _T_438 | _T_399 | _T_360;\twire [9:0] _can_allocate_T_93 = _slots_31_io_uop_fu_code \u0026amp; io_fu_types_0;\twire _T_1569 = _slots_31_io_request \u0026amp; (|_can_allocate_T_93) \u0026amp; ~_T_1534;\twire _T_1534 = _slots_30_io_request \u0026amp; (|_can_allocate_T_90) | _T_1495;\twire _T_1495 = _slots_29_io_request \u0026amp; (|_can_allocate_T_87) | _T_1456;\twire _T_1530 = _slots_30_io_request \u0026amp; (|_can_allocate_T_90) \u0026amp; ~_T_1495;\twire _T_1495 = _slots_29_io_request \u0026amp; (|_can_allocate_T_87) | _T_1456;\t... wire _T_360 = _slots_0_io_request \u0026amp; (|_can_allocate_T);\tassign io_iss_valids_1 = _T_1582 | _T_1543 | _T_1504 | _T_1465 | _T_1426 | _T_1387 | _T_1348 | _T_1309 | _T_1270 | _T_1231 | _T_1192 | _T_1153 | _T_1114 | _T_1075 | _T_1036 | _T_997 | _T_958 | _T_919 | _T_880 | _T_841 | _T_802 | _T_763 | _T_724 | _T_685 | _T_646 | _T_607 | _T_568 | _T_529 | _T_490 | _T_451 | _T_412 | _T_373;\twire [9:0] _can_allocate_T_94 = _slots_31_io_uop_fu_code \u0026amp; io_fu_types_1;\twire _T_1582 = _slots_31_io_request \u0026amp; ~_T_1577 \u0026amp; (|_can_allocate_T_94) \u0026amp; ~_T_1547;\twire _T_1577 = _slots_31_io_request \u0026amp; (|_can_allocate_T_93) \u0026amp; ~_T_1534;\t= _T_1569 wire _T_1547 = _slots_30_io_request \u0026amp; ~_T_1538 \u0026amp; (|_can_allocate_T_91) | _T_1508;\t看似是一堆或，实际上这些或只有一个会成立\n可以看到，如果_T_360满足条件的话后面的或实际上条件都是不满足的 ， 因为后面的或满足条件的前提就是前面的或不满足条件\n所以对应io_iss_valid_0来说，它就是优先找到一组满足 fu_code \u0026amp; io_fu_code 的发射队列 ， 然后就把相应发射槽的值赋给这个端口\n对于io_iss_valid_1来说，它就要多一个条件，即这个端口是没有被 0所占用的， 即上面的_T_1569, 满足_T_1569说明是会被端口1占用的\nissue-unit-unordered 乱序发射单元。\n是MIPS R10k采取的方案。当指令被派遣时，会选择发射队列中最靠前的可用位置进行安排（valid优先而不是前面的优先，即“乱序”），而后续不会移动位置（即“静态”）。 这就意味着如果某条指令在派遣时“恰好”被安排到了较为靠后的位置，那它就需要等待很久（等到排在前面位置的能够发射的指令不足时）才能被发射。 这种实现方式比较简单，但性能不够高。\n在IssueUnit抽象类的基础上实现了以下功能：\n为每一个发射槽增加一个写使能的独热码信号，用于将派遣的指令安排到发射队列中。 实现高低两个优先级的发射尝试。 插一嘴，这个extend真的很聪明，这样不仅是io,所有的变量都可以用\nexecution-units 构建执行单元组。\n将同类（都是非FPU或FPU）的执行单元放在一个“collection”类ExecutionUnits中。根据参数配置执行单元，检查执行单元中功能单元的完备性，完善调试输出信息以及定义执行单元组总的一些参数。\nexeunits 其中，灰色方框就是执行单元，而灰色方框连接的线上的就是功能单元。虚线表示继承关系（如FunctionalUnit抽象类由BoomModule类继承），而导图主体表示可选的包含关系（比如ALUExeUnit类中可以包含ALUUnit类、RoCCShim类等中的若干类，注意有些功能单元组合是不被允许的）。\n可以看出，不少的功能单元最后都包含有Rocket的功能单元（加粗的类），但需要注意的是，这功能单元是适用在Rocket这种顺序流水线上的，而在BOOM中，由于使用乱序流水线，被发射的指令有可能在中途被kill掉，那些功能单元不能兼容这种场景。 因此为了复用Rocket的功能单元，BOOM在这些FunctionalUnit抽象类中将Rocket上的功能单元包装起来（增加相关逻辑和端口等），以适应需要。\n一个ExecitionUnits有多个exe_units\nexecution-unit 在BOOM中，一个执行单元(Execution Unit)连接到一个发射端口上，接收一个发射的指令（即三发射的BOOM需要有三个执行单元），其内部拥有一个或多个功能单元(Functional Unit)。 比如一个执行单元可能仅包括一个整数ALU，也可能是整数ALU、整数乘法的组合。本文件中，先定义了一个抽象的执行单元类ExecutionUnit，然后派生出两个子类ALUExeUnit和FPUExeUnit，其中可含有的功能单元不同，而且含有什么样的功能单元可由构造时传入的参数决定。执行单元的示意图如下：\n发射窗口调度微指令到一个特定的执行流水线上\n一个给定的指令流水线可能包含多个功能单元；有一个或多个读写端口\n其中包括 ALUExeUnit, FPUExeUnit\nfunctional-unit 里面主要是有一些常见的功能单元 ， 包括ALUUnit(也可以用作jmpUnit)， MemAddrCalcUnit , FPUint , DivUnit , PipelinedMulUnit ,\nALUUnit内部用的就是rocket的alu ,ALUUnit里比较重要的应该是分支预测器的一些更新，它是需要去选择下一个pc是跳转pc还是pc+4的，一些分支的简单比较之类的，eq,\u0026gt;=之类的不是通过alu进行的，是另外的比较器来做的 ，地址的话应该是alu来计算的\nMemAddrAclcUnit:内存地址计算单元类，传入base和imm以计算地址，然后把要储存的数据传递给LSU。\nfunc-unit-decode —— 功能单元译码。\n从指令的发射阶段（ISS）接收valid信号和微指令uop，通过译码表得到读寄存器的控制信号（RRdCrtlSigs），根据此控制信号修改微指令uop中的成员，并将修改后的uop连同valid信号一并发送到读寄存器（RRD）阶段。\n在register-read.scala的连接输出部分中有应用。而且由于RegisterReadDecode类并没有考虑分支，实际上register-read.scala中应用这个类时还对输出进行了分支的修正。\nregfile —— 寄存器堆。\nBOOM使用统一的物理寄存器堆(Physical Register File, PRF)设计。寄存器堆同时保持提交状态和推测状态。此外，有两个寄存器堆：一个用于整数，另一个用于浮点寄存器值。重命名映射表跟踪与ISA寄存器对应的物理寄存器。\nregister-read —— 读寄存器。\n工作流程：从指令发射（ISS）阶段接受valid信号和微指令uop信息，以及读寄存器的地址（ISS阶段末）；在读寄存器（RDD）阶段的开始通过func-unit-decode中定义的译码器得到功能单元译码、考虑分支后的微指令uop；RDD阶段，从连接的寄存器堆读取数据；在RDD阶段末，用从ALU过来的旁路信息更新数据，最终传给执行（EXE）阶段。\n当前实现的寄存器堆静态地为所有已发射指令提供需要的所有寄存器读取端口。例如，如果发射端口#0对应于一个整数ALU，发射端口#1对应于内存单元，那么前两个寄存器读取端口将静态地为ALU服务，下两个寄存器读取端口将为内存单元服务，总共四个读取端口。\n未来的设计可以通过提供更少的寄存器读取端口和使用动态调度来仲裁(arbitrate)这些端口来提高区域效率。这尤其有用，因为大多数指令只需要一个操作数。然而，它确实增加了设计的额外复杂性，这通常表现为需要额外的流水线级来仲裁或者检测结构冲突。它还需要能够终止已发射的微指令，并在以后的周期中从发射队列重新发射它们。\ncore // BOOM has the following (conceptual) stages: // if0 - Instruction Fetch 0 (next-pc select) // if1 - Instruction Fetch 1 (I$ access) // if2 - Instruction Fetch 2 (instruction return) // if3 - Instruction Fetch 3 (enqueue to fetch buffer) // if4 - Instruction Fetch 4 (redirect from bpd) // dec - Decode // ren - Rename1 // dis - Rename2/Dispatch // iss - Issue // rrd - Register Read // exe - Execute // mem - Memory // sxt - Sign-extend // wb - Writeback // com - Commit rob 重排序缓存器(Reorder Buffer, ROB)跟踪在流水线中运行的微指令的状态。ROB的作用就是给程序员一种“他的程序是按顺序执行的”的错觉。指令在被译码和重命名后，将被派遣到ROB和发射队列并被标记为繁忙。指令完成执行后将告知ROB并且被重新标记为不繁忙。一旦ROB的“头”不再繁忙，就代表这条指令被提交了，它的体系结构状态现在是可见的。如果有一个异常发生，并且引发异常的指令在ROB的头部，流水线将被清除，并且在异常指令可见后不会出现任何体系结构的更改，然后ROB会重定向PC到相应的异常处理程序。\n上图是一个三发射双宽度(two-wide)BOOM的ROB。派遣的微指令将被写在ROB的底部（或尾部，tail），而提交的微指令将在顶部，即ROB头部提交，然后更新重命名阶段的相关信息。完成执行的微指令（等待写回的微指令，wb uops）会清除他们的繁忙位。注意：派遣的微指令组会同时被写进同一个ROB的行，在内存中连续存放，使得可以用一个PC代表整个行。\nROB在概念上是一个循环的缓冲区，顺序地追踪所有运行中的指令。最老（最先进入流水线）的指令将由commit head指向，最新的指令将在rob tail处插入。\n为了方便超标量派遣和提交，ROB被实现为一个有W栏(bank)的循环缓冲区，其中W是机器派遣和提交的宽度。（如上图中W=2）,这个就和香山的有些区别 ，香山应该是直接放连续的rob\n派遣时，最多w条指令将从取指包裹（或取指数据包，Fetch Packet，见下面引用部分）被写到一个ROB的行中，其中每条指令都会被写到不同的栏（列）中。由于一个取指包裹中的指令组在内存中都是连续存放的，可以用一个PC来联系一个取指包裹（包裹内指令的位置提供了它自己PC的低位）。这也意味着分支将在ROB中留下气泡（空指令占的位置），这使得向ROB添加更多指令的开销变小，因为本来很大的开销被每个ROB行平摊了。\n取指包裹(Fetch Packet)：前端返回的一个包，其中包含一组连续的指令，带有一个掩码，表示哪些指令有效，以及与指令提取和分支预测相关的其他元数据。Fetch PC将指向取指包裹中的第一条有效指令，因为它是前端用来获取取指包裹的PC。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-22T15:46:47+08:00","permalink":"https://VastCircle.github.io/2025/boom%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BBexu/","title":"Boom代码阅读——exu"},{"content":" recency-frindly : 局部性非常好 thrashing : 会频繁发生驱逐 scans:所有的数据块都会发生一次\n状态机和流水线，两种实现方法 ，直接把状态机的状态转移变成流水化\n如果l1向l2发起请求，l2缺失，此时l2如果不保存数据直接发送到l1,那就是exclusive,反之为inclusive\nTileLink是一种MSI协议\n内存一致性 RISCV用的是这个\n香山缓存设计 通过软件的方法可以实现（fence)icache的一致性\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-18T22:20:27+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E9%82%80%E8%AF%B7%E6%8A%A5%E5%91%8A%E7%BC%93%E5%AD%98%E5%9F%BA%E7%A1%80%E5%92%8C%E9%A6%99%E5%B1%B1%E7%BC%93%E5%AD%98/","title":"香山邀请报告——缓存基础和香山缓存"},{"content":" basic block是参考2中给出的一个概念，由程序中不包含跳转指令的一段连续指令组成。在simpoint中对程序的运行时先按100Million条指令为单位切段，就级，然后统计这段时间内，每个basic block执行的次数，再将每个basic block出现的次数和block中包含的指令条数相乘就得到这个basic block的对应的值，所有这些值组成一个向量。如果程序运行时包含N个100Million条指令组成的指令流，就会有N个向量，统称为basic block vector\n原文链接：https://blog.csdn.net/anfang654321/article/details/128225885\ninterval1 和interval2是更相似的 ，那就可以选择1,2中的一个\n先用功能CPU模型跑，在关键点的时候切成其他模型跑\n如何知道是正常开机还是断电状态的回复\n附录 参考文献 simpoint原理\nbasic-blocks\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-18T20:40:58+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E9%82%80%E8%AF%B7%E6%8A%A5%E5%91%8A%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E7%AE%97%E5%9F%BA%E7%A1%80/","title":"香山邀请报告——处理器的性能测算基础"},{"content":"香山ppt 如果向量寄存器是128位的话，SEW=8,说明有128/8个元素参与运算\n手册学习 Vector Extension Programmer\u0026rsquo;s Model VLEN: 向量bit数, ELEN: 最大支持的元素bit数 增加了32个vector regs, 7个非特权CSRs image-20250118195010316 3.4 VType,Vector type register 一个Vector reg被分成VLEN/SEW个元素，sew代表一个元素的大小\n多个vector可以组成一个group,lmul代表一组有多少个向量寄存器\n向量指令执行期间操作的元素索引可以分为四个不相交的子集。\n预启动元素（The prestart elements）: 是指索引小于vstart寄存器初始值的元素。预启动元素不会引发异常，也不会更新目标向量寄存器。 活跃元素（The active elements）: 指的是向量指令执行期间，在当前向量长度范围内的元素，并且在该元素位置启用了当前掩码。活动元素可以引发异常并更新目标向量寄存器组。 非活跃元素（The inactive elements）: 指的是向量指令执行期间，在当前向量长度范围内的元素，但是在该元素位置禁用了当前掩码。 除非指定了masked agnostic（ vtype.vma = 1 ），否则非活跃元素不会引发异常，也不会更新任何目标向量寄存器组，在 vtype.vma = 1 这种情况下，非活跃元素可能会被1覆盖。 尾部元素（The tail elements）: 是超出当前向量长度设置的元素。 尾部元素不会引发异常，并且只在指定了tail agnostic尾部不可知性（vtype.vta = 1）的情况下，才会更新目标向量寄存器组，在这种情况下，尾部元素可能会被1覆盖。 当LMUL \u0026lt;1时，尾部包含VLMAX之后的元素，这些元素保存在同一向量寄存器中。 主体部分（body）: 用于表示活跃元素或非活跃元素的集合，即在预启动元素之后但在尾部元素之前。 for element index x prestart = (0 \u0026lt;= x \u0026lt; vstart) mask(x) = unmasked || v0[x].LSB == 1 active(x) = (vstart \u0026lt;= x \u0026lt; vl) \u0026amp;\u0026amp; mask(x) inactive(x) = (vstart \u0026lt;= x \u0026lt; vl) \u0026amp;\u0026amp; !mask(x) body(x) = active(x) || inactive(x) tail(x) = (vl \u0026lt;= x \u0026lt; max(VLMAX,VLEN/SEW)) 对尾部元素的mask行为将被视为tail-agnostic, 无论vta如何配置.\n当指定了agnostic时,对应的向量元素可以保持之前的值, 也可以被重写为全1. 并且对于同样的输入, 是保持undisturbed还是覆写为1,可以是不确定的.\nagnostic策略实际上是为了兼容带有向量寄存器重命名的机器设计的. 如果只有undisturbed策略, 那么在寄存器重命名的时候就需要将旧的物理目的寄存器的内容复制到新的物理目的寄存器. 而设置为agnostic之后就可以忽略掉这部分无效的内容.\n对于超标量的流水线，会采用寄存器重命名的方式，来避免WAW以及WAR这两类hazard。那程序的逻辑寄存器会映射到物理寄存器，映射后的对应关系会更新到重命名映射表中。那对于undisturbed策略，需要目的寄存器相应的元素保持原来的值。那么在用新的物理寄存器重命名时，还需要根据重命名映射表，查到原有的映射关系，再把这部分元素的值先读出来，写到重命名后的对应元素位置。这种方式对于压根儿不关心尾部元素集合或者被屏蔽元素集合的值的后续操作，就既降低了性能，又增加了不必要的功耗。\n对于普通的in-order流水线，可以采用这种undisturbed的策略。对于超标量的流水线，使用agnostic策略就显得更加明智。\n标志之前的一次vsetvli指令下发了一次不支持的值\n当尝试执行一条vill位=1的指令时, 将会抛出非法指令异常\nvill=1时, vtype的其他部分需要被置为0\n3.5 Vector Length Register, vl 只能通过vset{i}vl{i}指令赋值 定义了需一条向量指令更新的向量元素个数 3.6 Vector Byte Length, vlenb vlenb = VLEN/8 该寄存器是给一些需要将VLEN以byte计数的场景，否则还需要手动计算byte数 3.7 Vector Start Index CSR, vstart 定义了一条向量指令执行时的第一个元素在向量中的索引号 一条向量指令结束时会将vstart归零 vstart之前的向量值将保持undisturbed 如果一条向量指令引发了非法异常，则不会修改vstart vstart可以被非特权等级的代码修改， 但是非0的vstart可能使得向量指令运行变慢，所以不应该被应用程序修改 3.8. Vector Fixed-Point Rounding Mode Register , vxrm vxrm[1:0]为可读可写寄存器，该寄存器不仅有独立的寄存器地址，并且在vcsr寄存器中也有对应的域。该寄存器控制定点舍入模式，一共四种模式，分别是round-to-nearest-up（rnu）、round-to-nearest-even(rne)、round-down(rdn)、round-to-odd(rod)。(问题：可否解释一下定点数在内存中的存放格式) vxrm[1:0]寄存器通过单条csrwi指令写入值。 假如源操作数是v，有低d bit数据要被截掉，那么做完rounding-mode之后的最终结果应该是(v\u0026raquo;d)+r，r就是根据不同的rounding mode得到的增量值。 rnu：向距离近的方向进行舍入，当距离与两边都相等时，向上舍入。 rne：向距离近的方向进行舍入，当距离与两边都相等时，向偶数方向舍入。 rdn：向下舍入，直接取移位后的值。 rod：舍入到奇数值方向。 其中，v[d-1]表示权重位。当v[d-1]=0，表示距离舍的方向更近；当v[d-1]=1且v[d-2:0]=0时，距离舍入两个方向距离均相等；当v[d-1]=1，且v[d-2:0] != 0时，表示距离入的方向更近。 img 3.9. Vector Fixed-Point Saturation Flag, vxsat vxsat为可读可写寄存器，该寄存器不仅有独立的寄存器地址，并且在vcsr寄存器中也有对应的域。该寄存器有效表示输出结果做了饱和截位以适应目的寄存器格式。比如当运算发生正溢出时，保留结果为能取到的最大正值；当运算发生负溢出时，保留结果为负数最小值。 3.10. Vector Control and Status Register, vcsr 实际上包含了vxrm和vxsat两个寄存器 img 3.11. State of Vector Extension at Reset 推荐的做法是在reset时， vtype.vill=1， 其余位为0， 且vl=0 大部分向量单元需要一个初始的vset{i}vl{i}, 来复位vstart. vxrm和vxsat也需要在使用前复位 5. Vector Instruction Formats 向量指令格式会单独扩展一个格式：OP-V 向量的load和store指令沿用LOAD-FP和STORE-FP: img 向量算数指令： img 向量配置指令： img img 向量指令可以接收标量或者向量操作数，生成标量或者向量操作数 大多数向量指令可以通过mask实现条件或者非条件执行 5.1. Scalar Operands 标量操作数可以是立即数，整数寄存器（x），浮点寄存器(f)或者一个vector寄存器的第0个元素。 标量结果可以写入整数寄存器（x），浮点寄存器(f)或者一个vector寄存器的第0个元素。 5.2. Vector Operands 每个向量操作数都有一个effective element width (EEW), 一般情况下EEW=SEW. 每个向量操作数都有一个effectiveLMUL (EMUL), 一般情况下EMUL=LMUL. 某些向量指令的源和目的向量具有相同的元素个数，但是元素位宽不同。此时EEW和EMUL就不等于SEW和LMUL, 但是EEW/EMUL = SEW/LMUL，这样才能保证元素个数相同。例如：大部分拓宽的向量算数指令的源操作向量组EEW=SEW, EMUL=LMUL, 但是目的操作向量组的EEW=2SEW, EMUL=2LMUL 向量操作数或者结果操作数可能占用一个或多个向量寄存器（取决于EMUL), 如果占用多个，默认占用编号值较低的向量寄存器。 以下情况可以将目的向量寄存器组直接覆盖源向量寄存器组： 目的EEW=源EEW 目的EEW\u0026lt;源EEW, 并且发生覆盖的源向量是源向量寄存器组中的最低编号的向量寄存器。例如：LMUL=1, vnsrl.wi v0, v0, 3 is legal, but a destination of v1 is not 目的EEW\u0026gt;源EEW, 源EMUL至少是1， 并且发生覆盖的是目的向量寄存器组中的最高编号的向量寄存器。例如：LMUL=8, vzext.vf4 v0, v6 is legal, but a source of v0, v2, or v4 is not 向量指令最多可以用8个向量寄存器，也就是是说EMUL\u0026lt;=8. 如果一条向量指令需要超过8个向量寄存器，则会引发非法指令异常（实际上这种情况的指令编码空间是被保留的，目前不支持，可以被扩展）。 例如，当 LMUL = 8 时，尝试进行加宽操作产生加宽的向量寄存器组将引发非法指令异常，因为这意味着 EMUL = 16。 拓宽（Widened)标量值时，放在向量寄存器的第一个元素，EMUL=1. 5.3. Vector Masking 许多向量指令都支持掩码。 被掩码（非活跃）的元素操作不产生异常。 根据 vtype 中的 vma 位的设置，用_掩码不受干扰或掩码不可知_（mask-undisturbed or mask-agnostic）这两种策略来处理与掩码元素相对应的目标向量寄存器元素。 在掩码向量指令中，由向量寄存器 v0 保存用于控制掩码向量指令执行的掩码值。 以后的向量扩展可能会提供更长的指令编码，并为完整的掩码寄存器说明符提供空间。 只有当目标向量寄存器写入掩码值（如，comparisons）或归约的标量结果时，用于掩码向量指令的目标向量寄存器组才可以与源掩码寄存器（ v0 ）重叠。 否则，将引发非法指令异常。 其他向量寄存器可用于保存有效的掩码值，并且提供掩码向量逻辑运算以执行谓词计算。 当使用比较结果写入掩码时，当前向量长度结束后的目标掩码位将根据 vtype中的 vta 位设置的尾部策略（ undisturbed or agnostic ）处理。 5.3.1. Mask Encoding 掩码编码在指令( inst[25] )中的 vm 字段中，占一位。 img 向量掩码在汇编代码中表示为另一个向量操作数，用 .t 表示当 v0.mask[i] 为 1 时是否发生操作。如果未指定掩码操作数，则假定为未掩码的向量执行（ vm = 1 ）。 在较早版本中，vm 字段占2位，即vm [1：0]，使用 v0 寄存器并编码标量运算，表示真值和掩码值。_ 即使基本向量扩展中，仅支持一个向量掩码寄存器 v0 ，并且仅支持真实的谓词形式，汇编语法仍将其完全写出，以便与以后的扩展兼容，以后的扩展可能会添加掩码寄存器说明符并支持真值和掩码值。 掩码操作数上的 .t 后缀还有助于掩码编码的可视化。 未完 ，主要去看参考文献1\n附录 参考文献 riscv向量v扩展\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-18T17:07:03+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E9%82%80%E8%AF%B7%E6%8A%A5%E5%91%8A%E5%90%91%E9%87%8F%E6%89%A9%E5%B1%95%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0/","title":"香山邀请报告——向量扩展的设计和实现"},{"content":"来自b站 image-20250118122646890 主流设计应该是后者，因为现在数据位宽越來越大\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-18T12:22:33+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81%E5%89%96%E6%9E%90%E6%8C%87%E4%BB%A4%E7%9A%84%E6%89%A7%E8%A1%8C/","title":"香山源代码剖析——指令的执行"},{"content":"ROB 来自香山视频 image-20250118155208467 image-20250118155407635 乱序阶段都包含rob表项顺序信息，在rob广播的时候，晚于rob的指令都会被刷掉\n通过artch表向spec table覆盖就可以恢复重命名表\n实际上需要flush的指令是1,2,但是arch复原的状态是DeqPtr,5,6,7,0的状态也被复原了，所以可以通过walk,把这一步的重命名表重新写入\nROB的作用 在乱序处理器中，ROB 的作用是给指令定序，使得程序正常执行的结果能够被保留下来。按照一条指令的执行流程，ROB 会依次影响指令的派遣、写回、提交流程，同时指令还可能在任何时刻被冲刷。\n派遣 在 Dispatch 阶段，指令会被分配一个 ROB 的表项，并将一些需要保存的信息 RobCommitInfo 存入 ROB 中，如指令的重命名信息、类型信息、对应 ftq 指针等。ROB 入队的宽度与重命名的宽度保持一致。\n在指令进入 ROB 之后，一些状态位会被更新，如 valid, writebacked, interrupt_safe（出于简化设计的考虑，目前访存指令是否是 MMIO 的信息不会传递到 ROB，他们会在提交前发生访存，因此目前我们简化设计避免访存指令触发中断）等。\n写回 指令完成执行后，会通知 ROB 对应的运算操作已经完成，并由 ROB 将 writebacked 标志位置为 true。\n提交 在每一个时钟周期中，ROB 会依次检查队头的指令是否能够正常提交，并尽量多地将可以提交的指令通过 io.commits 接口进行提交。\n针对有异常的指令，它们的提交会被阻塞，并通过 io.exception 接口向外发出异常信息。\n取消与回滚 在指令的执行过程中，如果出现分支预测错误、访存违例等情况，该指令及更之后的指令可能会需要被冲刷。在这种情况下，ROB 会通过 io.redirect 端口收到取消信息，并根据取消信息来判断哪一部分指令需要被取消。对于被取消掉的指令，ROB 会利用回滚的机制，通过 io.commits 端口恢复重命名等信息，此时 io.commits.isWalk 会被置为 true\n代码分析 Rab renameBuffer rab的结构挺简单的，大部分的代码都是在改变指针，还有传递给rob对应的commit_info\n通过一个状态机来控制commit , idle,walk, special_walk, 在idle和special_walk的时候commit_valid , 在special_walk 和walk的时候 valid_valid\nRab是对于寄存器映射信息的独立映射\n// 熟悉的指针组 // pointer private val enqPtrVec = RegInit(VecInit.tabulate(RenameWidth)(idx =\u0026gt; RenameBufferPtr(flag = false, idx))) private val enqPtr = enqPtrVec.head private val enqPtrOH = RegInit(1.U(size.W)) private val enqPtrOHShift = CircularShift(enqPtrOH) // may shift [0, RenameWidth] steps private val enqPtrOHVec = VecInit.tabulate(RenameWidth + 1)(enqPtrOHShift.left) private val enqPtrVecNext = Wire(enqPtrVec.cloneType) private val deqPtrVec = RegInit(VecInit.tabulate(RabCommitWidth)(idx =\u0026gt; RenameBufferPtr(flag = false, idx))) private val deqPtr = deqPtrVec.head private val deqPtrOH = RegInit(1.U(size.W)) private val deqPtrOHShift = CircularShift(deqPtrOH) private val deqPtrOHVec = VecInit.tabulate(RabCommitWidth + 1)(deqPtrOHShift.left) private val deqPtrVecNext = Wire(deqPtrVec.cloneType) XSError(deqPtr.toOH =/= deqPtrOH, p\u0026#34;wrong one-hot reg between $deqPtr and $deqPtrOH\u0026#34;) private val walkPtr = Reg(new RenameBufferPtr) private val walkPtrOH = walkPtr.toOH private val walkPtrOHVec = VecInit.tabulate(RabCommitWidth + 1)(CircularShift(walkPtrOH).left) private val walkPtrNext = Wire(new RenameBufferPtr) RenameBufferEntry class RenameBufferEntry(implicit p: Parameters) extends XSBundle { val info = new RabCommitInfo // 寄存器的映射关系 val robIdx = OptionWrapper(!env.FPGAPlatform, new RobPtr) // Rob的指针 } class RabCommitInfo(implicit p: Parameters) extends XSBundle { val ldest = UInt(LogicRegsWidth.W) val pdest = UInt(PhyRegIdxWidth.W) val rfWen = Bool() val fpWen = Bool() val vecWen = Bool() val v0Wen = Bool() val vlWen = Bool() val isMove = Bool() } VTypeBuffer VTypeBuffer是用来定序向量配置指令，储存向量配置信息的 ， 暂时先不看\nRob robEntries(i).valid 通过判断 1. 有指令要进入 true, 2. 有指令deq false , flush false\n指针的更新通过专门的ptrGenModule来更新\nload/store 指令会写入在lsq里 （load store queue)\nneedUpdate初始化的数据是通过robBanksRaddrThisLine定位的addr , 8个bank 对应8个数据，还有next_addr,总共16个数据 ，这16个数据其实就是连续的16个数据，16个连续的\nrob的commit主要是针对rename的提交，它需要去把一些物理寄存器的映射取消掉\nenq的指令是带有一个robIdx的，这是在dispatch的时候随着microop一起传递的，rob就是通过RobPtr向量(rob.resp)向dispatch传递robldx的\n从walkPtr到lastwalkPtr的内容都要进行回滚\n现在rob是没有存放old_pdest的，old_pdest貌似是在renameTable里存放的 , old_pdest现在是去更新arch_table的时候把被更新的值直接作为old_pdest，所以它其实没有必要和指令进行强绑定，它应该是要和逻辑寄存器号进行绑定的\n产生分支预测错误的指令，是直接把预测错误的指令和它后续的指令清除（具体就是Enq指针回退），实际不需要执行到这条语句的时候再处理\ncommitValid代表提交有效\nrobDeqGroup是直接和deqPtr指向的8个commit相连接的 ，commit_w说明执行的是否都已经回写\ncommit它需要保证是从当前deqPtr往后延伸的指令，中间有个0就已经结束了\nrobEntries -\u0026gt; robBanks -\u0026gt; robBanksRdataThisLine -\u0026gt; needUpdate -\u0026gt; robBanksRdataThisLineUpdate -\u0026gt; robDeqGroup -\u0026gt; commit\n香山的rob貌似一个表项不一定只有一个uop,这是因为向量指令的缘故，如果是向量指令的话一条指令会有多个uop\n有两段几乎是一模一样的代码段，一段是遍历rob表项对通过enq对表项赋值，另一段是通过遍历depPtr指向的一些表项进行相对应的更新\ndispatch阶段的robidx是通过一个独立的指针进行计数的，dispatch几条指令就加几，那代表它其实是不知道rob表项的具体使用情况的，真的会出现提交的和输入的一致的情况吗??\nenq指针它负责robEntires的写入，但是这个时候它是没有用到robindex的，它只是通过enq指针去顺序的写入\n必须得有波形，要不然太浪费时间了\n// 提交的表项 val robDeqGroup = Reg(Vec(bankNum, new RobCommitEntryBundle)) val rawInfo = VecInit((0 until CommitWidth).map(i =\u0026gt; robDeqGroup(deqPtrVec(i).value(bankAddrWidth-1, 0)))).toSeq val commitInfo = VecInit((0 until CommitWidth).map(i =\u0026gt; robDeqGroup(deqPtrVec(i).value(bankAddrWidth-1,0)))).toSeq val walkInfo = VecInit((0 until CommitWidth).map(i =\u0026gt; robDeqGroup(walkPtrVec(i).value(bankAddrWidth-1, 0)))).toSeq for (i \u0026lt;- 0 until CommitWidth) { connectCommitEntry(robDeqGroup(i), robBanksRdataThisLineUpdate(i)) when(allCommitted){ connectCommitEntry(robDeqGroup(i), robBanksRdataNextLineUpdate(i)) } } def connectCommitEntry(robCommitEntry: RobCommitEntryBundle, robEntry: RobEntryBundle): Unit = { robCommitEntry.walk_v := robEntry.valid robCommitEntry.commit_v := robEntry.valid robCommitEntry.commit_w := (robEntry.uopNum === 0.U) \u0026amp;\u0026amp; (robEntry.stdWritebacked === true.B) robCommitEntry.realDestSize := robEntry.realDestSize robCommitEntry.interrupt_safe := robEntry.interrupt_safe robCommitEntry.rfWen := robEntry.rfWen robCommitEntry.fpWen := robEntry.fpWen robCommitEntry.fflags := robEntry.fflags robCommitEntry.wflags := robEntry.wflags robCommitEntry.vxsat := robEntry.vxsat robCommitEntry.isRVC := robEntry.isRVC robCommitEntry.isVset := robEntry.isVset robCommitEntry.isHls := robEntry.isHls robCommitEntry.ftqIdx := robEntry.ftqIdx robCommitEntry.ftqOffset := robEntry.ftqOffset robCommitEntry.commitType := robEntry.commitType robCommitEntry.instrSize := robEntry.instrSize robCommitEntry.loadWaitBit := robEntry.loadWaitBit robCommitEntry.isMove := robEntry.eliminatedMove robCommitEntry.dirtyFs := robEntry.fpWen || robEntry.wflags robCommitEntry.dirtyVs := robEntry.dirtyVs robCommitEntry.needFlush := robEntry.needFlush robCommitEntry.traceBlockInPipe := robEntry.traceBlockInPipe robCommitEntry.debug_pc.foreach(_ := robEntry.debug_pc.get) robCommitEntry.debug_instr.foreach(_ := robEntry.debug_instr.get) robCommitEntry.debug_ldest.foreach(_ := robEntry.debug_ldest.get) robCommitEntry.debug_pdest.foreach(_ := robEntry.debug_pdest.get) robCommitEntry.debug_fuType.foreach(_ := robEntry.debug_fuType.get) } // rab和rob的交互 /** * connection of [[rab]] */ rab.io.redirect.valid := io.redirect.valid rab.io.req.zip(io.enq.req).map { case (dest, src) =\u0026gt; dest.bits := src.bits dest.valid := src.valid \u0026amp;\u0026amp; io.enq.canAccept } val walkDestSizeDeqGroup = RegInit(VecInit(Seq.fill(CommitWidth)(0.U(log2Up(MaxUopSize + 1).W)))) val realDestSizeSeq = VecInit(robDeqGroup.zip(hasCommitted).map{case (r, h) =\u0026gt; Mux(h, 0.U, r.realDestSize)}) val walkDestSizeSeq = VecInit(robDeqGroup.zip(donotNeedWalk).map{case (r, d) =\u0026gt; Mux(d, 0.U, r.realDestSize)}) val commitSizeSumSeq = VecInit((0 until CommitWidth).map(i =\u0026gt; realDestSizeSeq.take(i + 1).reduce(_ +\u0026amp; _))) // 从 0 到 i 的和 val walkSizeSumSeq = VecInit((0 until CommitWidth).map(i =\u0026gt; walkDestSizeSeq.take(i + 1).reduce(_ +\u0026amp; _))) val commitSizeSumCond = VecInit(commitValidThisLine.zip(hasCommitted).map{case (c,h) =\u0026gt; (c || h) \u0026amp;\u0026amp; io.commits.isCommit}) // (hasCommit || commitValid) val walkSizeSumCond = VecInit(io.commits.walkValid.zip(donotNeedWalk).map{case (w,d) =\u0026gt; (w || d) \u0026amp;\u0026amp; io.commits.isWalk}) val commitSizeSum = PriorityMuxDefault(commitSizeSumCond.reverse.zip(commitSizeSumSeq.reverse), 0.U) val walkSizeSum = PriorityMuxDefault(walkSizeSumCond.reverse.zip(walkSizeSumSeq.reverse), 0.U) // commitSize就是本次需要提交的指令数 rab.io.fromRob.commitSize := commitSizeSum rab.io.fromRob.walkSize := walkSizeSum rab.io.snpt := io.snpt rab.io.snpt.snptEnq := snptEnq io.rabCommits := rab.io.commits io.diffCommits.foreach(_ := rab.io.diffCommits.get) robEntry robEntry的项数还是比较多的\nval vls = Bool() // some instructions are not allowed to trigger interrupts // They have side effects on the states of the processor before they write back val interrupt_safe = Bool() val fpWen = Bool() val rfWen = Bool() val wflags = Bool() val dirtyVs = Bool() val commitType = CommitType() val ftqIdx = new FtqPtr val ftqOffset = UInt(log2Up(PredictWidth).W) val isRVC = Bool() val isVset = Bool() val isHls = Bool() val instrSize = UInt(log2Ceil(RenameWidth + 1).W) val loadWaitBit = Bool() // for perfEvents val eliminatedMove = Bool() // for perfEvents // data end // trace val traceBlockInPipe = new TracePipe(log2Up(RenameWidth * 2)) // status begin val valid = Bool() val fflags = UInt(5.W) val mmio = Bool() // store will be commited if both sta \u0026amp; std have been writebacked val stdWritebacked = Bool() val vxsat = Bool() val realDestSize = UInt(log2Up(MaxUopSize + 1).W) val uopNum = UInt(log2Up(MaxUopSize + 1).W) val commitTrigger = Bool() val needFlush = Bool() // status end // debug_begin val debug_pc = OptionWrapper(backendParams.debugEn, UInt(VAddrBits.W)) val debug_instr = OptionWrapper(backendParams.debugEn, UInt(32.W)) val debug_ldest = OptionWrapper(backendParams.debugEn, UInt(LogicRegsWidth.W)) val debug_pdest = OptionWrapper(backendParams.debugEn, UInt(PhyRegIdxWidth.W)) val debug_fuType = OptionWrapper(backendParams.debugEn, FuType()) // debug_end def isWritebacked: Bool = !uopNum.orR \u0026amp;\u0026amp; stdWritebacked def isUopWritebacked: Bool = !uopNum.orR 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-16T00:17:27+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81%E5%89%96%E6%9E%90%E6%89%A7%E8%A1%8C%E7%BB%93%E6%9E%9C%E7%9A%84%E5%9B%9E%E5%86%99%E5%92%8Ccommit/","title":"香山源代码剖析——执行结果的回写和commit"},{"content":" 译码阶段是香山CPU流水线后端的第一站，第一个阶段。它的输入来自于前端的指令缓冲器ibuffer ,从Ibuffer读出时由其将来自IFU的指令加预译码信息一起组装在一个CtrlFlow对象中，又由于流水线后端的宽度是6,所有译码阶段的输入就是6个CtrlFlow对象，译码阶段的输出即译码结果去往Rename中，是一排CfCtrl对象，CfCtrl就是CtrlFlow + CtrlSignals, 译码产生的结果就在CtrlSignals中，连同CtrlFlow一起往下游送。\nclass CfCtrl(implicit p: Parameters) extends XSBundle { val cf = new CtrlFlow val ctrl = new CtrlSignals } Rename向Dispatch的输出，成为MicroOp,这是对于CtrlFlow的扩充，主要是加上有关物理寄存器映射的信息。Dispatch的输出是MicroOp. Dispatch的输出不包括物理寄存器的内容即指令的源操作数，从物理寄存器组读取源操作数是流水线下游Scheduler的事情 。\n// Dequeue DecodeWidth insts from Ibuffer class CtrlFlow(implicit p: Parameters) extends XSBundle { val instr = UInt(32.W) val pc = UInt(VAddrBits.W) val foldpc = UInt(MemPredPCWidth.W) val exceptionVec = ExceptionVec() val trigger = TriggerAction() val pd = new PreDecodeInfo val pred_taken = Bool() val crossPageIPFFix = Bool() val storeSetHit = Bool() // inst has been allocated an store set val waitForRobIdx = new RobPtr // store set predicted previous store robIdx // Load wait is needed // load inst will not be executed until former store (predicted by mdp) addr calcuated val loadWaitBit = Bool() // If (loadWaitBit \u0026amp;\u0026amp; loadWaitStrict), strict load wait is needed // load inst will not be executed until ALL former store addr calcuated val loadWaitStrict = Bool() val ssid = UInt(SSIDWidth.W) val ftqPtr = new FtqPtr val ftqOffset = UInt(log2Up(PredictWidth).W) } // 这个和DocodedInst基本是一毛一样的 class CtrlSignals(implicit p: Parameters) extends XSBundle { val debug_globalID = UInt(XLEN.W) val srcType = Vec(4, SrcType()) // 源操作数的类型 val lsrc = Vec(4, UInt(LogicRegsWidth.W)) // 源操作数的逻辑寄存器号 val ldest = UInt(LogicRegsWidth.W) // 目标寄存器的逻辑寄存器号 val fuType = FuType() // 指令所属大类,funtcion Unit Type val fuOpType = FuOpType() val rfWen = Bool() val fpWen = Bool() val vecWen = Bool() val isXSTrap = Bool() val noSpecExec = Bool() // wait forward val blockBackward = Bool() // block backward val flushPipe = Bool() // This inst will flush all the pipe when commit, like exception but can commit val uopSplitType = UopSplitType() val selImm = SelImm() //立即数的类型,有符号，无符号 val imm = UInt(32.W) //立即数 val commitType = CommitType() //提交结果的类型 val fpu = new FPUCtrlSignals val uopIdx = UopIdx() val isMove = Bool() //是move指令 val vm = Bool() val singleStep = Bool() // This inst will flush all the pipe when it is the oldest inst in ROB, // then replay from this inst itself val replayInst = Bool() val canRobCompress = Bool() // 都是信号类型 private def allSignals = srcType.take(3) ++ Seq(fuType, fuOpType, rfWen, fpWen, vecWen, isXSTrap, noSpecExec, blockBackward, flushPipe, canRobCompress, uopSplitType, selImm) def decode(inst: UInt, table: Iterable[(BitPat, List[BitPat])]): CtrlSignals = { val decoder = freechips.rocketchip.rocket.DecodeLogic(inst, XDecode.decodeDefault, table, EspressoMinimizer) //实际上是调用了chisel的decoder , 译码 allSignals zip decoder foreach { case (s, d) =\u0026gt; s := d } commitType := DontCare this } def decode(bit: List[BitPat]): CtrlSignals = { allSignals.zip(bit.map(bitPatToUInt(_))).foreach{ case (s, d) =\u0026gt; s := d } this } def isWFI: Bool = fuType === FuType.csr.U \u0026amp;\u0026amp; fuOpType === CSROpType.wfi def isSoftPrefetch: Bool = { fuType === FuType.alu.U \u0026amp;\u0026amp; fuOpType === ALUOpType.or \u0026amp;\u0026amp; selImm === SelImm.IMM_I \u0026amp;\u0026amp; ldest === 0.U } def needWriteRf: Bool = (rfWen \u0026amp;\u0026amp; ldest =/= 0.U) || fpWen || vecWen def isHyperInst: Bool = { fuType === FuType.ldu.U \u0026amp;\u0026amp; LSUOpType.isHlv(fuOpType) || fuType === FuType.stu.U \u0026amp;\u0026amp; LSUOpType.isHsv(fuOpType) } } class DecodedInst(implicit p: Parameters) extends XSBundle { def numSrc = backendParams.numSrc // passed from StaticInst val instr = UInt(32.W) val pc = UInt(VAddrBits.W) val foldpc = UInt(MemPredPCWidth.W) val exceptionVec = ExceptionVec() val trigger = TriggerAction() val preDecodeInfo = new PreDecodeInfo val pred_taken = Bool() val crossPageIPFFix = Bool() val ftqPtr = new FtqPtr val ftqOffset = UInt(log2Up(PredictWidth).W) // decoded val srcType = Vec(numSrc, SrcType()) val lsrc = Vec(numSrc, UInt(LogicRegsWidth.W)) val ldest = UInt(LogicRegsWidth.W) val fuType = FuType() val fuOpType = FuOpType() val rfWen = Bool() val fpWen = Bool() val vecWen = Bool() val v0Wen = Bool() val vlWen = Bool() val isXSTrap = Bool() val waitForward = Bool() // no speculate execution val blockBackward = Bool() val flushPipe = Bool() // This inst will flush all the pipe when commit, like exception but can commit val canRobCompress = Bool() val selImm = SelImm() val imm = UInt(ImmUnion.maxLen.W) val fpu = new FPUCtrlSignals val vpu = new VPUCtrlSignals val vlsInstr = Bool() val wfflags = Bool() val isMove = Bool() val uopIdx = UopIdx() val uopSplitType = UopSplitType() val isVset = Bool() val firstUop = Bool() val lastUop = Bool() val numUops = UInt(log2Up(MaxUopSize).W) // rob need this val numWB = UInt(log2Up(MaxUopSize).W) // rob need this val commitType = CommitType() // Todo: remove it val needFrm = new NeedFrmBundle val debug_fuType = OptionWrapper(backendParams.debugEn, FuType()) private def allSignals = srcType.take(3) ++ Seq(fuType, fuOpType, rfWen, fpWen, vecWen, isXSTrap, waitForward, blockBackward, flushPipe, canRobCompress, uopSplitType, selImm) def decode(inst: UInt, table: Iterable[(BitPat, List[BitPat])]): DecodedInst = { // 使用listLookup去decode的，竟然不是用decode 去 decode ,返回值是一个Seq[Uint] val decoder: Seq[UInt] = ListLookup( inst, XDecode.decodeDefault.map(bitPatToUInt), table.map{ case (pat, pats) =\u0026gt; (pat, pats.map(bitPatToUInt)) }.toArray ) allSignals zip decoder foreach { case (s, d) =\u0026gt; s := d } debug_fuType.foreach(_ := fuType) this } def isSoftPrefetch: Bool = { fuType === FuType.alu.U \u0026amp;\u0026amp; fuOpType === ALUOpType.or \u0026amp;\u0026amp; selImm === SelImm.IMM_I \u0026amp;\u0026amp; ldest === 0.U } def connectStaticInst(source: StaticInst): Unit = { for ((name, data) \u0026lt;- this.elements) { if (source.elements.contains(name)) { data := source.elements(name) } } } } decode DecodeStage Module DecodeStage module是负责把输入的inst 通过 decode转化为 ctrlflow的，之后就会发送给Rename ,具体代码还是比较清楚的 ，主要只是负责转发的\nDecodeUnit 现在应该是不用ctrlFlow这一个数据结构了，换成了StaticInst\nclass DecodeUnitIO(implicit p: Parameters) extends XSBundle { val enq = new Bundle { val ctrlFlow = Input(new StaticInst) val vtype = Input(new VType) val vstart = Input(Vl()) } // val vconfig = Input(UInt(XLEN.W)) val deq = new DecodeUnitDeqIO val csrCtrl = Input(new CustomCSRCtrlIO) val fromCSR = Input(new CSRToDecode) } SRL -\u0026gt; XSDecode(SrcType.reg, SrcType.reg, SrcType.X, FuType.alu, ALUOpType.srl , SelImm.X , xWen = T, canRobCompress = T), 可以看到译码的表包括\nSrcType:pc, imm, reg 等，指源寄存器需要哪里的数据，\nFuType : 运算的类型 ， ldu,stu,alu，规定了指令的类型\nALUOpType or LSUOpType or .. ：这个根据FuType来分配的，实际上和指令的name是一样的\nSelImm:立即数的种类，比方说用于存储类指令，用于branch指令，用于lui,auipc指令，通过这个来解码立即数\nxWen,fwen,vwen : 是否写入寄存器\ncase class XSDecode( src1: BitPat, src2: BitPat, src3: BitPat, fu: FuType.OHType, fuOp: BitPat, selImm: BitPat, uopSplitType: BitPat = UopSplitType.X, xWen: Boolean = false, fWen: Boolean = false, vWen: Boolean = false, mWen: Boolean = false, xsTrap: Boolean = false, noSpec: Boolean = false, blockBack: Boolean = false, flushPipe: Boolean = false, canRobCompress: Boolean = false, ) extends XSDecodeBase { def generate() : List[BitPat] = { List (src1, src2, src3, BitPat(fu.U(FuType.num.W)), fuOp, xWen.B, fWen.B, (vWen || mWen).B, xsTrap.B, noSpec.B, blockBack.B, flushPipe.B, canRobCompress.B, uopSplitType, selImm) } } 寄存器映射 寄存器映射表RAT , 维护逻辑寄存器和物理寄存器之间的映射关系\n细节 ：\n每当指令流中有指令用到某个目标寄存器dest的时候，不管当前是否已经有映射了，总是要从FreeList中分配一个物理寄存器，比方说逻辑寄存器3建立物理寄存器33的映射， 此时需要在指令的MicroOp中记录下pdest = 33,\n但是在将新的映射写入3的时候，需要将原来老的映射值记录在MicroOp的old_pdest中，\n每当指令流中有指令要用所述逻辑寄存器，需要查询映射表获取当前映射，并将映射值写入本指令MiroOp的psrc中。 并且在创建该指令的ExuInput中企图从物理寄存器中读取内容，要是内容未到位就在ReservationStation中等待。\n一旦物理寄存器33为pdest的指令执行完成了，就把结果写回到33号物理寄存器，\n这条指令在完成回写，要冲流水线退休前夕，需要将记载的old_pdest释放掉，重置freeList，（为什么在这个时候释放，能早一点吗？原因应该是异常或者分支指令）\n在寄存器rename的时候还是顺序的\n寄存器重映射表 RenameTableWrapper 5个RAT,对应定点，浮点，向量，\n然后就是建立访问端口和RenameTable进行互联，每一个rat需要一对读写端口 ， dubug 和diff都是作为debug端口生成的 ，然后还有一个端口是 old_pdest,应该是在替换的时候输出的\nrabcommits会代表一条指令已经commit了，此时应该去把相应的rat映射取消\nval io = IO(new Bundle() { val redirect = Input(Bool()) val rabCommits = Input(new RabCommitIO) val diffCommits = if (backendParams.debugEn) Some(Input(new DiffCommitIO)) else None val intReadPorts = Vec(RenameWidth, Vec(2, new RatReadPort(IntLogicRegs))) val intRenamePorts = Vec(RenameWidth, Input(new RatWritePort(IntLogicRegs))) val fpReadPorts = Vec(RenameWidth, Vec(3, new RatReadPort(FpLogicRegs))) val fpRenamePorts = Vec(RenameWidth, Input(new RatWritePort(FpLogicRegs))) val vecReadPorts = Vec(RenameWidth, Vec(numVecRatPorts, new RatReadPort(VecLogicRegs))) val vecRenamePorts = Vec(RenameWidth, Input(new RatWritePort(VecLogicRegs))) val v0ReadPorts = Vec(RenameWidth, new RatReadPort(V0LogicRegs)) val v0RenamePorts = Vec(RenameWidth, Input(new RatWritePort(V0LogicRegs))) val vlReadPorts = Vec(RenameWidth, new RatReadPort(VlLogicRegs)) val vlRenamePorts = Vec(RenameWidth, Input(new RatWritePort(VlLogicRegs))) val int_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W))) val fp_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W))) val vec_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W))) val v0_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W))) val vl_old_pdest = Vec(RabCommitWidth, Output(UInt(PhyRegIdxWidth.W))) val int_need_free = Vec(RabCommitWidth, Output(Bool())) val snpt = Input(new SnapshotPort) // for debug printing val debug_int_rat = if (backendParams.debugEn) Some(Vec(32, Output(UInt(PhyRegIdxWidth.W)))) else None val debug_fp_rat = if (backendParams.debugEn) Some(Vec(32, Output(UInt(PhyRegIdxWidth.W)))) else None val debug_vec_rat = if (backendParams.debugEn) Some(Vec(31, Output(UInt(PhyRegIdxWidth.W)))) else None val debug_v0_rat = if (backendParams.debugEn) Some(Vec(1,Output(UInt(PhyRegIdxWidth.W)))) else None val debug_vl_rat = if (backendParams.debugEn) Some(Vec(1,Output(UInt(PhyRegIdxWidth.W)))) else None val diff_int_rat = if (backendParams.debugEn) Some(Vec(32, Output(UInt(PhyRegIdxWidth.W)))) else None val diff_fp_rat = if (backendParams.debugEn) Some(Vec(32, Output(UInt(PhyRegIdxWidth.W)))) else None val diff_vec_rat = if (backendParams.debugEn) Some(Vec(31, Output(UInt(PhyRegIdxWidth.W)))) else None val diff_v0_rat = if (backendParams.debugEn) Some(Vec(1,Output(UInt(PhyRegIdxWidth.W)))) else None val diff_vl_rat = if (backendParams.debugEn) Some(Vec(1,Output(UInt(PhyRegIdxWidth.W)))) else None }) val intRat = Module(new RenameTable(Reg_I)) val fpRat = Module(new RenameTable(Reg_F)) val vecRat = Module(new RenameTable(Reg_V)) val v0Rat = Module(new RenameTable(Reg_V0)) val vlRat = Module(new RenameTable(Reg_Vl)) io.debug_int_rat .foreach(_ := intRat.io.debug_rdata.get) io.diff_int_rat .foreach(_ := intRat.io.diff_rdata.get) intRat.io.readPorts \u0026lt;\u0026gt; io.intReadPorts.flatten // flatten to 1D array ， RenameWidth * 2 read ports, 两个是因为两个源 intRat.io.redirect := io.redirect intRat.io.snpt := io.snpt io.int_old_pdest := intRat.io.old_pdest // rabcommitwidth io.int_need_free := intRat.io.need_free // rabcommitwidth // rob可能处于commit 和 walk状态， commit代表要确认， walk代表要从转向中恢复（异常，分支） val intDestValid = io.rabCommits.info.map(_.rfWen) // 代表此时rab的指令需要写回到寄存器 for ((arch, i) \u0026lt;- intRat.io.archWritePorts.zipWithIndex) { // rabcommitwidth ,架构寄存器 arch.wen := io.rabCommits.isCommit \u0026amp;\u0026amp; io.rabCommits.commitValid(i) \u0026amp;\u0026amp; intDestValid(i) arch.addr := io.rabCommits.info(i).ldest // 逻辑寄存器 arch.data := io.rabCommits.info(i).pdest // 物理寄存器 XSError(arch.wen \u0026amp;\u0026amp; arch.addr === 0.U \u0026amp;\u0026amp; arch.data =/= 0.U, \u0026#34;pdest for $0 should be 0\\n\u0026#34;) } for ((spec, i) \u0026lt;- intRat.io.specWritePorts.zipWithIndex) { // 在指令walk的时候写入spec映射表 spec.wen := io.rabCommits.isWalk \u0026amp;\u0026amp; io.rabCommits.walkValid(i) \u0026amp;\u0026amp; intDestValid(i) spec.addr := io.rabCommits.info(i).ldest spec.data := io.rabCommits.info(i).pdest XSError(spec.wen \u0026amp;\u0026amp; spec.addr === 0.U \u0026amp;\u0026amp; spec.data =/= 0.U, \u0026#34;pdest for $0 should be 0\\n\u0026#34;) } for ((spec, rename) \u0026lt;- intRat.io.specWritePorts.zip(io.intRenamePorts)) { when (rename.wen) { // 写入rename表, spec表是一个草稿，寄存器的映射和建立都是通过spec_table的 spec.wen := true.B spec.addr := rename.addr spec.data := rename.data } } if (backendParams.debugEn) { for ((diff, i) \u0026lt;- intRat.io.diffWritePorts.get.zipWithIndex) { diff.wen := io.diffCommits.get.isCommit \u0026amp;\u0026amp; io.diffCommits.get.commitValid(i) \u0026amp;\u0026amp; io.diffCommits.get.info(i).rfWen diff.addr := io.diffCommits.get.info(i).ldest diff.data := io.diffCommits.get.info(i).pdest } } RenameTable 就是维护了两张rat,其中一张在rename和commit_walk的进行赋值，arch_table只在完成提交的时候进行赋值\nval spec_table = RegInit(rename_table_init) val spec_table_next = WireInit(spec_table) // arch state rename table val arch_table = RegInit(rename_table_init) val arch_table_next = WireDefault(arch_table) // old_pdest val old_pdest = RegInit(VecInit.fill(RabCommitWidth)(0.U(PhyRegIdxWidth.W))) val need_free = RegInit(VecInit.fill(RabCommitWidth)(false.B)) // For better timing, we optimize reading and writing to RenameTable as follows: // (1) Writing at T0 will be actually processed at T1. // (2) Reading is synchronous now. // (3) RAddr at T0 will be used to access the table and get data at T0. // (4) WData at T0 is bypassed to RData at T1. // 不论读写其实都会先打一拍 val t1_redirect = GatedValidRegNext(io.redirect, false.B) // io.redirect是代表指令需要被取消 val t1_raddr = io.readPorts.map(p =\u0026gt; RegEnable(p.addr, !p.hold)) // 如果不是hold话就把addr打一拍，反之保持addr不变 val t1_rdata_use_t1_raddr = VecInit(t1_raddr.map(spec_table(_))) // 读取spec_table,和addr是同一拍 val t1_wSpec = RegNext(Mux(io.redirect, 0.U.asTypeOf(io.specWritePorts), io.specWritePorts)) // 写打了一拍 ， 向量长度为RabCommitWidth val t1_snpt = RegNext(io.snpt, 0.U.asTypeOf(io.snpt)) val snapshots = SnapshotGenerator(spec_table, t1_snpt.snptEnq, t1_snpt.snptDeq, t1_redirect, t1_snpt.flushVec) // WRITE: when instruction commits or walking // t1_wSpec_addr 保存着将要写入的addr // 串行？ 并行 ? val t1_wSpec_addr = t1_wSpec.map(w =\u0026gt; Mux(w.wen, UIntToOH(w.addr), 0.U)) // 每一个提交的指令都会去判断wen, 然后会把地址(逻辑寄存器)转换为onehot for ((next, i) \u0026lt;- spec_table_next.zipWithIndex) { // 我比较好奇，难道不是直接根据addr去写入data更快吗，为什么要去遍历所有的addr,一个是flush不好flush，还有一个就是waw,如果多条指令有相同的逻辑寄存器的话，应该是写入最后那一条 val matchVec = t1_wSpec_addr.map(w =\u0026gt; w(i)) //单独判断onehot的那一位是不是1,这个i应该就是逻辑寄存器的编号,对应的话w(i)就是1, 这样是为了应对多条commit可能会写入同一个逻辑寄存器 val wMatch = ParallelPriorityMux(matchVec.reverse, t1_wSpec.map(_.data).reverse) // ParallelPriorityMux应该是通过二分加速的PriorityMux,优先选左边的1, 应该是0先写入的 // When there\u0026#39;s a flush, we use arch_table to update spec_table. next := Mux( t1_redirect, Mux(t1_snpt.useSnpt, snapshots(t1_snpt.snptSelect)(i), arch_table(i)), // flush的话使用arch_table去更新spec_table Mux(VecInit(matchVec).asUInt.orR, wMatch, spec_table(i)) // 写入相应的spec_table ) } spec_table := spec_table_next // 更新寄存器的内容 // READ: decode-rename stage,如果同时发起读写,且读写地址一致, for ((r, i) \u0026lt;- io.readPorts.zipWithIndex) { val t0_bypass = io.specWritePorts.map(w =\u0026gt; w.wen \u0026amp;\u0026amp; Mux(r.hold, w.addr === t1_raddr(i), w.addr === r.addr)) // bypass val t1_bypass = RegNext(Mux(io.redirect, 0.U.asTypeOf(VecInit(t0_bypass)), VecInit(t0_bypass))) // t0_bypass打了一拍,这一拍开始写 val bypass_data = ParallelPriorityMux(t1_bypass.reverse, t1_wSpec.map(_.data).reverse) // 直接将要写入的数据传递给读，要不然实际上r.data是有错误的 r.data := Mux(t1_bypass.asUInt.orR, bypass_data, t1_rdata_use_t1_raddr(i)) } // arch table, 这里就是正常的通过w.addr进行写了 for ((w, i) \u0026lt;- io.archWritePorts.zipWithIndex) { // rabcommitwidth when (w.wen) { arch_table_next(w.addr) := w.data } val arch_mask = VecInit.fill(PhyRegIdxWidth)(w.wen).asUInt old_pdest(i) := // 对应的是commit的old_pdest MuxCase(arch_table(w.addr) \u0026amp; arch_mask, //reverse是为了保证优先级高的在左边, arch_table(w.addr) \u0026amp; arch_mask 指的是没写入前对应的物理寄存器 io.archWritePorts.take(i).reverse.map(x =\u0026gt; (x.wen \u0026amp;\u0026amp; x.addr === w.addr, x.data \u0026amp; arch_mask))) // 如果有多个commit写入同一个逻辑寄存器，那么此时old_pdest应该是前面那一写入的 } arch_table := arch_table_next Rename Rename的输入来自于DecodeInst , 输出给Dispatch 的就是 DynInst\n然后还包括rename table交互的接口，\n对于输入的每个Staticinst都要创建一个microop,作为Rename的输出，Micro最重要的是源寄存器和目标寄存器的物理寄存器号。源寄存器src的物理寄存器号从rat读取当前的映射，目标寄存器dest需要从FreeList分配，并在RenameTable中建立新的映射，目标寄存器号释放要由Rob决定。\n其中还涉及到一些细节方面的问题，比方说需要根据rob的iswalk来决定一些mux,\n还有bypass ，主要针对同一周期进行重命名的指令，本身源寄存器获取都从rat获取，但有些是需要bypass从前面指令的目的寄存器获取的\n还有一些优化，比方说压缩指令，融合指令，move等等\n还有freeList的stall信号，后面再看它用来干什么\n无论是commit还是walk都会引起物理寄存器号的释放，提交意味着原先的old_pdest已经完全没有用了，因为后续依赖于这个逻辑寄存器的指令也会使用新的pdest,前面的指令也全部执行完成了，那就可以释放了，walk说明这一条指令要被冲刷了，那本条指令投入使用的pdest也可以释放了\n// decide if given instruction needs allocating a new physical register (CfCtrl: from decode; RobCommitInfo: from rob) def needDestReg[T \u0026lt;: DecodedInst](reg_t: RegType, x: T): Bool = reg_t match { case Reg_I =\u0026gt; x.rfWen \u0026amp;\u0026amp; x.ldest =/= 0.U // 指令的逻辑目标寄存器不是r0,需要提供映射 case Reg_F =\u0026gt; x.fpWen case Reg_V =\u0026gt; x.vecWen case Reg_V0 =\u0026gt; x.v0Wen case Reg_Vl =\u0026gt; x.vlWen } def needDestRegCommit[T \u0026lt;: RabCommitInfo](reg_t: RegType, x: T): Bool = { reg_t match { case Reg_I =\u0026gt; x.rfWen // 需要写入寄存器 case Reg_F =\u0026gt; x.fpWen case Reg_V =\u0026gt; x.vecWen case Reg_V0 =\u0026gt; x.v0Wen case Reg_Vl =\u0026gt; x.vlWen } } def needDestRegWalk[T \u0026lt;: RabCommitInfo](reg_t: RegType, x: T): Bool = { reg_t match { case Reg_I =\u0026gt; x.rfWen \u0026amp;\u0026amp; x.ldest =/= 0.U // 需要写入寄存器，且写入的不是0 case Reg_F =\u0026gt; x.fpWen case Reg_V =\u0026gt; x.vecWen case Reg_V0 =\u0026gt; x.v0Wen case Reg_Vl =\u0026gt; x.vlWen } } // connect [redirect + walk] ports for fp \u0026amp; vec \u0026amp; int free list Seq(fpFreeList, vecFreeList, intFreeList, v0FreeList, vlFreeList).foreach { case fl =\u0026gt; fl.io.redirect := io.redirect.valid fl.io.walk := io.rabCommits.isWalk } // only when all free list and dispatch1 has enough space can we do allocation // when isWalk, freelist can definitely allocate // 这是可以从FreeList分配使用物理寄存器的条件,必须要所有的FreeList都可以分配,或者是walk状态 intFreeList.io.doAllocate := fpFreeList.io.canAllocate \u0026amp;\u0026amp; vecFreeList.io.canAllocate \u0026amp;\u0026amp; v0FreeList.io.canAllocate \u0026amp;\u0026amp; vlFreeList.io.canAllocate \u0026amp;\u0026amp; dispatchCanAcc || io.rabCommits.isWalk fpFreeList.io.doAllocate := intFreeList.io.canAllocate \u0026amp;\u0026amp; vecFreeList.io.canAllocate \u0026amp;\u0026amp; v0FreeList.io.canAllocate \u0026amp;\u0026amp; vlFreeList.io.canAllocate \u0026amp;\u0026amp; dispatchCanAcc || io.rabCommits.isWalk vecFreeList.io.doAllocate := intFreeList.io.canAllocate \u0026amp;\u0026amp; fpFreeList.io.canAllocate \u0026amp;\u0026amp; v0FreeList.io.canAllocate \u0026amp;\u0026amp; vlFreeList.io.canAllocate \u0026amp;\u0026amp; dispatchCanAcc || io.rabCommits.isWalk v0FreeList.io.doAllocate := intFreeList.io.canAllocate \u0026amp;\u0026amp; fpFreeList.io.canAllocate \u0026amp;\u0026amp; vecFreeList.io.canAllocate \u0026amp;\u0026amp; vlFreeList.io.canAllocate \u0026amp;\u0026amp; dispatchCanAcc || io.rabCommits.isWalk vlFreeList.io.doAllocate := intFreeList.io.canAllocate \u0026amp;\u0026amp; fpFreeList.io.canAllocate \u0026amp;\u0026amp; vecFreeList.io.canAllocate \u0026amp;\u0026amp; v0FreeList.io.canAllocate \u0026amp;\u0026amp; dispatchCanAcc || io.rabCommits.isWalk // dispatch1 ready ++ float point free list ready ++ int free list ready ++ vec free list ready ++ not walk // 这是可以向指令分发阶段发送MicorOp的条件 val canOut = dispatchCanAcc \u0026amp;\u0026amp; fpFreeList.io.canAllocate \u0026amp;\u0026amp; intFreeList.io.canAllocate \u0026amp;\u0026amp; vecFreeList.io.canAllocate \u0026amp;\u0026amp; v0FreeList.io.canAllocate \u0026amp;\u0026amp; vlFreeList.io.canAllocate \u0026amp;\u0026amp; !io.rabCommits.isWalk // 后面应该有旁路相关的, /** * How to set psrc: * - bypass the pdest to psrc if previous instructions write to the same ldest as lsrc * - default: psrc from RAT * How to set pdest: * - Mux(isMove, psrc, pdest_from_freelist). * * The critical path of rename lies here: * When move elimination is enabled, we need to update the rat with psrc. * However, psrc maybe comes from previous instructions\u0026#39; pdest, which comes from freelist. * * If we expand these logic for pdest(N): * pdest(N) = Mux(isMove(N), psrc(N), freelist_out(N)) * = Mux(isMove(N), Mux(bypass(N, N - 1), pdest(N - 1), * Mux(bypass(N, N - 2), pdest(N - 2), * ... * Mux(bypass(N, 0), pdest(0), * rat_out(N))...)), * freelist_out(N)) */ // a simple functional model for now io.out(0).bits.pdest := Mux(isMove(0), uops(0).psrc.head, uops(0).pdest) // 如果是move指令直接就是psrc,要不然都是从freeList分配来的 // psrc(n) + pdest(1) ,用来检测本指令的寄存器与同一批的其他指令之间是否可以旁路 val bypassCond: Vec[MixedVec[UInt]] = Wire(Vec(numRegSrc + 1, MixedVec(List.tabulate(RenameWidth-1)(i =\u0026gt; UInt((i+1).W))))) require(io.in(0).bits.srcType.size == io.in(0).bits.numSrc) private val pdestLoc = io.in.head.bits.srcType.size // 2 vector src: v0, vl\u0026amp;vtype println(s\u0026#34;[Rename] idx of pdest in bypassCond $pdestLoc\u0026#34;) for (i \u0026lt;- 1 until RenameWidth) { val v0Cond = io.in(i).bits.srcType.zipWithIndex.map{ case (s, i) =\u0026gt; if (i == 3) (s === SrcType.vp) || (s === SrcType.v0) else false.B } :+ needV0Dest(i) val vlCond = io.in(i).bits.srcType.zipWithIndex.map{ case (s, i) =\u0026gt; if (i == 4) s === SrcType.vp else false.B } :+ needVlDest(i) val vecCond = io.in(i).bits.srcType.map(_ === SrcType.vp) :+ needVecDest(i) val fpCond = io.in(i).bits.srcType.map(_ === SrcType.fp) :+ needFpDest(i) val intCond = io.in(i).bits.srcType.map(_ === SrcType.xp) :+ needIntDest(i) // 源和目的寄存器都是需要寄存器的 val target = io.in(i).bits.lsrc :+ io.in(i).bits.ldest // (n 源寄存器 + 1 目标寄存器) for ((((((cond1, (condV0, condVl)), cond2), cond3), t), j) \u0026lt;- vecCond.zip(v0Cond.zip(vlCond)).zip(fpCond).zip(intCond).zip(target).zipWithIndex) { val destToSrc = io.in.take(i).zipWithIndex.map { case (in, j) =\u0026gt; val indexMatch = in.bits.ldest === t // 将第i条指令的(n 源寄存器，1目的寄存器）和前i条指令的目的寄存器进行比较,返回的是第j条指令的第t个寄存器与前i条指令的目的寄存器是否相等 val writeMatch = cond3 \u0026amp;\u0026amp; needIntDest(j) || cond2 \u0026amp;\u0026amp; needFpDest(j) || cond1 \u0026amp;\u0026amp; needVecDest(j) // 返回的是一个Seq,代表第i条指令的第j个寄存器是否需要寄存器 \u0026amp;\u0026amp; 前面i条指令是否有目的寄存器 val v0vlMatch = condV0 \u0026amp;\u0026amp; needV0Dest(j) || condVl \u0026amp;\u0026amp; needVlDest(j) indexMatch \u0026amp;\u0026amp; writeMatch || v0vlMatch // 返回的是一个（）， 代表第i条指令的第t个寄存器与前i条指令的目的寄存器是否相等,且确实有目的寄存器 } bypassCond(j)(i - 1) := VecInit(destToSrc).asUInt // 统计的就是第i条指令第j个寄存器和前i-1条指令的目的寄存器的对应情况 } // 输出经过旁路之后的寄存器号,如果是源相等的化应该是把最后一条目的寄存器赋值给源(RAW)，如果是目的寄存器和前面的目的寄存器相等的话(WAW)，其实没啥,犯贱 // foldLeft从左向右遍历,next是元素，在这里是（pdest,bypassCond）,z是当前的累计值,在每一次遍历后z会被新的值更新 io.out(i).bits.psrc(0) := io.out.take(i).map(_.bits.pdest).zip(bypassCond(0)(i-1).asBools).foldLeft(uops(i).psrc(0)) { (z, next) =\u0026gt; Mux(next._2, next._1, z) } io.out(i).bits.psrc(1) := io.out.take(i).map(_.bits.pdest).zip(bypassCond(1)(i-1).asBools).foldLeft(uops(i).psrc(1)) { (z, next) =\u0026gt; Mux(next._2, next._1, z) } io.out(i).bits.psrc(2) := io.out.take(i).map(_.bits.pdest).zip(bypassCond(2)(i-1).asBools).foldLeft(uops(i).psrc(2)) { (z, next) =\u0026gt; Mux(next._2, next._1, z) } io.out(i).bits.psrc(3) := io.out.take(i).map(_.bits.pdest).zip(bypassCond(3)(i-1).asBools).foldLeft(uops(i).psrc(3)) { (z, next) =\u0026gt; Mux(next._2, next._1, z) } io.out(i).bits.psrc(4) := io.out.take(i).map(_.bits.pdest).zip(bypassCond(4)(i-1).asBools).foldLeft(uops(i).psrc(4)) { (z, next) =\u0026gt; Mux(next._2, next._1, z) } io.out(i).bits.pdest := Mux(isMove(i), io.out(i).bits.psrc(0), uops(i).pdest) /** * Instructions commit: update freelist and rename table */ for (i \u0026lt;- 0 until RabCommitWidth) { val commitValid = io.rabCommits.isCommit \u0026amp;\u0026amp; io.rabCommits.commitValid(i) val walkValid = io.rabCommits.isWalk \u0026amp;\u0026amp; io.rabCommits.walkValid(i) // I. RAT Update // When redirect happens (mis-prediction), don\u0026#39;t update the rename table io.intRenamePorts(i).wen := intSpecWen(i) io.intRenamePorts(i).addr := uops(i).ldest(log2Ceil(IntLogicRegs) - 1, 0) io.intRenamePorts(i).data := io.out(i).bits.pdest io.fpRenamePorts(i).wen := fpSpecWen(i) io.fpRenamePorts(i).addr := uops(i).ldest(log2Ceil(FpLogicRegs) - 1, 0) io.fpRenamePorts(i).data := fpFreeList.io.allocatePhyReg(i) io.vecRenamePorts(i).wen := vecSpecWen(i) io.vecRenamePorts(i).addr := uops(i).ldest(log2Ceil(VecLogicRegs) - 1, 0) io.vecRenamePorts(i).data := vecFreeList.io.allocatePhyReg(i) io.v0RenamePorts(i).wen := v0SpecWen(i) io.v0RenamePorts(i).addr := uops(i).ldest(log2Ceil(V0LogicRegs) - 1, 0) io.v0RenamePorts(i).data := v0FreeList.io.allocatePhyReg(i) io.vlRenamePorts(i).wen := vlSpecWen(i) io.vlRenamePorts(i).addr := uops(i).ldest(log2Ceil(VlLogicRegs) - 1, 0) io.vlRenamePorts(i).data := vlFreeList.io.allocatePhyReg(i) // II. Free List Update intFreeList.io.freeReq(i) := io.int_need_free(i) intFreeList.io.freePhyReg(i) := RegNext(io.int_old_pdest(i)) fpFreeList.io.freeReq(i) := GatedValidRegNext(commitValid \u0026amp;\u0026amp; needDestRegCommit(Reg_F, io.rabCommits.info(i))) fpFreeList.io.freePhyReg(i) := io.fp_old_pdest(i) vecFreeList.io.freeReq(i) := GatedValidRegNext(commitValid \u0026amp;\u0026amp; needDestRegCommit(Reg_V, io.rabCommits.info(i))) vecFreeList.io.freePhyReg(i) := io.vec_old_pdest(i) v0FreeList.io.freeReq(i) := GatedValidRegNext(commitValid \u0026amp;\u0026amp; needDestRegCommit(Reg_V0, io.rabCommits.info(i))) v0FreeList.io.freePhyReg(i) := io.v0_old_pdest(i) vlFreeList.io.freeReq(i) := GatedValidRegNext(commitValid \u0026amp;\u0026amp; needDestRegCommit(Reg_Vl, io.rabCommits.info(i))) vlFreeList.io.freePhyReg(i) := io.vl_old_pdest(i) } compressunit 这应该是处理压缩指令的\nMEFreeList 和 StdFreeList FreeList 记录了所有的空闲寄存器状态，其大小是可以通过类参数 size 配置的。FreeList 本质上是一个队列，由入队指针、出队指针和队列存储组成。\n初始化时，FreeList 中包含所有可用的物理寄存器。在我们的设计中，初始时逻辑寄存器 i 会被映射至物理寄存器 i，因此 FreeList 在初始状态下包含 32-191 共 160 个空闲物理寄存器号。重命名时，FreeList 会给出至多 RenameWidth 个空闲物理寄存器号供使用。物理寄存器被释放时（ROB 提交指令或者回滚），FreeList 每一拍至多可以进入 CommitWidth 个空闲物理寄存器号。\n**在香山处理器的设计中，针对定点物理寄存器支持多次引用，并通过引用计数表（RefTable）记录每一个物理寄存器被引用的次数。**通过引用计数，香山支持将多个逻辑寄存器映射至同一个物理寄存器，并支持对 Move 指令的消除优化（Move Elimination）。在这种情况下，空闲的物理寄存器数量理论上最高可达到物理寄存器总数 - 1。因此，在香山处理器中，定点 FreeList 大小与物理寄存器堆大小相同（默认为 192），浮点 FreeList 大小是物理寄存器堆数量 - 32（默认为 160）。\n目前，FreeList 在香山中共有两种实现，分别在不存在 / 存在引用计数功能的情况下使用，对应 StdFreeList 和 MEFreeList。对于不存在引用计数的情况，当发生 ROB 回滚时，FreeList 中释放的空闲寄存器一定是前面恰好被分配出的那一些，且与回滚指令中需要分配新物理寄存器的数量相同。在种情况下，FreeList 的存储不需要被重复写入，只需要将出队指针往前回滚即可。对于存在引用计数的情况，由于重复引用情况的存在（不需要通过 FreeList 分配，而是增加一个物理寄存器的引用计数），回滚的物理寄存器数量与 FreeList 的释放数量并不一定相同。在这种情况下，FreeList 需要维护几个写端口，方便通过引用计数机制来维护实际释放的物理寄存器。\nMEFreeList 实际上是一个环形队列，排在队列的是空闲物理寄存器的号码 。 需要分配使用物理寄存器的时候就从头部摘除，Rob交付执行结果的时候进入队列的尾部。在正常情况下，指令成块从译码器出来进入分发模块，不管分发到哪个执行单元，都要在分发之前获取目标寄存器的映射 ， 所以空闲物理寄存器号的分配是成块的，俺指令的先后顺序不会被打乱。即使指令的执行乱序，但执行的结果要在ROB中恢复原来的排序，最后想寄存器组提交和映射物理寄存器释放也是成块的。所以freelist中两个指针的推进都是成块的\n是基于BseFreeList创建的\nclass MEFreeList(size: Int)(implicit p: Parameters) extends BaseFreeList(size) with HasPerfEvents { // 用Reg建立一个寄存器堆 val freeList = RegInit(VecInit( // originally {1, 2, ..., size - 1} are free. Register 0-31 are mapped to x0. Seq.tabulate(size - 1)(i =\u0026gt; (i + 1).U(PhyRegIdxWidth.W)) :+ 0.U(PhyRegIdxWidth.W))) val tailPtr = RegInit(FreeListPtr(false, size - 1)) // 循环队列尾指针 val doWalkRename = io.walk \u0026amp;\u0026amp; io.doAllocate \u0026amp;\u0026amp; !io.redirect val doNormalRename = io.canAllocate \u0026amp;\u0026amp; io.doAllocate \u0026amp;\u0026amp; !io.redirect val doRename = doWalkRename || doNormalRename //来自Rename模块的请求 val doCommit = io.commit.isCommit // Rob处于提交阶段 /** * Allocation: from freelist (same as StdFreelist) */ val phyRegCandidates = VecInit(headPtrOHVec.map(sel =\u0026gt; Mux1H(sel, freeList))) // 根据headPtrOHVec,选择空闲的物理寄存器号, headPtrOHVec 是 [1000,100,10,0] , 然后就通过这个选择 free[0],free[1] for (i \u0026lt;- 0 until RenameWidth) { // 分配空闲寄存器 //intFreeList.io.allocateReq(i) := needIntDest(i) \u0026amp;\u0026amp; !isMove(i) , allocateReq是这样定义的 //intFreeList.io.walkReq(i) := walkNeedIntDest(i) \u0026amp;\u0026amp; !walkIsMove(i) // enqueue instr, is move elimination io.allocatePhyReg(i) := phyRegCandidates(PopCount(io.allocateReq.take(i))) // 这种方法有点意思的，我现在前i个分配了x个，如果我第i+1需要分配，那显然第x+1个就是它的，反正不管,就它可以实现字增和连续分配 } // 头指针增加，代表物理寄存器被分配，尾指针增加，代表物理寄存器被释放,头尾之间的代表被分配的了的 // update arch head pointer val archAlloc = io.commit.commitValid zip io.commit.info map { // 这里是构成了需要free list的Vec case (valid, info) =\u0026gt; valid \u0026amp;\u0026amp; info.rfWen \u0026amp;\u0026amp; !info.isMove \u0026amp;\u0026amp; info.ldest =/= 0.U } val numArchAllocate = PopCount(archAlloc) val archHeadPtrNew = archHeadPtr + numArchAllocate //头指针向前推进 val archHeadPtrNext = Mux(doCommit, archHeadPtrNew, archHeadPtr) // 是否真的提交 archHeadPtr := archHeadPtrNext //改变头指针 // update head pointer, 比较好奇，它不能直接把原始版本的转换成独热码版本的吗 val numAllocate = Mux(io.walk, PopCount(io.walkReq), PopCount(io.allocateReq)) // 一种是walk,一种是rename,申请和释放 val headPtrNew = Mux(lastCycleRedirect, redirectedHeadPtr, headPtr + numAllocate) // 一个是archptr + walk_num,一个是headptr + allo_num val headPtrOHNew = Mux(lastCycleRedirect, redirectedHeadPtrOH, headPtrOHVec(numAllocate)) val headPtrNext = Mux(doRename, headPtrNew, headPtr) // 如果需要请求就换 val headPtrOHNext = Mux(doRename, headPtrOHNew, headPtrOH) // 相对应的OH版本 headPtr := headPtrNext headPtrOH := headPtrOHNext /** * Deallocation: when refCounter becomes zero, the register can be released to freelist */ for (i \u0026lt;- 0 until RabCommitWidth) { // rob的commit会导致物理寄存器的释放 when (io.freeReq(i)) { //一个一个空位的添加过去 val freePtr = tailPtr + PopCount(io.freeReq.take(i)) freeList(freePtr.value) := io.freePhyReg(i) } } // update tail pointer val tailPtrNext = tailPtr + PopCount(io.freeReq) tailPtr := tailPtrNext // 统计空闲寄存器的数量,tailPtrNext是释放过后的尾指针，headPtr是分配前的头指针, tailPtrNext一开始是最大的，所以它再往前已经flag反向了 val freeRegCnt = Mux(doWalkRename \u0026amp;\u0026amp; !lastCycleRedirect, distanceBetween(tailPtrNext, headPtr) - PopCount(io.walkReq), Mux(doNormalRename, distanceBetween(tailPtrNext, headPtr) - PopCount(io.allocateReq), distanceBetween(tailPtrNext, headPtr))) val freeRegCntReg = RegNext(freeRegCnt) io.canAllocate := freeRegCntReg \u0026gt;= RenameWidth.U //能够分配的条件是空闲寄存器的数量大于等于重命名宽度 Rename的整个过程没有用到寄存器，不构成流水线的一个阶段\nStdFreeList 物理寄存器组 物理寄存器组在ExuBlock的指令调度器scheduler.指令在进入scheduler时根据源寄存器当时的映射知道了它的操作数在哪一个或哪两个物理寄存器中，如果物理寄存器的数据尚未到达就会在Scheduler的某一个ReservationStation内去等待。而建立了具体映射的指令则会在取得执行结果后将结果写入相应的物理寄存器，并试图唤醒ReservationStation内正在等待这个结果的指令。一旦这条指令的源操作数都已经到位即被唤醒而可以被调度。\n这里应该是做了一些优化的，写法都比较奇特\nclass RfReadPort(dataWidth: Int, addrWidth: Int) extends Bundle { val addr = Input(UInt(addrWidth.W)) val data = Output(UInt(dataWidth.W)) } class RfWritePort(dataWidth: Int, addrWidth: Int) extends Bundle { val wen = Input(Bool()) val addr = Input(UInt(addrWidth.W)) val data = Input(UInt(dataWidth.W)) } class Regfile ( name: String, numPregs: Int, numReadPorts: Int, numWritePorts: Int, hasZero: Boolean, len: Int, width: Int, bankNum: Int = 1, isVlRegfile: Boolean = false, ) extends Module { val io = IO(new Bundle() { val readPorts = Vec(numReadPorts, new RfReadPort(len, width)) val writePorts = Vec(numWritePorts, new RfWritePort(len, width)) val debug_rports = Vec(65, new RfReadPort(len, width)) }) override def desiredName = name println(name + \u0026#34;: size:\u0026#34; + numPregs + \u0026#34; read: \u0026#34; + numReadPorts + \u0026#34; write: \u0026#34; + numWritePorts) val mem_0 = if (isVlRegfile) RegInit(0.U(len.W)) else Reg(UInt(len.W)) val mem = Reg(Vec(numPregs, UInt(len.W))) // 寄存器组 val memForRead = Wire(Vec(numPregs, UInt(len.W))) // memForRead是mem的一个副本，用于读取 memForRead.zipWithIndex.map{ case(m, i) =\u0026gt; if (i == 0) m := mem_0 else m := mem(i) } require(Seq(1, 2, 4).contains(bankNum), \u0026#34;bankNum must be 1 or 2 or 4\u0026#34;) // 寄存器分bank了 for (r \u0026lt;- io.readPorts) { if (bankNum == 1) { r.data := memForRead(RegNext(r.addr)) // 打了一拍 } else { val banks = (0 until bankNum).map { case i =\u0026gt; // filter用来筛选集合中的元素， 0 bankNum 2*bankNum 这些归于一个bank memForRead.zipWithIndex.filter{ case (m, index) =\u0026gt; (index % bankNum) == i }.map(_._1) } // 通过(bankWidth -1 ,0)选择bank // 比较好奇为什么用前bankWidth位来选择bank，如果用后bankWidth位来选择bank，那不是连续的了吗,我能想到一点好处,连续的寄存器可能会被同时读取，那分bank就能直接去并行读取了 // 比较有意思的点是所有的集合其实都会通过VecInit转化为Vec类型的 val bankWidth = bankNum.U.getWidth - 1 // 选择bank val hitBankWire = VecInit((0 until bankNum).map { case i =\u0026gt; r.addr(bankWidth - 1, 0) === i.U }) // 独热码,正常来说hitBankWire只有一个是拉高的 val hitBankReg = Reg(Vec(bankNum, Bool())) hitBankReg := hitBankWire val banksRdata = Wire(Vec(bankNum, UInt(len.W))) for (i \u0026lt;- 0 until bankNum) { // 通过后面的地址去读相应的寄存器,我比较奇怪的一点是不能直接写banks(i)(r.addr)吗，有什么区别吗 banksRdata(i) := RegEnable(VecInit(banks(i))(r.addr(r.addr.getWidth - 1, bankWidth)), hitBankWire(i)) } // 通过hitBankReg选择有效数据 r.data := Mux1H(hitBankReg, banksRdata) } } val writePorts = io.writePorts for (i \u0026lt;- writePorts.indices) { if (i \u0026lt; writePorts.size-1) { //就是不检查最后一个 // drop(i+1)，从第i+1端口开始的所有端口,有一个相同的hasSameWrite就会被触发 val hasSameWrite = writePorts.drop(i + 1).map(w =\u0026gt; w.wen \u0026amp;\u0026amp; w.addr === writePorts(i).addr \u0026amp;\u0026amp; writePorts(i).wen).reduce(_ || _) // 直接断言了，说明这样是不行的 assert(!hasSameWrite, \u0026#34;RegFile two or more writePorts write same addr\u0026#34;) } } // 它是自己写了一个sram,没有使用chisel的sram // 本来mem(w.addr) = wData就可以了的，这样写有什么好处吗? for (i \u0026lt;- mem.indices) { if (hasZero \u0026amp;\u0026amp; i == 0) { mem_0 := 0.U } else { val wenOH = VecInit(io.writePorts.map(w =\u0026gt; w.wen \u0026amp;\u0026amp; w.addr === i.U)) val wData = Mux1H(wenOH, io.writePorts.map(_.data)) when(wenOH.asUInt.orR) { if (i == 0) mem_0 := wData else mem(i) := wData } } } for (rport \u0026lt;- io.debug_rports) { rport.data := memForRead(rport.addr) } } 对物理寄存器的写入是来自于调度器，为什么不是通过ROB,在ROB排好顺序之后在按照程序编定的次序写入物理寄存器，这样是能够满足程序的正确次序。但是，实际上在在指令被执行之后，结果已经出来的时候就可以唤醒ReservationStation中正在等待结果的指令。从指令调度执行的角度，需要确保同一集合中的指令不会出现混淆，但是不同时间点的不同映射已经解决了这个问题。所以说，指令执行单元的回写需要进入ROB,但是真正的执行结果，可以超近路直接写入物理寄存器组和ReservationStation.\n指令的派发 第一级派遣的源码在 Dispatch.scala，其中包含了对不同指令类型的判断、对每一条指令是否能够进入下一级的判断以及对 BusyTable 的置位（指令会在这一流水级把它的目的寄存器状态置为无效）。第一级 Dispatch 负责将指令分类并发送至定点、浮点与访存三类派遣队列（Dispatch Queue）\n指令的派发是比较简单的，因为译码出来的结果带有指令应该在什么执行单元执行的信息，即FuType,Dispatch 只要根据这个信息将MicroOp发送到不同的分发队列里就可以了。另一方面，不管是怎么样的指令，都需要按顺序在Rob里留下一个副本，作为以后重新排序的依据。\n// valid bits for different dispatch queues ,根据FuType来判断指令的类型 val isInt = VecInit(io.fromRename.map(req =\u0026gt; req.valid \u0026amp;\u0026amp; FuType.isInt(req.bits.fuType))) val isIntDq0 = VecInit(io.fromRename.map(req =\u0026gt; req.valid \u0026amp;\u0026amp; FuType.isIntDq0(req.bits.fuType))) val isIntDq1 = VecInit(io.fromRename.map(req =\u0026gt; req.valid \u0026amp;\u0026amp; FuType.isIntDq1(req.bits.fuType))) val isAlu = VecInit(io.fromRename.map(req =\u0026gt; req.valid \u0026amp;\u0026amp; FuType.isBothDeq0(req.bits.fuType))) val isBrh = VecInit(io.fromRename.map(req =\u0026gt; req.valid \u0026amp;\u0026amp; (FuType.isBrh(req.bits.fuType) || FuType.isJump(req.bits.fuType)))) val isBranch = VecInit(io.fromRename.map(req =\u0026gt; // cover auipc (a fake branch) !req.bits.preDecodeInfo.notCFI || FuType.isJump(req.bits.fuType) )) val isFp = VecInit(io.fromRename.map(req =\u0026gt; FuType.isFArith(req.bits.fuType))) val isVec = VecInit(io.fromRename.map(req =\u0026gt; FuType.isVArith (req.bits.fuType) || FuType.isVsetRvfWvf(req.bits.fuType))) val isMem = VecInit(io.fromRename.map(req =\u0026gt; FuType.isMem(req.bits.fuType) || FuType.isVls (req.bits.fuType))) val isLs = VecInit(io.fromRename.map(req =\u0026gt; FuType.isLoadStore(req.bits.fuType))) val isVls = VecInit(io.fromRename.map(req =\u0026gt; FuType.isVls (req.bits.fuType))) val isStore = VecInit(io.fromRename.map(req =\u0026gt; FuType.isStore(req.bits.fuType))) val isVStore = VecInit(io.fromRename.map(req =\u0026gt; FuType.isVStore(req.bits.fuType))) val isAMO = VecInit(io.fromRename.map(req =\u0026gt; FuType.isAMO(req.bits.fuType))) val isBlockBackward = VecInit(io.fromRename.map(x =\u0026gt; x.valid \u0026amp;\u0026amp; x.bits.blockBackward)) val isWaitForward = VecInit(io.fromRename.map(x =\u0026gt; x.valid \u0026amp;\u0026amp; x.bits.waitForward)) 有一些mdp啥的看不太懂 ， 感觉也是一种扩展 ，分发本身不是就要干分发到发射队列，写到rob,和store buffer里去吗，为什么会这么复杂\n派遣队列 队列的一些定义 val io = IO(new DispatchQueueIO(enqnum, deqnum, size)) require(dpParams.IntDqDeqWidth == 8, \u0026#34;dpParams.IntDqDeqWidth must be 8\u0026#34;) require(backendParams.intSchdParams.get.issueBlockParams.size == 4, \u0026#34;int issueBlockParams must be 4\u0026#34;) backendParams.intSchdParams.get.issueBlockParams.map(x =\u0026gt; require(x.exuBlockParams.size == 2, \u0026#34;int issueBlockParam\u0026#39;s must be 2\u0026#34;)) // size: IntDqSize,队列的大小 val s_invalid :: s_valid :: Nil = Enum(2) // queue data array private def hasRen: Boolean = true val dataModule = Module(new SyncDataModuleTemplate(new DynInst, size, 2 * deqnum, enqnum, hasRen = hasRen)) // 缓冲区 , enqnum = RenameWidth ,deqnum=IntDqDeqWith / 2 val robIdxEntries = Reg(Vec(size, new RobPtr)) val stateEntries = RegInit(VecInit(Seq.fill(size)(s_invalid))) val validDeq0 = RegInit(VecInit(Seq.fill(size)(false.B))) val validDeq1 = RegInit(VecInit(Seq.fill(size)(false.B))) io.validDeq0Num := PopCount(validDeq0.zip(stateEntries).map{case (v, s) =\u0026gt; v \u0026amp;\u0026amp; (s===s_valid)}) io.validDeq1Num := PopCount(validDeq1.zip(stateEntries).map{case (v, s) =\u0026gt; v \u0026amp;\u0026amp; (s===s_valid)}) class DispatchQueuePtr extends CircularQueuePtr[DispatchQueuePtr](size) // 循环缓存指针 // head: first valid entry (dispatched entry) val headPtr = RegInit(VecInit((0 until 2 * deqnum).map(_.U.asTypeOf(new DispatchQueuePtr)))) // 生成这么多指针,从0 到 2*deqnum - 1 val headPtrNext = Wire(Vec(2 * deqnum, new DispatchQueuePtr)) val headPtrMask = UIntToMask(headPtr(0).value, size) val headPtrOH = RegInit(1.U(size.W)) val headPtrOHShift = CircularShift(headPtrOH) val headPtrOHVec = VecInit.tabulate(deqnum + 1)(headPtrOHShift.left) // tail: first invalid entry (free entry) val tailPtr = RegInit(VecInit((0 until enqnum).map(_.U.asTypeOf(new DispatchQueuePtr)))) val tailPtrMask = UIntToMask(tailPtr(0).value, size) val tailPtrOH = RegInit(1.U(size.W)) val tailPtrOHShift = CircularShift(tailPtrOH) val tailPtrOHVec = VecInit.tabulate(enqnum + 1)(tailPtrOHShift.left) // valid entries counter val validCounter = RegInit(0.U(log2Ceil(size + 1).W)) val allowEnqueue = RegInit(true.B) //allowEnqueue := (numNeedAlloc +\u0026amp; currentValidCounter \u0026lt;= (size - enqnum).U) || (numNeedAlloc +\u0026amp; currentValidCounter - (size - enqnum).U \u0026lt;= numDeq) val isTrueEmpty = !VecInit(stateEntries.map(_ === s_valid)).asUInt.orR val canEnqueue = allowEnqueue Part 1: update states and uops when enqueue, dequeue, commit, redirect/replay 队列写入\n/** * Part 1: update states and uops when enqueue, dequeue, commit, redirect/replay * * uop only changes when a new instruction enqueues. * * state changes when * (1) enqueue: from s_invalid to s_valid * (2) dequeue: from s_valid to s_dispatched * (3) commit: from s_dispatched to s_invalid * (4) redirect (branch misprediction or exception): from any state to s_invalid (flushed) * (5) redirect (replay): from s_dispatched to s_valid (re-dispatch) */ // enqueue: from s_invalid to s_valid // 允许入队 io.enq.canAccept := canEnqueue // needAlloc拉高就是fromRename.valid,反正就是dispatch那边需要分发到这个队列 val enqOffset = (0 until enqnum).map(i =\u0026gt; PopCount(io.enq.needAlloc.take(i))) //偏移量，从本周期的第一个入队指令开始计算,假设（0,1,1,2,3） val enqIndexOH = (0 until enqnum).map(i =\u0026gt; tailPtrOHVec(enqOffset(i))) // 把偏移量转化为OH编码 (1,10,10,100,1000), 如果选中第i个表项oh(i) = 1 for (i \u0026lt;- 0 until size) { // req.valid多了两个条件，canEnterrDpq 和 dqCanAccept,应该就是没有异常或者其他的情况 val validVec = io.enq.req.map(_.valid).zip(enqIndexOH).map{ case (v, oh) =\u0026gt; v \u0026amp;\u0026amp; oh(i) } // 选中的表项,为1的话代表这一条指令选择了这个表项 when (VecInit(validVec).asUInt.orR \u0026amp;\u0026amp; canEnqueue) {//这一条表项有指令选择 robIdxEntries(i) := Mux1H(validVec, io.enq.req.map(_.bits.robIdx)) //把这一条指令的值赋给robIdxEntries stateEntries(i) := s_valid //表项有效 if (dqIndex == 0) { //队列的id validDeq0(i) := FuType.isIntDq0Deq0(Mux1H(validVec, io.enq.req.map(_.bits.fuType))) //去判断是Deq0还是Deq1 validDeq1(i) := FuType.isIntDq0Deq1(Mux1H(validVec, io.enq.req.map(_.bits.fuType))) } else { validDeq0(i) := FuType.isIntDq1Deq0(Mux1H(validVec, io.enq.req.map(_.bits.fuType))) validDeq1(i) := FuType.isIntDq1Deq1(Mux1H(validVec, io.enq.req.map(_.bits.fuType))) } } } for (i \u0026lt;- 0 until enqnum) { dataModule.io.wen(i) := canEnqueue \u0026amp;\u0026amp; io.enq.req(i).valid // 写入缓冲区的条件,需要加入队列 dataModule.io.waddr(i) := tailPtr(enqOffset(i)).value // 写入的地址,队列的指针 dataModule.io.wdata(i) := io.enq.req(i).bits ///写入的数据,bits,microop } // dequeue: from s_valid to s_dispatched for (i \u0026lt;- 0 until size) { val validVec = io.deq.map(_.fire).zip(headPtrOHVec).map{ case (v, oh) =\u0026gt; v \u0026amp;\u0026amp; oh(i) } //指示哪一条指令可以出队列了,首先得hedPtr选择了这一条表项 when (VecInit(validVec).asUInt.orR \u0026amp;\u0026amp; !io.redirect.valid) { stateEntries(i) := s_invalid //失效表项 } } // redirect: cancel uops currently in the queue val needCancel = Wire(Vec(size, Bool())) for (i \u0026lt;- 0 until size) { needCancel(i) := stateEntries(i) =/= s_invalid \u0026amp;\u0026amp; robIdxEntries(i).needFlush(io.redirect) //表项是有效的但是需要flush when(needCancel(i)) { stateEntries(i) := s_invalid //此时就把表项置为无效 } XSInfo(needCancel(i), p\u0026#34;valid entry($i): robIndex ${robIdxEntries(i)} \u0026#34; + p\u0026#34;cancelled with redirect robIndex 0x${Hexadecimal(io.redirect.bits.robIdx.asUInt)}\\n\u0026#34;) } Part 2: update indices 更新队列的头和尾指针\n/** * Part 2: update indices,更新索引 * * tail: (1) enqueue; (2) redirect * head: dequeue */ // dequeue val currentValidCounter = distanceBetween(tailPtr(0), headPtr(0)) val numDeqTryMask = Mux(currentValidCounter \u0026gt;= deqnum.U, // all deq are valid (1 \u0026lt;\u0026lt; deqnum).U, // only the valid bits are set // 把currentValidCounter转化为独热码 UIntToOH(currentValidCounter, deqnum) //中间的某一个 ) // 感觉可以把头指针和尾指针的概念互换一下，现在头指针是负责出队列的，尾指针是负责入队列的 // 这些是已经放在端口上了，但是还没有被取出的 // 选择没握手的但是entry数据有效的 // numDeqTryMask是tailPtr(0)和headPtr(0)的距离,headPtr是同时增加的,tailPtr不是同时增加的 // 它应该是要保证deq的是连续的，所以如果遇到！deq.fire的话，就标记deqEnable_n,比方说deqEnable_n是000010,那么numDeq就是1 val deqEnable_n = io.deq.zipWithIndex.map { case (deq, i) =\u0026gt; // For dequeue, the first entry should never be s_invalid // Otherwise, there should be a redirect and tail walks back // in this case, we set numDeq to 0 if (i == 0) !deq.fire || numDeqTryMask(i) // When the state is s_invalid, we set deqEnable_n to false.B because // the entry may leave earlier and require to move forward the deqPtr. else (!deq.fire \u0026amp;\u0026amp; stateEntries(headPtr(i).value) =/= s_invalid) || numDeqTryMask(i) } :+ true.B val numDeq = PriorityEncoder(deqEnable_n) // PriorityEncoder是从右到左去选择的 // agreement with reservation station: don\u0026#39;t dequeue when redirect.valid for (i \u0026lt;- 0 until 2 * deqnum) { // 如果是redirect,那么就不出队列,否则就去往下一个表项,说明如果没有redirect的话，headPtr是同时加一个numDeq的 headPtrNext(i) := Mux(io.redirect.valid, headPtr(i), headPtr(i) + numDeq) } // 更新头指针 // headPtr是一个Vec,代表第更新的时候应该指向下一个要出队列的entry // 如果deqEnable_n是000010,那么headPtrOH其实是向左边移动了1位 headPtr := headPtrNext headPtrOH := Mux(io.redirect.valid, headPtrOH, ParallelPriorityMux(deqEnable_n, headPtrOHVec)) XSError(headPtrOH =/= headPtr.head.toOH, p\u0026#34;head: $headPtrOH != UIntToOH(${headPtr.head})\u0026#34;) // For branch mis-prediction or memory violation replay, // we delay updating the indices for one clock cycle. // For now, we simply use PopCount to count #instr cancelled. // 上一个周期分支错误 val lastCycleMisprediction = GatedValidRegNext(io.redirect.valid) // find the last one\u0026#39;s position, starting from headPtr and searching backwards // 寻找最后一个有效表项 val validBitVec = VecInit((0 until size).map(i =\u0026gt; stateEntries(i) === s_valid)) //有效表项的Vec val loValidBitVec = Cat((0 until size).map(i =\u0026gt; validBitVec(i) \u0026amp;\u0026amp; headPtrMask(i)))// 如果headPtrMask是3,headPtrMask是1000-1 = 0111,Cat是反过来的,0在最前面 val hiValidBitVec = Cat((0 until size).map(i =\u0026gt; validBitVec(i) \u0026amp;\u0026amp; !headPtrMask(i))) val flippedFlag = loValidBitVec.orR || validBitVec(size - 1) // 如果loValidBitVec有1,或者最后一个表项是有效的 val leadingZeros = PriorityEncoder(Mux(loValidBitVec.orR, loValidBitVec, hiValidBitVec)) // 找到最右边的表项，就是找到最大的一个表项号,但是此时是反过来的 val lastOneIndex = Mux(leadingZeros === 0.U, 0.U, size.U - leadingZeros) // 通过size.U - 得到真正的序号 val walkedTailPtr = Wire(new DispatchQueuePtr) walkedTailPtr.flag := flippedFlag ^ headPtr(0).flag walkedTailPtr.value := lastOneIndex // enqueue //io.enqRob.needAlloc(i) := io.fromRename(i).valid //io.enqRob.req(i).valid := io.fromRename(i).valid \u0026amp;\u0026amp; thisCanActualOut(i) \u0026amp;\u0026amp; dqCanAccept,doCanAccept指的是队列可以接受 val numEnq = Mux(io.enq.canAccept, PopCount(io.enq.req.map(_.valid)), 0.U) // 发起请求的有多少个，就进多少个 val numNeedAlloc = Mux(io.enq.canAccept, PopCount(io.enq.needAlloc), 0.U) // needAlloc的数量 tailPtr(0) := Mux(io.redirect.valid, tailPtr(0), Mux(lastCycleMisprediction, Mux(isTrueEmpty, headPtr(0), walkedTailPtr), tailPtr(0) + numEnq) ) val lastLastCycleMisprediction = GatedValidRegNext(lastCycleMisprediction) for (i \u0026lt;- 1 until enqnum) { tailPtr(i) := Mux(io.redirect.valid, tailPtr(i), Mux(lastLastCycleMisprediction, tailPtr(0) + i.U, tailPtr(i) + numEnq) ) } tailPtrOH := Mux(lastLastCycleMisprediction, tailPtr.head.toOH, tailPtrOHVec(numEnq)) val tailPtrOHAccurate = !lastCycleMisprediction \u0026amp;\u0026amp; !lastLastCycleMisprediction XSError(tailPtrOHAccurate \u0026amp;\u0026amp; tailPtrOH =/= tailPtr.head.toOH, p\u0026#34;tail: $tailPtrOH != UIntToOH(${tailPtr.head})\u0026#34;) // update valid counter and allowEnqueue reg validCounter := Mux(io.redirect.valid, validCounter, Mux(lastLastCycleMisprediction, currentValidCounter, validCounter + numEnq - numDeq) ) // 意思是空闲队列数是要大于enqnum的,或者就是空闲队列数大于enqnum - deqnum allowEnqueue := (numNeedAlloc +\u0026amp; currentValidCounter \u0026lt;= (size - enqnum).U) || (numNeedAlloc +\u0026amp; currentValidCounter - (size - enqnum).U \u0026lt;= numDeq) Part3:set output valid and data bits /** * Part 3: set output valid and data bits */ val deqData = Reg(Vec(deqnum, new DynInst)) // How to pipeline the data read: // T: get the required read data for (i \u0026lt;- 0 until deqnum) { io.deq(i).bits := deqData(i) // Some bits have bad timing in Dispatch but will not be used at Dispatch2 // They will use the slow path from data module io.deq(i).bits.fpu := dataModule.io.rdata(i).fpu // do not dequeue when io.redirect valid because it may cause dispatchPtr work improperly io.deq(i).valid := Mux1H(headPtrOHVec(i), stateEntries) === s_valid \u0026amp;\u0026amp; !lastCycleMisprediction } // T-1: select data from the following (deqnum + 1 + numEnq) sources with priority, 从以下（deqnum + 1 + numEnq）个数据源按照优先级选择数据 // For data(i): (1) current output (deqnum - i); (2) next-step data (i + 1) // 对于data(i),（1）当前输出（deqnum - i),(2)下一步data (i+1) // For the next-step data(i): (1) enqueue data (enqnum); (2) data from storage (1) // [0,deqnum-1] 和[deqnum,2*depnum-1]数据源是不一样的,我猜测[deqnum,2*deqnum-1]是下一步的数据 val nextStepData = Wire(Vec(2 * deqnum, new DynInst)) val ptrMatch = new QPtrMatchMatrix(headPtr, tailPtr) for (i \u0026lt;- 0 until 2 * deqnum) { val enqMatchVec = VecInit(ptrMatch(i)) // i是定的,旁路应该是直接把输入的数据旁路给输出的,它应该就是在deq是定的时候去遍历enq,判断是否有一样的指针,有问题啊？？这东西应该只有一个是拉高的 val enqBypassEnVec = io.enq.needAlloc.zip(enqOffset).map{ case (v, o) =\u0026gt; v \u0026amp;\u0026amp; enqMatchVec(o) } val enqBypassEn = io.enq.canAccept \u0026amp;\u0026amp; VecInit(enqBypassEnVec).asUInt.orR //旁路 val enqBypassData = Mux1H(enqBypassEnVec, io.enq.req.map(_.bits)) val readData = if (i \u0026lt; deqnum) deqData(i) else dataModule.io.rdata(i) nextStepData(i) := Mux(enqBypassEn, enqBypassData, readData) // 读取的数据,和旁路的数据 } for (i \u0026lt;- 0 until deqnum) { when (!io.redirect.valid) { // 如果deqEnable_n是000100, 那么deqData(0) = nextStepData(2), deqData(1) = nextStepData(3), deqData(2) = nextStepData(4) // 因为前几个数据已经被读了，所以需要顺位过去; // 如果本次读满了，deqEnable_n = 1 \u0026lt;\u0026lt; (deqnum + 1) , 那实际上是直接把下一批的数据覆盖过来,要不然还是会带着一些本批的数据 deqData(i) := ParallelPriorityMux(deqEnable_n, nextStepData.drop(i).take(deqnum + 1)) //丢弃前i个元素，保留后面的deqnum + 1个元素 } } // T-2: read data from storage: next for (i \u0026lt;- 0 until 2 * deqnum) { // 因为ren不一定有，所有要用get(i)确保安全访问 dataModule.io.ren.get(i) := io.redirect.valid || io.deq.map(_.valid).reduce(_|_) // 读取队列中的数据,读取条件是io.deq中有valid,或者 } dataModule.io.raddr := headPtrNext.map(_.value) // 设置好从dataModule读出的地址,它是直接从headPtrNext读的,T-2读数据，T-1读到数据 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-14T17:19:27+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81%E5%89%96%E6%9E%90%E6%8C%87%E4%BB%A4%E7%9A%84%E8%AF%91%E7%A0%81%E5%92%8C%E6%B4%BE%E5%8F%91/","title":"香山源代码剖析——指令的译码和派发"},{"content":"PMP : 物理存储保护（Physical Memory Protection) module ,它将所有的访问权限都集中起来\nPMA:物理存储属性（Physical Memory Attributes),PMP实施存储空间保护的依据\nPMP + PMA 的保护方案\n每当目标地址访问内存单元时，先向PMP模块查询一下，PMP用这个目标地址找到所述的区间，然后返回地址的属性。\n补充（来自 riscv手册） PMA是底层硬件的固有属性，在系统运行期间很少发生变化。与PMP不同，PMA不随执行上下文而变化。某些存储区域的 PMA 在芯片设计时就已确定——例如片上 ROM。其他的在电路板设计时是固定的，例如取决于哪些其他芯片连接到片外总线。片外总线还可能支持可以在每个电源周期（冷插拔）或在系统运行时动态更改（热插拔）的设备。某些设备可能在运行时进行配置，以支持意味着不同 PMA 的不同用途，例如，片上暂存器 RAM 可能由一个最终应用程序中的一个内核私有缓存，或者在另一个最终应用程序中作为共享非缓存内存进行访问最终应用程序。\n为了帮助系统调试，我们强烈建议在可能的情况下，RISCV 处理器精确捕获未通过 PMA 检查的物理内存访问。精确捕获的 PMA 违规表现为指令、加载或存储访问错误异常，与虚拟内存页错误异常不同。\n主内存与 I/O 与空闲区域 给定内存地址范围最重要的特征是它是否拥有常规主内存或 I/O 设备，或者是否为空。\n主内存区域始终支持所连接设备所需的所有访问宽度的读写，并且可以指定是否支持取指令。\nI/O 区域可以指定支持哪些数据宽度的读、写或执行访问组合。\n对于具有基于页面的虚拟内存的系统，I/O 和内存区域可以指定支持硬件页表读取和硬件页表写入的组合。\nAtomicity PMAs 原子性 PMA 描述了该地址区域支持哪些原子指令。对原子指令的支持分为两类：LR/SC 和 AMO。\n未完\nPMP 为了支持安全处理并包含故障，需要限制硬件上运行的软件可访问的物理地址。可选的物理内存保护 (PMP) 单元提供 per-hart 机器模式控制寄存器，允许为每个物理内存区域指定物理内存访问权限（读、写、执行）。 PMP 值的检查与第 3.6 节中描述的 PMA 检查并行。\nPMP 检查适用于所有有效特权模式为 S 或 U 的访问，包括 S 和 U 模式下的取指令、mstatus 寄存器中 MPRV 位清零时 S 和 U 模式下的数据访问，以及当 mstatus 寄存器中的 MPRV 位清零时的任何模式下的数据访问。 mstatus 中的 MPRV 位被设置，并且 mstatus 中的 MPP 字段包含 S 或 U。PMP 检查也适用于虚拟地址转换的页表访问，其有效特权模式为 S。可选地，PMP 检查可以另外还适用于 M 模式访问，在这种情况下，PMP 寄存器本身被锁定，因此即使是 M 模式软件也无法更改它们，直到 hart 复位。实际上，PMP 可以向 S 和 U 模式授予权限（默认情况下没有权限），并且可以撤销 M 模式的权限（默认情况下具有完全权限）。\nPMP CSRs PMP 条目由 8 位配置寄存器和 1 个 MXLEN 位地址寄存器描述。某些 PMP 设置还使用与前面的 PMP 条目关联的地址寄存器。最多支持 64 个 PMP 条目。实现可以实现零个、16 个或 64 个 PMP CSR；必须首先实施编号最低的 PMP CSR。所有 PMP CSR 字段都是 WARL，并且可以是只读零。 PMP CSR 仅适用于 M 模式。\nPMP 配置寄存器密集地封装到 CSR 中，以最大限度地减少上下文切换时间。对于 RV32，16 个 CSR（pmpcfg0–pmpcfg15）保存 64 个 PMP 条目的配置 pmp0cfg–pmp63cfg，如图 3.31 所示。对于 RV64，八个偶数 CSR、pmpcfg0、pmpcfg2、. 。 。 、pmpcfg14，保存了64个PMP表项的配置，如图3.32所示。对于 RV64，奇数配置寄存器 pmpcfg1、pmpcfg3、. 。 。 、pmpcfg15 是非法的。\nPMP 地址寄存器是名为 pmpaddr0–pmpaddr63 的 CSR。每个 PMP 地址寄存器对 RV32 的 34 位物理地址的第 33-2 位进行编码，如图 3.33 所示。对于 RV64，每个 PMP 地址寄存器对 56 位物理地址的第 55-2 位进行编码，如图 3.34 所示。并非所有物理地址位都可以实现，因此 pmpaddr 寄存器是 WARL。\nAddress Matching PMP 条目配置寄存器中的 A 字段对关联 PMP 地址寄存器的地址匹配模式进行编码。该字段的编码如表3.10所示。当A=0时，该PMP条目被禁用并且不匹配任何地址。支持另外两种地址匹配模式：自然对齐的 2 幂区域 (NAPOT)，包括自然对齐的四字节区域 (NA4) 的特殊情况；以及任意范围的顶部边界 (TOR)。这些模式支持四字节粒度。\nNAPOT 范围利用相关地址寄存器的低位来编码范围的大小，如表 3.11 所示。\npmpaddr的低位表示区域的大小，高位表示右移2bit的基地址\nhttps://www.reddit.com/r/RISCV/comments/ypu6kx/how_to_convert_a_range_of_memory_to_pmpaddrx_for/ 有助于理解它的意思\n比方说pmpaddr 为 10001 0111111的话， 基地址就是 10001 0000000 00 ， 大小就是 2^(6+3) = 1 000000000 ,所以比对的时候前9位是需要做mask的 ，需要比对后面的位数\n如果选择 TOR，则关联的地址寄存器形成地址范围的顶部，而前面的 PMP 地址寄存器形成地址范围的底部。如果 PMP 条目 i 的 A 字段设置为 TOR，则该条目与任何地址 y 匹配，使得 pmpaddri−1 ≤ y \u0026lt; pmpaddri （与 pmmpcfgi−1 的值无关）。如果 PMP 条目 0 的 A 字段设置为 TOR，则使用零作为下限，因此它匹配任何地址 y \u0026lt; pmpaddr0。\nPMP地址寄存器，在32位RISCV上，pmpaddr是32位，物理地址是36位，所以pmpaddr的内容是物理地址的bit2-bit33, bit34,bit35也是忽略的\nLocking and Privilege Mode L 位表示 PMP 条目已锁定，即对配置寄存器和相关地址寄存器的写入被忽略。锁定的 PMP 条目将保持锁定状态，直到重置 Hart。如果 PMP 条目 i 被锁定，则对 pmpicfg 和 pmpaddri 的写入将被忽略。此外，如果 PMP 条目 i 被锁定并且 pmpicfg.A 设置为 TOR，则忽略对 pmpaddri-1 的写入。 即使 A 字段设置为 OFF，设置 L 位也会锁定 PMP 条目。 除了锁定 PMP 条目之外，L 位还指示是否对 M 模式访问强制执行 R/W/X 权限。当 L 位被设置时，这些权限将针对所有特权模式强制执行。当L位清零时，任何与PMP条目匹配的M模式访问都会成功； R/W/X 权限仅适用于 S 和 U 模式。\n香山的pmp和pma // PMP.scala class PMP(implicit p: Parameters) extends PMPXSModule with HasXSParameter with PMPMethod with PMAMethod with HasCSRConst { val io = IO(new Bundle { val distribute_csr = Flipped(new DistributedCSRIO()) val pmp = Output(Vec(NumPMP, new PMPEntry())) val pma = Output(Vec(NumPMA, new PMPEntry())) }) val w = io.distribute_csr.w val pmp = Wire(Vec(NumPMP, new PMPEntry())) // NumPMP = 16 val pma = Wire(Vec(NumPMA, new PMPEntry())) // Numpma = 16 val pmpMapping = pmp_gen_mapping(pmp_init, NumPMP, PmpcfgBase, PmpaddrBase, pmp) // 生成PMP比对表 ， val pmaMapping = pmp_gen_mapping(pma_init, NumPMA, PmacfgBase, PmaaddrBase, pma) // 生成PMA比对表 val mapping = pmpMapping ++ pmaMapping val rdata = Wire(UInt(PMXLEN.W)) MaskedRegMap.generate(mapping, w.bits.addr, rdata, w.valid, w.bits.data) // 讲比对表项放在CSR寄存器里 io.pmp := pmp io.pma := pma } // 在 CSRConst.scala有寄存器的基地址 val PmpcfgBase = 0x3A0 val PmpaddrBase = 0x3B0 // Machine level PMA val PmacfgBase = 0x7C0 val PmaaddrBase = 0x7C8 // 64 entry at most trait PMPMethod extends PMPConst { def pmp_init() : (Vec[UInt], Vec[UInt], Vec[UInt])= { //生成了3组信号 val cfg = WireInit(0.U.asTypeOf(Vec(NumPMP/8, UInt(PMXLEN.W)))) // val addr = Wire(Vec(NumPMP, UInt((PMPAddrBits-PMPOffBits).W))) // val mask = Wire(Vec(NumPMP, UInt(PMPAddrBits.W))) // INFO: these CSRs could be uninitialized, but for difftesting with NEMU, we opt to initialize them. val addr = WireInit(0.U.asTypeOf(Vec(NumPMP, UInt((PMPAddrBits-PMPOffBits).W)))) val mask = WireInit(0.U.asTypeOf(Vec(NumPMP, UInt(PMPAddrBits.W)))) (cfg, addr, mask) } def pmp_gen_mapping ( init: () =\u0026gt; (Vec[UInt], Vec[UInt], Vec[UInt]), num: Int = 16, cfgBase: Int, addrBase: Int, entries: Vec[PMPEntry] ) = { // 一个csr寄存器配置的pmp条目 ， 32 / 8 val pmpCfgPerCSR = PMXLEN / new PMPConfig().getWidth // 获取第i个 pmp对应的CSR def pmpCfgIndex(i: Int) = (PMXLEN / 32) * (i / pmpCfgPerCSR) val init_value = init() /** to fit MaskedRegMap\u0026#39;s write, declare cfgs as Merged CSRs and split them into each pmp */ val cfgMerged = RegInit(init_value._1) //(Vec(num / pmpCfgPerCSR, UInt(PMXLEN.W))) // RegInit(VecInit(Seq.fill(num / pmpCfgPerCSR)(0.U(PMXLEN.W)))) // 这里把cfgs按照 pmp的个数进行划分了 val cfgs = WireInit(cfgMerged).asTypeOf(Vec(num, new PMPConfig())) val addr = RegInit(init_value._2) // (Vec(num, UInt((PMPAddrBits-PMPOffBits).W))) val mask = RegInit(init_value._3) // (Vec(num, UInt(PMPAddrBits.W))) for (i \u0026lt;- entries.indices) { entries(i).gen(cfgs(i), addr(i), mask(i)) } val cfg_mapping = (0 until num by pmpCfgPerCSR).map(i =\u0026gt; {Map( MaskedRegMap( addr = cfgBase + pmpCfgIndex(i), reg = cfgMerged(i/pmpCfgPerCSR), wmask = WritableMask, wfn = new PMPBase().write_cfg_vec(mask, addr, i, cfgMerged(i/pmpCfgPerCSR)) // cfgMerged（i/pmpCfgPerCSR)是以CSR为单位的 )) }).fold(Map())((a, b) =\u0026gt; a ++ b) // ugly code, hit me if u have better codes, 这个意思就是把每次的map 得到的键值对合并成一个大的Map , 而不是Seq了 val addr_mapping = (0 until num).map(i =\u0026gt; {Map( // MaskedRegMap对 整个数据进行重新组织了 (Int, (UInt, UInt, UInt =\u0026gt; UInt, UInt, UInt =\u0026gt; UInt)) = (addr, (reg, wmask, wfn, rmask, rfn)) MaskedRegMap( addr = addrBase + i, // CSR地址 reg = addr(i), // wmask = WritableMask, wfn = { if (i != num-1) entries(i).write_addr(entries(i+1).cfg, mask(i)) else entries(i).write_addr(mask(i)) }, rmask = WritableMask, rfn = new PMPBase().read_addr(entries(i).cfg) )) }).fold(Map())((a, b) =\u0026gt; a ++ b) // ugly code, hit me if u have better codes. cfg_mapping ++ addr_mapping } } // PMPReadWriteMethodBare特质的一个方法 def write_cfg_vec(mask: Vec[UInt], addr: Vec[UInt], index: Int, oldcfg: UInt)(cfgs: UInt): UInt = { // pmp为单位 val cfgVec = Wire(Vec(cfgs.getWidth/8, new PMPConfig)) for (i \u0026lt;- cfgVec.indices) { // new config val cfg_w_m_tmp = cfgs((i+1)*8-1, i*8).asUInt.asTypeOf(new PMPConfig) // old config val cfg_old_tmp = oldcfg((i+1)*8-1, i*8).asUInt.asTypeOf(new PMPConfig) cfgVec(i) := cfg_old_tmp when (!cfg_old_tmp.l) { // 如果没有lock的话 cfgVec(i) := cfg_w_m_tmp cfgVec(i).w := cfg_w_m_tmp.w \u0026amp;\u0026amp; cfg_w_m_tmp.r // 意思是说只有有读权限，写权限才是有效的 if (CoarserGrain) { cfgVec(i).a := Cat(cfg_w_m_tmp.a(1), cfg_w_m_tmp.a.orR) } // 10 -\u0026gt; 11 na4 -\u0026gt; napot when (cfgVec(i).na4_napot) { // a(1) mask(index + i) := match_mask(cfgVec(i), addr(index + i)) } } } cfgVec.asUInt } // PMPConfig:PMP配置， paddr: 物理地址 def match_mask(cfg: PMPConfig, paddr: UInt) = { // 1 \u0026lt;\u0026lt; platformGrain : 1page 4KB , 它会把 前10位全部赋值为1 val match_mask_c_addr = Cat(paddr, cfg.a(0)) | (((1 \u0026lt;\u0026lt; PlatformGrain) - 1) \u0026gt;\u0026gt; PMPOffBits).U((paddr.getWidth + 1).W) Cat(match_mask_c_addr \u0026amp; ~(match_mask_c_addr + 1.U), ((1 \u0026lt;\u0026lt; PMPOffBits) - 1).U(PMPOffBits.W)) } // (a \u0026amp; ~(a + 1) , 0b11) ， 1010 11111 0100 11111 -\u0026gt; 000011111 ,把第1个0左边的全部置0 ，所以它生成的是mask ,针对于物理地址， // PMPConfig就是封装了配置寄存器的的位 class PMPConfig(implicit p: Parameters) extends PMPBundle { val l = Bool() val c = Bool() // res(1), unuse in pmp val atomic = Bool() // res(0), unuse in pmp val a = UInt(2.W) val x = Bool() val w = Bool() val r = Bool() def res: UInt = Cat(c, atomic) // in pmp, unused def off = a === 0.U def tor = a === 1.U def na4 = { if (CoarserGrain) false.B else a === 2.U } def napot = { if (CoarserGrain) a(1).asBool else a === 3.U } def off_tor = !a(1) def na4_napot = a(1) def locked = l def addr_locked: Bool = locked def addr_locked(next: PMPConfig): Bool = locked || (next.locked \u0026amp;\u0026amp; next.tor) } // 所以说一个PMPEntry表项应该是有 cfg addr mask 3个变量 class PMPBase(implicit p: Parameters) extends PMPBundle with PMPReadWriteMethod { val cfg = new PMPConfig val addr = UInt((PMPAddrBits - PMPOffBits).W) // PMPOffBits = 2 def gen(cfg: PMPConfig, addr: UInt) = { require(addr.getWidth == this.addr.getWidth) this.cfg := cfg this.addr := addr } } class PMPEntry(implicit p: Parameters) extends PMPBase with PMPMatchMethod { val mask = UInt(PMPAddrBits.W) // help to match in napot def write_addr(next: PMPConfig, mask: UInt)(paddr: UInt) = { mask := Mux(!cfg.addr_locked(next), match_mask(paddr), mask) Mux(!cfg.addr_locked(next), paddr, addr) } def write_addr(mask: UInt)(paddr: UInt) = { mask := Mux(!cfg.addr_locked, match_mask(paddr), mask) Mux(!cfg.addr_locked, paddr, addr) } def gen(cfg: PMPConfig, addr: UInt, mask: UInt) = { require(addr.getWidth == this.addr.getWidth) this.cfg := cfg this.addr := addr this.mask := mask } } PMAMethod 中有个pma_init(),创建了PMA的全部表项 ，函数返回的类型也是Seq(cfg,addr,mask)\ndef pma_init() : (Vec[UInt], Vec[UInt], Vec[UInt]) = { def genAddr(init_addr: BigInt) = { init_addr.U((PMPAddrBits - PMPOffBits).W) } def genMask(init_addr: BigInt, a: BigInt) = { val match_mask_addr = (init_addr \u0026lt;\u0026lt; 1) | (a \u0026amp; 0x1) | (((1 \u0026lt;\u0026lt; PlatformGrain) - 1) \u0026gt;\u0026gt; PMPOffBits) val mask = ((match_mask_addr \u0026amp; ~(match_mask_addr + 1)) \u0026lt;\u0026lt; PMPOffBits) | ((1 \u0026lt;\u0026lt; PMPOffBits) - 1) mask.U(PMPAddrBits.W) } val num = NumPMA require(num \u0026gt;= 16) val cfg_list = ListBuffer[UInt]() val addr_list = ListBuffer[UInt]() val mask_list = ListBuffer[UInt]() def addPMA(base_addr: BigInt, range: BigInt = 0L, // only use for napot mode l: Boolean = false, c: Boolean = false, atomic: Boolean = false, a: Int = 0, x: Boolean = false, w: Boolean = false, r: Boolean = false) = { val addr = if (a \u0026lt; 2) { shift_addr(base_addr) } else { get_napot(base_addr, range) } cfg_list.append(PMPConfigUInt(l, c, atomic, a, x, w, r)) addr_list.append(genAddr(addr)) mask_list.append(genMask(addr, a)) } addPMA(0x0L, range = 0x1000000000L, c = true, atomic = true, a = 3, x = true, w = true, r = true) addPMA(0x0L, range = 0x80000000L, a = 3, w = true, r = true) addPMA(0x3C000000L, a = 1) addPMA(0x3A001000L, a = 1, w = true, r = true) addPMA(0x3A000000L, a = 1) addPMA(0x39002000L, a = 1, w = true, r = true) addPMA(0x39000000L, a = 1) addPMA(0x38022000L, a = 1, w = true, r = true) addPMA(0x38021000L, a = 1, x = true, w = true, r = true) addPMA(0x38020000L, a = 1, w = true, r = true) addPMA(0x30050000L, a = 1, w = true, r = true) // FIXME: GPU space is cacheable? addPMA(0x30010000L, a = 1, w = true, r = true) addPMA(0x20000000L, a = 1, x = true, w = true, r = true) addPMA(0x10000000L, a = 1, w = true, r = true) addPMA(0) while (cfg_list.length \u0026lt; 16) { addPMA(0) } val cfgInitMerge = Seq.tabulate(num / 8)(i =\u0026gt; { cfg_list.reverse.drop(8 * i).take(8).foldRight(BigInt(0L)) { case (a, result) =\u0026gt; (result \u0026lt;\u0026lt; a.getWidth) | a.litValue }.U(PMXLEN.W) }) val addr = addr_list.reverse val mask = mask_list.reverse (VecInit(cfgInitMerge), VecInit(addr.toSeq), VecInit(mask.toSeq)) } def get_napot(base: BigInt, range: BigInt): BigInt = { // 1 page = 4096 bytes val PlatformGrainBytes = (1 \u0026lt;\u0026lt; PlatformGrain) if ((base % PlatformGrainBytes) != 0) { println(\u0026#34;base:%x\u0026#34;, base) } if ((range % PlatformGrainBytes) != 0) { println(\u0026#34;range: %x\u0026#34;, range) } require((base % PlatformGrainBytes) == 0) require((range % PlatformGrainBytes) == 0) ((base + (range/2 - 1)) \u0026gt;\u0026gt; PMPOffBits) } def match_mask(paddr: UInt, cfg: PMPConfig) = { val match_mask_addr: UInt = Cat(paddr, cfg.a(0)).asUInt | (((1 \u0026lt;\u0026lt; PlatformGrain) - 1) \u0026gt;\u0026gt; PMPOffBits).U((paddr.getWidth + 1).W) Cat(match_mask_addr \u0026amp; ~(match_mask_addr + 1.U), ((1 \u0026lt;\u0026lt; PMPOffBits) - 1).U(PMPOffBits.W)) } def shift_addr(addr: BigInt) = { addr \u0026gt;\u0026gt; 2 } 每当想要访问一个物理存储地址的时候，就要在一个PMPReqBundle上向PMP发出一个查询请求,addr是物理地址，size是目标地址区间的大小，已字节为单位，cmd为访问意图，读写，还是执行\nclass PMPReqBundle(lgMaxSize: Int = 3)(implicit p: Parameters) extends PMPBundle { val addr = Output(UInt(PMPAddrBits.W)) val size = Output(UInt(log2Ceil(lgMaxSize+1).W)) val cmd = Output(TlbCmd()) def apply(addr: UInt, size: UInt, cmd: UInt): Unit = { this.addr := addr this.size := size this.cmd := cmd } def apply(addr: UInt): Unit = { // req minimal permission and req align size apply(addr, lgMaxSize.U, TlbCmd.read) } } class PMPRespBundle(implicit p: Parameters) extends PMPBundle { val ld = Output(Bool()) //表示可读 val st = Output(Bool()) //表示可写 val instr = Output(Bool()) // 表示可执行（指令） val mmio = Output(Bool()) // 表示目标单元在MMIO中，说明不可以缓存 val atomic = Output(Bool()) // 表示对此单元的访问可以是原子操作 def |(resp: PMPRespBundle): PMPRespBundle = { val res = Wire(new PMPRespBundle()) res.ld := this.ld || resp.ld res.st := this.st || resp.st res.instr := this.instr || resp.instr res.mmio := this.mmio || resp.mmio res.atomic := this.atomic || resp.atomic res } } PMPCheck module连接着PMPReqBundle和PMPRespBundle\nclass PMPCheckIO(lgMaxSize: Int)(implicit p: Parameters) extends PMPBundle { val check_env = Input(new PMPCheckerEnv()) val req = Flipped(Valid(new PMPReqBundle(lgMaxSize))) // usage: assign the valid to fire signal val resp = new PMPRespBundle() def apply(mode: UInt, pmp: Vec[PMPEntry], pma: Vec[PMPEntry], req: Valid[PMPReqBundle]) = { check_env.apply(mode, pmp, pma) this.req := req resp } def req_apply(valid: Bool, addr: UInt): Unit = { this.req.valid := valid this.req.bits.apply(addr) } def apply(mode: UInt, pmp: Vec[PMPEntry], pma: Vec[PMPEntry], valid: Bool, addr: UInt) = { check_env.apply(mode, pmp, pma) req_apply(valid, addr) resp } } // 检验环境， class PMPCheckerEnv(implicit p: Parameters) extends PMPBundle { val mode = UInt(2.W) val pmp = Vec(NumPMP, new PMPEntry()) val pma = Vec(NumPMA, new PMPEntry()) def apply(mode: UInt, pmp: Vec[PMPEntry], pma: Vec[PMPEntry]): Unit = { this.mode := mode this.pmp := pmp this.pma := pma } } class PMPChecker ( lgMaxSize: Int = 3, sameCycle: Boolean = false, leaveHitMux: Boolean = false, pmpUsed: Boolean = true )(implicit p: Parameters) extends PMPModule with PMPCheckMethod with PMACheckMethod { require(!(leaveHitMux \u0026amp;\u0026amp; sameCycle)) val io = IO(new PMPCheckIO(lgMaxSize)) val req = io.req.bits // 这个很重要，应该就是负责查找pmp的，然后返回对应的cfg val res_pmp = pmp_match_res(leaveHitMux, io.req.valid)(req.addr, req.size, io.check_env.pmp, io.check_env.mode, lgMaxSize) val res_pma = pma_match_res(leaveHitMux, io.req.valid)(req.addr, req.size, io.check_env.pma, io.check_env.mode, lgMaxSize) val resp_pmp = pmp_check(req.cmd, res_pmp.cfg) val resp_pma = pma_check(req.cmd, res_pma.cfg) val resp = if (pmpUsed) (resp_pmp | resp_pma) else resp_pma if (sameCycle || leaveHitMux) { io.resp := resp } else { io.resp := RegEnable(resp, io.req.valid) } } 比如在FrontendImp会创建pmp和pmp_check ,\n所以是pmp_check联系了pmp还有其他的组建\nval PortNumber = ICacheParameters().PortNumber val pmp = Module(new PMP()) // 比较神奇的点是这样竟然可以把PMPChecker的端口给复制几遍 val pmp_check = VecInit(Seq.fill(coreParams.ipmpPortNum)(Module(new PMPChecker(3, sameCycle = true)).io)) pmp.io.distribute_csr := csrCtrl.distribute_csr val pmp_req_vec = Wire(Vec(coreParams.ipmpPortNum, Valid(new PMPReqBundle()))) (0 until 2 * PortNumber).foreach(i =\u0026gt; pmp_req_vec(i) \u0026lt;\u0026gt; icache.io.pmp(i).req) pmp_req_vec.last \u0026lt;\u0026gt; ifu.io.pmp.req for (i \u0026lt;- pmp_check.indices) { pmp_check(i).apply(tlbCsr.priv.imode, pmp.io.pmp, pmp.io.pma, pmp_req_vec(i)) } (0 until 2 * PortNumber).foreach(i =\u0026gt; icache.io.pmp(i).resp \u0026lt;\u0026gt; pmp_check(i).resp) ifu.io.pmp.resp \u0026lt;\u0026gt; pmp_check.last.resp // PMPCheckMethod 这个trait应该就是负责去查找对应的地址然后返回pmp的config 的 trait PMPCheckMethod extends PMPConst { // 通过pmp_conf 和 cmd返回对应的权限 def pmp_check(cmd: UInt, cfg: PMPConfig) = { val resp = Wire(new PMPRespBundle) resp.ld := TlbCmd.isRead(cmd) \u0026amp;\u0026amp; !TlbCmd.isAmo(cmd) \u0026amp;\u0026amp; !cfg.r resp.st := (TlbCmd.isWrite(cmd) || TlbCmd.isAmo(cmd)) \u0026amp;\u0026amp; !cfg.w resp.instr := TlbCmd.isExec(cmd) \u0026amp;\u0026amp; !cfg.x resp.mmio := false.B resp.atomic := false.B resp } // 通过req的addr去查找对应的pmp_con f def pmp_match_res(leaveHitMux: Boolean = false, valid: Bool = true.B)( addr: UInt, size: UInt, pmpEntries: Vec[PMPEntry], mode: UInt, lgMaxSize: Int ) = { val num = pmpEntries.size require(num == NumPMP) val passThrough = if (pmpEntries.isEmpty) true.B else (mode \u0026gt; 1.U) val pmpDefault = WireInit(0.U.asTypeOf(new PMPEntry())) pmpDefault.cfg.r := passThrough pmpDefault.cfg.w := passThrough pmpDefault.cfg.x := passThrough val match_vec = Wire(Vec(num+1, Bool())) val cfg_vec = Wire(Vec(num+1, new PMPEntry())) // 把pmpDefault 放在第一个位置，后面跟随着pmpEntries的前num-1个位置 // 所以最终得到的是（pmp,last_pmp)的元组 // .zipWithIndex 会把元素和index一起传入,构成一个元组 pmpEntries.zip(pmpDefault +: pmpEntries.take(num-1)).zipWithIndex.foreach{ case ((pmp, last_pmp), i) =\u0026gt; // 通过mask进行比较 val is_match = pmp.is_match(addr, size, lgMaxSize, last_pmp) val ignore = passThrough \u0026amp;\u0026amp; !pmp.cfg.l val aligned = pmp.aligned(addr, size, lgMaxSize, last_pmp) val cur = WireInit(pmp) cur.cfg.r := aligned \u0026amp;\u0026amp; (pmp.cfg.r || ignore) cur.cfg.w := aligned \u0026amp;\u0026amp; (pmp.cfg.w || ignore) cur.cfg.x := aligned \u0026amp;\u0026amp; (pmp.cfg.x || ignore) // Mux(is_match, cur, prev) match_vec(i) := is_match cfg_vec(i) := cur } // default value match_vec(num) := true.B cfg_vec(num) := pmpDefault // 它应该是返回了一个符合要求的表项 if (leaveHitMux) { ParallelPriorityMux(match_vec.map(RegEnable(_, false.B, valid)), RegEnable(cfg_vec, valid)) } else { ParallelPriorityMux(match_vec, cfg_vec) } } } 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-12T23:49:47+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81%E5%89%96%E6%9E%90pma%E5%92%8Cpmp/","title":"香山源代码剖析——PMA和PMP"},{"content":"// top.scala里包含香山的头文件\n// 有一个XSCore.scala文件\nXSTop和XSCore class XSCore()(implicit p: config.Parameters) extends XSCoreBase with HasXSDts { lazy val module = new XSCoreImp(this) } abstract class XSCoreBase()(implicit p: config.Parameters) extends LazyModule with HasXSParameter { override def shouldBeInlined: Boolean = false // outer facing nodes val frontend = LazyModule(new Frontend()) val csrOut = BundleBridgeSource(Some(() =\u0026gt; new DistributedCSRIO())) val backend = LazyModule(new Backend(backendParams)) val memBlock = LazyModule(new MemBlock) memBlock.frontendBridge.icache_node := frontend.icache.clientNode memBlock.frontendBridge.instr_uncache_node := frontend.instrUncache.clientNode } 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-12T23:26:10+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81%E5%89%96%E6%9E%90%E9%A6%99%E5%B1%B1soc%E7%9A%84%E9%A1%B6%E5%B1%82/","title":"香山源代码剖析——香山SOC的顶层"},{"content":"Diplomacy将模块的Port抽象为节点(Node),然后进行协商，自动找到最优的线宽，以减少复用模块时需要修改的线宽代码\n原理 节点 Source Node :上级输入端口抽象的节点\nNexus Node:当前端口的节点\nSink Node:输出到下一个module的节点\nNode 的成员变量 ：\nin ,输入的端口序列\nout,输出的端口序列\nedges,输入输出参数\n参数 UpwardParam :表示从上层module传输过来的参数\nDownwardParam:表示传输到下层module的参数\nEdgeParam:表示当前module的参数\n参数协商 参数协商必须实现一个抽象接口SimpleNodeImp\nedge函数，完成参数的协商，并输出最终参数线宽\nbundle,输出实际的参数类型和线宽\nrender,输出参数信息，用于查看分析\n参数协商的加法器 为了展示拓扑参数化，实现思路如上图。将加法器的输入抽象成driver模块。实现操作的是adder模块。然后来一个checker模块，看看计算结果是不是正确。\ndriver产生随机数，adder累加，checker看看加的是不是对，输出判断结果。\n其中driver的数目是可参数化的。结点之间传递的参数要经过协商，取小的值。\n参数 case class UpwardParam(width: Int) case class DownwardParam(width: Int) case class EdgeParam(width: Int) 参数协商 object AdderNodeImp extends SimpleNodeImp[DownwardParam, UpwardParam, EdgeParam, UInt] { def edge(pd: DownwardParam, pu: UpwardParam, p: Parameters, sourceInfo: SourceInfo) = { if (pd.width \u0026lt; pu.width) EdgeParam(pd.width) else EdgeParam(pu.width) } def bundle(e: EdgeParam) = UInt(e.width.W) def render(e: EdgeParam) = RenderedEdge(\u0026#34;blue\u0026#34;, s\u0026#34;width = ${e.width}\u0026#34;) 节点 驱动节点 驱动器节点的参数是Seq，因为它输出到加法器和监控器两个节点。\n/** node for [[AdderDriver]] (source) */ class AdderDriverNode(widths: Seq[DownwardParam])(implicit valName: ValName) extends SourceNode(AdderNodeImp)(widths) 监控器节点 Monitor有3个节点，每个节点只有一个输入参数，但是最终SinkNode模块依然要转为Seq类型。\n/** node for [[AdderMonitor]] (sink) */ class AdderMonitorNode(width: UpwardParam)(implicit valName: ValName) extends SinkNode(AdderNodeImp)(Seq(width)) 加法器节点 /** node for [[Adder]] (nexus) */ class AdderNode(dFn: Seq[DownwardParam] =\u0026gt; DownwardParam, uFn: Seq[UpwardParam] =\u0026gt; UpwardParam)(implicit valName: ValName) extends NexusNode(AdderNodeImp)(dFn, uFn) 加法器电路 /** adder DUT (nexus) */ class Adder(implicit p: Parameters) extends LazyModule { val node = new AdderNode ( { case dps: Seq[DownwardParam] =\u0026gt; require(dps.forall(dp =\u0026gt; dp.width == dps.head.width), \u0026#34;inward, downward adder widths must be equivalent\u0026#34;) dps.head }, { case ups: Seq[UpwardParam] =\u0026gt; require(ups.forall(up =\u0026gt; up.width == ups.head.width), \u0026#34;outward, upward adder widths must be equivalent\u0026#34;) ups.head } ) // node元组的第一个元素存放着真实的信号， lazy val module = new LazyModuleImp(this) { require(node.in.size \u0026gt;= 2) node.out.head._1 := node.in.unzip._1.reduce(_ + _) } override lazy val desiredName = \u0026#34;Adder\u0026#34; 驱动器电路 驱动器电路有一个节点，节点有numOutputs个输出，\n/** driver (source) * drives one random number on multiple outputs */ class AdderDriver(width: Int, numOutputs: Int)(implicit p: Parameters) extends LazyModule { val node = new AdderDriverNode(Seq.fill(numOutputs)(DownwardParam(width))) lazy val module = new LazyModuleImp(this) { // check that node parameters converge after negotiation val negotiatedWidths = node.edges.out.map(_.width) require(negotiatedWidths.forall(_ == negotiatedWidths.head), \u0026#34;outputs must all have agreed on same width\u0026#34;) val finalWidth = negotiatedWidths.head // generate random addend (notice the use of the negotiated width) val randomAddend = FibonacciLFSR.maxPeriod(finalWidth) // drive signals node.out.foreach { case (addend, _) =\u0026gt; addend := randomAddend } } override lazy val desiredName = \u0026#34;AdderDriver\u0026#34; 监控器 /** monitor (sink) */ class AdderMonitor(width: Int, numOperands: Int)(implicit p: Parameters) extends LazyModule { val nodeSeq = Seq.fill(numOperands) { new AdderMonitorNode(UpwardParam(width)) } val nodeSum = new AdderMonitorNode(UpwardParam(width)) lazy val module = new LazyModuleImp(this) { val io = IO(new Bundle { val error = Output(Bool()) }) // print operation printf(nodeSeq.map(node =\u0026gt; p\u0026#34;${node.in.head._1}\u0026#34;).reduce(_ + p\u0026#34; + \u0026#34; + _) + p\u0026#34; = ${nodeSum.in.head._1}\u0026#34;) // basic correctness checking io.error := nodeSum.in.head._1 =/= nodeSeq.map(_.in.head._1).reduce(_ + _) } override lazy val desiredName = \u0026#34;AdderMonitor\u0026#34; 顶层module /** top-level connector */ class AdderTestHarness()(implicit p: Parameters) extends LazyModule { val numOperands = 2 val adder = LazyModule(new Adder) // 8 will be the downward-traveling widths from our drivers val drivers = Seq.fill(numOperands) { LazyModule(new AdderDriver(width = 8, numOutputs = 2)) } // 4 will be the upward-traveling width from our monitor val monitor = LazyModule(new AdderMonitor(width = 4, numOperands = numOperands)) // create edges via binding operators between nodes in order to define a complete graph drivers.foreach{ driver =\u0026gt; adder.node := driver.node } drivers.zip(monitor.nodeSeq).foreach { case (driver, monitorNode) =\u0026gt; monitorNode := driver.node } monitor.nodeSum := adder.node lazy val module = new LazyModuleImp(this) { when(monitor.module.io.error) { printf(\u0026#34;something went wrong\u0026#34;) } } override lazy val desiredName = \u0026#34;AdderTestHarness\u0026#34; } 附录 参考文献 chisel开发diplomacy框架\nchisel初体验-高级参数化\nchisel相比verilog的优势——diplomacy\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-10T14:14:12+08:00","permalink":"https://VastCircle.github.io/2025/chisel_diplomacy%E6%A1%86%E6%9E%B6/","title":"Chisel_diplomacy框架"},{"content":"大语言模型加速器\nllm for chip design\n全加操作\n内存利用率\n稀疏\n稀疏度要很高才可以打平这个帐\na55\n协处理器\n共享share的l1\nsmt提供一个核\n希望某一些数据不要被踢走\nDVR\n内存ECC\n可靠性\nARM R系列 汽车芯片\ngoogle 60%的处理器错误无法检测\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-08T15:51:40+08:00","permalink":"https://VastCircle.github.io/2025/%E7%AC%94%E8%AE%B0/","title":"笔记"},{"content":"简介 根据操作的目的和作用，可以把 Link 上的操作分成三大类：\nA 类， A 表示 Access 。凡用来从存储器读写数据的操作都属于 A 类，具体有 Get 、 Put 、 Atomic 等。\nH 类， H 表示 Hint 。用于预示即将访问的存储区域，属于这一类的操作只有 Intent （意图）。\nT 类， T 表示 Transfer ，用来在设备（节点）间迁移缓存数据块或改变其使用权限，具体有 Acquire 和 Release 等。\nacquire(获取)，release(释放)，probe(强制废除)\n操作权限的下降由下方节点对上方节点发出，下降由下方节点对上方节点发出\n从设备是根，主设备要去访问从设备的地址，下面的图实际上主设备没有画出来\nNothing: 当前不缓存数据副本的节点。既没有读权限，也没有写权限。\nTrunk :具有缓存副本的节点，位于 Tip 和 Root 之间的路径上。对副本既没有读权限，也没有写权限。对于提示处发生的写入，该副本可能已过时。\nTip（with no Branches）:具有缓存副本的节点，用作内存访问序列化点。对其副本具有读/写权限，该副本可能包含脏数据。\nTip（with Branches）:具有缓存副本的节点，用作写入序列化点。对其副本具有读取和写入权限，该副本可能包含过去写入的脏数据。\nBranch: 具有位于提示上方的缓存副本的节点。对其副本具有只读权限。\n“TT”代 表 Trunk Tip（最靠近主设备的结点），“T”代 表 Trunk，“B”代表Branch。\n从A-\u0026gt;B,是其中一个主设备发起了请求，此时整条路径会从N-\u0026gt;T,通过A,D通道就能够实现，如果主设备向TT写数据，只要通过A通道发起PutFullData或者PutParitialData就可以了\n此时如果第二个主设备发起访存，就会到c的情况，TT节点变成了B,不能写了，因为此时两个master是同时共享了缓存块，只有分叉点才可读可写，但实际上是无法跨过去的 ，此时 T-\u0026gt;B ,发起权限转变的是交叉点，通过B通道向上发起ProbePerm，如果c要写入的化，那就c-\u0026gt;b,把设备2的路径作废，并且写的设备要下沉到TT才可以（竟然不是需要了再回写），\nRelease只能通过C通道发起\n对于d图，设备3加入，此时设备A放弃了缓存，此时首先要强制TT回写到新的分叉点\nN 无， B可读 ，T可读可写\n代码 abstract class TLBundleBase(params: TLBundleParameters) extends GenericParameterizedBundle(params) // 有确定的sink和source case class TLBundleParameters( addressBits: Int, dataBits: Int, sourceBits: Int, sinkBits: Int, sizeBits: Int, echoFields: Seq[BundleFieldBase], requestFields: Seq[BundleFieldBase], responseFields: Seq[BundleFieldBase], hasBCE: Boolean) { // Chisel has issues with 0-width wires require (addressBits \u0026gt;= 1) require (dataBits \u0026gt;= 8) require (sourceBits \u0026gt;= 1) require (sinkBits \u0026gt;= 1) require (sizeBits \u0026gt;= 1) require (isPow2(dataBits)) echoFields.foreach { f =\u0026gt; require (f.key.isControl, s\u0026#34;${f} is not a legal echo field\u0026#34;) } val addrLoBits = log2Up(dataBits/8) def union(x: TLBundleParameters) = TLBundleParameters( max(addressBits, x.addressBits), max(dataBits, x.dataBits), max(sourceBits, x.sourceBits), max(sinkBits, x.sinkBits), max(sizeBits, x.sizeBits), echoFields = BundleField.union(echoFields ++ x.echoFields), requestFields = BundleField.union(requestFields ++ x.requestFields), responseFields = BundleField.union(responseFields ++ x.responseFields), hasBCE || x.hasBCE) } 在TLBundleBase(和TLBundleParameters)的基础上定义trait TLCannel , 派生出TLDataChannel 和 TLAddrChannel\nsealed trait TLChannel extends TLBundleBase { val channelName: String } sealed trait TLDataChannel extends TLChannel sealed trait TLAddrChannel extends TLDataChannel final class TLBundleA(params: TLBundleParameters) extends TLBundleBase(params) with TLAddrChannel { val channelName = \u0026#34;\u0026#39;A\u0026#39; channel\u0026#34; // fixed fields during multibeat: val opcode = UInt(3.W) val param = UInt(List(TLAtomics.width, TLPermissions.aWidth, TLHints.width).max.W) // amo_opcode || grow perms || hint val size = UInt(params.sizeBits.W) val source = UInt(params.sourceBits.W) // from val address = UInt(params.addressBits.W) // to val user = BundleMap(params.requestFields) val echo = BundleMap(params.echoFields) // variable fields during multibeat: val mask = UInt((params.dataBits/8).W) val data = UInt(params.dataBits.W) val corrupt = Bool() // only applies to *Data messages } // 报文及操作符的定义 object TLMessages { // A B C D E def PutFullData = 0.U // . . =\u0026gt; AccessAck def PutPartialData = 1.U // . . =\u0026gt; AccessAck def ArithmeticData = 2.U // . . =\u0026gt; AccessAckData def LogicalData = 3.U // . . =\u0026gt; AccessAckData def Get = 4.U // . . =\u0026gt; AccessAckData def Hint = 5.U // . . =\u0026gt; HintAck def AcquireBlock = 6.U // . =\u0026gt; Grant[Data] def AcquirePerm = 7.U // . =\u0026gt; Grant[Data] def Probe = 6.U // . =\u0026gt; ProbeAck[Data] def AccessAck = 0.U // . . def AccessAckData = 1.U // . . def HintAck = 2.U // . . def ProbeAck = 4.U // . def ProbeAckData = 5.U // . def Release = 6.U // . =\u0026gt; ReleaseAck def ReleaseData = 7.U // . =\u0026gt; ReleaseAck def Grant = 4.U // . =\u0026gt; GrantAck def GrantData = 5.U // . =\u0026gt; GrantAck def ReleaseAck = 6.U // . def GrantAck = 0.U // . def isA(x: UInt) = x \u0026lt;= AcquirePerm def isB(x: UInt) = x \u0026lt;= Probe def isC(x: UInt) = x \u0026lt;= ReleaseData def isD(x: UInt) = x \u0026lt;= ReleaseAck def adResponse = VecInit(AccessAck, AccessAck, AccessAckData, AccessAckData, AccessAckData, HintAck, Grant, Grant) def bcResponse = VecInit(AccessAck, AccessAck, AccessAckData, AccessAckData, AccessAckData, HintAck, ProbeAck, ProbeAck) def a = Seq( (\u0026#34;PutFullData\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;PutPartialData\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;ArithmeticData\u0026#34;,TLAtomics.ArithMsg), (\u0026#34;LogicalData\u0026#34;,TLAtomics.LogicMsg), (\u0026#34;Get\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;Hint\u0026#34;,TLHints.HintsMsg), (\u0026#34;AcquireBlock\u0026#34;,TLPermissions.PermMsgGrow), (\u0026#34;AcquirePerm\u0026#34;,TLPermissions.PermMsgGrow)) def b = Seq( (\u0026#34;PutFullData\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;PutPartialData\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;ArithmeticData\u0026#34;,TLAtomics.ArithMsg), (\u0026#34;LogicalData\u0026#34;,TLAtomics.LogicMsg), (\u0026#34;Get\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;Hint\u0026#34;,TLHints.HintsMsg), (\u0026#34;Probe\u0026#34;,TLPermissions.PermMsgCap)) def c = Seq( (\u0026#34;AccessAck\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;AccessAckData\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;HintAck\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;Invalid Opcode\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;ProbeAck\u0026#34;,TLPermissions.PermMsgReport), (\u0026#34;ProbeAckData\u0026#34;,TLPermissions.PermMsgReport), (\u0026#34;Release\u0026#34;,TLPermissions.PermMsgReport), (\u0026#34;ReleaseData\u0026#34;,TLPermissions.PermMsgReport)) def d = Seq( (\u0026#34;AccessAck\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;AccessAckData\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;HintAck\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;Invalid Opcode\u0026#34;,TLPermissions.PermMsgReserved), (\u0026#34;Grant\u0026#34;,TLPermissions.PermMsgCap), (\u0026#34;GrantData\u0026#34;,TLPermissions.PermMsgCap), (\u0026#34;ReleaseAck\u0026#34;,TLPermissions.PermMsgReserved)) } object TLPermissions { val aWidth = 2 val bdWidth = 2 val cWidth = 3 // Cap types (Grant = new permissions, Probe = permisions \u0026lt;= target) def toT = 0.U(bdWidth.W) def toB = 1.U(bdWidth.W) def toN = 2.U(bdWidth.W) def isCap(x: UInt) = x \u0026lt;= toN // Grow types (Acquire = permissions \u0026gt;= target) def NtoB = 0.U(aWidth.W) def NtoT = 1.U(aWidth.W) def BtoT = 2.U(aWidth.W) def isGrow(x: UInt) = x \u0026lt;= BtoT // Shrink types (ProbeAck, Release) def TtoB = 0.U(cWidth.W) def TtoN = 1.U(cWidth.W) def BtoN = 2.U(cWidth.W) def isShrink(x: UInt) = x \u0026lt;= BtoN // Report types (ProbeAck, Release) def TtoT = 3.U(cWidth.W) def BtoB = 4.U(cWidth.W) def NtoN = 5.U(cWidth.W) def isReport(x: UInt) = x \u0026lt;= NtoN def PermMsgGrow:Seq[String] = Seq(\u0026#34;Grow NtoB\u0026#34;, \u0026#34;Grow NtoT\u0026#34;, \u0026#34;Grow BtoT\u0026#34;) def PermMsgCap:Seq[String] = Seq(\u0026#34;Cap toT\u0026#34;, \u0026#34;Cap toB\u0026#34;, \u0026#34;Cap toN\u0026#34;) def PermMsgReport:Seq[String] = Seq(\u0026#34;Shrink TtoB\u0026#34;, \u0026#34;Shrink TtoN\u0026#34;, \u0026#34;Shrink BtoN\u0026#34;, \u0026#34;Report TotT\u0026#34;, \u0026#34;Report BtoB\u0026#34;, \u0026#34;Report NtoN\u0026#34;) def PermMsgReserved:Seq[String] = Seq(\u0026#34;Reserved\u0026#34;) } object TLAtomics { val width = 3 // Arithmetic types def MIN = 0.U(width.W) def MAX = 1.U(width.W) def MINU = 2.U(width.W) def MAXU = 3.U(width.W) def ADD = 4.U(width.W) def isArithmetic(x: UInt) = x \u0026lt;= ADD // Logical types def XOR = 0.U(width.W) def OR = 1.U(width.W) def AND = 2.U(width.W) def SWAP = 3.U(width.W) def isLogical(x: UInt) = x \u0026lt;= SWAP def ArithMsg:Seq[String] = Seq(\u0026#34;MIN\u0026#34;, \u0026#34;MAX\u0026#34;, \u0026#34;MINU\u0026#34;, \u0026#34;MAXU\u0026#34;, \u0026#34;ADD\u0026#34;) def LogicMsg:Seq[String] = Seq(\u0026#34;XOR\u0026#34;, \u0026#34;OR\u0026#34;, \u0026#34;AND\u0026#34;, \u0026#34;SWAP\u0026#34;) } object TLHints { val width = 1 def PREFETCH_READ = 0.U(width.W) def PREFETCH_WRITE = 1.U(width.W) def isHints(x: UInt) = x \u0026lt;= PREFETCH_WRITE def HintsMsg:Seq[String] = Seq(\u0026#34;PrefetchRead\u0026#34;, \u0026#34;PrefetchWrite\u0026#34;) } class TLBundle(val params: TLBundleParameters) extends Record { // Emulate a Bundle with elements abcde or ad depending on params.hasBCE // 因为通道不一定存在，所以通过opt先确定通道是否存在，然后在创建 private val optA = Some (Decoupled(new TLBundleA(params))) // Some表示必须要 private val optB = params.hasBCE.option(Flipped(Decoupled(new TLBundleB(params)))) private val optC = params.hasBCE.option(Decoupled(new TLBundleC(params))) private val optD = Some (Flipped(Decoupled(new TLBundleD(params)))) private val optE = params.hasBCE.option(Decoupled(new TLBundleE(params))) def a: DecoupledIO[TLBundleA] = optA.getOrElse(WireDefault(0.U.asTypeOf(Decoupled(new TLBundleA(params))))) def b: DecoupledIO[TLBundleB] = optB.getOrElse(WireDefault(0.U.asTypeOf(Decoupled(new TLBundleB(params))))) def c: DecoupledIO[TLBundleC] = optC.getOrElse(WireDefault(0.U.asTypeOf(Decoupled(new TLBundleC(params))))) def d: DecoupledIO[TLBundleD] = optD.getOrElse(WireDefault(0.U.asTypeOf(Decoupled(new TLBundleD(params))))) def e: DecoupledIO[TLBundleE] = optE.getOrElse(WireDefault(0.U.asTypeOf(Decoupled(new TLBundleE(params))))) override def cloneType: this.type = (new TLBundle(params)).asInstanceOf[this.type] val elements = if (params.hasBCE) ListMap(\u0026#34;e\u0026#34; -\u0026gt; e, \u0026#34;d\u0026#34; -\u0026gt; d, \u0026#34;c\u0026#34; -\u0026gt; c, \u0026#34;b\u0026#34; -\u0026gt; b, \u0026#34;a\u0026#34; -\u0026gt; a) else ListMap(\u0026#34;d\u0026#34; -\u0026gt; d, \u0026#34;a\u0026#34; -\u0026gt; a) def tieoff(): Unit = { DataMirror.specifiedDirectionOf(a.ready) match { case SpecifiedDirection.Input =\u0026gt; a.ready := false.B c.ready := false.B e.ready := false.B b.valid := false.B d.valid := false.B case SpecifiedDirection.Output =\u0026gt; a.valid := false.B c.valid := false.B e.valid := false.B b.ready := false.B d.ready := false.B case _ =\u0026gt; } } } object TLBundleParameters { val emptyBundleParams = TLBundleParameters( addressBits = 1, dataBits = 8, sourceBits = 1, sinkBits = 1, sizeBits = 1, echoFields = Nil, requestFields = Nil, responseFields = Nil, hasBCE = false) def union(x: Seq[TLBundleParameters]) = x.foldLeft(emptyBundleParams)((x,y) =\u0026gt; x.union(y)) def apply(master: TLMasterPortParameters, slave: TLSlavePortParameters) = new TLBundleParameters( addressBits = log2Up(slave.maxAddress + 1), dataBits = slave.beatBytes * 8, sourceBits = log2Up(master.endSourceId), sinkBits = log2Up(slave.endSinkId), sizeBits = log2Up(log2Ceil(max(master.maxTransfer, slave.maxTransfer))+1), echoFields = master.echoFields, requestFields = BundleField.accept(master.requestFields, slave.requestKeys), responseFields = BundleField.accept(slave.responseFields, master.responseKeys), hasBCE = master.anySupportProbe \u0026amp;\u0026amp; slave.anySupportAcquireB) } class TLMasterPortParameters private( val masters: Seq[TLMasterParameters], val channelBytes: TLChannelBeatBytes, val minLatency: Int, val echoFields: Seq[BundleFieldBase], val requestFields: Seq[BundleFieldBase], val responseKeys: Seq[BundleKeyBase]) 这些参数是需要经过一系列的参数协调的，总的TLBundle的生成路径是\n有待创建的 TLBundle 连接 Master 和 Slave 双方， Master 要有一组 TLMasterParameter , Slave 一方则要有一组 TLSlaveParameter\n首先是 Master 和 Slave 双方 TLMasterParameters 和 TLSlaveParamete 的创建。\n在此基础上创建原始的 TLMasterPortParameters 和 TLSlavePortParameters 。\n通过 Diplomacy 在原始 TLMasterPortParameters 和 TLSlavePortParameters 之间进行协调。根据协调后的 TLMasterPortParameters 和 TLSlavePortParameters 创建 TLBundleParameters 。\n根据所创建的 TLBundleParameters 创建 TLBundle 。\ncase class TLEdgeParameters( master: TLMasterPortParameters, slave: TLSlavePortParameters, params: Parameters, sourceInfo: SourceInfo) extends FormatEdge { // legacy names: def manager = slave def client = master val maxTransfer = max(master.maxTransfer, slave.maxTransfer) val maxLgSize = log2Ceil(maxTransfer) // Sanity check the link... require (maxTransfer \u0026gt;= slave.beatBytes, s\u0026#34;Link\u0026#39;s max transfer (${maxTransfer}) \u0026lt; ${slave.slaves.map(_.name)}\u0026#39;s beatBytes (${slave.beatBytes})\u0026#34;) def diplomaticClaimsMasterToSlave = master.anyEmitClaims.intersect(slave.anySupportClaims) val bundle = TLBundleParameters(master, slave) def formatEdge = master.infoString + \u0026#34;\\n\u0026#34; + slave.infoString } class TLEdge( client: TLClientPortParameters, manager: TLManagerPortParameters, params: Parameters, sourceInfo: SourceInfo) extends TLEdgeParameters(client, manager, params, sourceInfo) TLEdge是对于TLEdgeParameters的扩展，TLEdge 类提供了丰富的功能，用于处理 TileLink 协议中消息的各种操作。它包含对不同类型 TLBundle（A、B、C、D、E）消息的处理方法，涵盖了是否携带数据、是否为请求或响应、消息的大小、数据等信息。\nisAligned(address: UInt, lgSize: UInt): Bool：\n检查给定的地址是否与数据传输的大小对齐。 它根据 lgSize 生成一个掩码，并将其与 address 进行比较以确定对齐。 mask(address: UInt, lgSize: UInt): UInt：\n根据 address 和 lgSize 生成一个掩码，该掩码用于 TileLink 通信。它调用 MaskGen 来生成该掩码。 staticHasData(bundle: TLChannel): Option[Boolean]：\n检查特定的 TLBundle（A、B、C、D 或 E）是否静态地携带数据，这取决于 client 或 manager 的能力。 例如，某些类型的 TLBundleA 消息可能包含数据，具体取决于管理器是否支持算术、逻辑操作或特定的读/写操作。 isRequest(x: TLChannel): Bool：\n确定给定的 TLChannel（它可以是 A、B、C、D 或 E 类型的包）是否表示请求消息。 例如，TLBundleA、TLBundleB 和特定的 TLBundleC/D 消息是请求，而 TLBundleE 不是请求。 isResponse(x: TLChannel): Bool：\n与 isRequest 方法相反，检查给定的通道是否表示响应消息。例如，TLBundleD 和 TLBundleE 是响应消息。 hasData(x: TLChannel): Bool：\n检查给定的 TLChannel 是否包含数据。该方法结合了静态检查（通过 staticHasData）和基于消息 opcode 的动态检查。 opcode(x: TLDataChannel): UInt 和 param(x: TLDataChannel): UInt：\n这两个方法分别返回给定 TLDataChannel 的 opcode 和 param 字段。这些字段用于标识事务类型（例如，读、写、获取等）及其相关参数。 size(x: TLDataChannel): UInt 和 data(x: TLDataChannel): UInt：\n这些方法分别获取给定 TLDataChannel 的 size 和 data 字段，这对于确定传输数据的大小和实际数据内容至关重要。 corrupt(x: TLDataChannel): Bool：\n检查给定的 TLDataChannel 是否设置了损坏标志，这表示该事务在传输过程中可能已被损坏。 mask(x: TLAddrChannel): UInt 和 full_mask(x: TLAddrChannel): UInt：\n这些方法返回地址通道的 mask，它在 TileLink 中用于地址的筛选和特定位的过滤。 numBeats(x: TLChannel): UInt：\n该方法计算 TileLink 消息传输所需的节拍数。在 TileLink 协议中，消息的传输是按节拍进行的，方法根据消息大小、数据是否携带以及其他参数来计算所需的节拍数。 TLEdgeOut和TLEdgeIn又是对于TLEdge的补充，包含着报文的具体实现函数\ndef Put(fromSource: UInt, toAddress: UInt, lgSize: UInt, data: UInt, corrupt: Bool): (Bool, TLBundleA) = { require (manager.anySupportPutFull, s\u0026#34;TileLink: No managers visible from this edge support Puts, but one of these clients would try to request one: ${client.clients}\u0026#34;) val legal = manager.supportsPutFullFast(toAddress, lgSize) val a = Wire(new TLBundleA(bundle)) a := DontCare a.opcode := TLMessages.PutFullData a.param := 0.U a.size := lgSize a.source := fromSource a.address := toAddress a.mask := mask(toAddress, lgSize) a.data := data a.corrupt := corrupt (legal, a) } TLBuffer 就是一个队列，用于对数据进行缓冲的\nclass TLBuffer( a: BufferParams, b: BufferParams, c: BufferParams, d: BufferParams, e: BufferParams)(implicit p: Parameters) extends LazyModule { def this(ace: BufferParams, bd: BufferParams)(implicit p: Parameters) = this(ace, bd, ace, bd, ace) def this(abcde: BufferParams)(implicit p: Parameters) = this(abcde, abcde) def this()(implicit p: Parameters) = this(BufferParams.default) val node = new TLBufferNode(a, b, c, d, e) lazy val module = new Impl class Impl extends LazyModuleImp(this) { // node.in 和 node.out都是二元组，（in,edgein) (out,edgeOut) , 分别对应具体输入端口和输入参数 (node.in zip node.out) foreach { case ((in, edgeIn), (out, edgeOut)) =\u0026gt; // 为输入创建一个队列a连接到输出a out.a \u0026lt;\u0026gt; a(in .a) in .d \u0026lt;\u0026gt; d(out.d) if (edgeOut.manager.anySupportAcquireB \u0026amp;\u0026amp; edgeOut.client.anySupportProbe) { // 如果支持TL-C in .b \u0026lt;\u0026gt; b(out.b) out.c \u0026lt;\u0026gt; c(in .c) out.e \u0026lt;\u0026gt; e(in .e) } else { // 说明in是一个slave , out是一个master in.b.valid := false.B in.c.ready := true.B in.e.ready := true.B out.b.ready := true.B out.c.valid := false.B out.e.valid := false.B } } } } case class BufferParams(depth: Int, flow: Boolean, pipe: Boolean) { require (depth \u0026gt;= 0, \u0026#34;Buffer depth must be \u0026gt;= 0\u0026#34;) def isDefined = depth \u0026gt; 0 def latency = if (isDefined \u0026amp;\u0026amp; !flow) 1 else 0 // flow 表示，只要队列为空，数据不进队列，直接可以通过出口出去 // pipe表示每从队列出去一个数据就允许进入一个数据 ，应该主要是如果满了，在deq_ready的当前周期就允许输入数据了 def apply[T \u0026lt;: Data](x: DecoupledIO[T]) = if (isDefined) Queue(x, depth, flow=flow, pipe=pipe) else x def irrevocable[T \u0026lt;: Data](x: ReadyValidIO[T]) = if (isDefined) Queue.irrevocable(x, depth, flow=flow, pipe=pipe) else x def sq[T \u0026lt;: Data](x: DecoupledIO[T]) = if (!isDefined) x else { val sq = Module(new ShiftQueue(x.bits, depth, flow=flow, pipe=pipe)) sq.io.enq \u0026lt;\u0026gt; x sq.io.deq } override def toString() = \u0026#34;BufferParams:%d%s%s\u0026#34;.format(depth, if (flow) \u0026#34;F\u0026#34; else \u0026#34;\u0026#34;, if (pipe) \u0026#34;P\u0026#34; else \u0026#34;\u0026#34;) } // 参数协调 class TLBufferNode ( a: BufferParams, b: BufferParams, c: BufferParams, d: BufferParams, e: BufferParams)(implicit valName: ValName) extends TLAdapterNode( clientFn = { p =\u0026gt; p.v1copy(minLatency = p.minLatency + b.latency + c.latency) }, managerFn = { p =\u0026gt; p.v1copy(minLatency = p.minLatency + a.latency + d.latency) } ) { override lazy val nodedebugstring = s\u0026#34;a:${a.toString}, b:${b.toString}, c:${c.toString}, d:${d.toString}, e:${e.toString}\u0026#34; override def circuitIdentity = List(a,b,c,d,e).forall(_ == BufferParams.none) } object TLBuffer { def apply() (implicit p: Parameters): TLNode = apply(BufferParams.default) def apply(abcde: BufferParams) (implicit p: Parameters): TLNode = apply(abcde, abcde) def apply(ace: BufferParams, bd: BufferParams)(implicit p: Parameters): TLNode = apply(ace, bd, ace, bd, ace) def apply( a: BufferParams, b: BufferParams, c: BufferParams, d: BufferParams, e: BufferParams)(implicit p: Parameters): TLNode = { val buffer = LazyModule(new TLBuffer(a, b, c, d, e)) buffer.node // 返回的是一个node,TLBufferNode } def chain(depth: Int, name: Option[String] = None)(implicit p: Parameters): Seq[TLNode] = { val buffers = Seq.fill(depth) { LazyModule(new TLBuffer()) } name.foreach { n =\u0026gt; buffers.zipWithIndex.foreach { case (b, i) =\u0026gt; b.suggestName(s\u0026#34;${n}_${i}\u0026#34;) } } buffers.map(_.node) } def chainNode(depth: Int, name: Option[String] = None)(implicit p: Parameters): TLNode = { chain(depth, name) .reduceLeftOption(_ :*=* _) .getOrElse(TLNameNode(\u0026#34;no_buffer\u0026#34;)) } } TLXbar class TLXbar(policy: TLArbiter.Policy = TLArbiter.roundRobin)(implicit p: Parameters) extends LazyModule { val node = new TLNexusNode( clientFn = { seq =\u0026gt; seq(0).v1copy( echoFields = BundleField.union(seq.flatMap(_.echoFields)), requestFields = BundleField.union(seq.flatMap(_.requestFields)), responseKeys = seq.flatMap(_.responseKeys).distinct, minLatency = seq.map(_.minLatency).min, clients = (TLXbar.mapInputIds(seq) zip seq) flatMap { case (range, port) =\u0026gt; port.clients map { client =\u0026gt; client.v1copy( sourceId = client.sourceId.shift(range.start) )} } ) }, managerFn = { seq =\u0026gt; val fifoIdFactory = TLXbar.relabeler() seq(0).v1copy( responseFields = BundleField.union(seq.flatMap(_.responseFields)), requestKeys = seq.flatMap(_.requestKeys).distinct, minLatency = seq.map(_.minLatency).min, endSinkId = TLXbar.mapOutputIds(seq).map(_.end).max, managers = seq.flatMap { port =\u0026gt; require (port.beatBytes == seq(0).beatBytes, s\u0026#34;Xbar ($name with parent $parent) data widths don\u0026#39;t match: ${port.managers.map(_.name)} has ${port.beatBytes}B vs ${seq(0).managers.map(_.name)} has ${seq(0).beatBytes}B\u0026#34;) val fifoIdMapper = fifoIdFactory() port.managers map { manager =\u0026gt; manager.v1copy( fifoId = manager.fifoId.map(fifoIdMapper(_)) )} } ) } ){ override def circuitIdentity = outputs.size == 1 \u0026amp;\u0026amp; inputs.size == 1 } lazy val module = new Impl class Impl extends LazyModuleImp(this) { if ((node.in.size * node.out.size) \u0026gt; (8*32)) { println (s\u0026#34;!!! WARNING !!!\u0026#34;) println (s\u0026#34; Your TLXbar ($name with parent $parent) is very large, with ${node.in.size} Masters and ${node.out.size} Slaves.\u0026#34;) println (s\u0026#34;!!! WARNING !!!\u0026#34;) } TLXbar.circuit(policy, node.in, node.out) // 创建了一个TLXbar } } object TLXbar { // def circuit(policy: TLArbiter.Policy, seqIn: Seq[(TLBundle, TLEdge)], seqOut: Seq[(TLBundle, TLEdge)]): Unit = { val seqOut_ACancel = seqOut.map(sOut =\u0026gt; (Wire(new TLBundle_ACancel(sOut._1.params)), sOut._2)) val seqIn_ACancel = seqIn.map(sIn =\u0026gt; (TLBundle_ACancel(sIn._1), sIn._2)) // 调用TLXbar_ACancel.circule来对新生成的对象进行创建 TLXbar_ACancel.circuit(policy, seqIn_ACancel, seqOut_ACancel) // seqOut_Acencel是一个[TLBundle_ACancel,TLEdge]对象 (seqOut.map(_._1) zip seqOut_ACancel.map(_._1)) foreach { case (sOut, sOut_ACancel) =\u0026gt; sOut \u0026lt;\u0026gt; sOut_ACancel.asDecoupled() } } def apply(policy: TLArbiter.Policy = TLArbiter.roundRobin)(implicit p: Parameters): TLNode = { val xbar = LazyModule(new TLXbar(policy)) xbar.node } def mapInputIds (ports: Seq[TLMasterPortParameters]) = assignRanges(ports.map(_.endSourceId)) def mapOutputIds(ports: Seq[TLSlavePortParameters ]) = assignRanges(ports.map(_.endSinkId)) def assignRanges(sizes: Seq[Int]) = { val pow2Sizes = sizes.map { z =\u0026gt; if (z == 0) 0 else 1 \u0026lt;\u0026lt; log2Ceil(z) } val tuples = pow2Sizes.zipWithIndex.sortBy(_._1) // record old index, then sort by increasing size val starts = tuples.scanRight(0)(_._1 + _).tail // suffix-sum of the sizes = the start positions val ranges = (tuples zip starts) map { case ((sz, i), st) =\u0026gt; (if (sz == 0) IdRange(0,0) else IdRange(st, st+sz), i) } ranges.sortBy(_._2).map(_._1) // Restore original order } def relabeler() = { var idFactory = 0 () =\u0026gt; { val fifoMap = scala.collection.mutable.HashMap.empty[Int, Int] (x: Int) =\u0026gt; { if (fifoMap.contains(x)) fifoMap(x) else { val out = idFactory idFactory = idFactory + 1 fifoMap += (x -\u0026gt; out) out } } } } // Replicate an input port to each output port def fanout[T \u0026lt;: TLChannel](input: DecoupledIO[T], select: Seq[Bool], force: Seq[Boolean] = Nil): Seq[DecoupledIO[T]] = { val filtered = Wire(Vec(select.size, chiselTypeOf(input))) for (i \u0026lt;- 0 until select.size) { filtered(i).bits := (if (force.lift(i).getOrElse(false)) IdentityModule(input.bits) else input.bits) filtered(i).valid := input.valid \u0026amp;\u0026amp; (select(i) || (select.size == 1).B) } input.ready := Mux1H(select, filtered.map(_.ready)) filtered } } ReadyValidCancel机制:发送方有两个信号线 earlyValid和lateCancel,发送方在可能有信号发送的时候就发起earlyValid,但是统发发送lateCancel就可以取消报文\n在xbar中， 当有多路输入同时发起信号传输的时候，十字开关的仲裁器就可以选择其中的一路，指向被选中的那一路中继来自输出端的ready信号\n通过Bundle可以扩充ValidCancel\nclass ValidCancel[+T \u0026lt;: Data](gen: T) extends Bundle { val earlyValid = Output(Bool()) val lateCancel = Output(Bool()) val bits = Output(gen) def validQual(): Bool = earlyValid \u0026amp;\u0026amp; !lateCancel /** Down-converts a ValidCancel output to a Valid bundle, dropping early/late timing split. */ def andNotCancel(): Valid[T] = { val out = Wire(new Valid(gen)) out.valid := validQual() out.bits := bits out } } object ValidCancel { /** Wraps some Data with a ValidCancel interface. */ def apply[T \u0026lt;: Data](gen: T): ValidCancel[T] = new ValidCancel(gen) } /** A [[Bundle]] containing \u0026#39;earlyValid\u0026#39;, \u0026#39;lateCancel\u0026#39;, and \u0026#39;ready\u0026#39; signals that handshake * the transfer of data stored in the \u0026#39;bits\u0026#39; subfield. * The base protocol implied by the directionality is that * the producer uses the interface as-is (outputs bits) * while the consumer uses the flipped interface (inputs bits). * @param gen the type of data to be wrapped in Ready/Valid/Cancel */ class ReadyValidCancel[+T \u0026lt;: Data](gen: T) extends ValidCancel(gen) { val ready = Input(Bool()) def mightFire(): Bool = ready \u0026amp;\u0026amp; earlyValid def fire(): Bool = ready \u0026amp;\u0026amp; validQual() /** Down-converts a ReadyValidCancel output to a DecoupledIO bundle, dropping early/late timing split. */ def asDecoupled(): DecoupledIO[T] = { val out = Wire(new DecoupledIO(gen)) out.valid := validQual() out.bits := bits ready := out.ready out } } object ReadyValidCancel { /** Wraps some Data with a ReadyValidCancel interface. */ def apply[T \u0026lt;: Data](gen: T): ReadyValidCancel[T] = new ReadyValidCancel(gen) /** Up-converts a ReadyValid to a ReadyValidCancel, assuming conservative timing. */ def apply[T \u0026lt;: Data](in: ReadyValidIO[T]): ReadyValidCancel[T] = { val out = Wire(new ReadyValidCancel(chiselTypeOf(in.bits))) out.earlyValid := in.valid out.lateCancel := false.B out.bits := in.bits in.ready := out.ready out } } 所以TLBundle_ACancel如下所示\nclass TLBundle_ACancel(val params: TLBundleParameters) extends Record { val a = ReadyValidCancel(new TLBundleA(params)) val b = Flipped(Decoupled(new TLBundleB(params))) val c = Decoupled(new TLBundleC(params)) val d = Flipped(Decoupled(new TLBundleD(params))) val e = Decoupled(new TLBundleE(params)) override def cloneType: this.type = (new TLBundle_ACancel(params)).asInstanceOf[this.type] val elements = ListMap(\u0026#34;e\u0026#34; -\u0026gt; e, \u0026#34;d\u0026#34; -\u0026gt; d, \u0026#34;c\u0026#34; -\u0026gt; c, \u0026#34;b\u0026#34; -\u0026gt; b, \u0026#34;a\u0026#34; -\u0026gt; a) /** Down-converts a TLBundle_ACancel to a plain TLBundle, dropping early/late timing split. */ def asDecoupled(): TLBundle = { val out = Wire(new TLBundle(params)) out.a :\u0026lt;\u0026gt; a.asDecoupled() b :\u0026lt;\u0026gt; out.b out.c :\u0026lt;\u0026gt; c d :\u0026lt;\u0026gt; out.d out.e :\u0026lt;\u0026gt; e out } /** Down-converts a TLBundle_ACancel to a plain TLBundle, dropping early/late timing split. * This differs from [[asDecoupled]]: this is uni-directional, suitable solely for monitoring. */ def monitorAndNotCancel(): TLBundle = { val out = Wire(new TLBundle(params)) out.a.valid := a.validQual() out.a.bits := a.bits out.a.ready := a.ready out.b := b out.c := c out.d := d out.e := e out } } object TLXbar_ACancel { def circuit(policy: TLArbiter.Policy, seqIn: Seq[(TLBundle_ACancel, TLEdge)], seqOut: Seq[(TLBundle_ACancel, TLEdge)]): Unit = { val (io_in, edgesIn) = seqIn.unzip val (io_out, edgesOut) = seqOut.unzip // edgesIn应该包含一些报文 // Not every master need connect to every slave on every channel; determine which connections are necessary // 可以看成两个for循环 val reachableIO = edgesIn.map { cp =\u0026gt; edgesOut.map { mp =\u0026gt; cp.client.clients.exists { c =\u0026gt; mp.manager.managers.exists { m =\u0026gt; c.visibility.exists { ca =\u0026gt; m.address.exists { ma =\u0026gt; ca.overlaps(ma)}}}} }.toVector}.toVector val probeIO = (edgesIn zip reachableIO).map { case (cp, reachableO) =\u0026gt; (edgesOut zip reachableO).map { case (mp, reachable) =\u0026gt; reachable \u0026amp;\u0026amp; cp.client.anySupportProbe \u0026amp;\u0026amp; mp.manager.managers.exists(_.regionType \u0026gt;= RegionType.TRACKED) }.toVector}.toVector val releaseIO = (edgesIn zip reachableIO).map { case (cp, reachableO) =\u0026gt; (edgesOut zip reachableO).map { case (mp, reachable) =\u0026gt; reachable \u0026amp;\u0026amp; cp.client.anySupportProbe \u0026amp;\u0026amp; mp.manager.anySupportAcquireB }.toVector}.toVector val connectAIO = reachableIO val connectBIO = probeIO val connectCIO = releaseIO val connectDIO = reachableIO val connectEIO = releaseIO def transpose[T](x: Seq[Seq[T]]) = if (x.isEmpty) Nil else Vector.tabulate(x(0).size) { i =\u0026gt; Vector.tabulate(x.size) { j =\u0026gt; x(j)(i) } } val connectAOI = transpose(connectAIO) val connectBOI = transpose(connectBIO) val connectCOI = transpose(connectCIO) val connectDOI = transpose(connectDIO) val connectEOI = transpose(connectEIO) // Grab the port ID mapping val inputIdRanges = TLXbar.mapInputIds(edgesIn.map(_.client)) val outputIdRanges = TLXbar.mapOutputIds(edgesOut.map(_.manager)) // We need an intermediate size of bundle with the widest possible identifiers val wide_bundle = TLBundleParameters.union(io_in.map(_.params) ++ io_out.map(_.params)) // Handle size = 1 gracefully (Chisel3 empty range is broken) def trim(id: UInt, size: Int): UInt = if (size \u0026lt;= 1) 0.U else id(log2Ceil(size)-1, 0) // Transform input bundle sources (sinks use global namespace on both sides) val in = Wire(Vec(io_in.size, TLBundle_ACancel(wide_bundle))) for (i \u0026lt;- 0 until in.size) { val r = inputIdRanges(i) if (connectAIO(i).exists(x=\u0026gt;x)) { in(i).a :\u0026lt;\u0026gt; io_in(i).a in(i).a.bits.source := io_in(i).a.bits.source | r.start.U } else { in(i).a.earlyValid := false.B in(i).a.lateCancel := DontCare in(i).a.bits := DontCare io_in(i).a.ready := true.B io_in(i).a.lateCancel := DontCare io_in(i).a.bits := DontCare } if (connectBIO(i).exists(x=\u0026gt;x)) { io_in(i).b :\u0026lt;\u0026gt; in(i).b io_in(i).b.bits.source := trim(in(i).b.bits.source, r.size) } else { in(i).b.ready := true.B in(i).b.bits := DontCare io_in(i).b.valid := false.B io_in(i).b.bits := DontCare } if (connectCIO(i).exists(x=\u0026gt;x)) { in(i).c :\u0026lt;\u0026gt; io_in(i).c in(i).c.bits.source := io_in(i).c.bits.source | r.start.U } else { in(i).c.valid := false.B in(i).c.bits := DontCare io_in(i).c.ready := true.B io_in(i).c.bits := DontCare } if (connectDIO(i).exists(x=\u0026gt;x)) { io_in(i).d :\u0026lt;\u0026gt; in(i).d io_in(i).d.bits.source := trim(in(i).d.bits.source, r.size) } else { in(i).d.ready := true.B in(i).d.bits := DontCare io_in(i).d.valid := false.B io_in(i).d.bits := DontCare } if (connectEIO(i).exists(x=\u0026gt;x)) { in(i).e :\u0026lt;\u0026gt; io_in(i).e } else { in(i).e.valid := false.B in(i).e.bits := DontCare io_in(i).e.ready := true.B io_in(i).e.bits := DontCare } } // Transform output bundle sinks (sources use global namespace on both sides) val out = Wire(Vec(io_out.size, TLBundle_ACancel(wide_bundle))) for (o \u0026lt;- 0 until out.size) { val r = outputIdRanges(o) if (connectAOI(o).exists(x=\u0026gt;x)) { io_out(o).a :\u0026lt;\u0026gt; out(o).a } else { out(o).a.ready := true.B out(o).a.lateCancel := DontCare out(o).a.bits := DontCare io_out(o).a.earlyValid := false.B io_out(o).a.lateCancel := DontCare io_out(o).a.bits := DontCare } if (connectBOI(o).exists(x=\u0026gt;x)) { out(o).b :\u0026lt;\u0026gt; io_out(o).b } else { out(o).b.valid := false.B out(o).b.bits := DontCare io_out(o).b.ready := true.B io_out(o).b.bits := DontCare } if (connectCOI(o).exists(x=\u0026gt;x)) { io_out(o).c :\u0026lt;\u0026gt; out(o).c } else { out(o).c.ready := true.B out(o).c.bits := DontCare io_out(o).c.valid := false.B io_out(o).c.bits := DontCare } if (connectDOI(o).exists(x=\u0026gt;x)) { out(o).d :\u0026lt;\u0026gt; io_out(o).d out(o).d.bits.sink := io_out(o).d.bits.sink | r.start.U } else { out(o).d.valid := false.B out(o).d.bits := DontCare io_out(o).d.ready := true.B io_out(o).d.bits := DontCare } if (connectEOI(o).exists(x=\u0026gt;x)) { io_out(o).e :\u0026lt;\u0026gt; out(o).e io_out(o).e.bits.sink := trim(out(o).e.bits.sink, r.size) } else { out(o).e.ready := true.B out(o).e.bits := DontCare io_out(o).e.valid := false.B io_out(o).e.bits := DontCare } } // Filter a list to only those elements selected def filter[T](data: Seq[T], mask: Seq[Boolean]) = (data zip mask).filter(_._2).map(_._1) // Based on input=\u0026gt;output connectivity, create per-input minimal address decode circuits val requiredAC = (connectAIO ++ connectCIO).distinct val outputPortFns: Map[Vector[Boolean], Seq[UInt =\u0026gt; Bool]] = requiredAC.map { connectO =\u0026gt; val port_addrs = edgesOut.map(_.manager.managers.flatMap(_.address)) val routingMask = AddressDecoder(filter(port_addrs, connectO)) val route_addrs = port_addrs.map(seq =\u0026gt; AddressSet.unify(seq.map(_.widen(~routingMask)).distinct)) // Print the address mapping if (false) { println(\u0026#34;Xbar mapping:\u0026#34;) route_addrs.foreach { p =\u0026gt; print(\u0026#34; \u0026#34;) p.foreach { a =\u0026gt; print(s\u0026#34; ${a}\u0026#34;) } println(\u0026#34;\u0026#34;) } println(\u0026#34;--\u0026#34;) } (connectO, route_addrs.map(seq =\u0026gt; (addr: UInt) =\u0026gt; seq.map(_.contains(addr)).reduce(_ || _))) }.toMap // Print the ID mapping if (false) { println(s\u0026#34;XBar mapping:\u0026#34;) (edgesIn zip inputIdRanges).zipWithIndex.foreach { case ((edge, id), i) =\u0026gt; println(s\u0026#34;\\t$i assigned ${id} for ${edge.client.clients.map(_.name).mkString(\u0026#34;, \u0026#34;)}\u0026#34;) } println(\u0026#34;\u0026#34;) } val addressA = (in zip edgesIn) map { case (i, e) =\u0026gt; e.address(i.a.bits) } val addressC = (in zip edgesIn) map { case (i, e) =\u0026gt; e.address(i.c.bits) } def unique(x: Vector[Boolean]): Bool = (x.filter(x=\u0026gt;x).size \u0026lt;= 1).B val requestAIO = (connectAIO zip addressA) map { case (c, i) =\u0026gt; outputPortFns(c).map { o =\u0026gt; unique(c) || o(i) } } val requestCIO = (connectCIO zip addressC) map { case (c, i) =\u0026gt; outputPortFns(c).map { o =\u0026gt; unique(c) || o(i) } } val requestBOI = out.map { o =\u0026gt; inputIdRanges.map { i =\u0026gt; i.contains(o.b.bits.source) } } val requestDOI = out.map { o =\u0026gt; inputIdRanges.map { i =\u0026gt; i.contains(o.d.bits.source) } } val requestEIO = in.map { i =\u0026gt; outputIdRanges.map { o =\u0026gt; o.contains(i.e.bits.sink) } } val beatsAI = (in zip edgesIn) map { case (i, e) =\u0026gt; e.numBeats1(i.a.bits) } val beatsBO = (out zip edgesOut) map { case (o, e) =\u0026gt; e.numBeats1(o.b.bits) } val beatsCI = (in zip edgesIn) map { case (i, e) =\u0026gt; e.numBeats1(i.c.bits) } val beatsDO = (out zip edgesOut) map { case (o-, e) =\u0026gt; e.numBeats1(o.d.bits) } val beatsEI = (in zip edgesIn) map { case (i, e) =\u0026gt; e.numBeats1(i.e.bits) } // Fanout the input sources to the output sinks val portsAOI = transpose((in zip requestAIO) map { case (i, r) =\u0026gt; TLXbar_ACancel.fanout(i.a, r, edgesOut.map(_.params(ForceFanoutKey).a)) }) val portsBIO = transpose((out zip requestBOI) map { case (o, r) =\u0026gt; TLXbar .fanout(o.b, r, edgesIn .map(_.params(ForceFanoutKey).b)) }) val portsCOI = transpose((in zip requestCIO) map { case (i, r) =\u0026gt; TLXbar .fanout(i.c, r, edgesOut.map(_.params(ForceFanoutKey).c)) }) val portsDIO = transpose((out zip requestDOI) map { case (o, r) =\u0026gt; TLXbar .fanout(o.d, r, edgesIn .map(_.params(ForceFanoutKey).d)) }) val portsEOI = transpose((in zip requestEIO) map { case (i, r) =\u0026gt; TLXbar .fanout(i.e, r, edgesOut.map(_.params(ForceFanoutKey).e)) }) // Arbitrate amongst the sources for (o \u0026lt;- 0 until out.size) { TLArbiter.applyCancel(policy)(out(o).a, filter(beatsAI zip portsAOI(o), connectAOI(o)):_*) TLArbiter (policy)(out(o).c, filter(beatsCI zip portsCOI(o), connectCOI(o)):_*) TLArbiter (policy)(out(o).e, filter(beatsEI zip portsEOI(o), connectEOI(o)):_*) filter(portsAOI(o), connectAOI(o).map(!_)) foreach { r =\u0026gt; r.ready := false.B } filter(portsCOI(o), connectCOI(o).map(!_)) foreach { r =\u0026gt; r.ready := false.B } filter(portsEOI(o), connectEOI(o).map(!_)) foreach { r =\u0026gt; r.ready := false.B } } for (i \u0026lt;- 0 until in.size) { TLArbiter(policy)(in(i).b, filter(beatsBO zip portsBIO(i), connectBIO(i)):_*) TLArbiter(policy)(in(i).d, filter(beatsDO zip portsDIO(i), connectDIO(i)):_*) filter(portsBIO(i), connectBIO(i).map(!_)) foreach { r =\u0026gt; r.ready := false.B } filter(portsDIO(i), connectDIO(i).map(!_)) foreach { r =\u0026gt; r.ready := false.B } } } def apply(policy: TLArbiter.Policy = TLArbiter.roundRobin)(implicit p: Parameters): TLNode_ACancel = { val xbar = LazyModule(new TLXbar_ACancel(policy)) xbar.node } // Replicate an input port to each output port def fanout[T \u0026lt;: TLChannel](input: ReadyValidCancel[T], select: Seq[Bool], force: Seq[Boolean] = Nil): Seq[ReadyValidCancel[T]] = { val filtered = Wire(Vec(select.size, chiselTypeOf(input))) for (i \u0026lt;- 0 until select.size) { filtered(i).bits := (if (force.lift(i).getOrElse(false)) IdentityModule(input.bits) else input.bits) filtered(i).lateCancel := input.lateCancel filtered(i).earlyValid := input.earlyValid \u0026amp;\u0026amp; (select(i) || (select.size == 1).B) } input.ready := Mux1H(select, filtered.map(_.ready)) filtered } } 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-07T23:02:49+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81%E5%89%96%E6%9E%90%E5%AD%98%E5%82%A8%E5%AD%90%E7%B3%BB%E7%BB%9F%E4%B8%8Etilelink/","title":"香山源代码剖析——存储子系统与Tilelink"},{"content":"简述 在Diplomacy的术语中，模块称为“节点”。Diplomacy还把不同模块的按其输入输出抽象成不同类型的节点。 输入端和输出端数量相等的模块抽象成MixedAdapterNode或者AdapterNode,只有输入没有输出的节点抽象为SinkNode.只有输出没有输入的节点抽象为SouceNode\n参数协调与模块创建的拓扑有关系，与信号流通无关 。如果外部module接受参数设计，那与其对接的节点就是sink , 它在系统中是来接受参数的。反之，如果外部的module参数不容改变，那与其对接的module就作为source对内部提供参数。\nDiplomacy定义一种LazyModule,把有参数需要协调的Module包裹在里面，推出Module对象的创建，而先进行参数的协调，参数协调即Diplomacy部分， 1. 说明module有什么参数要协调，在参数协调中扮演主方或者从方，协调的规则是什么 2. 创建module内部的LazyModule子模块。LazyModule只应在另一个LazyModule中创建 3.说明子模块之间需要有参数协调的互相连接 ，即绑定\nDiplomacy框架中定义了一个抽象类BaseNode,然后派生出其他类\nclass Frontend(val icacheParams: ICacheParams, staticIdForMetadataUseOnly: Int)(implicit p: Parameters) extends LazyModule { lazy val module = new FrontendModule(this) val icache = LazyModule(new ICache(icacheParams, staticIdForMetadataUseOnly)) val masterNode = icache.masterNode val slaveNode = icache.slaveNode val resetVectorSinkNode = BundleBridgeSink[UInt](Some(() =\u0026gt; UInt(masterNode.edges.out.head.bundle.addressBits.W))) } 通过Frontend可以得到，在一个LazyModule的定义中Diplomacy部分不一定非要放在lazy val module前面 2. 一个LazyModule中可以有多个参数协调模块，masterNode and slaveNode ,\n大多数的LazyModule中只有一个参数协调结点\nDiplomacy框架\n一、在所创建的每个 LazyModule 模块中｛ 列举本模块在参数协调中扮演的功能/角色节点（通常只有一个）, 包括每个节点的性质、所主张参数、和用于参数协调的规则/算法： 如有需要就创建有参数协调要求的子模块（也是 LazyModule ); 说明所创建子模块之间，或子模块与其它模块之间的绑定/连接（建立\u0026#34;外交关系\u0026#34;); }//这是模块创建的 Diplomacy 阶段 二、等所有模块都已创建，形成了整个系统的结构图以后，再遍历结构图进行全局的参数协调。 并建立模块间的物理连接，这是 Diplomacy 的实施阶段： 三、然后对本模块的硬件描述加以解析，这才是对本模块硬件描述进行解析的阶段 参数的一致化 BaseNode提供例如sinkCard,sourceCard(以本结点为source,sink绑定的结点数)，instantiate()遍历拓扑树进行参数协调\n通过BaseNode可以衍生出InwardNode和OutwardNode,MixwardNode\n附录 参考文献 香山源代码剖析\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-07T20:20:37+08:00","permalink":"https://VastCircle.github.io/2025/%E9%A6%99%E5%B1%B1%E6%BA%90%E4%BB%A3%E7%A0%81%E5%89%96%E6%9E%90-%E5%8F%82%E6%95%B0%E5%8D%8F%E8%B0%83%E4%B8%8Ediplomacy/","title":"香山源代码剖析-参数协调与Diplomacy"},{"content":"安装nvim 安装kitty 终端 curl -L https://sw.kovidgoyal.net/kitty/installer.sh | sh /dev/stdin 安装wezterm 终端 https://wezfurlong.org/wezterm/install/linux.html#pre-built-deb-packages\n下载安装包\n通过\nsudo apt install -y ./wezterm-20240203-110809-5046fc22.Ubuntu22.04.deb 但是出现问题\nwezterm : Depends: libssl1.1 (\u0026gt;= 1.1.1) but it is not installable\n参考以下解决方式\nhttps://askubuntu.com/questions/1403619/mongodb-install-fails-on-ubuntu-22-04-depends-on-libssl1-1-but-it-is-not-insta\nnvim 学习 一些快捷键 s # 调用flash ctrl-d # 向下 ctrl-u # 向上 ctrl-f # 向前 ctrl-b # 向后 ## z模式 zc # 折叠 zo # 展开 zt # z top zz # z zb # z behind ：e path/to/filename # 打开文件 space + f + c # 查找config文件 w # 单词开头 e # 单词结尾 b ## 前一个单词 ge # 上一个单词的末尾 ctrl + o # 回到跳出的地方 ctrl + i # 和 ctrl + o 相反 ## space space ## 大写字母不能匹配小写字母，但是小写字母可以匹配大写字母，大写字母的存在会使得整个匹配区分大小写 ctrl + X # 按照标签选择 space f f# 在root目录查找 space fF # 在cmd（当前目录）查找 :lcd # 更改当前窗口的目录 ## \u0026lt;count\u0026gt;\u0026lt;verb\u0026gt;\u0026lt;motion\u0026gt; \u0026lt;verb\u0026gt;\u0026lt;count\u0026gt;\u0026lt;motion\u0026gt; 5i 123 esp # 可以插入 5次123 ## verb dh # 删除光标左边的字符 d3w 删除3个词 3dw # 删除一个单词3次 d2Ta # 删除光标与第2个a之前的文本 dsfoos c = di # D # 删除整行 C # 删除整行并进入编辑模式 dl # 删除单个字符 r #替换 gU #大写 ～ #反转大小写 . #重复 q #recode qQ #附加 Q #播放最近的record u # 撤销 ctrl + r 重做 ) # 往前移动到一个句子 ( # 移动到句子的开头111111111111111111 { # 向前移动段落 [ ] # 可以做括号的跳转 [ c ]c [f ]f ]m [m #跳转到上一个类和下一个类，函数定义，方法定义 [i ]i #对python有用 ，转到 ag # 整个文件 cag #删除整个文件 yig #复制全部 S #flash.nvim 可以用来快速跳转 cS #确定更改的范围 lazyvim的插件 通过 ：LazyExtras可以打开 lazy ectras ,\n通过在dashboard 点击x也可以\nnvim-metal metal的function\nsbt work\n安装coursier curl -fL \u0026#34;https://github.com/coursier/launchers/raw/master/cs-x86_64-pc-linux.gz\u0026#34; | gzip -d \u0026gt; cs chmod +x cs ./cs setup 附录 参考文献 neovim的一些发行版\nlazyvim\n1000 0000 0000 0000 0010 0001 1100 0000\n1000 0000 0000 0000 0010 0001 1111 1000\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2025-01-04T14:11:15+08:00","permalink":"https://VastCircle.github.io/2025/neovim%E9%85%8D%E7%BD%AE/","title":"Neovim配置"},{"content":"测试程序 以下程序基本能使得在后续的store中能够造成cache miss\nfor (int i = 0 ; i \u0026lt; 128 ; i++) { { // 填8个字节 for (int j = 0 ; j \u0026lt; 8 ; j ++) { Table[(i \u0026lt;\u0026lt; 11) + j] = i + j; } } } // 再读一次, for (int i = 0 ; i \u0026lt; 128 ; i++) { Table[i \u0026lt;\u0026lt; 11] = i; } 波形分析 以地址0x80002140为例\n发送了 acquireblock请求 (opcode=6) ,source = 0,param = 1 ,NtoT,权限升了\n通过d通道来回应相应的block,64Byte opcode = 5 : GrantData param = 0 ,to T\n在访问0x80005140的时候,会把0x80002140踢出去,是cpu先发起请求，然后通过c通道写回，然后再通过a通道读取\n1000 0000 0000 0000 0101 0001 0100 0000\n1000 0000 0000 0000 0010 0001 0100 0000\n通过c通道向l2发送相应的写请求 ,opcode 为7 releasedata\nparam 1 TtoN ,权限降了,这样其它核可以有权限去访问这块内存了\ncpu重发消息了吗?? 会不会是第一次req是l1写入l2,第二次req是l1读取l2，应该不是\n虽然说80005140发送了两次，但是从代码上来看a_bits_address依赖于s2_req_addr,这个 它在第一次store的时候就进行了赋值，所以按理来说即使第二次不发送，也是能够对l2发起read的 ，\n不过为什么会发送两次\n代码 rocket用的是普通的block-cache\ns_voluntary_writeback\nimage-20241228105139496 到底什么时候会release ,就是被踢出去的时候\nimage-20241228145401426 tl_out_c.valid 看下来就是在cached_miss且dirty的时候c_valid会拉高\n// s2_victim_dirty 在出现没有命中的时候会拉高,在出现命中的时候会拉低 val s2_victim_state = Mux(s2_hit_valid, s2_hit_state, Mux1H(s2_victim_way, s2_meta_corrected).coh) val (s2_victim_dirty, s2_shrink_param, voluntaryNewCoh) = s2_victim_state.onCacheControl(M_FLUSH) // cache_miss val s2_want_victimize = (!usingDataScratchpad).B \u0026amp;\u0026amp; (s2_valid_cached_miss || s2_valid_flush_line || s2_valid_data_error || s2_flush_valid) val s2_victimize = s2_want_victimize \u0026amp;\u0026amp; !s2_cannot_victimize when (s2_victimize) { // 状态变换 release_state := Mux(s2_victim_dirty \u0026amp;\u0026amp; !discard_line, s_voluntary_writeback, Mux(!cacheParams.silentDrop.B \u0026amp;\u0026amp; !release_ack_wait \u0026amp;\u0026amp; release_queue_empty \u0026amp;\u0026amp; s2_victim_state.isValid() \u0026amp;\u0026amp; (s2_valid_flush_line || s2_flush_valid || s2_readwrite \u0026amp;\u0026amp; !s2_hit_valid), s_voluntary_release, s_voluntary_write_meta)) } val inWriteback = release_state.isOneOf(s_voluntary_writeback, s_probe_rep_dirty) dataArb.io.in(2).valid := inWriteback \u0026amp;\u0026amp; releaseDataBeat \u0026lt; refillCycles.U dataArb.io.in(2).bits := dataArb.io.in(1).bits val s1_release_data_valid = RegNext(dataArb.io.in(2).fire()) val s2_release_data_valid = RegNext(s1_release_data_valid \u0026amp;\u0026amp; !releaseRejected) tl_out_c.valid := (s2_release_data_valid || (!cacheParams.silentDrop.B \u0026amp;\u0026amp; release_state === s_voluntary_release)) \u0026amp;\u0026amp; !(c_first \u0026amp;\u0026amp; release_ack_wait) image-20241228121846180 t1_out_c.addr and t1_out_c.data //address when (s2_victimize) { probe_bits := addressToProbe(s2_vaddr, Cat(s2_victim_tag, s2_req.addr(tagLSB-1, idxLSB)) \u0026lt;\u0026lt; idxLSB) tl_out_c.bits.address := probe_bits.address } //data val s2_data_decoded = decodeData(s2_data) val s2_data_corrected = (s2_data_decoded.map(_.corrected): Seq[UInt]).asUInt tl_out_c.bits.data := s2_data_corrected t1_out_a.valid // a.valid tl_out_a.valid := !io.cpu.s2_kill \u0026amp;\u0026amp; (s2_valid_uncached_pending || (s2_valid_cached_miss \u0026amp;\u0026amp; !(release_ack_wait \u0026amp;\u0026amp; (s2_req.addr ^ release_ack_addr)(((pgIdxBits + pgLevelBits) min paddrBits) - 1, idxLSB) === 0.U) \u0026amp;\u0026amp; (cacheParams.acquireBeforeRelease.B \u0026amp;\u0026amp; !release_ack_wait \u0026amp;\u0026amp; release_queue_empty || !s2_victim_dirty))) tl_out_a.bits := Mux(!s2_uncached, acquire(s2_vaddr, s2_req.addr, s2_grow_param), Mux(!s2_write, get, Mux(s2_req.cmd === M_PWR, putpartial, Mux(!s2_read, put, atomics)))) (s2_valid_cached_miss \u0026amp;\u0026amp; ! (release_ack_wait \u0026amp;\u0026amp; (s2_req.addr ^ release_ack_addr)(((pgIdxBits + pgLevelBits) min paddrBits) - 1, idxLSB) === 0.U) ## 应该是说不在release\ncacheParams.acquireBeforeRelease.B 一个配置,在release之前发起请求,看样子是false\n!release_ack_wait \u0026amp;\u0026amp; release_queue_empty || !s2_victim_dirty ,脏了是要写回的\na 80033940 1000 0000 0000 0011 0011 1001 01 00 0000\nc 80036940 1000 0000 0000 0011 0110 1001 01 00 0000\na 80037140 1000 0000 0000 0011 0111 0001 01 00 0000\nc 80037940 1000 0000 0000 0011 0111 1001 01 00 0000\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-28T00:38:28+08:00","permalink":"https://VastCircle.github.io/2024/rocketl1l2%E7%9A%84%E4%BA%A4%E4%BA%92/","title":"Rocketl1l2的交互"},{"content":"spike 的cache 为什么会出现 l2 miss的次数高于l1 ,按理来说只有l1 miss才有机会去读l2\nvoid cache_sim_t::access(uint64_t addr, size_t bytes, bool store) { // access次数的统计 store ? write_accesses++ : read_accesses++; (store ? bytes_written : bytes_read) += bytes; // 检查是否命中 uint64_t* hit_way = check_tag(addr); if (likely(hit_way != NULL)) { if (store) *hit_way |= DIRTY; return; } // 未命中 store ? write_misses++ : read_misses++; if (log) { std::cerr \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; (store ? \u0026#34;write\u0026#34; : \u0026#34;read\u0026#34;) \u0026lt;\u0026lt; \u0026#34; miss 0x\u0026#34; \u0026lt;\u0026lt; std::hex \u0026lt;\u0026lt; addr \u0026lt;\u0026lt; std::endl; } // victim 是需要进行替换的tag ,为0说明cache没有满 uint64_t victim = victimize(addr); // dirty \u0026amp;\u0026amp; valid if ((victim \u0026amp; (VALID | DIRTY)) == (VALID | DIRTY)) { // 把替换的block写入l2 uint64_t dirty_addr = (victim \u0026amp; ~(VALID | DIRTY)) \u0026lt;\u0026lt; idx_shift; // 如果有l2的话 if (miss_handler) miss_handler-\u0026gt;access(dirty_addr, linesz, true); writebacks++; } // read if (miss_handler) miss_handler-\u0026gt;access(addr \u0026amp; ~(linesz-1), linesz, false); if (store) *check_tag(addr) |= DIRTY; } // 这种存放的方式应该类似于哈希表,是有键值对的 // idx_shift应该和block的大小有关,即前面几位是一个block uint64_t fa_cache_sim_t::victimize(uint64_t addr) { uint64_t old_tag = 0; if (tags.size() == ways) { auto it = tags.begin(); std::advance(it, lfsr.next() % ways); old_tag = it-\u0026gt;second; tags.erase(it); } tags[addr \u0026gt;\u0026gt; idx_shift] = (addr \u0026gt;\u0026gt; idx_shift) | VALID; return old_tag; } D$ read miss + D$ write miss + I$ write miss = L2 $ read access\nL2 $write access = D$ write miss 中 dirty 的一部分\n附录 参考文献 TLCT-Open-Reports\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-27T17:34:48+08:00","permalink":"https://VastCircle.github.io/2024/spik_cache%E7%9A%84%E4%BA%A4%E4%BA%92/","title":"Spik_cache的交互"},{"content":"vim 安装插件 vim-plug\nhttps://github.com/junegunn/vim-plug\n安装主题\nhttps://github.com/kabbamine/yowish.vim?tab=readme-ov-file\nzsh安装 安装字体\nchipyard 安装 问题 附录 参考文献 wzy123wzy\nwzsh安装\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-25T01:25:07+08:00","permalink":"https://VastCircle.github.io/2024/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/","title":"服务器配置"},{"content":"问题 1.运行firesim runworkload 时报错 image-20241224213818951 该问题未解决\nint fpga_pci_check_file_id(char *,uint 16_t): Assert(temp_id == id) failed 这会导致仿真一开始就停止了\nimage-20241226164901385 从仿真截图上大致能看出问题,因为我本身是使用了81端口,但是现在它在仿真时还是使用21端口,这必然会出错\n修改run_farm_deploy_managers.py可以强制将bus设置为81 ,这样能够解决问题\nimage-20241226173219152 即使加入的withPrintfSynthesis仍然无法打印log 仔细观察firesim infrasetup 发现它所构建的还是没有synthesis printf的软件设施\nimage-20241226222829943 发现是没有设置指定的bitstream ,更改命令为\nfiresim infrasetup \u0026ndash;hwdbconfigfile built-hwdb-entries/alveo_u280_firesim_rocket_singlecore_no_nic即可\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-24T21:35:28+08:00","permalink":"https://VastCircle.github.io/2024/firesim/","title":"chipyard and Firesim"},{"content":"Hardware Performance Monitor the hardware performance monitor includes 29 additional 64-bit event counters,mhpmcounter3-mhpmcounter . The event selector CSRs , mhpmevent3-mhpmevent31, are MXLEN-bit WARL register tghat control which event causes the corresponding counter to increment\nmcycle：保存自过去任意时间以来CPU执行的周期数，是一个64-bit的CSR寄存器，当使用的是32-bit系统时，可以通过mcycle \u0026amp; mcycleh读取完整的64-bit数据。 minstret：记录自过去任意时间以来CPU退出的指令数，是一个64-bit的CSR寄存器，当使用的是32-bit系统时，可以通过minstret \u0026amp; minstreth读取完整的64-bit数据。 mhpmevent3–mhpmevent31：硬件性能监控的事件选择CSR寄存器，是一个32-bit的CSR寄存器。 mhpmcounter3– mhpmcounter31：额外29个事件触发CSR计数器，当选择监控的事件发生时，此计数器会自动加一，指令集中规定是64-bit的CSR寄存器，当使用的是32-bit系统时，可以通过mhpmcounterX \u0026amp; mhpmcounterXh读取完整的64-bit数据。\nrocket-chip 中 的event csr.io.counters foreach { c =\u0026gt; c.inc := RegNext(perfEvents.evaluate(c.eventSel)) } val perfEvents = new EventSets(Seq( new EventSet((mask, hits) =\u0026gt; Mux(wb_xcpt, mask(0), wb_valid \u0026amp;\u0026amp; pipelineIDToWB((mask \u0026amp; hits).orR)), Seq( (\u0026#34;exception\u0026#34;, () =\u0026gt; false.B), (\u0026#34;load\u0026#34;, () =\u0026gt; id_ctrl.mem \u0026amp;\u0026amp; id_ctrl.mem_cmd === M_XRD \u0026amp;\u0026amp; !id_ctrl.fp), (\u0026#34;store\u0026#34;, () =\u0026gt; id_ctrl.mem \u0026amp;\u0026amp; id_ctrl.mem_cmd === M_XWR \u0026amp;\u0026amp; !id_ctrl.fp), (\u0026#34;amo\u0026#34;, () =\u0026gt; usingAtomics.B \u0026amp;\u0026amp; id_ctrl.mem \u0026amp;\u0026amp; (isAMO(id_ctrl.mem_cmd) || id_ctrl.mem_cmd.isOneOf(M_XLR, M_XSC))), (\u0026#34;system\u0026#34;, () =\u0026gt; id_ctrl.csr =/= CSR.N), (\u0026#34;arith\u0026#34;, () =\u0026gt; id_ctrl.wxd \u0026amp;\u0026amp; !(id_ctrl.jal || id_ctrl.jalr || id_ctrl.mem || id_ctrl.fp || id_ctrl.mul || id_ctrl.div || id_ctrl.csr =/= CSR.N)), (\u0026#34;branch\u0026#34;, () =\u0026gt; id_ctrl.branch), (\u0026#34;jal\u0026#34;, () =\u0026gt; id_ctrl.jal), (\u0026#34;jalr\u0026#34;, () =\u0026gt; id_ctrl.jalr)) ++ (if (!usingMulDiv) Seq() else Seq( (\u0026#34;mul\u0026#34;, () =\u0026gt; if (pipelinedMul) id_ctrl.mul else id_ctrl.div \u0026amp;\u0026amp; (id_ctrl.alu_fn \u0026amp; aluFn.FN_DIV) =/= aluFn.FN_DIV), (\u0026#34;div\u0026#34;, () =\u0026gt; if (pipelinedMul) id_ctrl.div else id_ctrl.div \u0026amp;\u0026amp; (id_ctrl.alu_fn \u0026amp; aluFn.FN_DIV) === aluFn.FN_DIV))) ++ (if (!usingFPU) Seq() else Seq( (\u0026#34;fp load\u0026#34;, () =\u0026gt; id_ctrl.fp \u0026amp;\u0026amp; io.fpu.dec.ldst \u0026amp;\u0026amp; io.fpu.dec.wen), (\u0026#34;fp store\u0026#34;, () =\u0026gt; id_ctrl.fp \u0026amp;\u0026amp; io.fpu.dec.ldst \u0026amp;\u0026amp; !io.fpu.dec.wen), (\u0026#34;fp add\u0026#34;, () =\u0026gt; id_ctrl.fp \u0026amp;\u0026amp; io.fpu.dec.fma \u0026amp;\u0026amp; io.fpu.dec.swap23), (\u0026#34;fp mul\u0026#34;, () =\u0026gt; id_ctrl.fp \u0026amp;\u0026amp; io.fpu.dec.fma \u0026amp;\u0026amp; !io.fpu.dec.swap23 \u0026amp;\u0026amp; !io.fpu.dec.ren3), (\u0026#34;fp mul-add\u0026#34;, () =\u0026gt; id_ctrl.fp \u0026amp;\u0026amp; io.fpu.dec.fma \u0026amp;\u0026amp; io.fpu.dec.ren3), (\u0026#34;fp div/sqrt\u0026#34;, () =\u0026gt; id_ctrl.fp \u0026amp;\u0026amp; (io.fpu.dec.div || io.fpu.dec.sqrt)), (\u0026#34;fp other\u0026#34;, () =\u0026gt; id_ctrl.fp \u0026amp;\u0026amp; !(io.fpu.dec.ldst || io.fpu.dec.fma || io.fpu.dec.div || io.fpu.dec.sqrt))))), new EventSet((mask, hits) =\u0026gt; (mask \u0026amp; hits).orR, Seq( (\u0026#34;load-use interlock\u0026#34;, () =\u0026gt; id_ex_hazard \u0026amp;\u0026amp; ex_ctrl.mem || id_mem_hazard \u0026amp;\u0026amp; mem_ctrl.mem || id_wb_hazard \u0026amp;\u0026amp; wb_ctrl.mem), (\u0026#34;long-latency interlock\u0026#34;, () =\u0026gt; id_sboard_hazard), (\u0026#34;csr interlock\u0026#34;, () =\u0026gt; id_ex_hazard \u0026amp;\u0026amp; ex_ctrl.csr =/= CSR.N || id_mem_hazard \u0026amp;\u0026amp; mem_ctrl.csr =/= CSR.N || id_wb_hazard \u0026amp;\u0026amp; wb_ctrl.csr =/= CSR.N), (\u0026#34;I$ blocked\u0026#34;, () =\u0026gt; icache_blocked), (\u0026#34;D$ blocked\u0026#34;, () =\u0026gt; id_ctrl.mem \u0026amp;\u0026amp; dcache_blocked), (\u0026#34;branch misprediction\u0026#34;, () =\u0026gt; take_pc_mem \u0026amp;\u0026amp; mem_direction_misprediction), (\u0026#34;control-flow target misprediction\u0026#34;, () =\u0026gt; take_pc_mem \u0026amp;\u0026amp; mem_misprediction \u0026amp;\u0026amp; mem_cfi \u0026amp;\u0026amp; !mem_direction_misprediction \u0026amp;\u0026amp; !icache_blocked), (\u0026#34;flush\u0026#34;, () =\u0026gt; wb_reg_flush_pipe), (\u0026#34;replay\u0026#34;, () =\u0026gt; replay_wb)) ++ (if (!usingMulDiv) Seq() else Seq( (\u0026#34;mul/div interlock\u0026#34;, () =\u0026gt; id_ex_hazard \u0026amp;\u0026amp; (ex_ctrl.mul || ex_ctrl.div) || id_mem_hazard \u0026amp;\u0026amp; (mem_ctrl.mul || mem_ctrl.div) || id_wb_hazard \u0026amp;\u0026amp; wb_ctrl.div))) ++ (if (!usingFPU) Seq() else Seq( (\u0026#34;fp interlock\u0026#34;, () =\u0026gt; id_ex_hazard \u0026amp;\u0026amp; ex_ctrl.fp || id_mem_hazard \u0026amp;\u0026amp; mem_ctrl.fp || id_wb_hazard \u0026amp;\u0026amp; wb_ctrl.fp || id_ctrl.fp \u0026amp;\u0026amp; id_stall_fpu)))), new EventSet((mask, hits) =\u0026gt; (mask \u0026amp; hits).orR, Seq( (\u0026#34;I$ miss\u0026#34;, () =\u0026gt; io.imem.perf.acquire), (\u0026#34;D$ miss\u0026#34;, () =\u0026gt; io.dmem.perf.acquire), (\u0026#34;D$ release\u0026#34;, () =\u0026gt; io.dmem.perf.release), (\u0026#34;ITLB miss\u0026#34;, () =\u0026gt; io.imem.perf.tlbMiss), (\u0026#34;DTLB miss\u0026#34;, () =\u0026gt; io.dmem.perf.tlbMiss), (\u0026#34;L2 TLB miss\u0026#34;, () =\u0026gt; io.ptw.perf.l2miss))))) 附录 参考文献 Rocket-chip-Hardware-performance-monitor\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-22T15:05:57+08:00","permalink":"https://VastCircle.github.io/2024/rocket_chip_hardware_performance_monitor/","title":"Rocket_chip_hardware_performance_monitor"},{"content":"nas-sys randacc-no static void RandomAccessUpdate(u64Int TableSize, u64Int *Table) { u64Int i; u64Int ran[128]; /* Current random numbers */ int j; // ran[j]保存生成的一些伪随机数 for (j=0; j\u0026lt;128; j++) ran[j] = HPCC_starts ((NUPDATE/128) * j); for (i=0; i\u0026lt;NUPDATE/128; i++) { for (j=0; j\u0026lt;128; j++) { ran[j] = (ran[j] \u0026lt;\u0026lt; 1) ^ ((s64Int) ran[j] \u0026lt; 0 ? POLY : 0); Table[ran[j] \u0026amp; (TableSize-1)] ^= ran[j]; } } } // 伪随机数生成 u64Int HPCC_starts(s64Int n) { int i, j; u64Int m2[64]; u64Int temp, ran; while (n \u0026lt; 0) n += PERIOD; while (n \u0026gt; PERIOD) n -= PERIOD; if (n == 0) return 0x1; temp = 0x1; for (i=0; i\u0026lt;64; i++) { m2[i] = temp; temp = (temp \u0026lt;\u0026lt; 1) ^ ((s64Int) temp \u0026lt; 0 ? POLY : 0); temp = (temp \u0026lt;\u0026lt; 1) ^ ((s64Int) temp \u0026lt; 0 ? POLY : 0); } for (i=62; i\u0026gt;=0; i--) if ((n \u0026gt;\u0026gt; i) \u0026amp; 1) break; ran = 0x2; while (i \u0026gt; 0) { temp = 0; for (j=0; j\u0026lt;64; j++) if ((ran \u0026gt;\u0026gt; j) \u0026amp; 1) temp ^= m2[j]; ran = temp; i -= 1; if ((n \u0026gt;\u0026gt; i) \u0026amp; 1) ran = (ran \u0026lt;\u0026lt; 1) ^ ((s64Int) ran \u0026lt; 0 ? POLY : 0); } return ran; } 随机访存 for (i=0; i\u0026lt;NUPDATE/128; i++) { for (j=0; j\u0026lt;128; j++) { ran[j] = (ran[j] \u0026lt;\u0026lt; 1) ^ ((s64Int) ran[j] \u0026lt; 0 ? POLY : 0); Table[ran[j] \u0026amp; (TableSize-1)] ^= ran[j]; } } load ran[j] store ran[j] store Table\n103b6:\ta85d j\t1046c \u0026lt;RandomAccessUpdate+0x11a\u0026gt; 103b8:\tfe042223 sw\tzero,-28(s0) ## 3ffffffad8 103bc:\ta859 j\t10452 \u0026lt;RandomAccessUpdate+0x100\u0026gt; 103be:\tfe442783 lw\ta5,-28(s0) ## 3ffffffad4 127-0 103c2:\t078e slli\ta5,a5,0x3 103c4:\t17c1 addi\ta5,a5,-16 103c6:\t97a2 add\ta5,a5,s0 ##### 103c8:\tbf07b783 ld\ta5,-1040(a5) 步进 3ffffff6d0 -\u0026gt; 3ffffffac8 step = 8 ran[j] 103cc:\t00179713 slli\ta4,a5,0x1 103d0:\tfe442783 lw\ta5,-28(s0) ## 3ffffffad4 0:7f 103d4:\t078e slli\ta5,a5,0x3 103d6:\t17c1 addi\ta5,a5,-16 103d8:\t97a2 add\ta5,a5,s0 ##### 103da:\tbf07b783 ld\ta5,-1040(a5) 步进 3ffffff6d0 -\u0026gt; 3ffffffac8 step = 8 ran[j] 103de:\t0007d463 bgez\ta5,103e6 \u0026lt;RandomAccessUpdate+0x94\u0026gt; 103e2:\t479d li\ta5,7 103e4:\ta011 j\t103e8 \u0026lt;RandomAccessUpdate+0x96\u0026gt; 103e6:\t4781 li\ta5,0 103e8:\t8f3d xor\ta4,a4,a5 ## (ran[j] \u0026lt;\u0026lt; 1) ^ ((s64Int) ran[j] \u0026lt; 0 ? POLY : 0) 103ea:\tfe442783 lw\ta5,-28(s0) ## 3ffffffad4 0:7f 103ee:\t078e slli\ta5,a5,0x3 103f0:\t17c1 addi\ta5,a5,-16 103f2:\t97a2 add\ta5,a5,s0 ## 103f4:\tbee7b823 sd\ta4,-1040(a5) 步进 3ffffff6d0 -\u0026gt; 3ffffffac8 step = 8 ran[j] = 103f8:\tfe442783 lw\ta5,-28(s0) ## 3ffffffad4 0:7f 103fc:\t078e slli\ta5,a5,0x3 103fe:\t17c1 addi\ta5,a5,-16 10400:\t97a2 add\ta5,a5,s0 ## 10402:\tbf07b703 ld\ta4,-1040(a5) 步进 3ffffff6d0 -\u0026gt; 3ffffffac8 step = 8 ran[j] 10406:\tbd843783 ld\ta5,-1064(s0) ## 3fffff6c8 1040a:\t17fd addi\ta5,a5,-1 1040c:\t8ff9 and\ta5,a5,a4 1040e:\t078e slli\ta5,a5,0x3 10410:\tbd043703 ld\ta4,-1072(s0) ## 3ffffff6c0 10414:\t97ba add\ta5,a5,a4 10416:\t6394 ld\ta3,0(a5) ## random Table[?] 10418:\tfe442783 lw\ta5,-28(s0) ## 3fffffad4 0:7f 1041c:\t078e slli\ta5,a5,0x3 1041e:\t17c1 addi\ta5,a5,-16 10420:\t97a2 add\ta5,a5,s0 ## 10422:\tbf07b703 ld\ta4,-1040(a5) 步进 3ffffff6d0 -\u0026gt; 3ffffffac8 step = 8 ran[j] 10426:\tfe442783 lw\ta5,-28(s0) ## 3ffffffad4 0:7f 1042a:\t078e slli\ta5,a5,0x3 1042c:\t17c1 addi\ta5,a5,-16 1042e:\t97a2 add\ta5,a5,s0 ## 10430:\tbf07b603 ld\ta2,-1040(a5) ## 步进 3ffffff6d0 -\u0026gt; 3ffffffac8 step = 8 ran[j] 10434:\tbd843783 ld\ta5,-1064(s0) ## 3ffffff6c8 不变 10438:\t17fd addi\ta5,a5,-1 1043a:\t8ff1 and\ta5,a5,a2 1043c:\t078e slli\ta5,a5,0x3 1043e:\tbd043603 ld\ta2,-1072(s0) ## 3ffffff6c0 不变 10442:\t97b2 add\ta5,a5,a2 10444:\t8f35 xor\ta4,a4,a3 ## Table[?] ^ ran[j] 10446:\te398 sd\ta4,0(a5) ## Table[?] = 10448:\tfe442783 lw\ta5,-28(s0) ## ## 3fffffad4 0:7f 1044c:\t2785 addiw\ta5,a5,1 1044e:\tfef42223 sw\ta5,-28(s0) ## 3ffffffad4 j : 0-127 10452:\tfe442783 lw\ta5,-28(s0) ## 3ffffffad4 , j : 0:7f 10456:\t0007871b sext.w\ta4,a5 1045a:\t07f00793 li\ta5,127 ## cmp 1045e:\tf6e7d0e3 bge\ta5,a4,103be \u0026lt;RandomAccessUpdate+0x6c\u0026gt; 10462:\tfe843783 ld\ta5,-24(s0) 10466:\t0785 addi\ta5,a5,1 10468:\tfef43423 sd\ta5,-24(s0) 1046c:\tbd843783 ld\ta5,-1064(s0) ## 不变的 , 3ffffff6c8 10470:\t078a slli\ta5,a5,0x2 10472:\t839d srli\ta5,a5,0x7 10474:\tfe843703 ld\ta4,-24(s0) ## 不变的 ,3ffffffad8 ## cmp 10478:\tf4f760e3 bltu\ta4,a5,103b8 \u0026lt;RandomAccessUpdate+0x66\u0026gt; i 0:NUODATE/128 103b6 跳转 -\u0026gt; 1046c 顺序-\u0026gt; 10478 跳转-\u0026gt; 103b8 顺序-\u0026gt; 103bc 跳转-\u0026gt; 10452 顺序-\u0026gt; (1045e 跳转-\u0026gt; 103be 顺序-\u0026gt; 1045e 跳转-\u0026gt;103be) 顺序-\u0026gt;10478 跳转-\u0026gt;103b8\nO2优化 10330:\tfff48593 addi\ta1,s1,-1 10334:\t4501 li\ta0,0 10336:\t870a mv\ta4,sp 10338:\t631c ld\ta5,0(a4) ## stride load 0x3ffffff6e0 : 0x3ffffffad8 step = 8 1033a:\t00179693 slli\ta3,a5,0x1 ## dependent 1033e:\t0007d463 bgez\ta5,10346 \u0026lt;RandomAccessUpdate+0x60\u0026gt; ## dependent 10342:\t0076c693 xori\ta3,a3,7 ## dependent 10346:\t00d5f7b3 and\ta5,a1,a3 ## dependent 1034a:\t078e slli\ta5,a5,0x3 ## dependent 1034c:\t97ce add\ta5,a5,s3 ## dependent 1034e:\t6390 ld\ta2,0(a5) ## dependent load 10350:\te314 sd\ta3,0(a4) 10352:\t0721 addi\ta4,a4,8 10354:\t8eb1 xor\ta3,a3,a2 10356:\te394 sd\ta3,0(a5) 10358:\tfee410e3 bne\ts0,a4,10338 \u0026lt;RandomAccessUpdate+0x52\u0026gt; 1035c:\t0505 addi\ta0,a0,1 1035e:\tfca91ce3 bne\ts2,a0,10336 \u0026lt;RandomAccessUpdate+0x50\u0026gt; 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-19T16:52:19+08:00","permalink":"https://VastCircle.github.io/2024/%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD%E5%88%86%E6%9E%90/","title":"工作负载分析"},{"content":"SIMD技术简介 传统的通用处理器都是标量处理器，一条指令执行只得到一个数据结果。但对于图像、信号处理等应用，存在大量的数据并行性计算操作，这个时候，提高数据的并行性从而提高运算的性能就显得尤为重要。因此，SIMD技术应运而生。\nSIMD的英文全称是Single Instruction Multiple Data，即单指令流多数据技术，SIMD的概念是相对于SISD（Single Instruction Single Data，单指令流单数据）提出的。\n向量计算技术简介 提高数据并行性的另一种方式就是向量计算技术。与传统的SIMD技术一样，其也是通过扩展寄存器位宽，来增加计算的并行度；但不同的是，向量寄存器是可变长度的寄存器，而不像SIMD那样嵌入在操作码中。矢量技术的代表就是RISC-VV扩展指令集和ARM的SVE架构。\n从MMX到SSE , 再到AVX Pentium MMX系列处理器上新引入的MMX指令集开创了x86处理器支持SIMD操作的先河，该指令集定义了8个64-bit宽度的寄存器，每个寄存器的64-bit容量中可以放入八个8-bit长度的整数或四个16-bit长度整数或两个32-bit整数，CPU在识别到MMX指令集的新指令时会自动将寄存器中的数据进行分割计算，这样一来，单个指令就成功操作了多个数据，实现了SIMD\n但MMX毕竟太嫩，它实际上是通过复用CPU内部x87浮点单元的寄存器来实现SIMD的，所以与运行浮点运算的x87指令集有冲突，两者不能交叉使用，必须先进行切换。另外，由于上述的冲突，它只支持整数操作，在即将要到来的3D时代中显得有些不够用。\nSSE指令集解决了MMX指令集身上存在的两大问题，通过引入新的独立寄存器解决了与浮点运算间的冲突问题，同时也就支持了浮点SIMD运算.它的寄存器宽度随着处理器架构的进步而达到了128-bit.\n但Intel准备在未来的Sandy Bridge架构中引入一套新的SIMD指令集，这套新指令集在2008年公布，被命名为高级向量扩展（Advanced Vector Extensions）\n革新的AVX,越来越宽的寄存器 相比起迭代了多年的SSE系列指令集，AVX指令集带来了巨大的革新，其中最为主要的是，它在兼容SSE指令集性的同时，将SSE时代最大宽度为128-bit的寄存器拓宽到了256-bit\n但如果以为Intel会就此停下脚步的话，那就大错特错了，他们很快捣鼓出了更宽的AVX-512指令集，顾名思义，其寄存器宽度再次加倍，来到512-bit。\n宽度越大，处理器的计算能力也就越强，尤其是在浮点运算方面，理论上提升有一倍之多，而实际应用中，如果优化得当，其提升幅度还要大一些。但是，新指令集在带来性能增长的同时也带来了另一个让人感到头痛的问题——功耗。\n举例 // main.cpp #include \u0026lt;iostream\u0026gt; #include \u0026lt;immintrin.h\u0026gt; // 包含 AVX 指令集头文件 void matrix_addition_avx(float* A, float* B, float* C, int size) { for (int i = 0; i \u0026lt; size; i++) { for (int j = 0; j \u0026lt; size; j += 8) { // 每次处理 8 个元素（AVX 可以处理 256 位，即 8 个单精度浮点数） __m256 vecA = _mm256_loadu_ps(\u0026amp;A[i * size + j]); __m256 vecB = _mm256_loadu_ps(\u0026amp;B[i * size + j]); __m256 vecC = _mm256_add_ps(vecA, vecB); _mm256_storeu_ps(\u0026amp;C[i * size + j], vecC); } } } int main() { int size = 8; // 假设矩阵大小为 8x8 float A[64] = { /* ... */ }; // 初始化矩阵 A float B[64] = { /* ... */ }; // 初始化矩阵 B float C[64] = { 0 }; // 结果矩阵 C matrix_addition_avx(A, B, C, size); // 输出结果 for (int i = 0; i \u0026lt; size; i++) { for (int j = 0; j \u0026lt; size; j++) { std::cout \u0026lt;\u0026lt; C[i * size + j] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; } return 0; } _m256 vecA = _mm256_loadu_ps(\u0026amp;A[i * size + j])：从矩阵 A 中加载 8 个浮点数（一次性处理 256 位数据），存储在一个名为 vecA 的 __m256 类型变量中。\n__m256 vecB = _mm256_loadu_ps(\u0026amp;B[i * size + j])：同样地，从矩阵 B 中加载 8 个浮点数，存储在一个名为 vecB 的 __m256 类型变量中。\n__m256 vecC = _mm256_add_ps(vecA, vecB)：使用 AVX 指令 _mm256_add_ps 对 vecA 和 vecB 中的浮点数分别进行逐元素加法，并将结果存储在名为 vecC 的 __m256 类型变量中。\n_mm256_storeu_ps(\u0026amp;C[i * size + j], vecC)：将 vecC 中的 8 个加法结果存储回矩阵 C 的相应位置\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;immintrin.h\u0026gt; // 包含 AVX-512 指令集头文件 void matrix_addition_avx512(float *A, float *B, float *C, int size) { for (int i = 0; i \u0026lt; size; i++) { for (int j = 0; j \u0026lt; size; j += 16) { // 每次处理 16 个元素（AVX-512 可以处理 512 位，即 16 个单精度浮点数） __m512 vecA = _mm512_loadu_ps(\u0026amp;A[i * size + j]); __m512 vecB = _mm512_loadu_ps(\u0026amp;B[i * size + j]); __m512 vecC = _mm512_add_ps(vecA, vecB); _mm512_storeu_ps(\u0026amp;C[i * size + j], vecC); } } } int main() { int size = 16; // 假设矩阵大小为 16x16 float A[256] = { /* ... */ }; // 初始化矩阵 A float B[256] = { /* ... */ }; // 初始化矩阵 B float C[256] = {0}; // 结果矩阵 C matrix_addition_avx512(A, B, C, size); // 输出结果 for (int i = 0; i \u0026lt; size; i++) { for (int j = 0; j \u0026lt; size; j++) { std::cout \u0026lt;\u0026lt; C[i * size + j] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; } return 0; } 附录 参考文献 RISC-V生态全景解析(五):Vector向量计算技术与SIMD技术的对比\nAVX-512\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-18T17:03:41+08:00","permalink":"https://VastCircle.github.io/2024/simd/","title":"SIMD和Vector"},{"content":"摘要 内存墙对许多现代工作负载的性能造成了重大限制。这些应用程序具有复杂的依赖间接内存访问链，即使是最先进的微架构预取器也无法获取。结果是，当前无序超标量处理器的大部分时间都处于停滞状态。但是，为了实现高内存级别的并行性，标准的提前执行会在缓存未命中之前跳过。在现代工作负载中，这意味着它只预取每个依赖链中的第一个缺少缓存的load 。我们认为，这不是一个根本的限制。如果 runahead 是在 cache 未命中时停止以生成依赖链load ，那么如果它可以同时在多个 cache 上停止，则可以重新获得性能。\nintroduction 1.Runahead执行可以预取独立的Load Miss,但无法处理由相关load 未命中链构成的复杂间接访问模式 (间接加载链:一个加载指令的地址依赖于另一个加载指令的结果),Runahead 执行无法解决数据之间的依赖关系，它仅能处理无依赖的独立加载。\n2.Runahead执行仍然要经过正常的流水线前端,受限于处理器前端的Fetch/Decode/Rename宽度,如果未来指令流中存在大量 非 Load 指令（如算术运算、分支指令等），它们会占据前端处理带宽，导致处理器在进入 Runahead 模式后生成新的 Load Miss 的速率非常低。\n3.Runahead执行的推测深度受限于处理器后端的资源 .包括物理寄存器数量,指令队列插槽 .虽然指令的执行结果不会被提交，但它们仍然占用后端资源（如物理寄存器和调度队列）。一旦这些资源耗尽，Runahead 执行就会停止，无法继续生成新的内存请求。\nVector Runahead 延长 Runahead 执行的时间，直到依赖链中的所有加载指令都被发出，而不仅仅停在第一个阻塞的 Load Miss,这使得 Vector Runahead 能够预取整个load 链。\nVector Runahead 通过将标量指令重新解释为矢量运算来矢量化 runahead 指令流，以便在不同的偏移量处生成许多不同的缓存未命中。等效增加了取指/解码带宽,同时需要非常少的后端资源，\nVector Runahead 通过向量展开和流水线发出多轮这些矢量化指令，以更深入地推测并进一步增加有效的提前获取/解码带宽，\nbackground and Motivation B.Limitations of Runahead Techniques 标准的 runahead 执行 [25,32,34,57,58] 检查点，并在 fullwindow stall 后释放应用程序的架构状态，并进入 runahead 模式。然后，处理器继续推测性地生成内存访问。当阻塞内存访问返回时，runahead 间隔终止，此时管道被刷新，架构状态将恢复到 runahead 的入口点，并恢复正常执行。runahead 模式期间生成的 prefetches 将未来数据带入处理器高速缓存，从而减少 normal 模式下即将到来的 stall 数量，从而提高性能。\n（1） PRE 利用可用的后端 （issue queue 和物理 register file） 资源在 runahead 模式下推测性地执行指令，因此在进入和退出 runahead 模式时无需释放和刷新处理器状态。（2） PRE 仅推测性地预执行在全窗口停顿后生成内存访问所需的指令。（3） PRE 包括一种在预试模式下快速回收后端资源的机制。PRE 的性能优势来自于在预跑模式和正常模式之间转换时减少了开销，这使得即使在较短的超速间隔内也能超速运行，并且在超速模式下仅调度load 及其地址生成指令，而不是内存访问的依赖项（只要它们不会导致从属load ），从而减少超速模式期间所需的后端资源量。\nPRE无法预取大部分简介访问.超出超前运行间隔范围的访问很快就会使得核心停止运行\nPRE可以预取A,但是无法预取B,因为B依赖于A,\n硬件跨步预取可以从 A 预取数组元素，从而使 PRE 在超前运行模式下能够从 B 预取数组元素。不幸的是，数据值在超前运行模式下无法预取，因为它们依赖于 B。\nVector Runahead 在超前运行模式期间沿着内存依赖链对内存访问进行矢量化。对 A 的多个访问并行发生，然后是对 B 的并行访问，然后是并行数据值读取。\nC. Vector Runahead Execution for Dependent Loads 如果检测到后续指令依赖于预取指令的话,就无法去执行依赖预取指令的指令,所以PRE无法去执行第一级间接寻址,硬件步幅预取器能够预取对于数组A的跨步访问,所以在后续执行到A指令的时候是缓存命中的,所有可以去预取数组B\n首先，PRE 无法预取依赖load 链上的所有load ，因为链中下一次访问所需的数据不可用\nVector Runahead 更改了 runahead 模式的终止条件，即，一旦阻塞load 未命中从主内存返回，Vector Runahead 就不会返回正常模式，而是继续 runahead 模式**，直到相关load 链上的所有load 都已发出。**\nVector Runahead 在 runahead 模式下对动态指令流进行矢量化，这实际上相当于以更快的速率向前运行。当 vector-runahead 模式启动时，对数组 A 的多次访问被矢量化，即，相同的内存操作被推测性地在多个 induction-variable offset 并行发出。\n我们矢量化与可用矢量宽度一样多的副本，在本例中为 8。依赖于数组 A 中的值的指令也被矢量化，包括对数组 B 和依赖数据值的访问.在 runahead 模式下对 dependent instruction stream 进行矢量化，同时保持 runahead 模式直到发出最后一个 dependent load，从而可以推测性地预取整个 dependent loads 链。\n矢量化 runahead 指令流的效果是，在发出下一批依赖内存访问之前，同时从循环的多个迭代中发出相同的内存操作，依此类推。与原始指令流相比，这种对内存访问的有效重新排序使 Vector Runahead 能够首先对 A 发出一批访问，然后对 B 发出一批访问，最后对依赖数据值发出一批访问。（1） 它大大增加了 runahead 模式下的有效获取/解码带宽，即我们一次获取/解码多个循环迭代，以及 （2） 它需要非常少的后端硬件资源，即 vector-runahead 模式下的向量指令对应于原始代码中来自多个循环迭代的多个标量指令， 同时仅占用一个issue queue槽。\n请注意，Vector Runahead 不要求原始代码是可矢量化的，也不需要验证矢量化指令是否保留了原始序列的确切行为——它只在 runahead 模式下对指令流进行矢量化，通过允许许多缓存未命中一次符合预取条件来提高受 memorylatency 限制的代码的性能。\nVector Runahead stride Detector 用于查找代码中的常规访问模式，这些模式可用作“归纳变量”，以生成代码的推测矢量化副本。. Once we enter vector-runahead mode (Section III-C), instructions dependent on this vectorized stride pattern are tracked by a taint vector (Section III-D), and vectorized themselves (Section III-E): address-calculating arithmetic operations are converted into vector-unit operations, and the dependent loads themselves into vector gathers.假定分支在每个矢量化副本中匹配，掩码用于处理其他情况（第 III-F 节）。为了进一步将内存级并行性提高到比单个向量负载支持的更高水平，我们设计了向量展开和流水线技术（第 III-G 节）来同时发出许多未来的负载。由于这导致旧标量指令和新矢量指令之间存在一对多的关系，因此在前端引入了矢量寄存器分配表 （VRAT） 用于寄存器分配（第 III-H 节），在后端引入了寄存器释放队列 （RDQ）（第 III-I 节）。一旦我们完成了每次展开的迭代，Vector-runahead 模式就终止了（第 III-J 节），其中每次迭代都会执行所有依赖于矢量化步幅负载的载荷。\nDetecting Striding Loads 为了检测代码中的序列，我们可以从中生成归纳变量以矢量化未来的内存访问，我们使用一个简单的参考预测表 [19,62]，该表在每个加载指令执行后更新。它由加载 PC 编制索引，每个条目维护四个字段：（1） 最后访问的内存地址;（2） 最后一次观察到的负载步幅;（3） 一个 2 位饱和计数器，用于指示置信度;（4） 指令链中来自跨步负载的最终从属负载的终止符或v PC。\n由此，一旦我们进入 vector-runahead 模式，我们就可以生成新指令流，以根据跨步加载、计算和其他中间内存访问生成未来的间接内存访问。前 3 个字段 （1） 到 （3） 是参考预测表 [19] 的标准字段。最后一个字段 （ 4） 是新的，在一轮 vector runahead 期间填充，它允许我们在 vector-runahead 模式下完成所有有用的工作后提前终止（第 III-J 节）。\nEntering Vector Runahead 当加载指令阻塞 ROB 头部后，满足以下两个条件之一时，内核进入超前运行模式： **(1) ROB 已充满指令；或 (2) 问题队列已满至其满容量的 80%。**除了为从分支错误预测中恢复而存储的检查点之外，Vector Runahead 通过为前端 RAT 的每个条目存储一个检查点来对 PC 和前端寄存器分配表 (RAT) 设置检查点。这标志着进入超前运行模式。当我们返回正常模式时，处理器状态将恢复到该检查点。\n进入超前运行模式后，处理器继续获取、解码并执行未来的指令。我们访问每个加载指令的步幅检测器。在我们达到跨步负载之前，或者如果不存在这样的跨步负载，Vector Runahead 的执行与 PRE [64] 类似，但不使用其完全关联的停顿切片表，Vector Runahead 消除了这种需要，以避免损害没有此类模式的工作负载，并捕获 Vector Runahead 稍后使用的任何标量依赖关系。同样，这种模式的行为类似于传统的超前执行[57]，只是具有主动寄存器回收和高效的检查点[64]。当我们解码跨步负载（置信度 = 3）时，开始进入向量运行模式。我们对跨步负载进行矢量化，然后是依赖于它的指令序列。当检测到相同跨步负载的另一个动态实例或依赖链完成时，该过程终止（第 III-J 节）。我们将两个动态跨步加载实例之间的依赖指令称为间接链\nTaint Vector 为了跟踪哪些操作（传递地）依赖于指令流中新矢量化的跨步加载，我们使用污点向量（TV）。它为每个架构整数寄存器提供一个条目，并存储两个标志：(1) 写入该寄存器的前一条指令是否是向量化操作（向量化位）； (2) 之前写入该寄存器的指令是否无效（无效位）。 TV 在超前运行开始时是空的，因为每当超前运行终止时它都会被清除。向量化位最初是为发现的跨步负载的目标架构寄存器设置的。无效位最初是根据不支持的操作的目标设置的，例如，那些将浮点操作作为输入的操作（它们总是无效的，因此不需要 TV 条目）。这两个位都是使用矢量污点跟踪来传播的，这是一种在需要时传播矢量化的机制。如果指令的任何输入寄存器被标记，则目标寄存器也会被标记。如果没有标记输入寄存器，则目标寄存器的标志未设置。没有位集的指令作为传统标量先行操作发出，并被视为相对于当前向量先行模式迭代中指令序列的向量化副本的循环不变。具有无效位集的指令将被丢弃，而仅具有向量化位集的指令将被向量化。\nVectorizing Instructions 矢量化是通过微编程例程执行的，该例程生成输入标量指令的矢量化版本。对于跨步加载，矢量化器通过将跨步加载访问的当前内存地址及其步幅作为输入来生成其矢量化版本。矢量化器生成一个 512 位矢量加载指令，并将矢量指令注入到管道中（参见第 III-G 节，了解如何生成多个 512 位矢量指令）。无论输入位宽如何，这个 512 位向量中都适合 8 个标量操作数，因此我们可以对最高 64 位的任何大小进行操作。我们假设每个矢量指令都使用 512 位矢量寄存器（类似于 Intel AVX-512）作为其源和目标，并且我们重用微架构的物理矢量寄存器，以及由微架构的矢量单元实现的微操作。\n同样，我们根据跨步负载（直接或间接）对所有算术和加载指令进行矢量化，并生成相应的 512 位矢量版本。所有矢量化指令都使用矢量寄存器分配表 （VRAT） 重命名（第 III-H 节）。重命名的指令被调度到处理器后端，在那里它们被推测地执行。可能存在依赖于跨步负载的加载指令链，例如，在多级间接依赖负载的情况下（如在指针跟踪代码中）。在这种情况下，形成依赖关系链的所有加载指令都被矢量化为 gather 操作，并且在 runahead 开始时为空，则使用最新依赖 gather 负载的 PC 更新步幅表的终止符（第 III-B 节）。因此，Vector Runahead 可以为多级间接内存访问生成内存级并行性。如果 vector 中的单个通道生成无效的内存访问，则单个通道被标记为无效，这会导致后续矢量化指令中的通道被屏蔽，并忽略其执行。\n在 runahead 模式下执行的指令仅在生成内存访问时有用，并且它们的状态不在 ROB 中维护。因此，在 runahead 模式下不会分配任何 ROB 条目。相反，我们使用更简单的 register deallocation queue [64] （RDQ， Section III-I） 来处理 register 可用性。由于浮点指令很少用于计算地址本身，因此我们忽略了此类指令（将它们标记为无效和任何使用它们的指令 [57]），以及 stores 以及原始代码中已经矢量化的任何指令。\nControl Flow 在矢量化时，我们隐含假设所有矢量通道将遵循彼此相同的控制流模式。然而，当以向量运行模式执行时，当通道遇到分支指令时，通道之间可能会出现分歧。我们使用微操作将标量分支转换为八个向量通道的谓词掩码。由于 Vector Runahead 不需要覆盖所有代码，因此我们仅使用第一个通道的结果来确定分支的方向，并屏蔽掉可能采用不同控制路径的任何通道。这种屏蔽一直持续到我们终止向量运行的单次迭代为止。相比之下，单个向量超前运行间隔内的不同展开迭代（第 III-G 节）可能遵循独立的控制流。\nVector Unrolling and Pipelining 这种基本的 Vector Runahead 存在以下主要缺点，如图 4(a) 所示，假设处理器向量宽度为 four1： (1) 它在执行流中没有向前移动足够远 — 限制了及时性； (2) 没有在超前运行模式上花费足够的时间——限制覆盖范围； (3) 它没有发出足够的同时加载来使未命中状态保持寄存器 (MSHR) 饱和——限制了 MLP。\n为了解决前两个问题，我们在返回正常模式之前发出多轮向量超前运行，这个过程称为向量展开（图 4(b)）。第一轮完成后，我们为跨步序列中识别的下一个 N 个值发出向量负载，其中 N 是向量中的单词数（本例中为 4，对于 AVX-512 为 8）。然后我们重复此操作，递增跨步加载的地址，直到我们发出 U （展开长度）、向量运行序列的副本。如果 N = 8 且 U = 8，我们在离开向量运行模式之前对原始标量循环进行 64 次迭代。\n为什么要访问完value之后再发起新一轮vector runahead 后面的向量流水线就是解决这个问题的\nimage-20250102142145025 我们不是等待上一轮 Vector Runahead 完成后再开始下一轮，而是同时发出每个向量化指令的多个副本，所有副本都具有不同前瞻距离的跨步加载输入，从而在标量和向量之间创建一对多映射指示。\n这使我们能够并行向 A 发出两个向量负载（1 和 2），然后再继续并行发出它们的依赖项（3 和 4），最后是 5 和 6。虽然流水线更好地允许我们提取内存级并行性，但这样做是有限制的，因为我们永远无法为比 MSHR 还要多的同时缓存未命中提供服务。**不同管道组中展开的向量可以重用相同的物理寄存器，因为它们不是同时存在的。**相比之下，矢量流水线故意重叠不同展开迭代的物理寄存器的生命范围，并且还增加了 VRAT 大小（第 III-H 节）。默认情况下，我们假设展开长度 U 和管道深度 P 均为 8，这允许我们同时发出 64 个标量负载的矢量集合。虽然我们在实现中对这些进行了硬编码，但它们可以根据观察进行动态调整\nVector RAT 对于每个标量架构寄存器输入，当设置向量化位时，我们必须重定向新的向量指令到适当的源向量物理寄存器。通常，寄存器分配表（RAT）将架构标量寄存器重命名为物理标量寄存器。然而，我们必须重命名为物理向量寄存器，并且通过添加向量流水线（第 III-G 节），我们在架构标量寄存器和重命名的物理向量寄存器之间具有一对多关系。对于 4 的流水线深度，我们需要将架构标量寄存器重命名为 4 个独立的向量物理寄存器（每个寄存器覆盖 8 个数据元素）。这意味着我们添加一个新的向量寄存器分配表 (VRAT)，每个架构整数寄存器具有 P 个条目，记录分配给指令的 P 个流水线副本的 P 个目标物理向量寄存器。当我们在 VRAT 中查找这些 P 寄存器时，新向量化指令的每个 P 副本都使用 P 条目之一作为其自己的输入。这使我们能够区分向量流水线布置中单独流水线迭代的输入和输出，从指令获取的角度来看，这些迭代都是同一指令的别名。 16 个整数寄存器中的每一个都需要 P 个条目，这些寄存器的大小通常很小。\nManaging Pipeline Resources During Runahead 必须有足够数量的未使用的发出队列和物理（标量和向量）寄存器文件条目，用于推测执行导致间接加载的间接链。在Vector Runahead中，一条向量指令从调度到执行占据一个发出队列条目。执行后，问题队列条目被释放并可以分配给较新的指令，类似于标准的 OoO 内核。与issue queue不同，物理寄存器文件条目不能乱序释放。**在 OoO 内核中，仅当提交新指令写入物理寄存器映射到的同一架构寄存器时，才会释放物理寄存器 [78]。**由于我们不在先行模式下提交指令，因此内核可能会因物理寄存器不可用而停止运行，因此当地址生成不再需要寄存器时，Vector Runahead 会释放该物理寄存器。这是通过一个简单的有序寄存器释放队列（RDQ）来完成的，PRE [64]也使用了这个队列。在 VRAT 中查找每条指令，以查看 P（矢量流水线下）物理矢量寄存器，该寄存器保存最后写入同一架构寄存器的指令的目的地，一旦新指令到达流水线末端，该寄存器就会失效。 P 个向量流水线指令副本，从单个标量指令生成并作为独立向量操作发布，每个副本都有自己的 RDQ 条目，覆盖 P 个即将失效的物理向量寄存器之一。\n图 5 显示了在 RandAcc 基准测试的热循环上运行的 RDQ，假设 P = 2。指令 #1 及其流水线副本 #2 是跨步加载，它们根据跨步检测器加载地址。在进入向量运行模式之前，我们假设S1..3是标量物理寄存器，当前分别存储rdx、rdi和rbp； S4是一个免费的物理标量寄存器； P 1..15 是自由物理向量寄存器。除了 #3 和无效存储之外的所有指令形成两个间接链，导致间接加载 #16 和 #17，因此除了指令 #3 和 store 之外的所有内容都被矢量化。在每条指令旁边，我们显示源和目标物理寄存器 ID 以及 RDQ 的内容，**其中包括要释放的物理寄存器 ID（在安全的情况下）和一个指示指令是否已执行的位。**为每个矢量化指令分配一个 RDQ 条目;没有为无效指令分配 RDQ 条目，例如以深灰色存储 -mark。RDQ 维护一个指向第一个未执行的指令的头指针;在我们的示例中，头指针指向已执行较新指令 #7all 并标记为浅灰色的指令。当指令到达 RDQ 的头部并已执行时，RDQ 会释放指示的物理寄存器并移动头部指针。到目前为止唯一被释放的向量寄存器是 P 1，它被重新用于指令 #17.一旦 #7 执行，寄存器 P 2 和 P 5 将被释放（因为指令 #8 也被执行），头指针将移动到指令 #9。\n它不记录目的寄存器吗\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-17T14:50:55+08:00","permalink":"https://VastCircle.github.io/2024/vector_runahead/","title":"Vector_runahead"},{"content":"摘要 我们提出了解耦矢量预取 （DVR），这是一种内核内预取技术，与主应用程序线程分开执行，它利用大量内存级并行性来提高具有间接内存访问功能的应用程序的性能。DVR 在运行时动态推断循环边界，识别跨步负载，并矢量化作为间接链一部分的后续指令。它会主动为将来的负载发出内存访问，即使无序内核尚未停止，也会将其数据带入 L1 缓存，从而为主线程提供及时的预取。DVR 可以在运行时调整矢量化程度，在内部循环的多次调用中对同一间接内存访问链进行矢量化，并有效地处理沿矢量化链的分支发散。DVR 作为按需、推测性、按顺序、轻量级硬件子线程与内核内的主线程一起运行，并且产生的最小硬件开销仅为 1139 字节。相对于大型超标量 5 宽无序基线和 Vector Runahead（一种用于加速乱序处理器上的间接内存访问的最新微架构技术），DVR 为一组图形分析、数据库和 HPC 工作负载提供了 2.4× 和 2× 的性能。\nintroduction Vector Runahead 不像早期的 runahead 提案那样跳过工作 [29,40,62,66] 来不断发现内存级并行性，而是将在 runahead 模式下执行的瞬态执行重新格式化为主要基于循环级并行性，遵循程序中未来循环迭代中许多不同依赖内存访问链的独立组，并以矢量化方式运行它们以减少前端和后端管道资源需求。\n传统 Runahead 依赖于主线程的停滞条件，当处理器在 ROB（Reorder Buffer） 上停滞时才启动 Runahead 模式。DVR在一个轻量级,有序的子线程上下文中运行runahead进程 ,即使内核没有在完整的ROB上停滞,也允许启动,并允许主线程继续在其预期的计算上取得进展.\n其次，它基于 VR 构建，在推测性提前上下文中的许多未来循环迭代产生的许多动态生成的 “通道” 上实现了 GPU 风格的发散和再收敛。发散：动态生成的通道可以独立执行，允许预取大量潜在的内存请求。再收敛：将这些发散的执行路径重新合并，从而有效组织内存请求，避免资源浪费。\n第三，它在主计算的线程中执行发现模式，以精确预测将访问多少个未来的循环，以限制不准确的预取。当 DVR 发现 单个发现模式（仅外部循环）不足以覆盖足够的未来循环时，它进一步深入内部循环,然后可以有效地将所有这些输入矢量化在一起，以实现极端的内存级并行性.\nDVR 技术可以大幅提前预取那些会导致缓存未命中的 load 指令,避免它们在 ROB 中长时间占据资源\nDVR 意味着 runahead 不再是乱序处理器的超大指令窗口的替代品\nbackground 间接内存访问 (Indirect Memory Accesses) 数组A[i]是顺序访问的.但是,访问数组 B 的索引是通过对 A 的特定索引处的值进行哈希处理来计算的，而数组 C 的索引是通过对 B 的访问进行哈希处理来计算的。也就是说，对 C 的访问依赖于对 B 的访问，而对 B 的访问又依赖于对 A 的访问。对 B 和 C 的访问分别称为间接内存访问的第一级和第二级，数组 A 的访问和对数组 C 的访问之间的指令链称为间接链.\n当访问需要多级间接寻址时，Runahead 的执行将因为前一级 Load 未完成而停滞，无法预取后续地址。对于图 1 中的示例，根据工作跳过技术，数组 C 的输入将无效，或者无法在提前终止之前返回.\n受到处理器前端宽度和runahead 间隔的限制。\nVector runahead 自动生成不同索引,在遇到间接链开始的跨步 load 时，VR 会自动推测出多个不同偏移量的索引地址。这些地址会被解析并产生多个新的指令，模拟未来循环迭代中的不同访问位置。\n将不同索引处的指令进行重排序，并同时发送多个 load 指令到内存系统。当处理器遇到 load 指令链时，不是按顺序执行一个接一个的加载，而是并行等待多个加载返回。\n向量化标量指令以节约后端资源,将多个重排序的标量指令分组为向量指令。向量化使得多个 load 或计算操作可以同时发出，并通过一个向量操作完成。\n延迟终止,生成完整的内存访问链.继续运行 Runahead 模式，直到生成完整的间接内存访问链。通过这种延迟终止，VR 能够覆盖更多的内存加载并提高预取的覆盖范围。\nMotivation Vector Runahead 的劣势 ROB增大时性能提升减少 ,ROB的大小一直在增加,需要跟多周期才能填充,进入runahead模式的机会随着ROB大小的增大而减少 .因此为了能够最大限度的利用预取机会,\nVR不能等待full-ROB stall .\n在**矢量超前执行（Vector Runahead, VR）**中，超前执行模式的终止是基于将整个间接内存访问链中的所有加载指令进行矢量化并生成预取。这意味着，尽管原本导致重排序缓冲区（ROB）填满的加载指令可能已经从内存中返回，但 VR 依然保持超前执行状态，直到处理完所有相关的加载指令。\n无法适应运行时特征。Vector Runahead 尝试为每个标量负载生成尽可能多的收集。**目标是通过保持所有未命中状态保持寄存器 （MSHR） 被未完成的内存访问占用来实现高内存级并行性。**对于类似于广度优先搜索,循环长度与图的大小和结构相关,这意味着Vector Runahead 会预取大量数据，而这些数据在真实执行中永远不会被访问.\n​ VR 需要 （i） 了解它运行的每个循环的数据依赖性的动态迭代次数，以避免获取无用的数据，以及 （ii） 每次运行时更新它以响应最新的运行时值\n无法矢量化同个循环的多个调用.希望不仅从循环内部运行许多加载，而且同时从不同的外部循环运行许多不同版本的内循环。 如果动态确定单个循环太小而无法使内存系统饱和，VR 需要提前查看同一循环的许多未来迭代，方法是向前跳以发现来自将在不久的将来执行的不同外部循环迭代的相同代码的输入。\n在 Vector Runahead (VR) 执行中，控制流分歧（Control-Flow Divergence）是一个挑战. 一旦在矢量化指令集中发生控制流分歧，VR 将失去对所有分支路径的跟踪，无法继续执行预取操作. 就是if 的存在会使得直接跳出循环,使得后续的预取全部失效. GPU的单指令多线程(SIMT)模型,支持分支重合和分支分歧\n分支分歧：当某个矢量化通道在执行过程中遇到控制流分歧时，VR 可以允许每个通道独立地执行不同的路径，就像在 GPU 中，线程可以在遇到分支时分别执行不同的路径。\n分支重合：在分支结束后，VR 可以重新将所有矢量化通道合并到一个统一的控制流中，避免各个通道分支的不同执行路径对整体性能的影响。\nDVR微架构 跨步检测器(stride detector)从管道的调度和执行(dispatch and execute)阶段获取有关负载的信息。一旦检测到跨步，DVR 就会进入发现模式(Discovery Mode)，该模式使用污点跟踪器和循环绑定检测器(Taint Tracker and Loop-Bound Detector)来发现后续运行的信息。如果发现模式发现循环中需要向量化的元素太少，则将使用嵌套发现模式(Nested Discovery Mode)逻辑。一旦发现模式完成，向量程序计数器 vector program counter (PCv) 将填充跨步加载的 PC，VRAT 将填充跨步加载地址和主线程标量寄存器的副本，以及解耦的向量运行子线程将启动。再收敛堆栈(Reconvergence Stack)将在矢量通道之间的控制流出现分歧时进行处理。\nDVR 通过引入一个与主线程并行执行的专用子线程，来预取未来的内存访问，从而在不干扰主线程执行的情况下提高性能。\n核发现它正在执行具有相关负载的循环时，基于可用于预测未来循环迭代的跨步负载，将在与当前正在执行的主线程相同的内核上激活专用的 vector-runahead 子线程。此子线程是动态生成的，用于将许多内存访问预取到将来，但不会影响主线程的语义。vector-runahead 子线程在同一内核上与主线程一起运行，很像线程在同步多线程 （SMT） [91] 中协同执行的方式，不同之处在于子线程是微架构生成的、瞬态的（预取到缓存中而不是实现实际计算）、推测性的、重新排序以实现极高的内存级并行性，并且明显更简单，即子线程按顺序执行。\n为了从这个按顺序向量运行子线程实现高内存级并行性，即使遵循使子线程停顿的依赖负载链，我们使用单指令多线程 （SIMT） 数据级并行性 [54]，从前端执行大量每条指令，每条指令同时代表不同的循环迭代，从而预取到很远的未来。由于这种情况是连续发生的，并且与主线程的执行重叠，因此大多数主乱序线程的内存访问在到达 L1 时都会命中 - 因此，即使对于具有巨大窗口的超大型处理器，也可以实现显著的加速。\n4.1 Discovery Mode 系统需要识别一个合适的诱导变量加载（induction-variable load），以便从中派生出多个未来循环的副本.这个过程首先通过检测一个步幅加载来开始，步幅加载是指访问内存时采用规律的地址序列（即具有可预测步幅的加载）。Discovery Mode的目的（i） 检查跨步负载是否是最适合 DVR 的候选者，通过成为最内层的跨步负载，（ii） 派生循环边界，以确定要生成多少个推测性向量预取，以及 （iii） 发现是否有任何基于跨步负载的依赖负载可以由 vector-runahead 子线程适当地预取。Discovery Mode 通过循环的一次迭代跟踪主线程的执行，直到它再次达到跨步加载，此时它退出 Discovery Mode。\n4.1.1 最内层步幅加载检测 一旦检测到初始的步幅加载并进入发现模式（Discovery Mode），系统会继续跟踪主线程的执行，检测其他可能更适合启动向量超前执行的步幅加载。特别是，系统可能会发现某个步幅加载属于一个更内层的循环，且如果在向量超前执行模式下预取它们的未来迭代，这些加载将更加及时。因此，步幅加载检测的目标是识别最合适的内层循环加载。(对于内层循环,确实会更快的进入steady状态)\n步幅加载检测流程： 使用参考预测表（RPT）： 步幅加载检测是通过使用**参考预测表（RPT）**来完成的。RPT跟踪所有步幅加载及其对应的步幅。RPT中保存了每个步幅加载的位图（bit-map），每个条目对应一个加载，且每个条目中有一位用于表示该步幅加载的状态。 检测新步幅加载： 系统会保持一个寄存器，初始值为零，并且每个RPT条目都有一个对应的位。当一个步幅加载被检测到时，它会将对应的位设置为1。如果在发现模式中，在当前目标步幅加载之前，已经见过相同的步幅加载地址（程序计数器PC），并且对应位已经被设置为1，则表示这个新步幅加载属于一个更内层的循环。 切换到更内层步幅加载： 当检测到新的步幅加载属于更内层循环时，系统会切换到该步幅加载上继续执行发现模式。这时需要重置之前的寄存器和其他相关的状态信息，如VTT（向量目标表）和FLR（加载结果队列），以确保新的步幅加载被正确处理。 选择触发步幅： 系统可以在同一个循环中向量化多个步幅加载（例如，因循环展开导致的多个步幅加载）。在这种情况下，系统会选择一个步幅加载作为向量化的触发器，通常优先选择最内层的步幅加载，因为它会更频繁且更及时地被执行。 补充(RPT) correct : addr = prev_addr + stride , incorrect : addr != prev_addr + stride\nA.1.没有对应的条目。指令输入到RPT中，prev addr字段设置为addr，stride设置为0，state设置为initial\nA.2.有相应的条目。然后：\nWhen incorrect and state = initial , Set prev_addr to addr , stride to (addr - prev_addr) ,and state to transient\nwhen correct and (state = initial ,transient , or steady), set prev_addr to addr , leave stride unchanged ,and set state to steady\nwhen incorrect and state = steady: set prev_addr to addr , leave stride unchanged , and set state to initial\nwhen incorrect and state = transient , set prev_addr to addr , stride to addr - prev_addr and state = no prediction\nwhen correct and state = no prediction , set prev_addr to addr , leave stride unchange , and set state to transient\nwhen incorrect and state = no prediction : set prev_addr to addr , stride to addr - prv_addr , and leave state unchanged\n和分支预测类似, 在 steady 状态时,两次连续的错误才会修改 stride\n在initial , transient , 和 steady状态如果miss会去启动预取\n4.1.2 依赖加载检查（Dependent-Load Checking） 为了使向量超前执行（DVR）触发有意义，它必须带来比简单的步幅预取器更有用的数据到缓存中。我们假设系统中总会有一个步幅预取器，并且始终保持启用（即使向量超前执行并未触发）。这意味着，必须有更多依赖于通过步幅检测器识别出的值的加载操作，才有必要启动向量超前执行。\n为此，我们使用一个小型的向量污染跟踪器（Vector Taint Tracker，VTT），它为每个架构整数寄存器分配一个比特位，以标识将来会被向量化的指令。\n初始化VTT： 在进入发现模式（Discovery Mode）时，VTT被初始化为全零，除了触发步幅加载的目标架构寄存器，该寄存器的位被设置为1。也就是说，我们将初始步幅加载指令的目标寄存器的污染位设置为1，表示该寄存器将在未来的指令中被使用并可能被向量化。\n污染传播： 在发现模式中，污染通过指令进行传播。具体来说，如果某条指令的源寄存器已经被污染（VTT中的比特位为1），那么该指令的目标寄存器的污染位会被设置为1。这样，后续的指令就知道它们依赖于先前的污染寄存器。\n重置污染位： 如果某条指令写入的寄存器的污染位已经设置为1，但它的源寄存器并未被污染，那么该目标寄存器的污染位会被重置为0。这是因为该指令并没有依赖于污染寄存器的内容，所以它不需要向量化。\n最终加载寄存器（FLR）： 每当某个加载指令的输入被污染时，最终加载寄存器（Final-Load Register，FLR）会更新为该加载指令的程序计数器（PC）。FLR用于跟踪从触发步幅加载开始的依赖链中最后一个加载指令的PC。\n4.1.3 循环边界推断(Loop-Bound Inference) 它决定了在 Discovery Mode 阶段，应该为当前内循环执行多少次预测性的向量预取（speculative vector prefetches）。\n检测循环开始：\n在 Discovery Mode 中，首先会检测到一个向后跳转的分支（backward branch），这个分支指示一个循环的开始。 通过该分支的比较指令（compare instruction）来确定循环的边界（loop bound）。具体而言，这个比较指令提供了控制流是否应继续执行的依据，并且它的操作数会帮助推断循环的边界。 重要数据结构：\nLCR (Last-Compare Register)：用于保存上一个比较指令的源和目标寄存器的 ID。 SBB (Seen-Branch Bit)：这个标志位用于记录是否已经处理过这个分支。每次更新 Final-Load Register (FLR) 时，LCR 和 SBB 都会被清零。 检查比较指令与分支：\n当发现一个比较指令并且 SBB 为零时，会将比较指令的源和目标寄存器的 ID 存入 LCR。 如果后续遇到一个分支，且该分支的源寄存器与 LCR 中保存的目标寄存器相匹配，并且该分支跳转的目标地址小于或等于 striding load 的程序计数器（PC），则表示当前分支属于该循环，更新 SBB，以指示不再修改 LCR，直到发现新的最终加载指令。 循环边界推断：\n通过进入 Discovery Mode 和离开 Discovery Mode 时的两个检查点，我们可以查看寄存器文件的状态。\n比较指令的输入寄存器的映射关系：\n如果其中一个寄存器在 Discovery Mode期间保持不变，而另一个发生了变化，我们就可以推断出：\n常量值（不变寄存器的值）作为循环的边界（loop bound）。 变化值的差异（变化寄存器的值）作为循环的增量（loop increment）。\n通过这些信息，我们可以准确推测出循环的剩余迭代次数。\n失败的情况：\n如果在 Discovery Mode 中无法找到合适的匹配（即没有找到合适的比较指令或者无法推断出循环的边界），则默认为执行 128 次迭代，这是 DVR 的最大迭代次数。 4.2 Vector-Runahead Subthread Operation 一旦发现模式识别出跨步负载、其跨步、其依赖链以及内部循环的剩余迭代，一旦主线程再次达到候选跨步负载，就会生成向量运行超前子线程。子线程从跨步加载开始，到存储在 FLR 中的 PC 结束，其目标是推测性地预取大量（在我们的设置中最多 128 个）矢量化副本。特别是，矢量化器通过使用其步幅生成的矢量化副本来替换步幅负载。未来指令流中依赖于跨步负载的任何指令也会被矢量化。\n对于下面这一段程序,Vector Runahead thread 应该是从lw r4,0(r2)到 lw r7,0(r1)\n子线程使用与主线程相同的获取、解码和执行单元。子线程指令是从前端缓冲区生成的，前端缓冲区通过保存解码的微操作（在我们的设置中为八个）将提取阶段与管道的其余部分解耦。虽然子线程指令使用相同的执行单元，但它们使用不同的向量发出寄存器（VIR）——而不是乱序指令队列，因为它是有序的——来处理向量指令副本的执行。每当主线程没有为同一执行端口准备好指令时，就会发出向量运行子线程的发出寄存器中的指令。\n4.2.1 Vector Register Allocation Table VRAT（向量寄存器分配表）用于管理子线程（Vector Runahead Subthread）的标量架构寄存器到物理寄存器的映射关系。即使子线程是有序的，我们仍然需要重命名它的架构寄存器，因为它与主线程共享物理标量和向量寄存器文件.标量架构寄存器可以重命名为 （i） 所有矢量通道中的相同标量物理寄存器，如果架构寄存器未矢量化且通道之间没有控制流发散，或 （ii） 多个矢量物理寄存器，其中架构寄存器已矢量化或存在控制流发散。\n为了初始化 VRAT，主线程中的所有架构寄存器都分配了一个新的物理标量寄存器，以将子线程与其主线程解耦,当跨步负载被发送到 VIR 时，我们分配 16 个向量（例如 AVX-512）物理寄存器来映射负载的目标架构寄存器。与乱序处理器不同，物理寄存器不会随每条新指令重新映射，因为重命名不会试图删除 WAW 或 WAR 依赖项，即子线程按程序顺序执行。\n物理寄存器被覆盖后(指的是它的值被后续的指令取代了)，将返回到空闲列表。被覆盖的寄存器会立即释放，前提是它们不用作发射指令的源寄存器,and tracked in the Vector Issue Register via the ‘dead-source’ bits\nVRAT 的寄存器分配规则\n子线程中寄存器的分配触发条件 子线程的物理寄存器分配只发生在以下两种情况：\n源寄存器被向量化，但目标寄存器尚未向量化： 在这种情况下，目标寄存器需要分配 16 个空闲的向量物理寄存器。 目标寄存器已被向量化，但即将被标量指令覆盖： 这种情况可能是由于原始代码中的写后写（WAW）依赖导致，目标寄存器会被分配到空闲标量物理寄存器。 处理控制流分歧 当由于分支跳转（Branch Divergence），部分向量 lanes 被禁用时：\n只有相关的 lanes 的寄存器会被重命名，而非所有 lanes。 寄存器释放策略\n当寄存器被覆盖时，立即将其归还到空闲列表，前提是它不再被用作源寄存器。 4.2.2 Vector Issue Register 为了实现比单个向量寄存器（8 个 64 位加载，如 AVX-512）显着更高程度的内存级并行性，我们重叠执行同一指令的多个向量副本，目标是实现 16 个 AVX -512 个向量（或 16 × 8 = 128 个标量等效循环）同时进行。我们不使用标量发布队列，而是使用单个向量发布寄存器 (VIR)，负责发布标量指令的每个向量副本（图 5）。\n如果指令的所有 inputs 都是标量，则只发出一条标量指令。如果指令被标记为步幅加载，我们使用步幅检测器填充所有 128 个值，并将这些值作为 16 个矢量化 AVX-512 加载发出。如果指令依赖于至少一个矢量化输入，我们同样会按顺序向执行单元发出指令的 16 个矢量化副本。每当有合适的单元空闲时（主线程未使用），就会向执行单元发出矢量化指令副本。在一个 AVX-512 指令中，我们有 8 个掩码位，用于指示其中一个源被标记为无效的通道，无论是由于故障、使用浮点寄存器还是通过控制流发散。如果 Discovery Mode 的 loop-bound inference 预测它可以获取的标量等效循环将少于 128 个，则某些通道可能会以掩码 out 开始。一旦所有指令副本都发出并执行，如果在任何源上设置了 \u0026lsquo;dead-source\u0026rsquo; 位，则释放物理寄存器。然后，我们获取下一条指令，并重复。\n矢量化加载指令被视为矢量收集操作[87]：它们在 LSQ 中被拆分为标量加载并发送到单独缓存层次结构。内存系统与其他常规标量加载同时处理它们，分配不同的 MSHR。\n4.2.3 Branch Reconvergence. 相关负载可能是有条件的，即它们出现在某些控制流路径上，而不是内循环内的其他路径上。我们允许每个标量等效车道与其他车道分开。因此，我们使用类似 **GPU 的再收敛堆栈。**所有活动通道中的分支结果都会相互比较。如果任何通道的下一个 PC 与其他通道不同，我们会根据新的目的地分割通道，根据公共组生成掩码，并将掩码和目标 PC 放置到重新收敛堆栈上。我们沿着第一条路径一直到达重新收敛点(是不是相同的指令地址?)，我们将其设置为矢量超前运行终止点（第 4.2.4 节），以避免特殊跟踪。一旦我们到达一组匹配通道的终止点，我们就会将头从再收敛堆栈中弹出，重置掩码，然后从堆栈中的下一个 PC 继续。\n每个车道同时映射到 VRAT 中。如果我们在标量重命名中存在分歧（因为我们使用不同的标量），并且这种分歧整齐地发生在 AVX-512 指令边界上，那么我们会根据 16 个 AVX-512 指令中的哪一个使用它来覆盖每个标量。如果 AVX-512 指令中的标量重命名存在分歧，我们会将目标转换为 AVX-512 物理寄存器，并复制要替换的标量值。\n4.2.4 Termination. 当(1)通道到达序列中的最终间接负载（由 FLR 识别）时，或者(2)在发散的情况下达到步幅 PC 的下一次迭代时，向量运行子线程终止，并(3)具有 200 条指令超时（如果我们离开以循环绑定检测器未拾取的方式完全循环，例如，通过中断）。主线程与向量运行子线程同时执行。一旦子线程终止，主线程下次执行跨步加载时将再次有资格进入发现模式，从而重新启动 DVR。此时主线程将取得重大进展，并且如果 DVR 子线程准确且及时，其大部分缓存访问将成为 L1 命中。\n4.3 嵌套向量运行(Nested Vector Runahead) Nested Vector Runahead 通过分析嵌套循环结构，对外层和内层循环联合向量化,来解决内层循环次数不够的问题\nNested Vector Runahead 分两步工作。首先，它执行嵌套发现模式 （NDM） 以将指令链从外部跨步负载矢量化到内部跨步负载，并发现循环边界和数据输入到内部循环的多个调用。其次，在到达 inner striding loop 时，它会进一步扩展矢量化以覆盖 inner loop。\n4.3.1 Nested Discovery Mode NDM 的目标是同时找到内部循环的许多不同调用的起始跨步地址和循环边界。discovery 模式（第 4.1 节）期间，loop-bound detector 可能会发现 loop 的 Approximate 迭代少于 64 次。在这种情况下，一旦生成了 vector-runahead 子线程，我们不是立即执行 vector runahead，而是用backward edge 改变分支的方向(把跳转转为不跳转,那就直接跑到外部去了)，并通过将PCv设置为分支后面的指令（未采用路径指令）来在in-order subthread上开始 NDM。子线程与主线程同时运行。仍然将两个 source registers 保存在 LCR 中。跨步负载的常数循环增量和地址分别保存在两个新寄存器中，分别称为增量寄存器 （IR） 和内部负载寄存器 （ILR）。\nNDM 子线程开始执行标量操作，但由于分支方向更改而跳过内部循环的所有即将进行的迭代，并执行内部循环外部的指令。当它发现一个外跨步负载的地址小于 ILR 中的地址时（例如，算法 1 中的第 4 行与第 8 行），它执行第一个向量化步骤：它对跨步负载进行向量化（乘以 16，以尝试找到至少 128 个可行的内循环迭代）并在污点向量中标记负载的目的地。\n对于每个外部跨步负载的依赖项，矢量化过程继续进行，直到到达每个内部跨步负载的第一次迭代。在算法 1 中，第 4 行的外部跨步负载在第 5 行和第 6 行都有相关性。\n当它达到 inner striding load （第 8 行） 时，它会读取 LCR 中源寄存器的矢量化副本的值，并使用这些值和 IR 中的值来计算每个矢量化 outer loops 的 inner loops 调用次数。如果在进入 NDM 后的 200 条指令内没有出现地址低于内跨步负载的外部跨步负载，则子线程将根据 LCR 和 IR 中的值重新计算循环边界，并通过循环边界对内部跨步负载进行矢量化。也就是说，子线程会回到 loop bound detector 在初始发现模式期间计算的迭代次数。 (LCR中保存cmp的源寄存器,在外部矢量化的时候,这个源寄存器也会被矢量化,通过这个值和)\n4.3.2 Further Vectorization 根据检测到的循环边界，NDM 子线程收集尽可能多的跨步内存地址，最多限于128个地址。超过前128个的地址将被丢弃。然后，NDM 子线程从内跨步加载开始执行向量化，通过将这些128个目标地址填充到其向量寄存器中，其他寄存器根据它是从哪个外循环的 16 个 lane 中生成的来设置（对于当前未污点的寄存器使用标量，对于在 NDM 中被污点的寄存器使用向量）。它将内跨步加载的目标标记为污点，并按照第 4.2 节所述，进入 DVR 模式，每个 lane 都会启动和终止。\nHardware Overhead 支持 DVR 的硬件结构仅产生 1139 字节的开销。 32 条目步幅检测器需要 460 字节：每个条目需要 48 位用于加载 PC，48 位用于前一个内存地址，16 位用于步距，2 位用于饱和计数器，1 位用于最内层检测。 VRAT 是一个 16 条目表（288 字节）：每个条目具有 16 个寄存器标识符，每个寄存器标识符需要 9 位（以选择 128 个向量物理寄存器和 256 个整数物理寄存器之一）。 VIR 占用 86 个字节：128 位用于掩码，16 位已发出，16 位已执行，64 位 uop 和 imm，9×16 位用于目标，10×16 位用于 src1，10×16 位用于 src2。前端缓冲区为 8 个微操作占用 64 个字节。 8 项再收敛堆栈需要 176 个字节：6 个字节用于 PC，128 位掩码用于每个 PC。 FLR和LCR分别只需要6字节和2字节； SBB 仅需要 1 位。循环绑定检测器保存两个检查点（2×16×8 位用于寄存器 ID 映射）和两个用于比较和分支指令的寄存器，总共 48 个字节。污点跟踪器需要 16 位。对于 NDM，IR 和 ILR 需要 7 位和 6 个字节来跟踪循环增量（最大 128）和内部跨越负载的地址 ID。\n参考文献 向量寄存器和gpu\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-17T12:28:27+08:00","permalink":"https://VastCircle.github.io/2024/decoupled_vector_runahead/","title":"Decoupled_Vector_Runahead"},{"content":"摘要 像Spectre及其变种这样的瞬态执行攻击可能通过缓存层次结构导致信息泄漏。缓解推测执行攻击的技术分为两类：基于延迟的技术和不可见推测技术。像GhostMinion这样的基于不可见推测的技术是高性能且安全的技术，可以缓解所有类型的推测执行攻击。与缓存系统类似，硬件预取器也可能导致推测性信息泄漏。为了解决这个问题，GhostMinion提倡在缓存系统中基于严格排序的提交时预取。我们的实验表明，GhostMinion缓存系统与硬件预取器之间的互动产生了负面影响，导致不同缓存层次之间的冗余流量。这些流量会引起争用，并增加丢失延迟，从而导致性能下降。接下来，我们观察到，由GhostMinion强制执行的提交时预取导致性能损失，因为它影响了预取器的及时性。我们首次对先进的预取技术和安全缓存系统之间的互动进行了彻底分析。在此基础上，我们提出了两种微架构解决方案，确保在设计安全预取器时能够提供高性能，同时保证安全的缓存系统。第一种解决方案通过非推测性更新缓存层次结构时检测和过滤冗余流量。第二种解决方案确保预取器的及时性，以弥补在提交时触发预取请求的延迟，从而实现既安全又高效的预取器。总体而言，我们的改进是安全的，并且在硬件预取器和安全缓存系统之间提供了协同作用。我们的实验表明，在使用先进的预取器的情况下，我们的过滤器始终能提高像GhostMinion这样的安全缓存系统的性能（对于单核系统提高1.9%，对于多核系统提高19.0%，使用的是性能最好的预取器）。我们还观察到过滤器与我们提出的安全预取器之间的协同效应，进一步提高了性能，单核和多核系统分别提高了6.3%和23.0%（相比于最好的预取器）。我们的改进极为轻量，每个核心的存储开销为0.59 KB。\nintroduction 瞬态执行攻击以Spectre [28]为代表，很快又出现了其他攻击 [9], [15], [17], [18], [33]，它们利用瞬态指令对缓存状态的影响。瞬态指令是不会提交的推测性指令。推测执行是一种高性能处理器的基本技术，因此为了安全起见，它不能被禁用。为了缓解利用缓存的推测执行攻击，各种提案 [10], [11], [27], [36]–[38], [45], [46], [48] 致力于在性能损失最小的情况下提供安全保障。文献中一般提出了两种缓解技术：基于延迟的技术和不可见推测技术。\n在基于延迟的方法中，依赖秘密的值的传递会被暂停，直到被认为可以安全地继续为止。判断安全性可能很复杂，需要复杂的机制来准确确定何时可以认为指令是安全的。而在不可见推测中，允许依赖秘密的加载执行，但这些执行的效果被隐藏在缓存层次结构和其他微架构结构之外。在所有的提案中，GhostMinion [11]、推测污染追踪 (STT) [48] 和非推测数据访问 (NDA) [45] 是最严格的，因为它们能够缓解回溯时间攻击，例如推测干扰攻击 [15]。在STT、NDA和GhostMinion之间，GhostMinion 是一种轻量级且高性能的缓解技术。GhostMinion是一种不可见推测技术，通过严格的排序保证通过缓存系统缓解各种推测执行攻击，包括缓存层次、未命中状态保持寄存器（MSHRs）以及硬件预取器 [10]。\nGhostMinion使用一个小型推测缓存（GM）来存储与推测加载相关的数据，当加载指令提交时，数据会传递到L1D。当相同数据从L1D驱逐时，数据会传递到L2，而从L2驱逐时，数据会传递到LLC。平均而言，与非安全缓存系统相比，GhostMinion会导致大约5%的性能损失。数据预取器通过将缓存未命中转换为命中，在提高缓存性能方面发挥了重要作用。最近的数据预取器进展推动了单线程性能的提升，平均性能提高了3%到5% [13], [16], [31], [32]。过去十年里，两次数据预取冠军赛 [1], [5] 也促进了这一趋势。\n不幸的是，硬件预取器会在推测加载时训练和触发，即使在安全缓存系统中也可能成为信息泄漏的来源 [10], [11]。利用预取器的推测攻击的工作原理如下：(i) 攻击者预热缓存；对应的缓存有一个预取器；(ii) 受害者加载类似于Spectre攻击的秘密数据；(iii) 受害者生成的推测加载训练并触发硬件预取器；(iv) 预取器根据其地址预测请求数据到缓存；(v) 最后，攻击者探测缓存。GhostMinion通过提交时预取为安全硬件预取器提供了案例：安全预取器应在提交时训练，并且预取只能在提交时发生。这样，预取器将不会推测性地影响缓存和MSHR状态，瞬态指令也无法利用预取器进行信息泄漏。\n我们表明，数据预取的确可以缓解安全缓存系统的性能损失。尽管数据预取很重要，但尚未对安全预取技术的影响进行详细研究。本文首次分析了广泛的先进硬件预取器与高性能安全缓存系统之间的交互。我们在类似GhostMinion的安全缓存系统上评估了IP-stride [12]（工业界常用的知名预取器）、Bingo [13]、SPP+PPF [16]、IPCP [32]（第3届数据预取冠军赛的冠军 [5]）以及Berti [31]。Berti是先进的L1D预取器（准确率接近90%），能够协调其在缓存层次中的请求。\n我们发现，预取器与像GhostMinion这样的安全缓存系统之间存在负面交互。研究表明，这些预取器无法实现最佳性能的主要原因有两个，并提出了微架构解决方案以克服这些问题。\n**我们的观察。**首先，我们分析了所评估的预取器在非安全缓存系统和类似GhostMinion的安全缓存系统上的性能改进，分别针对SPEC CPU 2017和GAP工作负载（详见第VI节的模拟细节）。我们观察到预取技术在安全和非安全缓存系统上都能改善性能，但两者之间的差距较大。性能差距是由于不可见加载引入的额外内存流量导致的内存访问延迟增加。平均而言，与使用硬件预取器的非安全缓存系统相比，GhostMinion会为L1D引入超过1.5倍的额外流量（详见第III节）。\n接下来，我们分析了在安全缓存系统上实现安全预取器的影响，即在提交时而不是访问时进行训练和预取的影响。图1显示了在安全缓存系统中训练并触发时（第二栏）和提交时（第三栏）的预取器性能改进。我们观察到，与访问时预取相比，在提交时训练/预取会导致所有预取器的一致性能损失（3%-4%）。关键因素是及时性，而不是无法捕获应用程序的访问模式（详见第III节）。\n对于提交时预取，性能损失的一个主要部分是由于我们称之为“提交延迟”的新类预取请求：在处理器请求数据时尚未启动预取，但如果预取请求在访问时触发，则会启动的未命中。在非安全缓存系统上与访问时预取相比，平均而言，在安全缓存系统上采用提交时预取会导致约10%的性能损失。\n**我们的贡献。**在本文中，我们分析了导致安全预取器性能低下的原因，并提出了一种低成本但有效的解决方案，以弥补性能损失并充分发挥安全预取的潜力，缩小与非安全缓存系统的性能差距。本文的主要贡献包括：\n我们表明，预取器在安全缓存系统上的相对性能下降主要是由于：(i) 安全缓存系统引入的额外内存流量，以及 (ii) 预取的及时性问题（详见第III节）。 我们提出了一种机制，用于过滤掉安全缓存系统中执行的多余非推测性更新。我们的过滤器轻量化，存储开销仅为0.12KB（详见第IV节）。 我们提出了一种机制，以确保在提交时训练和发出预取请求的预取器的及时性，从而实现一个既安全又及时且高性能的预取器。最终结果是第一个高性能安全预取器，存储开销为0.47KB（详见第V节）。 我们表明，在当前最先进的预取器基础上进行的增强，有助于缩小非安全缓存系统与安全缓存系统之间的性能差距。对于SPEC CPU2017和GAP基准测试，我们的增强措施将性能提升了6.3%（其中约30%的改进来自我们的过滤器，其余来自更优的提交时预取器训练）。对于一个4核系统，我们的机制在安全缓存系统中相比当前最先进的提交时预取器，将性能提升了23.0%（详见第VII节）。 background and related work A. 威胁模型 我们假设瞬态执行攻击者具有以下能力： (i) 攻击者能够通过缓存系统发起类似Spectre和推测性干扰[15]的攻击。 (ii) 攻击者可以通过预测训练和预取利用硬件预取器，从而改变缓存状态，如Muontrap中所述[10]。 (iii) 攻击者和受害者可以属于同一进程或不同进程。攻击者可以运行任意代码，但无法直接访问机密数据，即攻击者在用户级或内核级的沙箱中运行。 (iv) 存在基于时序的旁道和隐蔽通道，这些通道涉及硬件数据预取器和缓存[19], [20], [41]，可以通过现有的空间隔离技术进行缓解[22], [35]。\nB. 最近的缓解技术 一个独立的表格（表I）总结了近期的缓解技术，并结合了安全性、性能和存储需求的考量。如第I节所述，缓解技术分为两大类：基于延迟的技术[38], [45], [48]和不可见预测技术[10], [11], [37], [46]。 为了性能评估，我们采用了SPEC CPU2017[43]和GAP[8]基准测试。 在所有基于延迟的技术中，STT在提供安全保证的同时，性能开销最小。STT的操作前提是：除非指令构成隐蔽通道，否则可以安全地将机密数据转发给依赖的预测加载指令。对于显式隐蔽通道，它会阻止来源寄存器包含预测派生值的LOAD指令。 一种名为Doppelganger[29]的最新性能增强技术改进了包括STT在内的基于延迟的技术的性能。与存储开销较高的基于延迟的技术相比，不可见预测技术（如GhostMinion）以较低的性能损失和最低的存储开销著称。因此，在本文中，我们选择GhostMinion作为我们的安全缓存系统。\nC. GhostMinion安全缓存系统 GhostMinion使用一个小型2KB缓存（称为GM），该缓存与L1D并行访问，存储推测性指令的数据，直到它们提交（或退休）。当推测性指令在GM中产生需求未命中时，它会像传统的缓存层级一样在L1D、L2和LLC中搜索数据。然而，当在L1D、L2或LLC命中时，缓存状态（替换策略优先级位）不会更新。如果在L1D、L2和LLC中都未命中，则响应直接填充到GM中，而绕过L1D、L2和LLC（图2，1）。\n当提交时，提交指令的数据如果在GM命中，会通过提交时写入被转移到L1D缓存中。如果数据随后从L1D被驱逐，则会被转移到L2缓存中，进一步从L2驱逐会导致其传输到LLC（图2，2a）。在GM未命中的情况下，数据会被重新提取到非推测性缓存层级中（L1至LLC）（图2，2b）。\nGM既不包含也不排斥其余的缓存层级。在GM中，根据时间顺序，指令被限制查看其他指令的插入或驱逐。时间顺序基于时间戳维护。GhostMinion使用的TimeGuarding确保在多次推测下插入和驱逐是不可见的。为了隐藏在MSHRs中的争用，时间戳元数据在每个缓存级别的MSHRs中传播，允许较年轻的加载被取消并由较老的加载取代（跃迁）。此外，在GhostMinion中，一个块只能处于共享或无效状态，且GM和非推测性缓存的协同状态不会在指令提交之前被更改。\n动机 A. 安全缓存系统对硬件预取的影响 本节分析了为何预取器在像GhostMinion这样的安全缓存系统中表现不佳。 图3展示了本文评估的预取器在GhostMinion安全缓存系统中和基于访问的预取下L1D访问量的增长。在非安全系统且无预取的情况下，每千指令的平均L1D访问量（APKI）为199，而在GhostMinion中，由于提交请求更新了缓存状态（参见第II-C节），APKI上升到375。使用GhostMinion的Berti预取器时，APKI进一步上升到570。类似的趋势出现在所有预取器中。对于像Bingo和SPP+PPF这样的L2预取器，由于预取请求由L2发出，它们不会访问L1D。APKI的增加导致了额外的流量，从而增加了L1D未命中延迟（见图4）。\n一个关键的因素是硬件预取器存在的以下趋势，这种趋势使延迟变得更严重：\nL1D的MSHR占用率增加：在安全缓存系统中，Berti预取器的平均MSHR占用率增加了10.4%，MSHR满的时间额外增加了8.7%。 无预取时的对比：从非安全系统转移到安全系统时，L1D MSHR占用率降低了15.9%，因为需求未命中优先由GM服务。 通过对605.mcf_s-1554B进行详细分析，图5(a)显示，相较于无预取的非安全基线，性能显著下降（如Berti预取器的性能下降超过300%）。图5(b)显示了GhostMinion提交请求、加载请求和预取请求对L1D流量的贡献，图5(c)则显示了L1D未命中延迟的显著增加。\n进一步分析显示：\n无预取的L1D MSHR状态：无预取时，从非安全系统转到安全系统，L1D MSHR占用率下降了16.2%，因为需求请求优先由GM服务。 有预取的L1D MSHR状态：有预取时，从非安全系统转到安全系统，L1D MSHR占用率增加了10.1%。原因是非安全系统中L1D MSHR仅处理需求和预取请求，而安全系统中还需处理GhostMinion的提交请求，增加了MSHR压力。 此外，无预取时，L1D MSHR几乎从未满，而有预取时，L1D MSHR满的时间从6.3%增加到20%。 第IV节将提出一种机制以解决硬件预取启用时因额外流量导致的性能损失。\nB. 安全硬件预取的影响 正如GhostMinion[11]所描述，基于提交的预取能够防止因预测执行导致的信息泄露。然而，图1表明，将先进预取器移到提交阶段会导致3%-4%的性能损失，相较于基于访问的预取。\n图6展示了本文工作负载的每千指令需求未命中（MPKI）的平均值。MPKI按预取器工作的缓存级别（L1D或L2C）分类，并对基于访问和基于提交的预取分别进行评估。\nMPKI被划分为以下四类：\n提交延迟预取：这是一种新定义的延迟预取请求，仅出现在提交阶段预取器中。当发生缓存需求未命中时，提交阶段预取器尚未触发目标缓存行的预取请求，而访问阶段预取器已触发。 传统延迟预取：需求未命中时，MSHR中已有对目标缓存行的预取请求，二者合并。 错失机会：需求未命中目标缓存行，该行本可以由访问阶段预取器正确预测，但因提交阶段训练顺序不同而被漏掉。 未覆盖：未命中需求未归入前述类别。 观察到一个普遍趋势：将预取器移至提交阶段时，未覆盖的需求未命中数量减少。即使将“错失机会”加入“未覆盖”中，提交阶段预取器的总MPKI通常仍低于访问阶段预取器。\n然而，与基于访问的预取相比，基于提交的预取性能更差。原因在于预取及时性问题。虽然传统延迟预取请求几乎未增加，但新增的提交延迟类导致了MPKI的总体上升。为弥补基于提交预取的延迟，第V节提出了一种机制以缓解其及时性不足问题。\nIV. 适合预取的安全缓存系统 基于不可见预测的安全缓存系统在内存指令不是预测性时（例如在提交时）更新缓存层次结构。对于GhostMinion而言，这意味着在GM中未命中时重新获取缓存行，或者在GM命中时向缓存层次结构的其余部分发送基于提交的写请求（针对已清除的缓存行），如第II-C节所述。这些额外的数据传输的目标是填充缓存层次结构，特别是当数据是由核心预测性请求时未更新的部分，以减少随后的访问中的缓存未命中。无论是重新获取还是写传播都会对内存层次结构的流量产生重要影响。然而，这些额外的流量在内存系统未严重争用时不会显著降低性能，例如在具有预取机制的系统中。然而，预取机制会加剧缓存层次队列和MSHR的压力，从而阻止预取器提升性能（如第III-A节所示）。我们观察到，许多旨在恢复缓存层次结构的请求实际上并不必要，并且会引发严重的争用。例如，触发数据重新获取，即使数据已经由L1D提供，也会占用L1D端口，仅仅是为了更新LRU替换策略。在同一上下文中，基于提交的写请求会在内存层次结构中传播，直到数据已经出现在某个缓存级别。因此，可以避免访问已经包含该缓存行的缓存级别。\n受到这一观察的启发，我们提出了安全更新过滤器（SUF）。SUF记录当请求数据时，提供该数据的缓存级别。然后，在提交时，SUF会根据提供数据的缓存级别来过滤重新获取操作，或者停止在提交时的写传播，直到提供缓存行的级别之前。如果SUF预测错误，因为在此期间缓存行可能已被驱逐，则随后的获取请求会增加额外的延迟，因为它将从更高的级别提供。得益于SUF的高准确性，缓存访问的次数减少，从而减少了生成的流量。SUF与底层的预取技术无关，以透明的方式工作。\n识别持有缓存行的缓存级别 SUF使用持有缓存行的较低级别（L1D是最低级别，LLC是缓存的最高级别）来决定是否应使用过滤。通过在处理器请求数据时，将提供缓存行的缓存级别沿缓存层次结构向下传播，可以确定缓存级别。这些信息使用2位来编码，表示数据来自于L1D（或并行访问的GM）、L2C、LLC或DRAM。该2位的命中级别信息与请求数据一起存储在加载队列（LQ）中的内存操作条目中（见图7，第1步）。\n过滤更新 一旦预测性加载被提交，它会检查GM，以决定是否需要沿着层次结构重新获取缓存行（GM未命中）或在层次结构中向上传播缓存行（GM命中）。SUF检查命中级别字段，并按如下方式操作：\n如果数据来自L1D（值为00），SUF会丢弃更新（无论是重新获取还是提交时的传播）。 否则，重新获取或传播按常规方式进行，使缓存行从GM移动到L1D（见第2步）。 当L1D或L2中的缓存行被驱逐时，决定是否传播写回块是由GhostMinion写回位确定的。在提交时，L1D和L2的GhostMinion写回位会使用命中级别进行评估，并与写回块一起传播。每个L1D中的缓存行也存储了L2写回位，因此它会在写回时传播到L2（见第3步）。最后，在从L2驱逐时，GhostMinion写回位再次用于确定是否传播（见第4步）。\n适用性 SUF适用于任何基于不可见预测的安全缓存系统，该系统在提交时更新缓存层次结构。\n存储开销 SUF仅需要额外的0.12 KB存储空间：LQ上占用0.03 KB，L1D上占用0.09 KB。LQ中的128个条目每个都扩展了一个2位的命中级别字段，L1D中的768个条目每个都扩展了一个L2写回位。\n附录 参考文献 CPU Meltdown 和 Spectre漏洞分析\n理解CPU Spectre漏洞\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-14T13:17:45+08:00","permalink":"https://VastCircle.github.io/2024/secure_prefetching_for_secure_cache_systems/","title":"Secure_prefetching_for_secure_cache_systems"},{"content":"附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-11T21:00:41+08:00","permalink":"https://VastCircle.github.io/2024/failed_to_connetct_socket/","title":"Failed_to_connetct_socket"},{"content":"附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-11T20:58:55+08:00","permalink":"https://VastCircle.github.io/2024/ssh%E7%89%88%E6%9C%AC%E4%B8%8D%E5%8C%B9%E9%85%8D/","title":"Ssh版本不匹配"},{"content":"create a simple simobject create a python class 每个 SimObject 都有一个与之关联的 Python 类。此 Python 类描述了 SimObject 的参数，这些参数可以通过 Python 配置文件进行控制.\nfrom m5.params import * from m5.SimObject import SimObject class HelloObject(SimObject): type = \u0026#39;HelloObject\u0026#39; cxx_header = \u0026#34;learning_gem5/part2/hello_object.hh\u0026#34; cxx_class = \u0026#34;gem5::HelloObject\u0026#34; implement your simobject in c++ 创建hello_object.cc 和 hello_object.hh\n代码略\nNote: If the constructor of your SimObject follows the following signature,\nFoo(const FooParams \u0026amp;) then a FooParams::create() method will be automatically defined. The purpose of the create() method is to call the SimObject constructor and return an instance of the SimObject.\n注册SimObject和C++文件 创建SConscript文件\nImport(\u0026#39;*\u0026#39;) SimObject(\u0026#39;HelloObject.py\u0026#39;, sim_objects=[\u0026#39;HelloObject\u0026#39;]) Source(\u0026#39;hello_object.cc\u0026#39;) 重新构建gem5 scons build/X86/gem5.opt 创建配置脚本使用新的SimObject 调试gem5 ## DRAM build/X86/gem5.opt --debug-flags=DRAM configs/learning_gem5/part1/simple.py | head -n 50 ## EXEC build/X86/gem5.opt --debug-flags=Exec configs/learning_gem5/part1/simple.py | head -n 50 ## 通过 build/X86/gem5.opt --debug-help 可以看出相应的debug指令 添加新的调试标志 在SConscript 添加\nDebugFlag(\u0026#39;HelloExample\u0026#39;) 就可以创造新的调试标志 ,就可以在SimObject中使用\n在cc文件中添加\n#include \u0026#34;base/trace.hh\u0026#34; #include \u0026#34;debug/HelloExample.hh\u0026#34; 可以使用\nDPRINTF(HelloExample, \u0026#34;Created the hello object\\n\u0026#34;); 去打印调试信息\nDPRINTF会打印 (1) the current tick . (2)the name of the SimObject that called DPRINFT . (3)whatever format string you passed to the DPRINTF function\nEvent-driven programming creating a simple event callback 在gem5的事件驱动模型中,每个事件都有一个回调函数,在函数中处理该事件.该函数继承自cppEvent\n在helloObject中声明一个新函数,函数每次触发的时候会执行processEvent ,.该函数不采用任何参数,也不返回任何内容\n接下来,添加Event实例. helloObject中使用EventFunctionWrapper允许执行任何函数的实例\nevent的第一个参数是一个std : : function \u0026lt; void (void)\u0026gt;类型的,表示无参数也无返回值\n[this]{processEvent();}是一个lambda函数,使用[this]捕获当前对象的指针.通过this,lambda函数可以调用类的成员函数或者访问类的成员变量,这里访问了函数processEvent\nlambda函数可以直接隐式转换为 std::function\u0026lt;void(void)\u0026gt;\nHelloObject::HelloObject(const HelloObjectParams \u0026amp;params) : SimObject(params), event([this]{processEvent();}, name()) { DPRINTF(HelloExample, \u0026#34;Created the hello object\\n\u0026#34;); } 补充(lambda函数) 一种匿名函数\n[捕获列表](参数列表) -\u0026gt; 返回类型{函数体}\nadd = [](int a, int b) -\u0026gt; int{ return a + b; }; auto sum1 = [x,y](){return x + y;}; // 捕获 x,y auto sum2 = [\u0026amp;x,\u0026amp;y](){return x + y;}; //按引用捕获 scheduling events for the event to be processed , we first have to schedule(调度) the event . for this we use the : cppschedule function. this function schedules some instance of an Event for some time in the future\n我们会在添加到 HelloObject 类中的 startup() 函数里初始调度事件。startup() 函数是允许 SimObjects 调度内部事件的地方。它在tick = 0时会执行（即从 Python 配置文件中调用 simulate() 函数时才会执行）。\n// 在tick = 100 时schedule一次事件 void HelloObject::startup() { schedule(event,100); } 结果 此时的hello_object.cc\n#include \u0026#34;learning_gem5/part2/hello_object.hh\u0026#34; #include \u0026lt;iostream\u0026gt; // debug #include \u0026#34;base/trace.hh\u0026#34; #include \u0026#34;debug/HelloExample.hh\u0026#34; namespace gem5 { HelloObject::HelloObject(const HelloObjectParams \u0026amp;params) : SimObject(params), event([this]{processEvent();}, name()), latency(100),timesLeft(10) { DPRINTF(HelloExample, \u0026#34;Created the hello object\\n\u0026#34;); } void HelloObject :: processEvent() { timesLeft--; DPRINTF(HelloExample, \u0026#34;Processing the event\\n\u0026#34;); if (timesLeft \u0026lt;= 0) { DPRINTF(HelloExample, \u0026#34;Done firing!\\n\u0026#34;); } else { schedule(event, curTick() + latency); } } void HelloObject::startup() { schedule(event,latency); } } hello_object.hh\n#ifndef __LEARNING_GEM5_HELLO_OBJECT_HH__ #define __LEARNING_GEM5_HELLO_OBJECT_HH__ #include \u0026#34;params/HelloObject.hh\u0026#34; #include \u0026#34;sim/sim_object.hh\u0026#34; namespace gem5 { class HelloObject : public SimObject { private : void processEvent(); EventFunctionWrapper event; const Tick latency; int timesLeft; public : HelloObject(const HelloObjectParams \u0026amp;p); void startup() override; }; } #endif // __LEARNING_GEM5_HELLO_OBJECT_HH__ 向SimObjects添加参数 gem5 python 能够将参数从Python传递到gem5中的C++对象\n简单参数 可以在HelloObject.py class HelloObject中加入\nParam.\u0026lt;TypeName\u0026gt;\n第一个parameter为default value . 第二个为discreption\n## time_to_wait is a Latency.Latency takes a value as a time value as a string and converts it into simulator ticks . 默认刻度为1ps. 1ns会自动转化为1000 , Latency parameter time_to_wait = Param.Latency(\u0026#34;Time before firing the event\u0026#34;) ## int parameter number_of_fires = Param.Int(1, \u0026#34;Number of times to fire the event before \u0026#34; \u0026#34;goodbye\u0026#34;) 修改hello_object.cc为\nHelloObject::HelloObject(const HelloObjectParams \u0026amp;params) : SimObject(params), event([this]{ processEvent(); }, name() + \u0026#34;.event\u0026#34;), myName(params.name), latency(params.time_to_wait), timesLeft(params.number_of_fires) { DPRINTF(HelloExample, \u0026#34;Created the hello object\\n\u0026#34;); } hello.hh的private加入 const std::string myName;\nrun_hello.py 指定time_to_wait\nroot.hello = HelloObject(time_to_wait = \u0026#39;2us\u0026#39;) 其他SimObject作为参数 直接将goodbyeobject作为HelloObject的参数 ,能直接写 Param.GoodbyeObject的原因应该是GoodByeObject继承的SimObject吧\ngoodbye_object = Param.GoodbyeObject(\u0026#34;A goodbye object\u0026#34;) 需要去构造goodbyeobject然后再将goodbyeobject作为HelloObject的参数\n在hello_object.hh中需要包含头文件\n#include \u0026#34;learning_gem5/part2/goodbye_object.hh\u0026#34; 在HelloObject.py中\nclass HelloObject(SimObject): ... goodbye_object = Param.GoodbyeObject(\u0026#34;A goodbye object\u0026#34;) 在配置文件hello_goodbye.py中必须是goodbye_object,相当于hello的一个配置选项,但是root.hello这个hello是可以任意取的\nroot.hello = HelloObject(time_to_wait = \u0026#39;2us\u0026#39;,number_of_fires = 5) root.hello.goodbye_object = GoodbyeObject(buffer_size = \u0026#39;100B\u0026#39;) bandwidth * bytes_copied bandwidth 是带宽,代表每s传输多少个Bit(这里实际是每s传输多少Byte) , bytes_copied代表总共传输的Bytes数,两者相乘代表消耗的时间\n配置的 bandwidth = 100MB/s bandwidth=9537,所以这个bandwidth = 1/(100MB/s) = 1/1024/1024 = 9.537*10^(-9)s =9537ps\n配置的bandwidth = 50MB/s , bandwidth = 19073\nimage-20241213182604593 总共100B , saygoodbye一次 13\nprocessEvent 7次, 13 *8 = 104 ,够了\nCreating SimObjects in the memory system 创建位于CPU和内存总线之间的简单内存对象\ngem5请求和响应端口 three different memory system modes : timing,atomic and functional .\ntiming mode is theomly mode that produces correct simulation .\nAtomic mode is useful for fastforwarding simulation to a region of interest and warming up the simulator. this mode assumes that no events will be generated in the memory system.\nFunction mode is better described as debugging mode . Functional mode is used for things like reading data from the host into the simulator memory. or instance, functional mode is used to load the binary in the process.cmd from the host into the simulated system’s memory so the simulated system can access it.功能访问应该在读取时返回最新的数据，无论数据在哪里，并且应该在写入时更新所有可能的有效数据（例如，在具有缓存的系统中，可能有多个具有相同地址的有效缓存块）。\nPackets Packets are sent across ports . A packet is made up of a memreq which is the memory request object.The MemReq holds information about the original request that initiated the packet such as the requestor , the address and the typed of request .\nPackets also have a MemCmd , which is the current command of the packet .此命令可以在数据包的整个生命周期内发生变化.The most common MemCmd are ReadReq (read request), ReadResp (read response), WriteReq (write request), WriteResp (write response). There are also writeback requests (WritebackDirty, WritebackClean) for caches and many other command types.\nPackets also either keep the data for the request, or a pointer to the data. There are options when creating the packet whether the data is dynamic (explicitly allocated and deallocated), or static (allocated and deallocated by the packet object)(由数据包对象分配和释放).\nFinally, packets are used in the classic caches as the unit to track coherency.因此，大部分数据包代码特定于经典缓存一致性协议。但是，数据包用于 gem5 中内存对象之间的所有通信，即使它们不直接涉及一致性（例如，DRAM 控制器和 CPU 模型）。\ngem5 includes a typedef for it : PacketPtr\nPort interface request ports and response ports\nTo do this, you create a new class that inherits from either RequestPort or ResponsePort for request and response ports,\nall of the port interfaces require a PacketPtr as a parameter. Each of these functions (sendTimingReq, recvTimingReq, etc.), accepts a single parameter, a PacketPtr.\nTo send a request packet, the requestor calls sendTimingReq. In turn, (and in the same callchain), the function recvTimingReq is called on the responder with the same PacketPtr as its sole parameter.\nwhere the responder is busy when the original request was sent.\nwhen the requestor is busy at the time the responder tries to send a response.\nsimple memory object 补充 (c++的prIvate protect 和 public) private: 只能由该类中的函数、其友元函数访问，不能被其他任何访问，该类的对象也不能访问；\nprotected: 可以被该类中的函数，子类的函数，以及其友元函数访问，不能被该类的对象访问；\npublic: 可以被该类中的函数，子类中的函数，其友元函数访问，也可以由该类的对象访问。\n声明simobject SimpleMemobj.py\nclass SimpleMemobj(SimObject) : ... getPort是一个纯虚函数,必须要在C++中实现来定义\n定义SimpleMemobj类 simple_memobj.hh\nclass SimpleMemobj : public SimObject { private: public: /** constructor */ SimpleMemobj(SimpleMemobjParams *params); }; 定义响应端口类型 simple_memobj.hh\nCPUSidePort ,从ResponsePort来继承\nclass CPUSidePort : public ResponsePort { private: SimpleMemobj *owner; public: CPUSidePort(const std::string\u0026amp; name, SimpleMemobj *owner) : ResponsePort(name, owner), owner(owner) { } AddrRangeList getAddrRanges() const override; protected: Tick recvAtomic(PacketPtr pkt) override { panic(\u0026#34;recvAtomic unimpl.\u0026#34;); } void recvFunctional(PacketPtr pkt) override; bool recvTimingReq(PacketPtr pkt) override; void recvRespRetry() override; }; 定义请求端口类型 simple_memobj.hh\nMemSidePort 从RequestPort来继承 ,将来自CPU端口的请求转发到内存系统的其余部分\nclass MemSidePort : public RequestPort { private: SimpleMemobj *owner; public: MemSidePort(const std::string\u0026amp; name, SimpleMemobj *owner) : RequestPort(name, owner), owner(owner) { } protected: bool recvTimingResp(PacketPtr pkt) override; void recvReqRetry() override; void recvRangeChange() override; }; 定义SimObject接口 simple_memobj.hh\nclass SimpleMemobj : public SimObject { private: \u0026lt;CPUSidePort declaration\u0026gt; \u0026lt;MemSidePort declaration\u0026gt; CPUSidePort instPort; CPUSidePort dataPort; MemSidePort memPort; public: SimpleMemobj(SimpleMemobjParams *params); Port \u0026amp;getPort(const std::string \u0026amp;if_name, PortID idx=InvalidPortID) override; }; 实现基本的SimObject函数 即实现SimpleMemobj,getPort函数 Simple_memobj.cc\nSimpleMemobj::SimpleMemobj(SimpleMemobjParams *params) : SimObject(params), instPort(params-\u0026gt;name + \u0026#34;.inst_port\u0026#34;, this), dataPort(params-\u0026gt;name + \u0026#34;.data_port\u0026#34;, this), memPort(params-\u0026gt;name + \u0026#34;.mem_side\u0026#34;, this), blocked(false) { } 实现请求和响应端口函数 大多数情况下,每个端口函数只是将信息转发到主内存对象 (SimpleMemobj *owner)\nAddrRangeList SimpleMemobj::CPUSidePort::getAddrRanges() const { return owner-\u0026gt;getAddrRanges(); } void SimpleMemobj::CPUSidePort::recvFunctional(PacketPtr pkt) { return owner-\u0026gt;handleFunctional(pkt); } void SimpleMemobj::handleFunctional(PacketPtr pkt) { memPort.sendFunctional(pkt); } AddrRangeList SimpleMemobj::getAddrRanges() const { DPRINTF(SimpleMemobj, \u0026#34;Sending new ranges\\n\u0026#34;); return memPort.getAddrRanges(); } void SimpleMemobj::MemSidePort::recvRangeChange() { owner-\u0026gt;sendRangeChange(); } void SimpleMemobj::sendRangeChange() { instPort.sendRangeChange(); dataPort.sendRangeChange(); } 实现接收请求 recvTimingReq , 需要检查是否SimpleMemobj可以接受请求 . SimpleMemobj是一个非常简单的阻塞结构；我们一次只允许一个未完成的请求。因此，如果我们在另一个请求未完成的情况下收到一个请求，SimpleMemobj将会阻塞第二个请求。\nCPUSidePort存储端口接口所有的流量控制信息. 需要添加needRetry . a boolean that stores whether we need to send a retry whenever the simplememobj becomes free .\nto handle the request for the simplememobj ,we first check if the simplememobj is already blocked waiting for a response to another request . if it is blocked ,then we return false to signal the calling request port that we cannot accept the request right now .Otherwise, we mark the port as blocked and send the packet out of the memory port. For this, we can define a helper function in the MemSidePort object to hide the flow control from the SimpleMemobj implementation.We will assume the memPort handles all of the flow control and always return true from handleRequest since we were successful in consuming the request.\nNext, we need to implement the sendPacket function in the MemSidePortThis function will handle the flow control in case its peer response port cannot accept the request. For this, we need to add a member to the MemSidePort to store the packet in case it is blocked. It is the responsibility of the sender to store the packet if the receiver cannot receive the request (or response).\n此函数只是通过sendTimingReq调用函数来发送数据包\nvoid SimpleMemobj::MemSidePort::sendPacket(PacketPtr pkt) { panic_if(blockedPacket != nullptr, \u0026#34;Should never try to send if blocked!\u0026#34;); if (!sendTimingReq(pkt)) { blockedPacket = pkt; } } 实现接收响应 当 MemSidePort收到响应时，我们将响应通过 SimpleMemobj到相应的CPUSidePort\nbool SimpleMemobj::MemSidePort::recvTimingResp(PacketPtr pkt) { return owner-\u0026gt;handleResponse(pkt); } 未完\n总结 getAddrRanges() // cpuSidePort 调用 SimpleMemobj的方法获取地址范围 AddrRangeList SimpleMemobj::CPUSidePort::getAddrRanges() const { return owner-\u0026gt;getAddrRanges(); // SimpleMemobj调用memPort的方法获取地址范围 AddrRangeList SimpleMemobj::getAddrRanges() const { DRPINTF(SimpleMemobj, \u0026#34;Sending new ranges\\n\u0026#34;); return memPort.getAddrRanges(); } // 内存模块的地址范围由其下游端口（memPort）决定，因此需要通过下游端口获取。 sendRangeChange() // MemSIdePort在获取地址变化的时候调用SimpleMemobj的方法将地址变化转发出去了 void SimpleMemobj::MemSidePort::recvRangeChange() { owner-\u0026gt;sendRangeChange(); } // SimpleMemobj在接受到地址变化是调用instPort和dataPort(cpuPort)的方法转发地址变化 void SimpleMemobj::sendRangeChange() { instPort.sendRangeChange(); dataPort.sendRangeChange(); } recvFunctional(pkt) // 功能性请求 void SimpleMemobj::CPUSidePort::recvFunctional(PacketPtr pkt) { return owner-\u0026gt;handleFunctional(pkt); } void SimpleMemobj::handleFunctional(PacketPtr pkt) { memPort.sendFunctional(pkt); } recvTimingReq(pkt) cpu向mem发送请求的整个流程\n// 接收时序请求 // 通过owner-\u0026gt;handleRequest(pkt)发送,如果block了,那就发送失败,需要通过上游needretry ,否则就将pkt发送到SimpleMemobj module了 bool SimpleMemobj::CPUSidePort::recvTimingReq(PacketPtr pkt) { if (!owner-\u0026gt;handleRequest(pkt)) { needRetry = true; return false; } else { return true; } } // 如果blocked 就返回false ,否则调用memPort去发送Packet bool SimpleMemobj::handleRequeset(PacketPtr pkt) { if (blocked) { return false; } DPRINTF(SimpleMemobj, \u0026#34;Got request for addr %#x\\n\u0026#34;, pkt-\u0026gt;getAddr()); blocked = true; memPort.sendPacket(pkt); return true; } // memSidePort 最终会调用sendTimingReq去发送给下游packet ,如果下游阻塞的话将packet保存到bloacketPacket去 void SimpleMemobj::MemSidePort::sendPacket(PacketPtr pkt) { panic_if(blockedPacket != nullptr, \u0026#34;Should never try to send if blocked!\u0026#34;); if (!sendTimingReq(pkt)) { blockedPacket = pkt; } } // retry是memside内部的活动,将保存的blocketPacket重新发送 void SimpleMemobj::MemSidePort::recvReqRetry() { assert(blockedPacket != nullptr); PacketPtr pkt = blockedPacket; blockedPacket = nullptr; sendPacket(pkt); } sendTimingResp(pkt) // 在 memSidePort端口调用SimpleMemobj的方法去转发packet bool SimpleMemobj::MemSidePort::recvTimingResp(PacketPtr pkt) { return owner-\u0026gt;handleResponse(pkt); } // 有packet了就没有必要继续阻塞了,那就解除阻塞 ,然后转发到cpuPort去 bool SimpleMemobj::handleResponse(PacketPtr pkt) { assert(blocked); DPRINTF(SimpleMemobj, \u0026#34;Got response for addr %#x\\n\u0026#34;, pkt-\u0026gt;getAddr()); blocked = false; if (pkt-\u0026gt;req-\u0026gt;isInstFetch()) { instPort.sendPacket(pkt); } else { dataPort.sendPacket(pkt); } // 由于已经解除了block,所以可以通知cpu侧端口去retry失败的请求了 instPort.trySendRetry(); dataPort.trySendRetry(); return true; } // trySendRetry void SimpleMemobj::CPUSidePort::trySendRetry() { // 要判断blocketPacket是因为如果blocketPacket不为空代表mem那边还是blocked的 if (needRetry \u0026amp;\u0026amp; blockedPacket == nullptr) { needRetry = false; DPRINTF(SimpleMemobj, \u0026#34;Sending retry req.\\n\u0026#34;); // sendRetryReq竟然不需要重写 sendRetryReq(); } } // 在CPUSidePort端去发送数据给CPU,如果CPU那边block的话,就在后续retry void SimpleMemobj::CPUSidePort::sendPacket(PacketPtr pkt) { panic_if(blockedPacket != nullptr, \u0026#34;Should never try to send if blocked!\u0026#34;); if (!sendTimingResp(pkt)) { blockedPacket = pkt; } } void SimpleMemobj::CPUSidePort::recvRespRetry() { assert(blockedPacket != nullptr); PacketPtr pkt = blockedPacket; blockedPacket = nullptr; sendPacket(pkt); } 创造简单缓存 VectorResponsePort 和 ResponsePort ResponsePort 是一个基本的端口，用于处理响应（通常是从内存或其他外设返回的响应）。这个端口通常用于单一的响应通道，表示一个特定的响应类型。\nVectorResponsePort 是 ResponsePort 的扩展，它允许处理多个响应通道。这意味着它可以同时处理多个请求或多个响应，这在一些复杂的系统设计中非常有用。\nsimple cache object System parameter, which is a pointer to the main system this cache is connected to. we can get the cache block size from the system object when we are initializing the cache.\nimplementing the SimpleCache There are a couple of changes in the constructor and the key memory object functions\nwe need to add an extra parameter to handleRequest that is the id of the port which the request originated .\nthe new handleRequest does two different things . First , it stores the port if of the request as discussed above . Since the SimpleCache is blocking and only allows a single request outstanding at a time, we only need to save a single port id\nsecond , it takes time to access . Therefore , we need to take into account the latency to access the cache tags and the cache data for a request . we added an extra parameter to the cache object for this . and in handleRequest we now use an event to stall the request for the needed amount of time . we schedule a new event for latency cycles in th future .. the clockEdge function returns the tick that the nth cycle in the future occurs on .\ninstead of using an EventWrapper, in the SimpleCache we will use a new class . The reason we cannot use an EventWrapper, is that we need to pass the packet (pkt) from handleRequest to the event handler function.\n// simple_cache.hh class AccessEvent : public Event { private: SimpleCache *cache; PacketPtr pkt; public: AccessEvent(SimpleCache *cache, PacketPtr pkt) : Event(Default_Pri, AutoDelete), cache(cache), pkt(pkt) { } void process() override { cache-\u0026gt;accessTiming(pkt); } }; // simple_cache.cc bool SimpleCache::handleRequest(PacketPtr pkt, int port_id) { if (blocked) { return false; } DPRINTF(SimpleCache, \u0026#34;Got request for addr %#x\\n\u0026#34;, pkt-\u0026gt;getAddr()); blocked = true; waitingPortId = port_id; schedule(new AccessEvent(this, pkt), clockEdge(latency)); return true; } // this function first functionally accesses the cache.This function accessFunctional performs the functional access of the cache and either reads or writes the cache on a hit or returns that the access was a miss. // If the access is a hit, we simply need to respond to the packet.To respond, you first must call the function makeResponse on the packet.This converts the packet from a request packet to a response packet. Then, we can send the response back to the CPU. void SimpleCache::accessTiming(PacketPtr pkt) { bool hit = accessFunctional(pkt); if (hit) { pkt-\u0026gt;makeResponse(); sendResponse(pkt); } else {// 如果数据包对齐,并且请求的大小是缓存块的大小,就可以把请求转发到内存,如果数据包小于缓存块,需要创建一个新的数据包来从内存中读取整个缓存块, 无论数据包是读取还是写入,都会向内存发送读取请求.新的数据包的大小为blocksize.然后保存原来的数据包用于恢复,发送新的数据包给内存 Addr addr = pkt-\u0026gt;getAddr(); // 获取请求地址 Addr block_addr = pkt-\u0026gt;getBlockAddr(blockSize); // 获取数据块地址 unsigned size = pkt-\u0026gt;getSize(); // 获取请求大小 // 如果请求的地址与缓存块地址相同且请求的大小等于缓存块大小 if (addr == block_addr \u0026amp;\u0026amp; size == blockSize) { DPRINTF(SimpleCache, \u0026#34;forwarding packet\\n\u0026#34;); memPort.sendPacket(pkt); // 将请求转发给内存端口 } else { DPRINTF(SimpleCache, \u0026#34;Upgrading packet to block size\\n\u0026#34;); // 检查请求的访问是否会跨越多个缓存行 panic_if(addr - block_addr + size \u0026gt; blockSize, \u0026#34;Cannot handle accesses that span multiple cache lines\u0026#34;); assert(pkt-\u0026gt;needsResponse()); // 确保请求需要响应 MemCmd cmd; if (pkt-\u0026gt;isWrite() || pkt-\u0026gt;isRead()) { cmd = MemCmd::ReadReq; // 如果是写请求或读请求，设置为读请求 } else { panic(\u0026#34;Unknown packet type in upgrade size\u0026#34;); // 如果是其他请求类型，触发 panic } // 创建新的请求包，大小为块大小 PacketPtr new_pkt = new Packet(pkt-\u0026gt;req, cmd, blockSize); new_pkt-\u0026gt;allocate(); // 为新的请求包分配内存 outstandingPacket = pkt; // 记录当前的请求包，稍后将其恢复 memPort.sendPacket(new_pkt); // 将新的请求包发送到内存端口 } } } // the sendResponse function does the same things as the handleResponse function in the SimpleMemobj except that it uses the waitingPortId to send the packet to the right port. void SimpleCache::sendResponse(PacketPtr pkt) { int port = waitingPortId; blocked = false; waitingPortId = -1; cpuPorts[port].sendPacket(pkt); for (auto\u0026amp; port : cpuPorts) { port.trySendRetry(); } } bool SimpleCache::handleResponse(PacketPtr pkt) { assert(blocked); DPRINTF(SimpleCache, \u0026#34;Got response for addr %#x\\n\u0026#34;, pkt-\u0026gt;getAddr()); insert(pkt); // 如果有outstandingPacket,需要将原始数据包转发给原始请求,如果没有,将pkt中的响应转发给原始请求 如果我们收到的响应数据包是升级数据包，因为原始请求小于缓存行，那么我们需要将新数据复制到未完成数据包中或在写入时写入缓存。然后，我们需要删除在未命中处理逻辑中生成的新数据包。 // 此时缓存已经更新完成了 if (outstandingPacket != nullptr) { accessFunctional(outstandingPacket); outstandingPacket-\u0026gt;makeResponse(); delete pkt; pkt = outstandingPacket; outstandingPacket = nullptr; } // else, pkt contains the data it needs sendResponse(pkt); return true; } 功能缓存逻辑 最简单的缓存存储是从地址映射到数据的映射(哈希表),\nstd::unordered_map\u0026lt;Addr, uint8_t*\u0026gt; cacheStore; 补充(std::unordered_map) unordered_map和map类似,都是存储的key-value的值,可以通过key快速索引到value,但是unordered_map是乱序的\nstd::unordered_map\u0026lt;key_type, value_type\u0026gt; map_name; myMap.erase(1); // 删除键为1的元素 auto it = myMap.find(2); //查找键值为2的元素 // 如果检查到命中,如果数据包是写入操作,就更新缓存中的数据,使用writeDataToBlock来写入,如果读取操作,需要来更新数据包中的值 bool SimpleCache::accessFunctional(PacketPtr pkt) { // 通过getBlockAddr去获取和blockSize对齐的地址 Addr block_addr = pkt-\u0026gt;getBlockAddr(blockSize); auto it = cacheStore.find(block_addr); if (it != cacheStore.end()) { if (pkt-\u0026gt;isWrite()) { pkt-\u0026gt;writeDataToBlock(it-\u0026gt;second, blockSize); } else if (pkt-\u0026gt;isRead()) { pkt-\u0026gt;setDataFromBlock(it-\u0026gt;second, blockSize); } else { panic(\u0026#34;Unknown packet type!\u0026#34;); } return true; } return false; } insert 用于将数据插入缓存\n第一步是检查缓存当前是否已满。如果缓存中的条目（块）多于 SimObject 参数设置的缓存容量，则我们需要逐出某些条目。以下代码利用 C++ 的哈希表实现逐出随机条目unordered_map。\n在驱逐时，我们需要将数据写回到后备内存中，以防数据已被更新。为此，我们创建一个新的Request-Packet 对。数据包使用新的内存命令：MemCmd::WritebackDirty。然后，我们通过内存侧端口 () 发送数据包memPort并擦除缓存存储映射中的条目。\n然后，在某个块可能被逐出后，我们将新地址添加到缓存中。为此，我们只需为该块分配空间并向映射添加一个条目。最后，我们将响应数据包中的数据写入新分配的块中。由于我们确保如果数据包小于缓存块，则在缓存未命中逻辑中创建一个新数据包，因此该数据保证为缓存块的大小。\nvoid SimpleCache::insert(PacketPtr pkt) { if (cacheStore.size() \u0026gt;= capacity) { // Select random thing to evict. This is a little convoluted since we // are using a std::unordered_map. See http://bit.ly/2hrnLP2 int bucket, bucket_size; do { bucket = random_mt.random(0, (int)cacheStore.bucket_count() - 1); } while ( (bucket_size = cacheStore.bucket_size(bucket)) == 0 ); // 返回 cacheStore.begin(bucket)迭代器往后移动 random_mt.random步的位置,也是一个迭代器 ,或者说地址 auto block = std::next(cacheStore.begin(bucket), random_mt.random(0, bucket_size - 1)); //创建写回包并将其发送到内存端口 ,一个请求包含地址,大小,flags , id RequestPtr req = new Request(block-\u0026gt;first, blockSize, 0, 0); PacketPtr new_pkt = new Packet(req, MemCmd::WritebackDirty, blockSize); // 将被驱逐快的数据添加都新的包里,block_\u0026gt;second为数据指针,block-\u0026gt;first为地址 new_pkt-\u0026gt;dataDynamic(block-\u0026gt;second); // This will be deleted later DPRINTF(SimpleCache, \u0026#34;Writing packet back %s\\n\u0026#34;, pkt-\u0026gt;print()); // 发送 memPort.sendTimingReq(new_pkt); cacheStore.erase(block-\u0026gt;first); } // 为新的缓存块分配内存 uint8_t *data = new uint8_t[blockSize]; // cacheStore采取的是类似于哈希表的形式,地址作为key,保存数据指针 cacheStore[pkt-\u0026gt;getAddr()] = data; // 将请求的数据写入缓存 pkt-\u0026gt;writeDataToBlock(data, blockSize); } 总结 相比较于SimpleMemobj,\nrecvTimingReq没有改变\nhandleRequest改变,首先,增加了id,可以明确发起请求的端口是什么id ,其次,需要去延时执行一个事件accessTiming,\n对于accessTiming函数来说,在通过accessFunctional函数获取1.是否hit,2.hit的话写入数据包的值,将req的数据包转为resp,然后就可以直接sendResp ,\n如果未命中的话,会去内存读一个缓存行大小的数据包,即先sendPacket(没变)-\u0026gt;sendTimingReq(没变)-\u0026gt;recvTimingResp((没变)-\u0026gt;handleResponse\n对于handleResponse,首先需要去insert(pkt),即选择相应的缓存行去插入,同时需要将排除的缓存行写回内存(再次调用memPort.sendPacket),另外,有一个有意思的点是originalPacket,就是如果req的时候不是对整个block大小请求,就会去新建一个packet包发给memport,然后originalPacket就保存着原来的数据包,所以在handleResponse的时候会去判断originalPacket是否存在,如果存在的话会用originalPacket重新去读一次缓存(accessFunction)获取到对应的数据,然后sendResponse\nsendResponse有一个改变就是通过id去选择Port了,然后就是SendPacket-\u0026gt;SendTimingReq,中间会由于cpu阻塞进行RecvRespRetry,均没有改变\n最大的改变其实是handleRequest和handleResponse,本身只控制阻塞和简单的转发,现在控制cache的整个逻辑\nblock在handlereq上的时候转变为true,在sendResponse的时候转化为false\nblockedPacket在recvRespRetry,recvReqRetry的时候会清空,在sendPacket时会进行赋值,赋值的条件就是后续的操作阻塞了,sendTimingReq或者sendTimingResp ,发起retry就会清空blockedPacket .\n对于recvRespRetry和recvReqRetry没有任何条件,猜测是由下级或者上级根据某种条件发送的,这个retry就是把已经得到的数据获取,是接受数据的retry\n还有一个retry,是TrySendRetry,它是希望CPU重新再发送一次请求,因为有一些req可能会直接卡在handleRequest这边,在sendResponse的时候会发起retry ,最终sendRetryReq的条件是 needRetry \u0026amp;\u0026amp; blockedPacket == nullptr\nneedRetry 在 trySendRetry会 变成false , 在recvTimingReq会变成true ,变成true的条件就是handleRequest是block的,还有 ( blocketPacket || needRetry )(why?这个唯一增加的约束是在recvRespRetry那边有blockPacket的时候,本来可以成功,但是现在失败了)\n附录 参考文献 lambda函数\nc++中public,protected,private的区别\ngem5学习,主要是看insert\nunordered_map\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-11T20:52:34+08:00","permalink":"https://VastCircle.github.io/2024/gem5_%E4%BF%AE%E6%94%B9%E6%89%A9%E5%B1%95/","title":"Gem5_修改扩展"},{"content":"配置 使用如下命令去安装gem5\ngit clone https://github.com/gem5/gem5 安装依赖 https://www.gem5.org/documentation/general_docs/building\nsudo apt install build-essential git m4 scons zlib1g zlib1g-dev \\ libprotobuf-dev protobuf-compiler libprotoc-dev libgoogle-perftools-dev \\ python3-dev libboost-all-dev pkg-config python3-tk 执行\npython3 `which scons` build/X86/gem5.opt -j9 问题1 : you\u0026rsquo;re missing the pre-commit/commit-msg hooks (未解决) 出现错误\nYou\u0026rsquo;re missing the pre-commit/commit-msg hooks. These hook help to ensure your code follows gem5\u0026rsquo;s style rules on git commit and your commit messages follow our commit message requirements. This script will now install these hooks in your .git/hooks/ directory.\n问题2 : can\u0026rsquo;t find a working python installation Error: Can\u0026rsquo;t find a working Python installation with Python-3.11 version\n在.zshrc里增加\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/python361/lib 问题3 : couldn\u0026rsquo;t find any hdf5 c++ libraries (未解决) Warning: Header file \u0026lt;png.h\u0026gt; not found. This host has no libpng library. Disabling support for PNG framebuffers. Warning: Couldn\u0026rsquo;t find any HDF5 C++ libraries. Disabling HDF5 support.\nsudo apt-get install libhdf5-dev sudo apt-get install libpng-dev 上面的指令还是无效(应该是没有含c++库),需要自己构建hdf5的c++库\n从链接获取hdf5的安装包\n## 解压 tar zxf hdf5-X.Y.Z.tar.gz ## 修改configure文件 HDF_CXX=no -\u0026gt; HDF_CXX=yes ## 构建 ./configure --prefix=/usr/local/hdf5 sudo make sudo make install 没救了,还是找不到\nvscode python 环境配置 GEM 5 的 SimObject Python 定义都在 m5.objects 包下，但 python 文件组织却不是按照目录进行的，每个 SimObject 虽然都属于 m5.objects 包，但其对应的文件却各自位于对应 C++ 源代码目录下。GEM 5 本身使用了其他的技巧来使得这些分散的 python 文件都置于 m5.objects 包下方便使用（详见 src/SConscript 文件中的 SimObject 以及 src/python/importer.py 文件）。\n为了使 vscode 的 pylance 能够正确识别所有的 SimObject 方便代码阅读，可以将这些文件通过软链接的方式置于 build/ARM/python/m5/objects 目录下。可以在 GEM 5 运行的 python 脚本（比如 config/learning_gem5/part1/simple.py）中添加以下代码来生成创建软链接的脚本：\nf = open(\u0026#39;create_link.sh\u0026#39;, \u0026#39;w\u0026#39;) for key,val in sys.meta_path[0].modules.items(): if key.startswith(\u0026#39;m5.objects\u0026#39;): # 将 xx 改为对应的前缀长度 f.write(\u0026#34;ln -s ../../../../../src/\u0026#34; + val[0][xx:] + \u0026#34; ./\\n\u0026#34;) 通过运行 ./build/ARM/gem5.opt simple.py 就可以生成对应的脚本。之后将该脚本在 build/ARM/python/m5/objects 目录下执行。注意生成的脚本中有一些 python 文件是在 build/ARM 文件夹下的所以使用 val[0][xx:] 截取会有问题，需要手动修改（几个 mem/ruby/protocol 下的 python 文件）。\n之后还需要在 m5/objects/__init__.py 文件中加入对应的 from xx import * 来使这些 SimObject 能够通过 from m5.objects import * 导入。将上面 python 代码中的 f.write 一行变为：f.write(\u0026quot;from \u0026quot; + key.split('.')[-1] + \u0026quot; import *\\n\u0026quot;) 来生成这些代码并将这些代码加入到 m5/objects/__init__.py 文件中。\n最后在 vscode 的 pylance 配置中将 ./build/ARM/python 加入到 extraPaths 中：修改 .vscode/settings.json 文件，将其加入到 python.analysis.extraPaths 中。\n创建简单配置脚本 import m5 from m5.ojbects import * ## 创建SimObject system = System() ## 设计时钟 system.clk_domain = SrcClockDomain() system.clk_domain.clock = \u0026#39;1GHz\u0026#39; system.clk_domain.voltage_domain = VoltageDomain() ## 设置模拟内存 system.mem_mode = \u0026#39;timing\u0026#39; system.mem_ranges = [AddrRange(\u0026#39;512MB\u0026#39;)] ## 设置cpu system.cpu = X86TimingSimpleCPU() ## 创建内存总线 system.membus = SystemXBar() ## 将cpu的缓存端口连接到内存总线 system.cpu.icache_port = system.membus.cpu_side_ports system.cpu.dcache_port = system.membus.cpu_side_ports ## system.cpu.createInterruptController() system.cpu.interrupts[0].pio = system.membus.mem_side_ports system.cpu.interrupts[0].int_requestor = system.membus.cpu_side_ports system.cpu.interrupts[0].int_responder = system.membus.mem_side_ports system.system_port = system.membus.cpu_side_ports ## 创建内存控制器并将其连接到membus system.mem_ctrl = MemCtrl() system.mem_ctrl.dram = DDR3_1600_8x8() system.mem_ctrl.dram.range = system.mem_ranges[0] system.mem_ctrl.port = system.membus.mem_side_ports ## bin文件的路径 thispath = os.path.dirname(os.path.realpath(__file__)) binary = os.path.join( thispath, \u0026#34;../../../\u0026#34;, \u0026#34;tests/test-progs/hello/bin/x86/linux/hello\u0026#34;, ) # 创建一个进程给\u0026#34;hello world\u0026#34;应用 system.workload = SEWorkload.init_compatible(binary) process = Process() process.cmd = [binary] system.cpu.workload = process system.cpu.createThreads() root = Root(full_system = False, system = system) m5.instantiate() print(\u0026#34;Beginning simulation!\u0026#34;) exit_event = m5.simulate() print(\u0026#39;Exiting @ tick {} because {}\u0026#39; .format(m5.curTick(), exit_event.getCause())) 通过build/X86/gem5.opt configs/tutorial/part1/simple.py可以观察到终端能够输出具体的结果\n将缓存添加到配置脚本 经典缓存和Ruby gem5 目前有两个完全不同的子系统来模拟系统中的片上缓存，即“经典缓存”和“Ruby”。历史原因是 gem5 是密歇根州的 m5 和威斯康星州的 GEMS 的组合。GEMS 使用 Ruby 作为其缓存模型，而经典缓存来自 m5 代码库（因此称为“经典”）。这两个模型之间的区别在于 Ruby 旨在详细模拟缓存一致性。\ncache Cache SimObject 声明可以在 src/mem/cache/Cache.py 中找到\ngem5的数据统计和输出 运行gem5在m5out生成三个文件\nconfig.ini\n包含为模拟创建的每个 SimObject 的列表及其参数值。\nconfig.json\n与 config.ini 相同，但采用 json 格式。\nstats.txt\n为模拟注册的所有 gem5 统计数据的文本表示。\nstats.txt 比较重要的数据\nsimSeconds : 模拟的总时间\nsimInsts : CPU提交的指令数\nhostInstrate : gem5的性能\ncpi : 指令周期,每条指令运行的周期\nipc : 周期指令,每周期运行的指令\nnumCycles:总运行周期\nsytem.cpu. : cpu的统计信息\nsystem.mem_ctrl : 内存的统计信息\ngem5自带的配置文件 在config里面\nconfigs/boot: bbench-gb.rcS bbench-ics.rcS hack_back_ckpt.rcS halt.sh configs/common: Benchmarks.py Caches.py cpu2000.py FileSystemConfig.py GPUTLBConfig.py HMC.py MemConfig.py Options.py Simulation.py CacheConfig.py cores CpuConfig.py FSConfig.py GPUTLBOptions.py __init__.py ObjectList.py SimpleOpts.py SysPaths.py configs/dist: sw.py configs/dram: lat_mem_rd.py low_power_sweep.py sweep.py configs/example: apu_se.py etrace_replay.py garnet_synth_traffic.py hmctest.py hsaTopology.py memtest.py read_config.py ruby_direct_test.py ruby_mem_test.py sc_main.py arm fs.py hmc_hello.py hmc_tgen.cfg memcheck.py noc_config riscv ruby_gpu_random_test.py ruby_random_test.py se.py configs/learning_gem5: part1 part2 part3 README configs/network: __init__.py Network.py configs/nvm: sweep_hybrid.py sweep.py configs/ruby: AMD_Base_Constructor.py CHI.py Garnet_standalone.py __init__.py MESI_Three_Level.py MI_example.py MOESI_CMP_directory.py MOESI_hammer.py CHI_config.py CntrlBase.py GPU_VIPER.py MESI_Three_Level_HTM.py MESI_Two_Level.py MOESI_AMD_Base.py MOESI_CMP_token.py Ruby.py configs/splash2: cluster.py run.py configs/topologies: BaseTopology.py Cluster.py CrossbarGarnet.py Crossbar.py CustomMesh.py __init__.py MeshDirCorners_XY.py Mesh_westfirst.py Mesh_XY.py Pt2Pt.py boot 全系统的rcS文件.这些文件在Linux启动后由模拟器加载并由shell执行.大多数用于在全系统模式下运行时控制基准测试 .有些是实用函数，例如 hack_back_ckpt.rcS\ncommon 包含许多用于创建模拟系统的辅助脚本和函数.\nCaches.py和上述caches.py类似\nOptions.py包含可能在命令行中设置的选项.例如CPU数量,系统时钟\nCaceConfig.py包含用于设置经典内存系统缓存参数的选项和函数\nMemConfig.py提供用于设置内存系统的辅助函数\nFSConfig.py包含为多种不同类型的系统设置全系统模拟所需的功能\nSimulations.py饱和用于设置和运行gem5的辅助函数.许多代码用于管理saving and restoring checkpoints.\nDram 包含测试DRAM的脚本\nexample 此目录包含一些示例 gem5 配置脚本，可立即用于运行 gem5。具体来说，se.py和 fs.py非常有用(这两脚本被移动到/deprecated/example里面了)。\nlearning_gem5 包含learning_gem5 book的所有脚本\nnetwork 包含HeteroGarnet network的配置脚本\nnvm 包含NVM接口的示例脚本\nruby 包含ruby及其包含的缓存一致性的配置脚本\nsplash2 该目录包含运行 splash2 基准测试套件的脚本以及一些用于配置模拟系统的选项。\ntopologies 包含创建Ruby缓存层次结构时可以使用的拓扑的实现\n附录 参考文献 wsl安装gem5\ngem5入门(官方)\ngem5安装修复python3-config\nHDF5 install\nvscode python环境\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-09T15:11:13+08:00","permalink":"https://VastCircle.github.io/2024/gem5_learning/","title":"Gem5_learning"},{"content":"ParaVerser：利用异构并行性实现数据中心中经济实惠的故障检测 abstract 数据中心运营商已经意识到，由于有缺陷的硅计算单元导致的无声数据损坏是大规模流行的。已经部署了软件扫描仪来缓解该问题，但要么覆盖率低，要么需要数月时间，从而导致长时间不正确行为。相比之下，汽车中使用的冗余机制使所需的功率和面积增加了一倍，因此无法实际部署在服务器空间中。我们推出了 ParaVerser，这是一种高覆盖率、低开销的服务器硬件级错误检测解决方案。通过较小的架构修改，我们使异构服务器级处理器中的传统核心能够充当检查器核心，从而利用异构性、扩展频率和重复运行中固有的并行性来提供节能的错误检查。通过将 big.LITTLE 型无序超标量核心与有序超标量核心动态耦合，在相同保证的情况下，我们相对于典型锁步系统将能源开销降低了 70%，而性能仅下降 4.3%，每核心面积开销为 1064B 。\n简介 随着数据中心规模的扩大，静默数据损坏的威胁已日益频繁，无法再被忽视。Meta [41] 和 Google [52] 警告称，随着晶体管的尺寸缩小和分布式计算规模扩大，尽管已有可靠性、可用性和可维护性（RAS）机制 [13], [30], [67]，但CPU仍然持续无提示地产生错误结果，既无崩溃也无外部错误迹象。为应对这一问题，解决方案已经分化为两极：一端是软件诊断技术 [40]，另一端是全硬件锁步机制 [17]。\n在数据中心，软件扫描器 [16], [40], [82] 已广泛用于测试生产系统中的永久性故障。尽管这些工具部署简单，但需要长时间暂停对资源的访问，或只能检测少量故障。因此，清除生产中的故障硬件可能需要长达六个月 [40]。相比之下，汽车系统长期采用双核和三核锁步机制 [17], [57]，通过核心完全同步来比较输出，以实现全面的硬件错误检测。然而，这种方法会导致在相同面积和功耗预算下计算性能减半，对于数据中心而言并不现实。\n尽管如此，仍然存在可行的替代方案。例如，为容错目的重复运行计算，其并行度通常高于原始运行 [2]–[4]。可以根据初始运行中的数据依赖性，将程序划分为多个段，然后通过归纳法重建完整的容错计算轨迹。这些段可以在缓慢、高效的并行硬件上运行 [2]。\n此外，服务器环境中的核心大小异构性已经开始出现 [72], [81]。然而，现有的错误检测系统通常采用最慢的核心 [4]，这意味着每个运行计算的主核心需要多达16个检查核心。虽然这在效率上可行，但如果服务器运行对容错需求较低的工作负载，微型检查核心将无法运行实际应用。而实际的异构系统中的“较小”核心通常是更大的超标量核心 [81]。\n我们证明，通过调整可靠性和性能功能，可以在微架构级别实现服务器级SoC中的错误检测，在必要时几乎不影响性能，并通过异构并行性将开销降至最低。我们提出 ParaVerser，一种硬件机制，用于机会性并行错误检测，利用备用CPU资源（异构或同构）高效地重复计算，所需的核心修改最小化。\n我们的贡献如下：\n新型微架构设计：用于检测硬件中的永久性和瞬时性故障，复用常规服务器级芯片中的核心。我们的设计引入了归纳并行性机制 [2]，将运行分段，并在多个较慢的并行核心上重放和检查执行的代码。异构SoC中的每个核心均可用于运行工作负载或冗余验证。 两种运行模式 全覆盖模式：能够捕获所有永久性和瞬时性错误； 机会性模式：只在资源空闲时检查尽可能多的计算，提供部分覆盖。 设计优化 设计混合的加载-存储日志和数据缓存以降低SRAM开销； 实现加载-存储推送单元，直接将数据推送至检查核心，消除主核心缓冲造成的本地缓存压力和一致性开销； 启用推测性的乱序检查； 通过新的哈希机制最小化跨芯片网络流量。 性能评估：ParaVerser在全覆盖模式下的性能开销根据检查核心的类型、数量和频率不同，几何均值范围为1%至4%。在这些极端之间，能耗开销从95%减少到仅29%。机会性模式仅引入1%的开销，资源分配不同可覆盖94%至99%的执行指令。 比较分析：与现有研究 [2], [4] 相比，ParaVerser提供更合理和详细的核心模型。我们证明12个专用检查核心 [2] 无法满足需求（9%开销），而16个专用检查核心 [4] 在低延迟下达成35%的面积开销。 ParaVerser 能以最小的性能和面积影响，在微架构级别实现对硬件中永久性和瞬时性故障的全面检测，其能耗仅为同构锁步方案的三分之一。该设计还支持硬件预测性维护 [88]，通过识别可能因老化 [62] 而变得易出错的CPU，提前预防故障。其灵活性还允许在系统负载较高时自动停用错误检测机制。ParaVerser 是数据中心在追求高质量服务的同时，实现可靠故障检测能力的理想解决方案。\nII. 动机 A. 数据中心规模的错误 在大规模数据中心中，硅级故障日益普遍，通常表现为静默数据损坏（SDC），且不会触发系统崩溃或警告。Meta [41] 和 Google [52] 的报告表明，这些错误经常绕过内置的**可靠性、可用性和可维护性（RAS）**功能。\n现有解决方案及其局限性 软件扫描工具 FleetScanner：执行离线测试，将服务器置于维护模式。尽管它在六个月内实现了 93% 的故障覆盖率，但这导致了长时间的漏洞窗口，在此期间错误可能影响实际运行的工作负载。 Ripple：在生产环境中进行测试，可以在实际工作负载同时运行，但覆盖率显著较低，仅能捕捉一小部分错误。 不足：这些工具通常运行模拟代码以代替实际工作负载，但错误往往依赖于具体数据输入 [41]，且受温度/电压变化的影响 [27]，因此覆盖率不可避免地不完整。 B. 异构并行错误检测 为了实现可接受的功耗开销，可以使用类似 ParaMedic 的方法 [2], [3]，通过异构并行错误检测来提高效率。\n关键思想 如果记录 CPU 的所有存储操作及其观察到的所有加载值，则可以将工作负载分解为多个独立的“检查点”，并通过重叠运行这些片段来验证错误（详见图 1）。每个检查点的执行依赖于前一个检查点的寄存器文件及加载/存储日志。通过归纳式方法，可以验证以下条件：\n所有加载/存储操作正确； 存储值与原始运行一致； 每个片段的终态寄存器文件与下一片段的初态寄存器文件一致。 限制与改进 以往研究 [2]-[4] 提出的方案围绕主核部署了大量微控制器级小核进行检测，这些小核虽高效，但不适合系统在非容错需求场景下的使用。解决方法是复用系统中的现有核，通过异构并行处理实现能效优化。例如，利用 Arm big.LITTLE [28], [81]、AMD Zen4/Zen4c [55], [72] 或 Intel P-/E-核 [56] 的现有架构。\nC. 机会性并行错误检测 目标是比软件扫描工具更快速、更高效地检测服务器中的不可靠计算。具体方法：\n动态调整检测覆盖率：当闲置资源不足时，通过降低覆盖率以维持性能；在系统负载较轻时，利用多余资源实现全面覆盖。 无需完全锁步：与基于采样的锁步方法 [69] 类似，但不需要完全相同的硬件或周期同步，降低实现复杂性。 硬错误优先检测：专注于检测硬错误和半硬错误（服务器系统的主要问题 [41]），而非瞬态错误（如宇宙射线引发的位翻转）。 D. 检测核的设计考量 PARAVERSER 如果我们正在重复利用备用的服务器核心，而这些核心有时更适合用于调度用户代码，而非用于小型、低性能的专用容错引擎[4]，则校验核心不可避免地不会像先前关于高效错误检测的研究[2]中那样小或高度并行化——在这些研究中，1216个微型校验核心被部署在每个主核心旁边。在我们的研究中，我们主要关注异构的big.LITTLE风格[28]微架构，因为（i）这使得在小核心上实现能量高效的错误检测成为可能，并且（ii）未来的数据中心SoC预计将包含异构核心[72]、[81]、[87]，尽管我们在第VI节中展示了ParaVerser也可以高效地在同构核心上实现。如果每个校验核心具有更高的吞吐量，我们需要的核心数量将会减少，即使每个核心在功耗和面积上更大。由于我们扩展的硬件功能并非始终被使用，因此其面积影响必须最小化，并尽可能重复利用现有硬件：例如，重新利用现有的SRAM缓存存储器而非专用存储器[2]来进行容错日志记录，重新利用现有的片上网络（NoC）布局而非专用布线[2]来转发中间结果。\n如果我们在为转发中间结果使用现有的NoC（片上网络）布局[2]，则第三部分介绍了ParaVerser的设计。图2展示了ParaVerser对次级核心的轻微修改。这些修改允许任意核心作为主核心1或校验核心运行，目的是使校验核心更加数量庞大、并行且能效更高。对于缓存和主存储器的错误，我们假设使用了ECC（纠错码）[13]或奇偶校验。\n我们描述了在全覆盖模式和机会模式之间如何不同地管理和分配校验资源（详见第III-A节）。前者在校验核心集体较慢时暂停主计算，让其赶上进度，而后者则跳过多余指令的校验。 我们增强了每个L1数据缓存，以允许校验核心存储记录的内存访问和寄存器检查点，从而能够并行重放计算片段（详见第III-B节）。 我们新增了一个单元，可以通过现有的NoC将记录的加载、存储以及其他不可重复事件直接推送到任意校验核心的日志中，从而避免共享存储和一致性开销（详见第III-C节）。 我们新增了一个寄存器检查点单元（详见第III-D节），用于在主核心生成起始和结束寄存器检查点，并在校验核心上存储并比较结束寄存器检查点。同时还新增了一个加载-存储比较器（详见第III-E节），比较内存地址和存储数据与加载-存储日志缓存中的记录版本。 最后，我们新增了一个计数器单元（详见第III-F节），用于在相同的指令计数下中断主核心和校验核心，以支持重放操作。片段通过寄存器检查点单元生成的检查点进行分割。我们还设计了新的机制，以处理可能为乱序和/或超标量的校验核心，这些核心的微架构可能与主核心完全不同（详见第III-G节）。这需要在支持主核心执行的推测和重新排序的同时，仍然观察到原始运行的正确且等效的加载和存储行为日志。 我们通过允许校验核心在主核心完成相关检查点之前启动执行（详见第III-H节）来提高设计效率，同时提出了对加载和存储行为的约束，以避免两者之间可能产生的不一致。此外，我们提出了一种减少跨核心数据传输的方法，以避免在资源不足的NoC上导致减速（详见第III-I节）。最后，我们解释了如何处理多进程和多核工作负载行为（详见第III-J节）。\nA. Basic Operation 对于给定的主核心，将选择一个空闲的校验核心。寄存器文件的副本会被获取（详见第III-D节）并推送到校验核心，后者从同一点开始执行。加载和存储由主核心记录并发送到校验核心以重放内存访问。当加载-存储日志缓存（详见第III-B节）已满、超时或接收到中断时，会获取一个结束检查点并发送到校验核心以供后续验证。由于主核心故意具有比校验核心更高的单线程吞吐量，因此前一个检查点的完整验证会在主核心创建后的一段时间才完成。为了避免阻塞，它通过为下一个时间间隔选择新的校验核心来并行化错误检测过程，而之前的检查点仍在被验证中。\n在全覆盖模式中，如果所有可能的目标都忙于错误检测（例如，由于可用的校验核心无法集体跟上主核心）或被调度运行其他程序，主核心将暂停执行。一旦有可用资源，一个新的起始检查点会被发送到新的校验核心，计算继续进行。在机会模式中，如果没有剩余的校验资源，寄存器检查点和日志记录会被短暂关闭。之前的片段会继续被检查，但当前检查点不会被转发，主核心继续执行以避免性能下降。一旦之前的检查点被检查并释放了校验核心，主核心会立即获取一个新的检查点，从该点重新开始检查。\n我们让操作系统根据当前负载决定分配哪些CPU作为校验核心，哪些作为主核心2。优先分配空闲核心以及较低性能的核心作为校验核心，因为校验不需要高单线程性能。如果操作系统决定当前校验核心数量超过所需或需要更多主核心计算，核心可以在每个检查点结束时从校验核心切换回主核心3。\nB. Load-Store Log Cache 先前的技术（例如，Ainsworth和Jones[2]）使用了专用的SRAM加载-存储日志，但引入了内存存储开销。相比之下，我们轻微修改并重新利用通用核心上已经可用的数据缓存，用于存储数据以重新生成计算并验证正确性（除了在第III-I节的Hash模式下，当验证元数据未存储在缓存中时）。我们称这种新结构为加载-存储日志缓存（LSL$）。\nLSL$中存储的用于计算重放的数据包括加载的数据和其他不可重复指令的值，例如条件存储、计时器、系统寄存器的读写以及随机数生成器。这使得无论中间存在任何多核通信，都可以精确重放。用于验证正确性的存储数据包括加载/存储地址、大小和存储数据。\n一个典型的LSL$条目由一个7字节的地址、一个1字节的大小以及一个为数据对齐到最近的8字节的可变长度负载组成（例如在Arm架构中，如果加载和存储同时需要，则数据先加载后存储）。这些条目首先在提交时按顺序由主核心的LSPU（详见第III-C节）填充，并在校验核心上被解释为相同的序列。然后，条目的缓存行（每行512位缓存存储4个条目，每个条目通常为64位结果）通过NoC推送到LSL$。\n如图3所示，LSL$的结构中每个缓存行的标签增加了一个额外的位，用于指示存储的数据是日志（L）还是主存数据的缓存副本（C）。当核心开始被用作校验时，其缓存被重新用作线性日志，而不是地址的内容可寻址存储器。我们从校验核心缓存的第一个索引和集合开始填充，并逐出当前位置的缓存行（如果有效且尚未是日志条目）。存储在新加载-存储日志结束寄存器中的一个字指示当前结束元素所在的行。\nC. 加载-存储推送单元 我们为核心新增了一个加载-存储推送单元（LSPU），以便通过通用NoC在主核心和校验核心之间传送加载-存储日志（LSL）条目。与之前的异构错误检测技术[2]–[4]不同，ParaVerser需要核心之间的全互联通信（任何核心可以检查其他核心）。这种跨核心通信的开销通过在每个主核心的LSPU中本地缓冲一个缓存行的LSL条目得以缓解。此外，由于LSL$条目被视为临时存储，而不是一致性流量，它们可以直接发送，而无需经过目录或最后一级缓存（LLC）。除非条目本身大于一个缓存行，否则无法容纳在当前缓存行剩余空间的条目会被放入下一个缓存行。\n为了允许大核心和小核心的微架构有所不同，LSL$以ISA格式存储数据。这需要在流水线提交时将多个微操作的数据融合在一起。对于提交时的每个加载/存储微操作，当访问来自相同指令时，主核心继续在LSPU中更新相同的LSL条目。合并的条目涵盖了从单一基址开始的所有加载数据，随后是基址的任何存储数据。在访问LSL$时，访问地址和大小会与LSL$条目中的地址和大小范围进行比较，并使用地址作为偏移量进入LSL$条目的数据段以检索或检查相应数据。要推送到日志的数据（详见第III-B节）在提交时从核心的加载-存储队列（LSQ）访问。\n为了避免限制覆盖范围，我们对LSQ进行了轻微修改：任何到达内存的存储中的错误也必须到达校验核心。相反，任何加载值中的错误不得到达校验核心，从而确保至少有一个核心接收到正确的值。对于加载操作，来自缓存的ECC或奇偶校验位（无论系统中使用哪种方式）会被转发到加载队列，并在转发到LSPU之前进行检查。对于存储操作，在存储传播到本地缓存和LSL$之前，会生成ECC或奇偶校验位。主核心和校验核心之间以及寄存器文件中的错误不会传播，因为这些组件中的错误仅限于主核心或校验核心。\nLSPU的大小与缓存行、NoC宽度或目标ISA单条指令可能生成的最大LSL$条目相同（以较大者为准），并在其满时或获取结束检查点时推送到NoC（从而切换校验核心）。虽然在LSPU中的中间状态可能违反ISA兼容性，但推送到NoC的所有数据均遵守ISA兼容性。\nD. Register Checkpointing Unit 寄存器检查点单元（RCU）用于在主核心上获取起始和结束寄存器检查点，并在校验核心上存储结束寄存器检查点。在检查点的开始，RCU会复制架构寄存器文件，通过NoC转发到选定的校验核心，该核心更新其寄存器文件并开始校验。在检查点结束时，主核心的RCU将新的架构寄存器文件副本转发到选定的校验核心的RCU，并更新新分配的校验核心（如果有）。最后，一旦校验核心被指令计数器中断，架构寄存器文件将与RCU副本进行比较。\n虽然系统可见状态通过LSL中的加载和存储或Hash模式中的哈希值（详见第III-I节）进行检查，但还需要在每个检查点的开始和结束进行寄存器文件检查，以通过归纳法[2]验证完整的程序序列的正确性。\nE. Load-Store Comparator 负载存储比较器（LSC）将检查器核心生成的地址和大小与记录中存储的每个负载和存储的地址和大小进行比较。对于存储，它还将记录的值与检查器核心的结果进行比较。对于负载，这个过程是无序进行的（第III-G节）：当访问LSL条目时，数据负载被复制到负载队列中，并且负载队列中存储的地址与来自LSL$的值进行比较。对于存储，这在提交时发生：当存储被提交时，LSL$条目与存储队列中的地址和数据进行比较。为了避免减慢速度，每个负载或存储单元都有一个比较器。\nF. Instruction Counter 该计数器用于精确匹配主核心和检查器核心之间的检查点结束时间。在主核心一侧，当发生以下情况时，会生成检查点：(i) LSL$满了，(ii) 有中断或上下文切换，或(iii) 达到超时。此时，RCU会拍摄一份架构寄存器文件，并将其转发到检查器核心。在检查器核心一侧，我们在主核心提交的指令数与主核心检查点的时间点匹配时完成检查，并比较寄存器文件。\nG. Speculative Out-Of-Order Checker Cores LSL按程序顺序填充，在主核心提交时，如之前的工作[2]–[4]所示。然而，之前的工作依赖于按顺序访问LSL进行检查，限制了检查器仅能用于最简单的按顺序核心，在这些核心中，错误的预测永远不会到达数据路径，并且内存访问无法重新排序。这对于典型的可编程服务器核心来说是一个错误假设，即使是我们评估中最小的核心。为了解决这个问题，我们为LSL$使用了索引访问方案。无序检查器核心不再按顺序访问日志。当检查器核心解码负载/存储时，我们根据预期的LSL$负载的大小在按顺序前端增加一个猜测计数器（第III-B节），以便索引将指向程序顺序中的适当条目（见图4）。对于负载，这个猜测索引跟随指令进入负载队列，并在数据负载字段中，直到被返回的数据覆盖。对于存储，它没有显式存储，而是在提交时重新生成，当访问日志时进行处理。当负载/存储指令被分解为微操作时，这些微操作共享相同的索引。由于索引是猜测性质的，即使没有发生错误，访问LSL$时，访问的条目也可能与索引条目不匹配：猜测错误的指令将被压扁，并且访问的条目是预定用于返回到正确执行的指令。因此，怀疑的故障必须作为精确异常来处理：我们记录LSL$访问时的错误，但直到提交时才引发它们。当指令被压扁时，猜测的索引必须进行调整，以匹配提交顺序。我们通过在每个被压扁的指令上从前端的猜测索引中扣除来处理这一点。此外，当检查器开始检查新的LSL$段/检查点时，这个索引会被重置为0。\nH. Eager Checker-Core Waking 在之前的工作[2]–[4]中，检查器核心仅在检查点完成后被唤醒，以确保执行的一致性。如果检查器核心足够简单，几乎不占用资源，这是合理的，但如果检查器核心的大小与常规核心相当，这样会浪费资源，因为至少有一个核心总是等待检查点完成而停滞。检查器核心可以提前启动，只要它从不执行超出主核心的指令，且因此不会读取无效的LSL$条目，也不能执行主核心从未执行的指令（由于达到超时或发生中断，第III-J节）。为了实现这一点，同时确保匹配行为并防止检查器核心提前执行，我们使用LSL$作为限制器。检查器核心不能执行任何超出当前推送到检查器核心的最后LSL$条目的指令。如果它尝试这样做，并且RCU检查点尚未设置，检查器核心将睡眠，直到向其LSL$推送一个缓存行或设置RCU检查点。试图读取LSL$中最后有效条目的内存访问指令会导致所有后续指令被压扁（除了作为相同宏操作的一部分的微操作）。当新的日志缓存行到达或接收到检查点寄存器文件以指示检查点结束时，取指从第一个被压扁的指令重新开始。如果读取最后有效条目的操作本身被压扁，指令取指也会重新开始，任何随后的尝试读取当前最后LSL$条目的操作都会使核心重新进入睡眠状态。\nI. Hash Mode ParaVerser使用大量的NoC流量将LSL$条目从主核心发送到检查器核心。为了限制这一点，我们还提供了哈希模式，其中仅记录执行所需的数据（例如，加载的数据）并将其传输到LSL$条目中，并通过NoC传输（条目仍按顺序连续存储）。仅用于验证正确性的数据（例如，地址和存储数据）会进行校验和处理，只有哈希值被传输到NoC并在检查点结束时进行比较。哈希模式将负载流量减少50%，并完全消除了存储的流量，但可靠性将取决于哈希函数的属性。不能检测相同位上的重复错误或重排序的哈希函数应避免使用——在这里我们使用SHA-256[29]。哈希模式需要对之前提到的机制进行一些修改。在哈希模式下，LSL$条目仅包含按提交顺序重现执行所需的数据，因此无序核心的猜测索引只有在指令具有这些数据时才会增加。对于微操作，偏移量在解码时计算并与索引一起存储，直到访问LSL$。主核心和检查器核心都使用LSPU来缓冲要用于哈希计算的数据，在指令提交时保持访问顺序。检查器核心不再使用LSC来检测LSL$访问错误。相反，哈希值在RCU中计算，并与寄存器检查点一起发送到检查器的RCU进行比较。\nJ. Multiprocess and Multicore 为了避免在主核心和检查器核心之间同时重播中断的需求，每当发生中断时都会进行寄存器检查点。这对于上下文切换也是如此：因此，每个寄存器检查点只与一个进程相关联。多个进程在一个主核心上的检查可以在多个检查器核心上并行进行，就像多个进程在多个主核心上的检查也可以并行进行一样。如果在任何特定进程的检查点中发生错误，则会引发该进程的异常。ParaVerser不是一个错误修正系统，因为它在执行和检查之间会产生延迟，以实现线程级并行性，因此，如果发现错误，软件必须自行清理（第II-C节）。ParaVerser使用的日志系统可以在不做修改的情况下扩展到多核共享内存工作负载[3]。由于主核心看到的确切负载和存储然后传播到检查器核心，任何由此产生的跨线程通信也会被准确地模拟和检查。在检查器核心分配方面，我们将每个主核心视为一个单独的检查任务，并将其分配到多个检查器中。\nSPHERE OF REPLICATION ParaVerser 是一种计算冗余机制，因此复制的范围是处理器核心本身，边界位于负载存储队列（LSQ），其内容被复制并通过负载存储日志（LSL）传输到检查核心。缓存位于复制范围之外，需要使用奇偶校验或错误更正码（ECC）来确保其正确性，以及缓存系统内部任何计算（如一致性）的冗余。\n检查核心上的冗余执行不会重复数据地址转换，并假设记录在 LSL 中的加载数据是正确的；如果希望覆盖核心的每个晶体管，应该在页表遍历器和 LSQ 中增加额外的冗余。在这种情况下，这涉及在数据发送到 LSL 之前传播和检查奇偶校验位，以及冗余机制来捕捉来自 LSQ 逻辑本身的故障错误（例如，由于位翻转而错误地检测到访问顺序违规）。\n在完全覆盖模式下，ParaVerser 可以检测系统中的硬错误和软错误。机会模式仅针对最终可以检测到的硬错误，但也会在检查的片段中检测到软错误。由于我们不区分硬错误和软错误，操作员需要在我们检测到错误后运行自己的测试，以确定核心是否存在硬故障并需要退役。如果需要更精确的故障分析，我们的起始寄存器检查点允许重复回放以识别故障原因，代价是每个核心额外 776B 的开销。不会改变执行的错误仍然可以被检测到，如果 LSL 的内容、哈希模式中的哈希值，或者寄存器检查点开始或结束时的寄存器值发生变化，我们无法直接区分错误来自主核心还是检查核心。这些可以被认为是假阳性，因为检测到的错误并不影响主核心的执行。然而，这些仍然代表系统中某个地方发生的真实错误；因此，它们仍然有助于在发生硬错误时尽早退役故障核心。在哈希模式下，我们使用 SHA-256 哈希，因为具有和不具有错误的值产生的哈希值碰撞的可能性极低，具有 128 位碰撞抗性安全性。\nEXPERIMENTAL SETUP 为了评估ParaVerser，我们将ParaDox模拟器[4]移植到了gem5 v22.0.0.1版本。我们添加了第III节中描述的新机制，并设计了高性能服务器风格的Arm核心CPU模型（见表I），基于公开的Cortex-X2 [6]，[11]，[92]和Cortex-A510 [10]，[91]核心的信息，这些核心分别构成了Arm异构数据中心Neoverse V2和E2的基础[81]。我们的主核心始终为3GHz的乱序核心；我们在不同的时钟频率下运行不同数量和类型（大核心、小核心）的检查核心。先前的工作[2]，[4]在原始评估中使用了gem5的通用MinorCPU模型，该模型例如为所有浮点运算提供了不现实的6周期延迟，而诸如除法等指令的延迟可能长达22周期[10]，[12]。即便是整数运算，该模型也缺乏共享相同功能单元的操作的可变延迟建模，而gem5的HPI核心则为我们的A510模型提供了这方面的改进。这意味着先前工作的核心模型并未提供合理的比较基础，因此我们采用了基于Cortex-A55 [12]的专用检查核心模型，并限制其为标量核心，以模拟Cortex-A34/35 [5]核心的性能（由于文档缺失）。这些是支持AArch64 [14]的最小乱序Cortex-A处理器。\n我们使用SPECspeed 2017基准进行评估，统计数据来自详细仿真，仿真1B指令，除非另有说明，模拟将跳过初始化并运行PARSEC至完成，慢速执行时相对于没有检查的基准来展示。在评估完全覆盖模式时，我们评估性能开销；在评估机会模式时，我们也评估检查覆盖率。\n我们通过将gem5网络参数输入到MM1排队网络模型中，模拟了NoC延迟，该模型采用2D网格布局。图5展示了我们实验中使用的4x4网格布局，核心作为主核心用阿拉伯数字0-3表示，作为相同颜色主核心的检查核心用罗马数字iiv表示。NoC配置为256位宽，时钟频率为2GHz，除非另有说明，类似于ARM Neoverse CMN-700网格网络的能力[7]。网格中间的4个交叉点每个都连接一个LLC切片和一个核心，每个LLC切片假定为每个主核心提供1/4的需求数据。除了角落的4个交叉点，其他交叉点每个连接2个核心。我们选择没有LLC切片的交叉点上的核心作为主核心，因为这种情况在我们的布局中更常见，而与主核心相邻的核心则作为检查核心使用。当使用异构主核心和检查核心时，该布局表示一个带有大核心和小核心分布的平铺系统，而不是同质核心的聚集。仅使用1个主核心时，使用核心0作为主核心；使用2个主核心时，使用核心0和核心1。在选择检查核心时，首先选择检查核心i，因为它会导致需求流量的争用并带来更大的性能开销。如果需要更多检查核心，则使用核心ii–iv。未使用的主核心和检查核心假定为空闲，不产生流量。我们通过回传从额外的LSL$流量中观察到的平均延迟，进入gem5的LLC访问延迟，以估算开销，并在第VI-D节中探讨NoC带宽的影响。\nEVALUATION(评估) A. 完全覆盖模式 图6显示了在完全覆盖模式下（所有动态指令都被检查）不同检查核心配置下主核心的性能下降，相比于先前的工作，DSN18 [2]配置了12个检查核心，Paradox [4]配置了16个专用检查核心。通过将检查核心配置为与3GHz主核心相同的异构系统，检查核心能够跟上主核心的执行进度，几何平均性能下降为1.6%。而DSN18的配置显示出9%的几何平均性能下降，无法跟上我们X2主核心的性能。虽然Paradox在16个专用检查核心的配置下显示出仅1.2%的性能下降，但这需要35%的面积开销（第VI-E节），限制了可用于计算的硅区域。ParaVerser提供了利用已有核心的检查功能，当检查功能关闭时，它不影响性能。采用2个运行在半频率（1.5GHz）的X2检查核心时，性能下降几乎与异构系统相同。虽然LSL流量与NoC的需求流量发生争用，但这一优势被由未共享组件（如icache预取和分支预测训练）带来的额外性能开销所抵消，导致略微增加的未命中率和预测错误率。使用4个运行在2GHz的A510核心作为检查核心时，性能下降为3.4%。检查核心的集体性能通常与主核心相匹配，除了bwaves。在bwaves中，大量的浮点除法指令和大核心X2 [11]与小核心A510 [10]之间在浮点除法性能上的巨大差异，导致最差的检查核心无法跟上最好的主核心。通过DVFS，我们还将A510检查核心的频率从2GHz调整至1.4GHz，并相应调整电压，以寻找每个基准的最佳ED2P点，性能下降仍仅为4.3%。\n接下来，我们考虑开销的原因：\n寄存器检查点 在之前的工作[2]中，寄存器检查点由于延迟主核心的提交来复制寄存器文件而产生显著开销，而在ParaVerser中，这种开销可以忽略不计。通过重新利用常规核心的缓存，我们拥有更大的LSL（64KiB对比3KiB [2]），因此检查点的频率大大降低。 停顿开销 在完全覆盖模式下，当检查核心无法跟上主核心时，主核心必须停顿，直到有检查核心可用。这是主核心减少时钟频率、数量和乱序能力时的主要因素。 指令获取 虽然检查核心永远不会引起对主内存或共享缓存的访问，因为它们的加载和存储通过LSL$提供服务，但它们仍然会通过LSL$访问指令。这在完全覆盖模式和机会模式下会导致轻微的争用效应，特别是在如gcc这样的工作负载中，其中频繁发生L1 icache未命中。 NoC开销 加载和存储会根据总线宽度（第III-C节）分组，记录并转发到检查核心。虽然这不会对检查核心造成显著延迟（因为它们是推送消息而不是请求消息），但它会对同一网络上其他请求造成次要争用效应，尤其是LLC访问。 B. 机会模式 图7显示了与第VI-A节相同的检查核心配置，但启用了机会模式，机会模式在资源不足时减少覆盖，而不是停顿。出乎意料的是，开销低于完全覆盖模式，对于异构系统，几何平均性能下降为1.4%，对于2个X2或4个A510，性能下降不到1%。开销主要来自于NoC争用，因此无论核心频率如何，性能下降都保持平稳。为了研究机会模式的硬错误覆盖率，我们根据文献中的标准模型[59]注入了硬错误，图8展示了不同检查核心配置下的结果。由于错误检测是对称的，为避免注入的错误妨碍主核心的执行，错误被注入到检查核心。我们将硬错误建模为单比特卡住错误，并将错误注入到gem5模型中的功能单元输出值。 在完全覆盖模式下，我们注入了10M条指令，发现76%的注入错误在完全覆盖模式下被检测到，其余错误（正确地）被掩盖，因为它们没有改变执行。图8中，几乎所有未被掩盖的注入错误都能在运行100M条指令内被检测到，即使只有一个A510运行在500MHz。对于大多数工作负载，这种配置能检测到所有有效错误；只有bwaves、deepsjeng、imagick和perlbench的检测率较低，为87-99%。除imagick外，其他所有工作负载在1GHz时可以达到100%的检测率，imagick在2个A510运行在2GHz时也能达到100%的检测率。\n我们还发现，在机会模式下，运行时指令覆盖率（即被检查的主核心指令的比例）在有足够的检查核心时较高。使用3GHz的X2检查核心时，几何平均覆盖率高达98%以上，且几乎没有性能开销。当检查核心频率降低至2.7GHz时，覆盖率降至94%。使用4个A510检查核心时，在2GHz、1.8GHz和1.6GHz时，几何平均覆盖率分别为97%、96%和95%。与完全覆盖模式中的性能下降类似，bwaves的运行时指令覆盖率显著低于其他基准，即使使用2GHz的A510，覆盖率也仅为71%，这是由于其大量的浮点指令。\nC. 数据导向、并行和多进程工作负载 为了展示更广泛的服务器端工作负载，我们还看了图形工作负载的GAP套件[20]。GAP如此依赖内存，以至于即使是少数几个检查核心也能跟上主核心的执行；图9显示，即使在完全覆盖模式下，2个A510也足以应对，除了PageRank之外。ParaVerser还能够处理并行工作负载。图9还显示了在2线程的PARSEC [23]上，ParaVerser在完全覆盖模式下的性能下降。虽然PARSEC不像GAP那样严重依赖内存，但当每个主核心使用3个A510时，性能下降仅为7.6%。\n为了评估ParaVerser对多进程工作负载的影响，我们运行了SPECspeed 2017基准的随机混合测试14，模拟了4个主核心的1亿条总指令（在最快的核心上快速转发10亿条指令后），每个核心至少运行250百万条指令（混合1-4）或至少100百万条指令（混合5），以应对模拟时间限制。图10显示了在不同检查核心配置下的总CPI性能下降。虽然来自一个进程的额外LSL流量与其他进程的需求流量发生争用，但整体性能开销较小，几何平均仅为1%，对于1.5GHz的异构检查核心或2个X2检查核心，性能下降不到0.6%，对于2GHz的4个A510检查核心，性能下降不到0.6%。\nD. NoC 灵敏度研究 为了评估 LSL 流量的影响，我们进行了灵敏度研究，将检查器核心配置为最高频率，并采用128位宽、1.5GHz频率的较慢 NoC 配置。同时，我们还展示了启用哈希模式（参见章节 III-I）对这一较慢 NoC 的影响。图11显示，一些基准测试受到了显著影响，导致几何平均开销超过15%。启用哈希模式后，LSL 流量至少减少一半，NoC 压力大幅缓解，使得几何平均开销降至仅比较快 NoC（256位宽、2GHz 时钟频率）高0.8%。较快 NoC 对同构检查器核心的 NoC 开销为1.5%，而对异构核心的开销低于1%。\nE. 功耗与面积开销 ParaVerser 修改仅增加了每个核心1064B的存储开销：包括2宽 LSC 的48B，每个加载和存储队列项的2位奇偶校验位（如果尚未存在）、前后端 LSL$ 索引的16位、用于 LSPU 的512位（或一个缓存行）、LSL$ 中每个缓存行的1位、指令计时器的13位以及RCU的776B。 此前研究【4】估算专用检查器核心的面积开销低于2014年 Cortex A57 的三分之一，但其基于 RISCV 核心，并与 ARM 主核心对比，尽管该技术需要相同的 ISA。我们基于 X2 和 A510 核心的晶圆照片像素计算【8】，使用三星 4LPE 工艺得出其面积分别约为 2.43mm² 和 0.44mm²。通过推算【32】【33】基于 28nm TSMC 的 A35 核心【5】，我们估算16个 A35 核心的面积约为 0.84mm²，导致35%的面积开销。 尽管检查器核心是从现有计算单元中复用而非新增，但每个检查器核心的开启势必比闲置状态消耗更多功率。我们通过 McPAT【60】在22nm下评估其开销。对于4个2GHz运行的 A510 检查器，静态和动态功耗加时间的能量开销几何平均值比全部检查器核心电源关闭的基线高49%。对于2个1.5GHz运行的 X2 检查器，能量开销为45%；而1个3GHz运行的 X2 检查器（同构，可比双核锁步【57】【58】【90】），能量开销为95%。 通过降低4个 A510 核心的频率和电压以减少运行至2GHz以下，我们实现了 ED2P 最小配置，其能量开销为29%，性能减速为4.3%（相比于全速下的49%能量开销和3.4%减速）。相比之下，针对先前研究中的专用检查器核心【2】【4】，我们观察到其能量开销为25%。考虑到额外的35%面积开销，与系统中现有的4个 A510 核心实现 ED2P 最小配置相比，这并未提供显著的能量节省。\nF. 计算机会成本 从另一种角度来看，用于检查的核心可以执行额外的计算。对于包括大多数 SPEC 应用程序在内的单线程工作负载，这无关紧要：程序在多核上并不更快。对于并行工作负载，直观上重复所有计算会导致2倍的减速。然而，并行应用程序的扩展性通常不如检查，且更依赖内存，导致竞争进而减慢所有核心的运行速度。例如，在1个大核心和2个小核心上运行 GAP，仅比单独运行1个大核心快1.52倍：相同数量的小核心可以在10%性能开销下实现全面检查。同样，对于在1个大核心和3个小核心上运行的 PARSEC，仅观察到1.44倍的加速，而将小核心用于检查的同一设置下的开销仅为7.6%。相比之下，同构设置下使用两个大核心时，GAP 和 PARSEC 的加速分别为1.9倍和1.8倍。\nCONCLUSION ParaVerser 是第一个能够在满足 HPC 和数据中心严格的功耗/性能/面积（PPA）限制的条件下，实现高覆盖率、低成本错误检测能力的系统。通过微小的改动，下一代服务器能够在性能不受损的情况下，同时实现强大的全面保障和高覆盖率采样。相较于仅依赖软件扫描器，硬件级的静默错误检测更能有效缓解日益严重的问题；通过归纳并行实现的异构性，则提供了此前仅能通过高成本锁步机制实现的高效保障。由于 ParaVerser 是通过重新利用计算单元，而非增加专用的高开销组件来实现检测功能，既需要保障的系统与无需保障的系统均可使用同一设备。ParaVerser 首次为大规模静默数据损坏问题提供了实用的解决方案。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-07T20:28:43+08:00","permalink":"https://VastCircle.github.io/2024/paraverser_harnessing_heterogeneous_parallelism_for_affordable_fault_detection_in_data_centers/","title":"ParaVerser_Harnessing_Heterogeneous_Parallelism_For_Affordable_Fault_Detection_in_Data_Centers"},{"content":"https://github.com/TheKingOfDuck/FileMonitor?tab=readme-ov-file\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-06T13:29:58+08:00","permalink":"https://VastCircle.github.io/2024/filemonitor/","title":"Filemonitor"},{"content":"firemershal 生成linux 执行文件 以下的命令可以构建工作负载 , 在构建完成之后可以在images 可以看到 br-base-bin 和 br-base.img 分别是 boot-binary (linux + boot loader) and root filesystem\n./marshal build br-base.json 通过 ./marshal launch br-base.json可以通过qemu启动linux\nfiremarshal的实现细节 wlutil/build.py\n构建工作负载的目标是生成一个可用的启动二进制文件，以及（可选的）一个用于启动的根文件系统。生成的输出可同时用于 Spike、Qemu 和 FireSim。唯一的例外是 Spike 不支持磁盘，因此用户可以选择为 Spike 创建仅包含 initramfs 的工作负载版本（该二进制文件同样可以在 Qemu 和 FireSim 上启动）。\nBuild Parents 第一步是确保工作负载的基础工作负载已准备就绪。Marshal 将首先遵循基础的依赖关系链，并确保在开始请求的工作负载之前构建所有依赖关系。一旦直接父级完成，Marshal 就会开始构建过程，创建父级根文件系统的副本，以用作请求的工作负载的基础（发行版对其 rootfs 进行硬编码以结束递归）。\nhost init 在执行任何其他操作之前，Marshal 会运行工作负载的host-init脚本（如果有）来准备工作负载。此脚本可以执行任何操作，因此我们必须在流程早期运行它，以防它更改从 Linux 内核源代码到根文件系统覆盖的任何内容。\nbuild binary wlutil/build.py:makeBin() 我们在完成 rootfs 之前构建了启动二进制文件(br-base-bin)，因为我们可能需要在 Qemu 中启动工作负载才能构建它。如果用户提供了硬编码的启动二进制文件，则跳过此步骤。\nCreate Final Linux Configuration 用户仅提供内核配置片段，必须处理这些片段才能创建真正的 Linux 配置。我们首先在 Linux 源目录（默认或用户提供）中运行“make ARCH=riscv defconfig”。然后我们附加配置选项以包含 initramfs（CONFIG_BLK_DEV_INITRD 和 CONFIG_INITRAMFS_SOURCE），更多信息见下文。然后我们调用 Linux 提供的脚本来组合内核片段（riscv-linux/scripts/kconfig/merge_config.sh）。\nBuild Platform Drivers FireSim 提供了一些非标准设备，这些设备需要定制的 Linux 驱动程序。特别是块设备驱动程序是启动可用系统所必需的。为了避免维护一个定制的 Linux 内核分支（以及要求用户与其保持同步），我们提供了一个定制的 initramfs，它在主系统启动之前加载这些驱动程序。\nFireSim 的驱动程序位于 boards/firechip/drivers 目录下。Marshal 首先在 Linux 源代码树中运行 make modules_prepare，然后基于提供的源代码编译每个驱动程序。这一过程在每次新构建时执行，以确保驱动程序与最新的内核源代码和配置保持一致（尤其是在工作负载使用定制内核时，这一点尤为重要）。\n目前，我们不支持替代驱动程序，因此任何定制的 Linux 内核必须在这些驱动程序方面与默认内核兼容。\nGenerate Initramfs 由于某些驱动程序必须在系统启动时加载，因此我们将这些驱动程序打包到一个定制的 initramfs 中，并将其编译到内核中。Marshal 通过在 wlutil/initramfs 的以下目录中组织多个文件系统来生成此归档文件：\ndisk/： 包含一个功能齐全的根文件系统，包括基于 busybox 的环境和一个 init 脚本。该脚本负责加载驱动程序，并查找启动磁盘（对于 QEMU 是 /dev/vda，对于 FireSim 是 /dev/iceblk）。 nodisk/： 仅包含用于加载驱动程序的 init 脚本（需要与一个可用的根文件系统配合使用）。 drivers/： 包含之前构建的硬件平台驱动程序。 devNodes.cpio： 一个预构建的归档文件，包含特殊设备文件 /dev/console 和 /dev/tty。这些文件需要特殊的创建步骤，因此我们仅创建一次并将结果提交保存。 Marshal 将所需的 initramfs 源文件在一个临时目录中合并为单个 cpio 归档文件，并配置内核在启动时包含此归档文件。\nLinux Kernel Generation and Linking 在所有依赖项完成后，我们终于可以编译 Linux 内核并将其与引导加载程序（bootloader）链接起来。尽管每个工作负载可以使用自定义的内核源代码，但所有工作负载都会使用相同的引导加载程序。最终链接生成的 sbi+linux+initramfs 文件会被复制到 images/workloadName-bin 路径下。\nBuild Rootfs Add Files Marshal 会将文件和叠加选项（overlay options）都转换为 FileSpec 对象列表，这些对象描述了源路径和目标路径。随后，使用 guestmount 工具将访客（guest）的根文件系统挂载到 disk-mount/ 目录下（具体逻辑见 wlutil/wlutil.py 中的 applyOverlay() 和 copyImageFiles() 函数）。\nGuest Init 现在我们有了可运行的二进制文件和根文件系统，我们可以运行用户 guest-init脚本（如果提供）。我们将映像配置为在启动时运行此脚本（请参阅下文了解如何操作），并在 Qemu 中精确启动一次。\nRun Script or Command 最后一步是应用用户的run脚本或command选项（如果有）。为简单起见，命令在继续之前被转换成运行脚本（存储在 中 wlutil/generated/_command.sh）。\n运行脚本以每个发行版的方式处理（因为发行版以不同的方式实现它）。Marshal 通过请求发行版生成我们应用于映像的“bootScriptOverlay”来抽象这一点。在 Buildroot 中，这会将脚本放置在已知位置并使用运行它的硬编码 init 脚本。Fedora 有一个运行该脚本的 systemd 服务。\nfiremershal\n附录 参考文献 一个成功boot的开源程序\n什么是initramfs\n\u0026lt;深度探索Linux操作系统:系统构建和原理解析\u0026gt;\n在本地FPGA跑firesim\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-04T21:26:52+08:00","permalink":"https://VastCircle.github.io/2024/chipyard_boot_linux/","title":"Chipyard_boot_linux"},{"content":"问题简述 对于chipyard的串口,猜测是通过log去打印的,但是即使是通过dpic-log打印,也应该传输到串口的地址,但是从波形图来看是没有的\n测试配置 class MyRocketConfig extends Config( new freechips.rocketchip.subsystem.WithNBigCores(1) ++ // single rocket-core new chipyard.config.WithUART(baudrate = 115200) ++ new chipyard.config.AbstractConfig) 串口输出 通过分析hello.riscv,可以看出发送串口数据的函数是sfputc_r\n具体ftrace是 main -\u0026gt; iprintf -\u0026gt; vfiprintf_r -\u0026gt; sfputs_r-\u0026gt;sfputc_r ,如果字符串是\u0026quot;hello world\u0026quot;,应该会循环11次\n以下代码在遍历字符串\n80000790:\t00044783 lbu\ta5,0(s0) 80000794:\tc399 beqz\ta5,8000079a \u0026lt;_vfiprintf_r+0x7e\u0026gt; 80000796:\t0f779263 bne\ta5,s7,8000087a \u0026lt;_vfiprintf_r+0x15e\u0026gt; 8000087a:\t0405 addi\ts0,s0,1 8000087c:\tbf11 j\t80000790 \u0026lt;_vfiprintf_r+0x74\u0026gt; 以下代码在输出数据,可以看出来0(s0)对应字符串对应的数据,函数输入是a1 ,所以通过观察0x800006d6读取的数据就可以得到相应字符串的值\n800006ce:\t00941463 bne\ts0,s1,800006d6 \u0026lt;__sfputs_r+0x22\u0026gt; 800006d2:\t4501 li\ta0,0 800006d4:\ta811 j\t800006e8 \u0026lt;__sfputs_r+0x34\u0026gt; 800006d6:\t00044583 lbu\ta1,0(s0) 800006da:\t864e mv\ta2,s3 800006dc:\t854a mv\ta0,s2 800006de:\tfadff0ef jal\tra,8000068a \u0026lt;__sfputc_r\u0026gt; 800006e2:\t0405 addi\ts0,s0,1 800006e4:\tff4515e3 bne\ta0,s4,800006ce \u0026lt;__sfputs_r+0x1a\u0026gt; 从波形看是没什么问题的\n这一段代码的作用是把字符写入缓存区 ,a1是具体的字符 ,a4代表缓存区的大小 , 12(a2)的内存区域写入的是缓冲区的大小,倒是可以看出缓存区大小是0-1,即最大值,12(a2)=0x8000021c8+12,代表的可能是调用者传入的目标缓冲区或流指针\n所以串口的数据实际上是写入了一个构建的缓存区\n000000008000068a \u0026lt;__sfputc_r\u0026gt;: 8000068a:\t465c lw\ta5,12(a2) # 从a2偏移12处加载缓冲区剩余大小到a5 8000068c:\tfff7871b addiw\ta4,a5,-1 # 将剩余大小减1，结果存入a4 80000690:\tc658 sw\ta4,12(a2) # 将更新后的剩余大小存回a2偏移12处 80000692:\t00075963 bgez\ta4,800006a4 # 如果剩余大小非负，跳转到800006a4 80000696:\t561c lw\ta5,40(a2) # 从a2偏移40处加载缓冲区低水位标记到a5 80000698:\t00f74563 blt\ta4,a5,800006a2 # 如果剩余大小小于低水位标记，跳转到800006a2 8000069c:\t47a9 li\ta5,10 # 将常量10加载到a5 8000069e:\t00f59363 bne\ta1,a5,800006a4 # 如果当前字符不是换行符，跳转到800006a4 800006a2:\ta115 j\t80000ac6 # 跳转到函数__swbuf_r的入口地址 800006a4:\t621c ld\ta5,0(a2) # 从a2偏移0处加载缓冲区当前指针到a5 800006a6:\t852e mv\ta0,a1 # 将当前字符（a1）复制到a0 800006a8:\t00178713 addi\ta4,a5,1 # 缓冲区指针递增1，结果存入a4 800006ac:\te218 sd\ta4,0(a2) # 更新后的缓冲区指针存回a2偏移0处 800006ae:\t00b78023 sb\ta1,0(a5) # 将当前字符存入缓冲区当前位置 800006b2:\t8082 ret # 返回到调用函数 从图中看串口是写入了0x8000023e0往后的,但是不管怎么样,这个数据都应该通过某种方式进行log出来\n发现l2是有请求过0x8000023c0的数据 , 为什么是c0,因为l2的block size=64,所以关于64字节对齐,就是请求0x8000023c0\n究其根本,应该是serdesser去请求了l2相应地址的数据,所以根据缓存一致性的协议,先从dcache 写回到l2再被读取\n所以说还是只能运用于仿真\n如何得到真正的串口 在经过一系列资料查找后,我目前得到的结论是printf本身就没有重定向到串口数据,要是需要在串口输出的话,需要实现串口数据的重定向,就是说,硬件上是没有什么问题的\n按照这种方式重写printf之后,能够正确跳转到串口的地址了\n/* For GCC compiler revise _write() function for printf functionality */ int _write(int file, char *ptr, int len) { int i; file = file; for (i = 0; i \u0026lt; len; i++) { UART_PutByte(*ptr++); } return len; } 发现相比与前面,主要是跳转到了函数__swbuf_r的入口地址,然后去执行__swbuf_r -\u0026gt; _fflush_r -\u0026gt;__sflush_r -\u0026gt;\n-\u0026gt; __swrite -\u0026gt; _write_r -\u0026gt; write\n这样得到能够写入串口的程序,但是貌似这样无法打印到终端上了\n000000008000068a \u0026lt;__sfputc_r\u0026gt;: ... 800006a2:\ta115 j\t80000ac6 # 跳转到函数__swbuf_r的入口地址 ... 附录 https://stackoverflow.com/questions/76611040/rocketchip-sifive-blocks-uart-unable-to-make-use-of-system-printf-function\nhttps://community.infineon.com/t5/PSoC-5-3-1/printf-with-newlib-nano-vs-newlib-retargeting-to-UART/td-p/110224\n参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-03T19:43:44+08:00","permalink":"https://VastCircle.github.io/2024/chipyard%E4%B8%B2%E5%8F%A3%E7%96%91%E9%97%AE/","title":"Chipyard串口疑问"},{"content":"zotero7 安装 ## 创建zotero目录,这里选择的是/opt/这个目录下创建的，因为这个目录通常放下Google Chrome和火狐浏览器和pycharm。 sudo mkdir /opt/zotero ## 复制解压文件到/opt/zotero目录下 sudo mv Zotero_linux-x86_64/* /opt/zotero/ ##更新zotero的桌面位置 cd /opt/zotero sudo ./set_launcher_icon ##创造软连接到应用程序桌面 ln -s /opt/zotero/zotero.desktop ~/.local/share/applications/zotero.desktop zotero style 配置easyscholar 参见网站https://www.easyscholar.cc/blogs/10007\nzotero tag 下载 https://github.com/windingwind/zotero-actions-tags\nzotero 6只能使用v0.3.0版本的\n动作 通过动作添加的标签便于我们对文献状态的判断（是添加进来待读的、还是已经打开读过了、还是打开度过了还做了批注和注释）。\n附录 参考文献 zotero7安装\n[插件网站][https://zotero-chinese.com/plugins/]\nzotero_style 文档\nzotero_tag的使用\npkmer-一些常见学术软件\nzotero中文社区\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-12-02T16:37:43+08:00","permalink":"https://VastCircle.github.io/2024/zotero_tag/","title":"Zotero_tag"},{"content":"针对不规则工作负载的事件触发可编程预取器 abstract 许多现代工作负载需要处理大量数据，通常伴随不规则的内存访问。现有架构在处理这些工作负载时表现不佳，因为现有的预取技术无法捕捉内存访问模式，导致这些应用程序严重依赖内存。尽管已经有一些技术可以通过显式配置预取器的遍历模式来显著提高性能，这些方法的适用性通常局限于特定的数据结构。\n为此，我们提出了一种事件触发的可编程预取器，结合了通用计算单元的灵活性与基于事件的编程模型，并配合编译器技术自动从带注释的原始源代码生成事件。这种方法允许做出更复杂的预取决策，而无需在需要中间结果时发生停滞。\n通过使用我们的可编程预取系统，并结合从应用程序中提取的小型预取内核，我们在仿真中针对多种图算法、数据库和高性能计算（HPC）工作负载实现了平均3.0倍的性能提升。\nIntroduction 许多现代及新兴的工作负载需要处理海量数据，这些数据往往无法完全存储在当前系统的缓存中。这些数据访问通常是不规则的，难以提前预测，导致执行过程中频繁受到高DRAM延迟的影响而出现严重的内存瓶颈和停顿。\n为应对这些挑战，目前有多种技术可供选择。一种方法是利用应用程序中的线程级并行性，通过激进的多线程技术来应对延迟，通过让多个线程同时处于等待状态来实现负载的并行化。例如，这种方法在运行于图形卡上的工作负载中较为典型。然而，这种技术的效果依赖于应用程序是否具备高度的线程级并行性，而这在大数据工作负载中往往并不成立。原因在于这些工作负载通常涉及对同一数据的复杂且不可预测的读写操作，并且很难为并行内核创建有效的分区。\n另一种方法是预取技术，包括硬件预取单元或软件指令。然而，传统的基于地址的（如步幅）预取器仅适用于非常规则的计算，例如处理密集矩阵或完全顺序的内存访问。基于历史的预取器则仅适用于高度重复的计算。这两种方法都不适用于许多大数据应用，例如数据库、图算法和许多高性能计算（HPC）工作负载，这些应用通常表现出更加复杂和不规则的数据遍历，包括指针追踪和间接数组查找。\n针对不规则访问，也有一些特定技术被提出，例如指针预取器，它通过观察内存加载来预取可能的指针。然而，这些技术无法在数组中进行预见性查找，无法处理常用的基于索引的数据结构（因为加载的内存不包含指针），并且由于缺乏对预取进行细粒度控制的能力，容易导致严重的内存过度预取。\n尽管传统的隐式预取技术在这些工作负载中并不成功，但仍有可能通过其他方法来减轻内存访问延迟带来的开销。针对各种内存受限应用的技术已经出现，通过显式配置遍历模式，可为特定工作负载带来显著的性能提升。然而，目前此类架构技术高度专用化，仅适用于目标计算，因而难以应用于通用系统。此外，由于这些技术的固定功能特性，它们难以应对该领域中算法的快速演变。\n为此，我们设计了一种基于事件的可编程预取系统，用于处理包括图算法、数据库和高性能计算（HPC）在内的多个领域的稀疏内存访问通用工作负载。**我们将一个传统的高性能乱序计算核心与一个专用的L1缓存预取结构相结合，并附加多个顺序执行的可编程预取单元.**这种基于事件的编程模型使得每个预取单元能够同时发出多个加载请求并对其作出响应，而不会导致停顿。这不仅允许系统基于先前预取的结果进行预取，还能够同时从多个数据结构中进行预取。\n此外，我们提供了编译器技术，用于根据原始源代码为这些核心生成事件程序，从而通过注释指定需要预取的内容，减少对手动配置的依赖，尤其是针对简单访问模式。对于一组广泛的内存受限基准测试，我们实现了3.0×的平均性能提升，在缓存中对预取数据的利用率很高，并且对大多数工作负载的额外内存访问需求几乎可以忽略不计。\nExisting Work 文献中关于预取的研究非常丰富，我们在此总结与不规则内存访问工作负载最相关的研究，并突出了其中对这些工作负载有益的元素。以下是一些研究的概述，包括Mittal和Falsafi与Wenisch的工作。\n预取单元 许多针对不规则工作负载高效执行的研究集中在高度专用的预取单元。这些单元通过控制特定访问模式的内存访问，并利用数据的并行加载来提高性能，通常可以实现显著的性能提升。例如，SQRL和DASX是专为B树、向量和哈希表结构的迭代访问设计的预取系统。同样，Kocberber等人专注于通过并行哈希表遍历优化数据库内部连接操作。在后续的研究中，他们进一步在软件中模拟了类似的技术。\n此外，Ho等人将预取单元的概念推广，通过将内存访问编码为一组规则，使加载和存储操作能够映射到数据流架构中。预取单元还能通过移除原始加载指令来实现能耗节约。然而，必须修改原始应用程序，产生与不具有提取器单元的设备不兼容的代码，并且通常不允许存储所提取的数据。\n可配置预取器 本文开发了一种在架构级别公开的可配置预取器，并且过去已经提出了显示其好处的想法。阿尔-苏赫尼等人在程序级别使用显式 Harbinger 指令来控制链表指针的获取。 Yang 和 Lebeck开发了一种用于链接数据结构的可编程预取方案。可编程提取器被允许停止，因此不能处理需要重叠存储器访问以实现高性能的模式。 Ainsworth 和 Jones 专门针对图形工作负载设计了一个可配置预取器，获得了大幅加速，但仅针对特定图形格式的特定遍历。科胡特等人设计一个可配置的预取器来获取列表的列表。\n隐式不规则预取器 许多研究尝试通过传统的隐式预取方案来处理不规则结构，而无需显式配置。这种方法具有吸引力，因为它减少了手动干预的工作量，也无需重新编译。然而，尽管取得了一些进展，这些方法至今尚未被商用系统采用。\n指针预取器 指针预取器通过从核心读取的缓存行中提取所有可能的虚拟地址来实现预取，这种方法已在多种方案中提出。其主要缺点是过度预取率较高，此外，这些方案无法处理许多工作负载中出现的数组间接访问模式。\n依赖图流提取 也有尝试通过检测依赖加载来在运行时提取依赖图流。这些方法通过在识别加载起点后，将动态检测到的加载流运行在可编程单元上，从而预取数据。然而，这需要在流水线的提交阶段增加大量的分析硬件，并需要显著的处理能力来运行检测到的加载流。\nRunahead 方案 Mutlu等人提出了一种runahead方案，利用缓存未命中时的空闲芯片资源动态预取数据。然而，这种方法因严格依赖指令流而受限，无法实现显著的前瞻性预取，也无法基于其他已预取的数据进行进一步预取。Hashemi等人对此方案进行了扩展，使用运行时分析硬件访问所有微架构状态，生成关键指令的代码片段。这些片段仍可能在依赖加载时停顿，但通过更简单的硬件完成数据加载，并移除了一些冗余执行。\n数组间接模式预取 Yu等人通过运行时分析执行代码，找到数组基址和每个数据元素的大小，从而捕捉步幅间接模式。这种方法实现了对单一模式的预取，但代价是缓存中需要复杂的分析硬件，这可能影响执行的关键路径。\n辅助线程 一种针对不规则应用的预取解决方案是使用独立的CPU线程在软件中进行数据预取。以下是相关研究的总结：\n自动生成的预执行线程 Kim 和 Yeung通过编译器分析自动生成“预执行线程”。这种方法的优点是不需要额外硬件，但它在高性能核心上使用额外线程，可能消耗大量能量。此外，该方法无法处理基于其他预取操作的预取，且容易因停顿而受限【28】。由于缺乏硬件事件队列，加载操作的同步变得困难且代价高昂。\n具有架构支持的辅助内核 Lau等人提出了类似的方案，但增加了架构支持：在主核心旁边附加一个小型辅助核心以协助处理任务。这种紧耦合机制在一定程度上缓解了同步问题，但仍然会出现与上述相同的停顿。此外，单个核心通常无法满足复杂访问模式的处理需求。\n分离访问与执行线程的核心 Ham等人提出了一个方案，将核心分为独立的访问线程和执行线程，运行不同代码。这种方法提供了更紧密的同步，并且由于每个线程是专用的，可以运行在更高效的硬件上。但它要求加载和计算单元都具有高性能，并且在处理复杂地址生成时仍会因中间加载而停顿。\n基于辅助线程的预取机制 Ganusov 和 Burtscher通过硬件支持，将观察到的加载操作转发给新生成的线程，从而在软件中模拟常见的 Markov【26】和步幅预取方案。\n我们的改进 我们在硬件中转发类似的数据，但创建了完全可编程的预取事件。这些事件能够对其他预取作出反应，支持真实数据结构的遍历，并通过许多专用单元的紧密耦合和运行自定义预取代码的轻量抽象来实现高效的并行性。\nmotivation 图1展示了数据库中常用的典型哈希连接内核的示例。我们通过对键数组的顺序访问进行哈希操作，间接访问哈希表数组，然后进行链表遍历。现有预取器在处理此类模式时面临多个挑战：\n哈希函数导致的访问不可预测性 由于哈希函数的存在，对哈希表数组的访问是不可预测的，且分布在内存的各个位置，缺乏空间和时间局部性。在不知道哈希函数的情况下，预取器几乎无法准确预取相关条目。 链表遍历的延迟问题 在链表遍历中，每个元素的处理工作量较少。尽管指针预取器可以识别l-\u0026gt;next作为下一个需要处理的元素地址，但由于while循环中每次迭代的工作量不足，预取器无法掩盖加载下一链表项时的内存访问延迟。 图2(a)显示了未修改代码的执行方式。浅绿色框表示哈希计算和哈希表桶的加载，深绿色框表示链表项的加载。框中的对角线表示由于数据等待从更低级缓存或主存到达而产生的停顿。可以看出，由于代码缺乏时间和空间局部性，每次加载都会导致停顿。\n软件预取 在这个示例中，软件预取比硬件预取器更有优势，因为我们可以在预取逻辑中编码哈希函数。图1显示了这种指令及其在代码中的位置。通过在for循环的未来固定迭代次数（即距离dist）预取，我们可以提前将哈希表元素加载到缓存中，以供后续使用。\n然而，对于链表遍历，软件预取无法提供帮助，因为软件无法得知哈希表项预取的结果。我们只能预取当前哈希表项的链表，但这与硬件的情况一样，存在无法隐藏内存访问延迟的问题。\n图2(b)展示了软件预取如何提升性能。黄色框表示预取地址计算和相应的预取指令。在本示例中，我们假设预取距离为1次迭代，即第1次迭代预取第2次迭代的哈希表桶，依此类推。如图所示，从第2次迭代开始，加载哈希表桶时没有停顿（尽管预取指令本身会产生一定的开销）。经过4次迭代后，执行时间比原始代码略短，但由于无法预取链表项，性能提升受到限制。\n多线程处理 第三种选择是利用线程级并行性（Thread-Level Parallelism, TLP）。for循环的每次迭代都可以作为一个独立的线程执行，从而隐藏内存访问延迟。然而，这种算法并非完全并行，因为若以无序的方式执行迭代会改变输出键的顺序，因此需要同步机制以防止这种情况的发生。\n图1展示了这一选项的代码，而图2(c)则展示了其在两个线程上的执行情况。当找到匹配的键时，线程需要等待其成为最老的迭代才能将结果写入输出数组，以保持顺序。这是通过调用wait_til_oldest()来实现的；同时，每次迭代结束时通过signal_iter_done()发出信号，用于跟踪当前最老的迭代。\n在示例中（图2(c)），第2次迭代的第一个链表项找到匹配键。然而，由于核心0上的第1次迭代仍在运行，第2次迭代必须等待第1次迭代完成后才能将结果写入输出数组。尽管存在这一空闲等待时间，在本示例中，通过尽可能重叠执行与停顿，多线程版本的完成时间仍然比软件预取更快。\n辅助线程 第四种预取方式是将循环中负责内存访问的部分复制到一个独立的辅助线程中。如果支持同时多线程（Simultaneous Multithreading, SMT），该线程可以在与主线程相同的核心的不同上下文中运行，以便将数据预取到主L1缓存中。图2(d)展示了该技术的执行情况。\n此方法的根本局限在于，辅助线程无法以足够快的速度加载数据，无法始终领先主线程。辅助线程无法使用预取指令，只能在每次加载时停顿以利用加载结果。虽然可以通过使用多个辅助线程在一定程度上缓解这一问题，但这需要消耗大量的系统资源，因为我们需要足够多的辅助线程来隐藏所有的内存停顿。(辅助线程非常快可以吗)\n为了实现这一点，我们需要让预取器能够对自身预取返回的数据作出反应，并让其了解所执行的计算内容，从而基于正在遍历的数据结构计算下一组预取地址。\n理想行为 在理想情况下，我们希望完全避免停顿。这种工作负载实际上包含大量内存级并行性（Memory-Level Parallelism, MLP），但现有技术无法充分利用。具体来说，我们可以在in.key数组上并行化，从而同时预取多个链表，并重叠顺序链表的预取操作。\n如果我们能够将预取地址的计算与主线程的执行解耦，并避免在每次加载时停顿，就能够利用这些并行性，在数据即将被使用前将其加载到缓存中。这将导致如图2(e)所示的执行方式：在经历一个预热阶段后，计算可以不受停顿影响继续进行，因为数据会立即从一级缓存中获得。\n为了实现这一点，我们需要让预取器能够对自身预取返回的数据作出反应，并让其了解所执行的计算内容，从而基于正在遍历的数据结构计算下一组预取地址。\nProgrammable Prefetcher(可编程预取器) 与常见的跨步预取器一样，新的预取由缓存内的读取事件以及到达缓存的预取数据触发。使我们的方案适合更多样化和不规则应用的原因是，这些事件具有可编程行为，由配置的地址范围触发，这会导致运行小型的、完全可编程的事件代码序列，从而生成新的预取。由于每个事件都与前一个事件分开，因此它们是极其并行的，从而可以在许多微型可编程单元上实现高效和高性能的执行。对先前的预取做出反应的能力是其他具有可编程性的方案（例如软件预取或辅助线程）无法实现的，允许在不停止的情况下预取通常具有多个相关访问特征的不规则模式。\noverview 图 3 展示了我们设计的总体架构。我们添加了可编程单元和支持硬件，用于根据程序的当前和未来工作集生成预取请求。预取器是基于事件的，以避免停顿，同时仍然能够通过早期预取结果支持进一步的预取操作。从主核发出的所有读取操作以及到达 L1 缓存的预取数据都会首先进入地址过滤器（见第 4.2 节）。被过滤为感兴趣的数据将进入观察队列，当调度器（见第 4.3 节）检测到有空闲的可编程预取单元（PPU，见第 4.4 节）时会将数据移出。\n这些可编程单元是低频、顺序执行的核心，针对从调度器接收到的每个地址执行一个小型的定制计算，并生成零个或多个预取请求。它们利用加载事件中的数据、配置在全局寄存器中的状态以及由 EWMA 计算器（见第 4.5 节）计算的前瞻距离，来生成新的预取请求，这些请求被放入一个 FIFO 预取请求队列（见第 4.6 节）。当 L1 缓存有空闲的 MSHR 时，它会从预取请求队列中取出一个预取请求并将其发送到 L2 缓存。\n在预取器未被使用的情况下，可以关闭其电源以避免影响性能。以下各小节将详细描述每个结构。\nAddress Filter 地址过滤器对来自主核的所有加载操作以及从 L2 进入 L1 缓存的预取数据进行监听。此过滤器保存了多个需要监控的地址范围，并利用这些范围生成新的预取请求，例如图 1 中内核的哈希表（htab）。地址过滤器通过运行在主核上的显式地址边界配置指令进行配置。这些指令由编译器或程序员在为 PPU 创建代码时生成。(哈希表去取线性表吗??)\n配置数据存储在过滤表中，其中包括每个重要数据结构的虚拟地址范围，以及两个指向小型计算内核的函数指针：Load Ptr（在观察到加载操作时运行）和 PF Ptr（在预取到该范围时运行）。\n部分配置也用于调度目的（见第 4.5 节），这些条目在表中标记出来。过滤后的地址（观测值）会连同其函数指针以及（在预取观测情况下）预取的缓存行一起放入观察队列。地址范围可以重叠；若一个地址属于多个范围，则队列中会为每个范围存储一个条目。\nObservation Queue and Scheduler 过滤后的地址会先放入一个小型观察队列中，随后再分配给核心。该队列是一个简单的 FIFO 缓冲区，用于存储观测值，直到有空闲的 PPU 可用。由于预取仅是性能优化措施，如果队列满了，可以安全地丢弃旧的观测值，而不会影响主程序的正确性。\n当一个 PPU 空闲时，调度器会将数据的缓存行和虚拟地址写入该 PPU 的寄存器，然后将 PPU 的程序计数器设置为与该观测值相关联的预取内核，启动核心执行。调度器的任务仅仅是监控 PPUs，并在需要时从 FIFO 观察队列中为它们分配工作。\nProgrammable Prefetch Units (PPUs) PPUs 是一组顺序执行、低功耗的可编程 RISC 核，与预取器的调度器相连，负责生成新的预取请求。PPUs 与主核使用相同的字长，以便能够通过一条指令执行地址运算。默认情况下，预取单元是暂停的。当观察队列中有数据且有空闲的 PPU 时，调度器将最旧的观察值发送到该 PPU 执行。PPU 运行直到完成内核任务，通常只需几行代码。在执行过程中，它会生成若干预取请求，这些请求会被放入预取请求队列，然后 PPU 进入休眠状态，等待调度器重新唤醒。\nPPUs 共享一个单独的多端口指令缓存，但不与主核共享指令缓存；(执行的是相对于的函数指针吗?)PPU 的代码与主应用程序代码是独立的，且任何观察值都可以由任意 PPU 执行。大多数应用程序所需的可编程预取代码非常小，因此指令缓存的需求较少：在第 7 节描述的基准测试中，每个应用程序的 PPU 从主存储器中获取的指令总量最多为 1KB。\nPPUs 没有加载或存储单元，因此不需要数据缓存。它们只能读取转发给它们的单个缓存行、本地寄存器存储，以及全局预取器寄存器。去除访问其他内存的能力既简化了 PPU 的设计，也减少了它们发生停顿的可能性。尽管这限制了预取计算中可用的数据，但我们尚未发现需要额外数据的场景。通常，预取代码只需从缓存行中提取一些数据，执行简单的算术操作，然后将其与全局预取器状态（如数组的基地址）结合，生成新的预取地址。\n由于无法访问其他内存，每个 PPU 也没有用于中间值的栈空间，但寄存器可以提供充足的临时存储。在实际应用中，这并未造成问题。\nMoving Average (EWMA) Calculators 对于某些应用，预取的前瞻距离无法通过固定值设置。它可能依赖于输入，并可能根据特定系统的时间统计信息变化。在一些工作负载中，特别是图的广度优先搜索中，预取距离可能在计算过程中发生变化，因为各阶段访问的元素大小不同 [1]。先前的研究通过考虑计算时间与内存访问时间之间的比率应对这一挑战。例如，Mowry 等人 [45] 将预取延迟除以循环中最短路径的指令数量，以确定需要预取的迭代次数。\n我们推广了这一思想，并在硬件中动态执行计算，使用指数加权移动平均（EWMA）计算器为各种观察到的事件生成时间。EWMA 可以在硬件中高效实现，仅需少量状态存储 [18]，因此 PPU 不需要执行时间计算。我们动态计算完成一串预取所需的时间与每次循环迭代所需时间的比率，并据此决定在基础数组中需要提前预取多远。这意味着我们尝试预取刚好在当前预取完成后将被访问的元素。\n当对某个数据结构的读取操作被观测到时，会记录该事件与该地址范围上前一个事件之间的时间。这可以为我们提供例如广度优先搜索中 FIFO 访问之间的时间间隔。为了计量加载操作的耗时，我们标记开始一次计时预取的 EWMA，并将当前时间附加到生成的事件中。随后将其传播到由此产生的预取操作，直到到达具有标志位的地址范围，然后使用事件之间的时间间隔作为加载时间 EWMA 的输入。\nPrefetch Request Queue 预取请求队列是一个 FIFO 队列，包含由 PPU 计算得出的尚未处理的虚拟地址，用于预取操作。当 L1 数据缓存有空闲的 MSHR 时，它会从队列中取出最旧的条目，通过共享的 TLB 将其转换为物理地址，然后向该地址发出预取请求。与观察队列类似，如果队列已满，可以安全地丢弃旧请求，而不会影响应用程序的正确性。\nMemory Request Tags 虽然数组范围（可以通过虚拟地址边界捕获）可以通过第 4.2 节讨论的配置步骤轻松识别，但预取器需要响应的结构不仅限于此。链式结构（如树、图、链表）可能在非连续的内存区域中逐个元素分配，并且在预取数据到达缓存时需要进行识别。\n为了解决这个问题，我们在 MSHR 中存储一个标记，用来标识预取目标的数据结构，例如哈希表桶的链表。当预取请求返回数据并且带有已注册的标记时，缓存行将被发送到加载了该结构函数指针的 PPU，进行进一步的处理。每个结构都会有具体的结构函数.\nHardware Requirements 尽管预取器具有许多可编程单元，但每个单元都非常小，类似于微控制器的规模，例如 ARM Cortex M0+，其包含不到 12,000 个门电路（大约 50,000 个晶体管）[7]。根据公开数据 [4, 5]，在相似的硅工艺下，我们可以预计这十二个核心的硬件影响大约占 Cortex A57 处理器面积的 1.3%（不包括共享缓存）。在实际实现中，可能希望支持这些核心的 64 位操作，因此我们可以预期面积将增加到 2.6%。当我们为指令缓存、全局寄存器、预取请求队列和观察队列增加 8.5KiB 内存 [56] 时，总的面积开销仍然只有 3%。这一开销与 L1 数据缓存的面积相当。\nsummer 我们开发了一个可编程预取器，它响应过滤后的加载和预取观察事件。这些输入到一组可编程单元中，这些单元根据事件运行内核以向缓存中发出预取。为了简洁起见，我们在这里省略了多核预取的介绍，但实现和预期结果是相似的 [1, 2]。以下部分描述了如何对其进行编程。\nOS and Application Support 为了使预取器发挥作用，必须为每个应用程序生成定制代码。本节描述了用于这一目的的基于事件的编程模型，适用于多个 PPU 上的延迟容忍取指。它还考虑了与操作系统和上下文切换的交互。在本节中，我们假设预取代码是手动编写的。接下来，我们将在第 6 节中探讨编译器的支持.\nEvent Programming Model PPU 编程模型是基于事件的，这与预取指令的特点自然契合，因为预取指令在返回数据之前具有可变的延迟。事件生成预取操作，而不是加载操作，这些操作可以在数据到达核心时通过新事件进行响应。当资源可用时，预取请求会被发往内存层级，如第 4 节所述。这种方式自然具备延迟容忍性，避免了等待预取数据时 PPU 的停滞。\n运行在 PPU 上的事件是由加载或预取到缓存中的地址决定的。如果预取操作返回数据，调度器可以选择任何 PPU 来执行相应的事件，而不必局限于发起事件的单元。这使得该架构适合处理需要加载中间值的预取操作，否则这些操作会导致预取器停滞。\n这种编程方式的一个优点是，PPU 不需要在每个事件的计算之间保持状态。每个事件的代码类似于传统处理器中的标准 C 函数，但有一些限制。由于 PPU 无法访问内存（除非是发出预取请求），因此无法进行数据加载、存储或堆栈存储。PPU 可以访问的唯一数据是触发事件的地址、已观察到的缓存行（存储在本地寄存器中）和全局预取器状态（存储在全局寄存器中，如地址边界或配置的值，如哈希掩码）。\n我们为 PPU 添加了特殊的预取指令，这些指令不同于软件预取，因为它们会在返回数据后触发随后的事件，由 PPU 处理。不能进行函数调用，因为没有堆栈，也不支持系统调用。预取事件可以随时终止，因为它们对于主核心上运行的应用程序的正确执行不是必需的。例如，当上下文切换时，当前应用程序被移出主核心，此时所有 PPU 会被暂停，且其预取事件会被中止。此外，任何通常会导致陷阱或异常的操作（例如除以零）都会立即终止预取事件。\nexample image-20241206205302636 考虑图 4(a) 中的程序。它的数据访问非常不规则，具有间接访问数组 B 和 C 的特点。然而，由于数组 A 的顺序访问，我们可以利用每次迭代中的内存层级并行性，来并行加载数据。这可以通过加载 PPUs 以执行图 4(b) 中的代码来实现。我们假设 A、B 和 C 都是 8 字节值的数组。通过在原始代码中插入指令，我们将数组 A、B 和 C 的地址范围分别配置为预取器的地址范围 0、1 和 2。同样，图 4(b) 中内核的地址也被提取并配置为预取器的相关加载事件。\n当主程序对 A 进行读取时，预取事件被触发，从当前读取的地址开始，提前预取两缓存行。当预取完成后，获取到的数据将作为索引分别用于访问 B（get_base(1)）和 C（get_base(2)）。\n需要注意的是，预取器代码是将一组阻塞加载转换为一组非阻塞的预取事件。主程序的核心代码保持顺序执行且没有改变，唯一的变化是插入了配置指令。大部分的缓存缺失应该通过 PPUs 提前发出加载请求来避免，从而减少核心程序的缓存缺失。预取器函数（get_vaddr()、get_base() 和 get_fetched_data()）是编译器内建函数，它们会被转换为寄存器读取或从附加的小型共享预取器状态内存中加载数据。\nOperating System Visibility 尽管 PPUs 拥有与常规核心类似的许多功能，但它们并不会被操作系统视为独立的核心，因此操作系统无法将进程调度到它们上。相反，操作系统只能看到需要在上下文切换时保存的状态。虽然在某些情况下，操作系统将 PPUs 视为完整核心可能是有用的，但避免与操作系统的交互简化了它们的设计（例如，它不需要特权指令）。因此，尽管预取器会发起页表遍历，但它无法处理页错误，遇到这种情况时我们会丢弃该预取。\n预取单元仅用于提升性能，不能影响主程序的正确性。因此，所需保存的状态量很小。例如，我们不需要保留内部 PPU 寄存器，而只需在上下文切换时丢弃它们。出于同样的原因，我们也可以丢弃观察队列中的所有事件和获取队列中的地址。只要上下文切换不频繁，这将导致性能下降较小。EWMA 值在上下文切换时不需要保留，因为它们可以重新计算。\n因此，在上下文切换时所需保存的内容仅是预取器配置：全局寄存器和地址表。\nCompiler Assistance 手动编写事件需要大量的手动工作。更理想的方式是通过编译器从原始代码中生成这些事件，以便最终用户使用。软件预取[2, 12]是一种常见的技术，处理器可以在不等待结果的情况下将数据加载到缓存系统中。这种方法为最终用户提供了高层次的抽象，但如第3节所讨论的，直接执行时存在许多缺点。然而，我们可以通过逆向分析循环中出现的地址生成代码，来生成硬件事件，从而生成可编程预取器代码。这使得我们能够在不减慢主计算线程速度的情况下执行预取。我们提供了在LLVM [36]中实现的编译器传递，既可以将软件预取转换为可编程事件，也可以通过在程序员需要预取的循环中添加pragma，直接生成事件，从而提供了一系列的技术，权衡了手动工作与性能之间的平衡。伪代码如算法1所示。\nAnalysis 我们的编译器分析传递从软件预取指令开始，利用深度优先分析数据依赖图向后追踪。我们在遇到常量、循环不变值、非循环不变负载或phi节点时终止。目标是将预取地址生成拆分为一系列节点，最终形成一个以单个负载结尾的序列，并将在后续的传递中将其转化为PPU事件。\n为了为PPU代码获得适当的提前量，软件预取指令必须位于一个具有可识别归纳变量的循环中。我们还需要一个使用归纳变量访问的数据结构，以便可以通过观察缓存中的负载来推断其值。\nPhi节点标识要么是循环的归纳变量，要么是其他受控制流依赖的值。在前一种情况下，只要在深度优先搜索的当前迭代中没有找到负载，我们就可以将归纳变量替换为通过地址推断的代码，并将找到的指令集作为一组预取的第一个事件。后一种情况需要更复杂的分析，并且在实际中较为罕见，因此我们不再讨论。\n如果在搜索中发现多个不同的非循环不变负载，那么将使用多个加载的值来创建地址，而事件不能由单个数据值的到达触发。在这种情况下，转换失败。然而，如果只找到一个负载，我们将这些指令打包成一个事件，并从负载开始重复分析。\n图6展示了图5(a)中代码的控制流图。分析从预取指令（第14行）开始，对其输入v5进行深度优先搜索，并在达到第12行的负载时终止。由于这是一个非循环不变负载，这三条指令被打包成一个事件，分析重新从负载开始。接着，第二次分析传递在第10行的负载处终止，再次创建一个事件。最后，第三次分析传递在phi节点处终止，该节点对应于循环的归纳变量，因此创建了一个新的事件，不再需要进一步分析。\nArray Bounds Detection 预取器需要获取通过归纳变量访问的每个数组的地址边界，并将其存储在地址过滤器中，以便在监视到加载或预取时触发正确的事件。例如，在图6中的代码中，必须在观察到主核心对数组A的加载时执行事件A。返回的预取通过使用内存请求标签来处理，这些标签在第4.7节中进行了描述。\n每个数组的起始地址可以通过地址生成指令轻松获取，在有类型的数组的情况下，结束地址也很简单，因为数组的大小是明确声明的。然而，在像C这样的语言中，数组通常表示为指针，这使得确定地址边界变得更加复杂。一种方法是针对常见情况进行模式匹配，例如，向后查找分配指令。另一种方法是识别循环终止条件，前提是该条件是循环不变的。\nCode Generation 代码生成阶段的任务是插入预取器配置指令、生成PPU代码并删除原始的软件预取指令。使用第6.2节中描述的分析，已知数组的边界，因此为每个数组的配置指令会放置在循环之前。同时，为PPU代码所需的任何循环不变值添加配置指令，将它们分配给唯一的预取器全局寄存器。\n为了生成预取器代码，我们从第6.1节中通过分析识别的指令集合，转换为事件函数。在第一个事件中，我们用当前地址观察值（可以从PPU寄存器访问）减去基数组地址并除以数组元素的大小（通常转换为移位操作）来替换归纳变量的phi节点。我们用硬件预取指令替换每个事件中的最后一条指令，该指令可能是加载或软件预取。对于加载，我们添加回调，以便当此预取返回时，调用序列中的下一个事件。我们将所有循环不变值替换为对在主代码中配置的全局寄存器的访问。剩下的唯一加载必须是从当前预取或加载事件中观察到的数据，因此可以将其转换为寄存器访问。最后，删除现在不再需要的软件预取指令。然后使用死代码消除技术去除仅用于软件预取的代码，保留仍然需要的指令的公共子表达式。\nPragma Prefetching 虽然软件预取是一种相对描述性较强的机制，可用于转换为硬件事件，但这仍然需要一些手动操作。一种选择是让编译器负责生成初始的软件预取【2】，然后将其转换为事件。然而，一个更简单直接的选择是直接指明需要进行预取的循环，并让编译器从头生成预取事件。我们通过一个自定义的预取编译指令（如图5(b)所示）支持这一功能，采用与第6.1节类似的深度优先搜索方法。\n我们从具有间接访问的加载开始分析（这些加载很可能发生缺失），并基于发现的归纳变量进行预取。以这种方式生成代码意味着我们掌握的信息少于软件预取阶段的情况，因为软件预取阶段可以对哪些数据会发生缺失以及哪些数据将被访问进行运行时编码，而循环上的简单编译指令可能会遗漏这些信息（例如，数组访问的步长模式）。此外，如果没有更多信息，编译时无法决定哪些加载可能访问已在L1缓存中的数据，因此对这些数据结构的预取是多余的（尽管可以通过分析硬件在运行时禁用这些预取）。然而，对于简单模式，这种描述器与软件预取转换一样强大。\nEvaluation 为了评估我们的预取器性能，我们使用 gem5 模拟器【10】在全系统模式下模拟了一个高性能系统。该系统运行 Linux，并采用 ARMv8 64 位指令集，其配置如表 1 所示，与之前的研究验证过的配置类似【21】。\nPerformance(性能) 图7显示，相比于未使用预取的情况，我们的可编程预取器在内存受限的工作负载中（详见第7节）通过手动编程(manual)可实现最高4.3倍的加速，而普通的步幅预取器(stride)和软件预取器(software)分别只能实现最高1.4倍和2.2倍的加速。\n使用常规配置的马尔可夫全局历史缓冲器【48】未能实现任何加速，因为我们评估的应用程序访问的数据量过大，仅凭其有限的状态无法进行有效预测。当我们将状态量扩展至1GiB（大容量配置）时，仅在访问数据量较小的基准测试（如 G500List 和 ConjGrad）中获得性能提升。而其他应用程序由于访问的数据量即使对于一个非常大的历史缓冲器来说仍然过多，或者其内存访问模式不具有重复性，因而无法从该技术中获益。\n通过编译器辅助的软件预取转换（converted）在大多数基准测试中获得了与手动编写事件相似的加速，但在 Graph500 工作负载中表现略逊。而基于pragma 的自动事件生成技术（pragma generated）能够对较简单的访问模式实现与手动编写事件相当的加速效果，但在我们的八个基准测试中有四个未能充分发挥其潜力。\nimage-20241206213624315 Speedups(加速比) 三个基准测试通过软件预取获得了显著的性能提升，分别是 RandAcc、IntSort 和 HJ-2。它们的访问模式基于单一步长加载的数组间接访问，非常适合软件预取。这种空间局部性意味着预取地址计算不会引发大量的流水线停顿。然而，在极端情况下（例如 IntSort），软件预取导致了动态指令数量的显著增加，IntSort 增加了 113%，RandAcc 增加了 83%，HJ-2 增加了 56%。相比之下，在我们的方案中将预取地址计算转移到可编程预取单元（PPUs）后，加速比更高：IntSort 从软件预取的 2.0× 提升到 2.8×，RandAcc 从 2.2× 提升到 3.0×，HJ-2 从 1.4× 提升到 3.9×。\n在其他基准中，步长和软件预取带来的收益较小，但我们的预取器能够解锁更多的内存级并行性，实现显著的加速。例如，在 HJ-8 中，步长和软件预取的加速几乎可以忽略，但我们的 PPUs 实现了 3.8× 的加速。\nG500-List 是唯一的显著例外，尽管实现了 1.7× 的加速，却是我们的预取器中表现最差的基准。这是因为该应用程序中不存在细粒度的并行性：图中每个顶点的出边被存储在一个链表中。当预取某个顶点时，每条边只能通过前一条边的指针来确定，这实际上将边的处理序列化了。相比之下，Peled 等人[50] 在同一基准测试中未能取得任何性能改进。\n在图 7 中，PageRank 的软件预取和预取转换没有柱状条。这是因为 Boost 图形库代码使用了模板迭代器，迭代器只能访问边对(pair)，无法获取单个元素的地址，因此无法插入软件预取指令。通过编译器辅助的预取（包括 pragma 和软件预取转换）在 IntSort、ConjGrad 和 HJ-2 中表现良好。\n在 PageRank 中，由于代码不允许插入软件预取指令（高层迭代器的限制），这对我们的 pragma pass 并不是问题，因为 pragma pass 在 LLVM IR 上工作，可以自动发现访问模式并生成事件。然而，在 IntSort、ConjGrad 和 PageRank 中，使用 pragma 自动生成的预取略微降低了性能，这是因为生成了一些无用的预取，而不是因为无法发现访问模式。\nRandAcc 中，pragma 转换获得的性能提升低于手动编写的软件预取。这是因为该基准反复迭代一个小的 128 项数组，手动预取时可以编码循环回绕的预取。而这一特性涉及多个控制流循环，自动化分析难以发现，因此我们的方案没有预取数组的前几个条目。但 pragma 方案对程序员的工作量要求比手动预取低得多，程序员只需标识目标循环，而无需手动指定预取逻辑和前瞻距离。\nHJ-8 在使用软件预取转换时获得了显著的性能提升，这是因为我们可以指定预取前 N 个哈希桶。这与软件预取不同，因为软件预取无法以延迟容忍的方式实现这一点（需要读取预取数据）。而对于 pragma 生成方案，由于 N 无法从代码中轻松推导，也存在类似的问题。通常，哈希表每个桶中元素较少，因此即使元素数目不同，保守的 “前 N” 方法也可以很好地工作。然而，通过手动预取，可以引入控制流循环，遍历每个桶，直到尝试预取空指针为止。\nG500-CSR 的性能随预取的程序员工作量增加而逐步提升。由于编译器转换无法处理控制流（软件预取本质上无法表达循环），因此无法预取数据相关的边范围，只能以固定 N 预取前 N 条边。此外，由于编译器 pass 假设一次只访问一个加载值，因此无法利用每个顶点的起始值和终止值会位于同一缓存行的知识。\n在 G500-CSR 中，pragma pass 无法识别从顶点数据中获取边或访问值的需求，这是由于其中复杂的控制流。结果仅实现了两种从 FIFO 队列到顶点、从边到访问信息的 stride-indirect 模式，限制了可实现的预取性能。尽管如此，这仍然显著高于其他近期研究[50]，其在相同基准上获得的性能提升不足 10%。\n由于 G500-List 严重依赖于链表形式的长边列表，其有效预取需要循环控制流。因此，无法将其表示为软件预取，编译器 pass 的作用也受到限制。\n对 L1 缓存的影响 图 8 对此进行了更详细的探讨。图 8(a) 显示，尽管在大多数基准中，使用我们的预取器时 L1 缓存利用率很高，但在 G500-List 中却相对较低。在该应用中，对于较大的顶点，其边链表可能超过 L1 缓存的容量。遍历该链表可能导致预取的数据在使用前因容量缺失（capacity misses）而从缓存中被驱逐，原因可能是： a) 对同一边链表的后续预取； b) 对其他数据的预取或加载。\n根本问题在于预取发生得过早，但没有机制可以延迟这些预取。除了在顶点被预取后启动边链表的预取之外，唯一的其他可能点是在实际应用线程开始处理该顶点时启动链表预取。然而，此时已经太晚，因为主线程需要依次处理这些边，导致预取和主应用的加载几乎同步执行（类似于图 2(d) 所示的情况）。\n图 8(b) 显示，尽管如此，G500-List 的 L1 缓存读命中率确实从 0.34 提升到了 0.42，但提升幅度有限。然而，尽管如此，该应用仍然从边链表的提前预取中获得了一定的好处，因为这些边被放置在 L2 缓存中。在这种情况下，L2 缓存的命中率从 0.20 提升到了 0.57。\nAnalysis 我们现有的可编程预取器配置包含 12 个 PPU，每个 PPU 运行频率为 1GHz，而主内核的运行频率为 3.2GHz。我们现在表明，这实现了大部分好处，并且随着 PPU 数量及其频率的增加，扩展继续进行，因为预取内核是令人尴尬的并行.\n时钟频率 图 9 显示了 PPU 时钟频率如何影响各个基准测试，以及减少 PPU 数量的影响。图 9(a) 表明，大约有一半的工作负载在提高 PPU 频率时收益不大。另一方面，HJ-2 需要 500MHz 的频率才能实现其最大加速比，而 ConjGrad 和 G500-CSR 的加速比随着 PPU 频率的提高持续增长。总体来看，大多数性能提升在 1GHz 时已能实现，此时几何平均加速比为 3 倍，而在 2GHz 时略微增加到 3.1 倍。\nPPU 数量 我们在图 9(b) 中探讨了 PPU 频率与 PPU 数量之间的关系，以 G500-CSR 为例，选择了一个随着频率增加而持续扩展的应用。我们将 PPU 频率的上限设为 4GHz，作为一个研究案例，用以评估这种关系；我们并不期望 PPU 的时钟频率达到此值。图中显示，通过将 PPU 数量加倍并将频率减半，能够维持加速比。例如，使用 3 个 PPU 在 2GHz、6 个 PPU 在 1GHz 或 12 个 PPU 在 500MHz 时，都能达到 1.9 倍加速比。运行在 PPU 上的预取内核是高度并行的，因为每次调用都是独立的，因此可以通过增加 PPU 数量或提高其频率来实现扩展。图中还显示，对于该工作负载，性能在 12 个 PPU 和 2GHz 时趋于饱和，进一步增加频率不会带来更多收益。\nPPU 活动 图 10 进一步探讨了在 1GHz 下，12 个 PPU 执行计算时的工作量。该图展示了每个 PPU 在计算过程中保持活跃的时间比例。我们的调度策略是从可用的 PPU 中选择 ID 最低的一个来分配预取工作。这意味着 ID 较低的 PPU 活跃的时间比 ID 较高的 PPU 更多。其他调度策略（如轮询）会将工作更均匀地分配，但不会改变整体性能，也无法进行这种分析。\n当工作负载是预取-计算绑定时，增加更多的 PPU 或提高时钟频率会提升性能（如在 G500-CSR 中）；工作会均匀地分配给 PPU，所有 PPU 都保持忙碌。相比之下，像 PageRank、RandAcc 和 IntSort 这样的基准测试无法充分利用所有 PPU：这些工作负载中至少有一个 PPU 永远不会被唤醒。主要原因是它们仅需简单计算来识别未来的预取目标。这些应用在较慢的 PPU 上或使用较少的 PPU 时，也会达到相似的性能（如图 9(a) 所示）。\nConjGrad 是一个异常情况，虽然一些 PPU 执行的工作很少，但它依然随着频率的增加而扩展（如图 9(a) 所示）。这种行为的原因是，在 1GHz 时，并没有足够的工作量需要所有 PPU 都活跃，但预取操作略有延迟。因此，当时钟速度增加时，预取计算完成得更早，从而获得了些许额外的性能提升。与此不同的是，G500-CSR 也随着时钟频率的提升而扩展，提升频率可以增加更多的预取操作，从而提高性能。\n没有应用程序的 PPU 是持续运行的：最大活动因子为 0.82。这反映了 PPU 仅在主核心发生事件时才会响应，因此在没有数据需要预取的阶段，它们是不需要的。\n额外内存访问 为了高效执行，减少我们向内存总线添加的额外流量是理想的目标。通常，编程解决方案应该非常高效地进行预取，只针对计算所需的地址进行预取。除了两个 Graph500 基准测试外，其他大多数基准测试的额外访问值是微不足道的：预取非常准确且及时，因此不会预取未使用的数据。G500-List 因为缺乏细粒度并行性而增加了 40% 的额外访问。这是由于链表的基本限制，限制了及时预取，正如第 7.1 节所讨论的那样。G500-CSR 增加了 16% 的额外内存访问，由于每个顶点的工作量不均，预取距离必须相对于 EWMA 被高估\n事件触发 为了研究我们通过延迟容忍的基于事件的编程模型所获得的性能，我们扩展了系统以支持对用于进一步计算的数据进行加载阻塞：如果预取是链中的最后一个，那么核心将可供调度，但如果不是，必须停顿，因为在没有事件触发的情况下这是必要的。结果如图 11 所示。当访问模式是简单的步幅间接模式时，性能相对接近：我们只需要在步幅访问时停顿，并且通过在单个线程中预取整个缓存行来缓解停顿的开销，从而每 8 次访问就会发生一次停顿。这意味着内存级并行性仍然很高。然而，当访问模式变得复杂时，性能会显著下降。在复杂的访问模式下，停顿会限制甚至完全消除预取带来的性能提升，因此即使有来自十二个核心的大量并行性，延迟容忍事件仍然是系统能够正常工作的必要条件。\nConclusion 我们提出了一种可编程预取器，它使用基于事件的编程模型，能够提取内存级并行性并提高各种不规则内存密集型工作负载的性能。在选择图形、数据库和 HPC 工作负载时，我们的预取器在不显着增加内存访问次数的情况下实现了平均 3.0 倍的加速。我们进一步提供了编译器技术，以减少程序员利用我们方案的性能优势的手动工作量，我们提出的两种方案平均加速 1.9 倍和 2.5 倍。\n附录 参考文献 哈希表\n指数移动加权平均法\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-11-29T23:39:07+08:00","permalink":"https://VastCircle.github.io/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/","title":"An_Event_Triggered_Programmable_Prefetcher_for_Irregular_Workloads"},{"content":"linux环境搭建的要求 1.搭建交叉开发环境 需要搭建交叉开发环境在pc机上编译出符合相应嵌入式系统体系结构和指令集的机器码，同时确定目标机和主机的连接方式，搭建数据传输通道。\n一般而言，目标机、主机的连接方式有：\nUART异步串行通信接口 USB串行通信接口 TCP/IP网络通信接口 Debug Jtag调试接口 连接方式的选择将会相应决定需要给SoC增加什么外设。\n2.移植u-boot\nu-boot是一个通用的引导程序，也就是bootloader的一种，它的功能是引导操作系统，即将内核加载到DDR中，而DDR必须要软件进行初始化才能运行，因此在搬运内核之前U-boot还需要初始化内存。U-boot的启动过程分为stage1和stage2两大部分，处理器驱动一般在stage1用汇编语言来实现，这一部分代码位于start.s文件中，实现定义执行入口，设置异常向量，设置中断控制器等功能。而stage2则一般用c语言实现，包括调用一系列初始化函数，初始化SD卡等系统设备。\n3.Kernel的配置，编译和移植\nKernel本质上也是一个程序，从开始运行一直进入到最后的while(1),内核一旦成功运行，U-boot即完成工作，内核则会一直在内存中运行，直到系统复位重启。内核会根据U-boot传递的参数去指定地址寻找根文件系统rootfs,一旦找到rootfs之后，控制权则会传递给文件系统。\n4.根文件系统的制作\nLinux需要在一个分区上存放系统启动的必要文件，内核启动运行后的第一个程序(init一号进程)、用于挂接文件系统的脚本、shell程序等，这些必要的文件的集合称为根文件系统，根文件系统的制作和移植则是Linux系统移植的最后一部。\n通过上述四个步骤我们可以确定一个能运行Linux系统的SoC最少需要如下外设：\nUART异步串行通信接口：实现目标机和主机交互 Debug Jtag调试接口：这里是根据选择的数据传输通道确定，用于完成程序的加载 BootRom:一小块内存单元，包含处理器在上电或者复位时执行的第一个代码。用来存储引导程序U-boot或者其他外设测试程序，一旦系统上电处理器就会运行BootRom中存储的程序。 SPI接口：与SD卡通讯，搬运存储在SD卡中的Linux内核和根文件系统。 DDR控制器：访问DDR4，用于存储处理器运行过程中产生的数据。\n启动原理 各级简介 BootROM：上电后固定首先执行的代码，由芯片厂家烧录，不可更改，可看作硬件初始化状态机的一种实现。它一般进行安全相关的工作，然后从外部存储中加载并启动后级代码。\nU-Boot SPL：SPL（Second Program Loader）的存在是由于U-Boot太大了，无法装在片上SRAM中，只能放在DDR，但DDR又还没有初始化，所以先加载一段简易程序，负责初始化DDR，并加载U-Boot到DDR执行。\nU-Boot：主要负责初始化板上硬件，然后加载并启动操作系统。\nOpenSBI：SBI（Supervisor Binary Interface）是伴随着RISC-V的M态概念而诞生的：利用M态，构建一个特权级在操作系统之上的管理程序，负责处理OS启动引导、M态中断\u0026amp;异常服务、来自S态的系统调用服务等。OpenSBI则是SBI的一个开源实现。\nLinux：一般而言，Linux镜像需要一个dtb镜像和一个可选的initramfs（或initrd）。Linux在启动过程中，会根据设备树提供的信息了解自己所拥有的硬件资源，从而使用正确的驱动操作它们。最终，Linux会运行根文件系统中的某个指定的init程序。作为第一个用户态进程，该进程一般不会退出，是一个死循环。至此启动完成。\n方案 平头哥方案 BootROM—\u0026gt;U-Boot SPL—\u0026gt;U-Boot—\u0026gt;OpenSBI—\u0026gt;Linux\n**外部存储：**该方案的外部存储使用eMMC，有三个分区，第一个分区没有安装文件系统，用来存放U-Boot和U-Boot SPL，第二、三个分区分别叫boot和root，都安装了ext4文件系统，其中boot存放Linux镜像、opensbi镜像、Linux设备树镜像、以及（如果需要的话）initramfs；root中是Linux的根文件系统。\n**运行流程：**U-Boot SPL运行在片上SRAM中，负责初始化DDR，然后从第一个（裸）分区中加载U-Boot镜像到DDR。U-Boot会从boot分区中读取opensbi镜像、Linux镜像、Linux设备树镜像、（如果需要的话）initramfs，分别加载到DDR的特定位置，然后从openSBI开始运行。（强调“Linux”设备树是因为该设备树只是给openSBI和Linux使用，U-Boot及其SPL则使用另一份在编译时分别被链接进它们各自的二进制文件中的设备树。）\nchipyard方案 BootROM—\u0026gt;OpenSBI—\u0026gt;Linux\n**外部存储：**该方案使用SD卡作为外部存储。有两个分区，分区1没有安装文件系统，存放OpenSBI+Linux镜像。之所以这么称呼是因为其OpenSBI使用了payload模式，所以在编译时会将Linux镜像和OpenSBI链接在一起；分区2中是Linux的根文件系统。\n**运行流程：**BootROM将OpenSBI+Linux镜像和设备树镜像加载到DDR指定位置，然后开始运行OpenSBI。在这个方案中，设备树镜像存放在BootROM中。\nU-Boot及其SPL 启动汇编 初始化（start.S）—\u0026gt;board_init_f()—\u0026gt;清空bss，重定位数据段（start.S）—\u0026gt;board_init_r()，然后board_init_r()函数不返回，直接跳转到U-Boot。我们这里先讲述start.S用于初始化的部分，我把它分为设置中断，决定启动核，开辟空间，设置gd变量4件事。\n设置中断 在整个U-Boot及其SPL中，mstatus的MIE（全局中断使能）都是关闭的，只是在mie（中断使能寄存器）中打开了MSIE（软件中断使能）。这种情况下，中断是无法trap的（因此赋值给mtvec的函数只是用于异常处理，我们不关心它），然而wfi状态的核心却可以被唤醒，且唤醒之后会执行pc+4的指令。这是wfi指令有趣设定的一部分，详见risc-v手册的wfi指令部分。利用wfi机制，非启动核等待ipi的函数被写成这样（删去了多个条件编译宏）：\nsecondary_hart_loop: wfi // 等待唤醒 csrr\tt0, MODE_PREFIX(ip) // 读mip andi\tt0, t0, MIE_MSIE // 判断被唤醒原因 beqz\tt0, secondary_hart_loop // 若唤醒原因不是MSIP，继续wfi mv\ta0, tp jal\thandle_ipi //处理ipi 这些做法实际上也都是risc-v手册中要求的。\n设置gd变量 在启动代码（bootloader，例如 U-Boot）中，gd 是一个全局变量，指向一个全局数据结构（global_data）。\n这个结构体通常包含系统运行时的信息，比如内存布局、设备状态等。\n即初始化gd指向的gd_t类型结构体的一些成员。gd变量是gd_t类型结构体的指针，该变量在C语言中声明为“以gp寄存器分派”：\nregister gd_t *gd asm (gp) 汇编中会将从栈中开辟的gd的地址赋值给gp寄存器：\njal\tboard_init_f_alloc_reserve // 该函数返回值是指向gd结构体起始的指针 mv\tgp, a0 // 赋值给gp寄存器 需要注意的是，多个核更改gd变量时需要维护一个锁：\n/* 摘自每个核分别在gd中注册自己的代码 */ // 多核处理器初始化：多个核在启动时注册自己到共享数据结构中，防止并发冲突。 ... la\tt0, available_harts_lock // 锁 li\tt1, 1 1:\tamoswap.w t1, t1, 0(t0) // 获取锁 fence\tr, rw bnez\tt1, 1b ... /* 临界区 */ ... fence\trw, w amoswap.w zero, zero, 0(t0) // 释放锁 完成初始化后，启动核继续执行board_init_f()，其他核进入刚刚分析过的secondary_hart_loop等待ipi。\n设备树与驱动模型 board_init_f()在源码中有多处定义。因为平头哥版本专门为ice-c910板写了一个board_init_f()，在board/thead/ice-c910/spl.c中，所以我们基于这个函数来讲解。它主要做了两件事：调用spl_early_init()生成udevice节点，以及调用preloader_console_init()首次初始化串口。本节就介绍第一个函数。\n但在介绍函数的具体操作之前，我们要先了解U-Boot驱动模型。首先，U-Boot驱动模型最终试图对驱动开发者、平台开发者、驱动调用者三方展现的大致接口是这样的：\n（a）驱动的编写者无须考虑运行代码的硬件平台。他们只需知道两点。第一，他们需要在一个可查找到的地方[3]静态定义一个drvier结构体，其中至少要包含诸如**（1）表示的驱动名字的of_match等字段，（2）指向外设初始化函数的probe字段，（3）**指向dm_xxx_ops结构体的指针等。（dm_xxx_ops结构体可以由驱动开发者定义（当然需要将定义告知调用者），其中存放驱动编写者实现的各驱动函数的指针。）第二，存在一种udevice结构体，每个udevice代表一个可用的设备，其中含有该设备所有信息。而驱动函数每次被调用时，调用者都会传入要操作的设备的udevice。\n（b）硬件平台的开发者无须了解驱动函数的实现，只需用设备树描述设备信息，及用compatible属性指定驱动名字。设备树在启动时传入。\n（c）驱动函数的调用者（调用者可以是U-Boot中其他模块，也可以是App）应当能通过驱动系统提供的udevice查找函数，找到任何udevice。且udevice应当包含一个driver字段，指向对应的driver，从而调用者得以进行“搜索udevice—\u0026gt;索引到其driver—\u0026gt;调用probe()—\u0026gt;调用各驱动函数”的流程。\n移植改动 移植U-Boot要做的改动。主要有三处。第一，要在include/configs下改动各个宏的值，主要包括SPL级和U-Boot的代码段起始及大小，BSS段起始及大小，SPL级MALLOC的起始及大小。另外还能使用CONFIG_EXTRA_ENV_SETTINGS宏指定一些环境变量，例如可以指定自己的启动命令序列。第二，要确保时钟、串口、SPI驱动能用。主要修改设备树和各硬件层ops即可。第三，SPL级的镜像加载函数可以自己写，并使用SPL_LOAD_IMAGE_METHOD宏静态注册。\nOpenSBI OpenSBI有两个任务：（1）引导Linux，（2）作为Linux的SBI接口的提供者。其中第二部分将以定时器为例介绍。\n引导Linux OpenSBI启动流程大致可以分为fw_base.S—\u0026gt;sbi_init()两个阶段。和我们分6小节讲解。从“平台相关初始化”开始，进入sbi_init()阶段。\n重定位 若编译时定义了FW_PIC make变量，OpenSBI会被编译为无论被加载到哪里都能就地运行的模式。其原理为，定义_link_start变量，其值初始化为FW_TEXT_START，该宏在编译时确定，为代码起始的链接时地址：\n_link_start: RISCV_PTR FW_TEXT_START 运行时再动态获取代码段起始标号的地址：\nlla t1, _start # 该标号为代码段起始处标号 这句伪指令在-pic参数下会被编译为相对PC寻址：\nlla\tt1, _start b8:\t00000317 auipc\tt1,0x0 bc:\tf4830313 addi\tt1,t1,-184 # 0 \u0026lt;_fw_start\u0026gt; _start 代码段起始的地址 ， _link_start 代码起始的链接时的地址\n意思是_link_start是在链接脚本中假定的加载地址，_start是实际的加载地址，但是_start 是在程序运行时才能够得到的，通过_link_start和_start差值就能够去纠正后续的指令，使得无论程序加载到哪里都能够运行\n本身在链接时程序的加载地址是能够被确定的，但是动态重定位能够使得在不加载到这个地址的情况下还能够正常运行\n也就是说，可以得到该标号真实的加载地址。只要将该地址与_link_start所存地址做差即可得到动态重定位所需的BASE。\n引导信息获取 OpenSBI提供了三类获取引导信息的方法，分别对应jump，dynamic和payload三种模式，使用make变量配置。代码不多但较为零碎，所以这里只做总结。对于每种模式，我们主要关心两个信息的获取：**（1）如何获取要传递给Linux的dtb（设备树），并知道应当把dtb加载到哪里[8]，（2）**如何获取要跳转的地址。\njump模式：\n通常由引导加载程序（如BootROM）负责，将控制权从OpenSBI转移到下一阶段的操作系统（如Linux）\n有三种方式指定要给Linux的dtb，优先级从低到高：**（1）由BootROM通过a1传入dtb地址；（2）FW_FDT_PATH指定一个dtb编译进OpenSBI镜像；（3）**调用由硬件平台开发者定义的fw_platform_init()函数，其中允许修改前二者指定的dtb，或直接指定一个位于其他地址的dtb。 有两种方式指定应当把dtb加载到哪里，优先级从低到高：**（1）设备树存在哪里，便放在那里；（2）**通过FW_JUMP_FDT_ADDR宏定义要加载到哪里。 跳转地址通过FW_JUMP_ADDR宏指定。 dynamic模式：\n指定dtb的方式同上。 dtb加载位置只能由前级引导程序通过a1传入。 跳转地址只能由前级引导程序通过a1传入。a2应当是一个fw_dynamic_info结构体的首地址，该结构体中包含next_addr成员。 payload模式：\n引导程序（如BootROM）通过a1传递DTB和跳转地址，适用于更动态的引导场景。\n指定dtb的方式同上。 有两种方式指定应当把dtb加载到哪里，优先级从低到高：**（1）设备树存在哪里，便放在那里；（2）**通过FW_PAYLOAD_FDT_ADDR宏定义要加载到哪里。 因为payload模式将Linux镜像编译进OpenSBI镜像，因此具体的跳转地址由OpenSBI在链接时自动决定。 中断初始化 中断初始化主要包括mtvec，stvec，mstatus的MIE和SIE，sie打开情况，mie打开情况，mideleg代理情况，以及medeleg代理情况。这里总结如下：\nmtvec在fw_base.S中被初始化为_trap_handler。 stvec在跳转前的最后一个函数sbi_hart_switch_mode()中被设为next_addr，因此若在Linux还未设定stvec之前发生异常，会跳回Linux第一条指令。 mstatus的MIE在sbi_hart_switch_mode()中使用清空MPP再MRET的方式再跳转时清空，SIE则未设置。注意：MIE虽然不打开，但当hart运行在低特权级时，只要发生被mie打开的M态中断，会无视MIE位跳转回来。 sie未设置。 mie未设置。注意：M态各中断一般由SBI服务函数打开。 mideleg和medeleg在delegate_traps()中被设置。该函数被调用流程如下： sbi_init() init_coldboot() sbi_hart_init() sbi_hart_reinit() delegate_traps() 其中代理的中断有SSIP、STIP和SEIP；代理的异常有：取指非对齐，断点，U态ECALL。如果平台定义了SBI_PLATFORM_HAS_MFAULTS_DELEGATION feature，则还会代理指令、load、store的page falut。\n平台相关初始化 OpenSBI中，硬件平台拥有两个自定义内容：（1）第一，也是最主要的，一个sbi_platform结构体全局变量。该变量必须命名为platform。在启动流程进入sbi_init()前，fw_base.S会初始化一个sbi_scratch结构体，其中存放OpenSBI启动相关的所有信息。platform的地址也会被存入其中，从而在后续启动流程中可以访问它。platform中最关键的成员是platform_ops_addr，它指向一个函数指针结构体，其中存放启动流程各步骤中会进行的回调。硬件平台需要定义这些函数。（2）第二，可选的fw_platform_init()函数，如果定义了，该函数会在fw_base.S早期被调用。\nOpenSBI本身自带了一个generic平台。其“通用性”在于，它定义的各个回调中会再执行其他硬件平台的回调：\n/* generic平台的回调 */ static int generic_early_init(bool cold_boot) { ... /* generic_plat指向另一个平台 */ if (generic_plat \u0026amp;\u0026amp; generic_plat-\u0026gt;early_init) { rc = generic_plat-\u0026gt;early_init(cold_boot, generic_plat_match);/* 执行另一个平台的回调 */ ... 具体来说，硬件平台的开发者可以在使用generic平台的基础上，自己定义一个platform_override类型变量，静态注册到special_platforms数组中：\nstatic const struct platform_override *special_platforms[] = { \u0026amp;sifive_fu540, // 这是sifive的一个示例 }; platform_override包含一个match table和各回调函数指针。match table用于和设备树中的platform匹配，special_platforms[]中第一个匹配成功者被注册为上面看到的generic_plat。匹配和赋值的过程均在generic定义的fw_platform_init()中进行。\n串口初始化 串口初始化函数sbi_console_init()被调用流程是：\nsbi_init() init_coldboot() sbi_console_init() 该函数最终会调用platform的console_init。generic平台中，该函数被赋值为fdt_serial_init()。fdt_serial_init()中会使用设备树的chosen节点的stdout-path属性指定的节点作为控制台，然后在静态定义的serial_drivers[]数组中寻找可匹配的串口。serial_drivers[]数组中的fdt_serial类型元素并非串口驱动，而是只包含match table和init函数。init函数负责解析设备树节点，初始化串口，并调用sbi_console_set_device()将真正的驱动结构体（含有putc()和getc()函数）注册到console_dev变量。OpenSBI中各种输入输出函数均依赖该变量进行输出。所有可用的输入输出函数见include/sbi/sbi_console.h。\n跳转至Linux 跳转主要在sbi_hart_switch_mode()函数中处理，其被调用流程是：\nsbi_init() init_coldboot() sbi_hart_switch_mode() sbi_hart_switch_mode()通过设置好mepc和mstatus.MPP后，执行MRET的方式来跳转。其简略定义如下：\nvoid __attribute__((noreturn)) sbi_hart_switch_mode(unsigned long arg0, unsigned long arg1, unsigned long next_addr, unsigned long next_mode, bool next_virt) { ... val = csr_read(CSR_MSTATUS); // read val = INSERT_FIELD(val, MSTATUS_MPP, next_mode); // 将MPP字段设为下一特权级 val = INSERT_FIELD(val, MSTATUS_MPIE, 0); // MPIE设为0 ... csr_write(CSR_MSTATUS, val); // write csr_write(CSR_MEPC, next_addr); // 设置跳转位置 if (next_mode == PRV_S) { csr_write(CSR_STVEC, next_addr); csr_write(CSR_SSCRATCH, 0); csr_write(CSR_SIE, 0); csr_write(CSR_SATP, 0); ... } /* 设置寄存器 */ register unsigned long a0 asm(\u0026#34;a0\u0026#34;) = arg0; register unsigned long a1 asm(\u0026#34;a1\u0026#34;) = arg1; __asm__ __volatile__(\u0026#34;mret\u0026#34; : : \u0026#34;r\u0026#34;(a0), \u0026#34;r\u0026#34;(a1)); // 使用mret跳转 __builtin_unreachable(); } xiangshan构建Linux 附录 参考文献 玄铁处理器的linux移植\n动态重定位\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-11-25T10:53:14+08:00","permalink":"https://VastCircle.github.io/2024/linux%E7%A7%BB%E6%A4%8D/","title":"Linux移植"},{"content":"在chipyard的build-setup.sh里可以看到它是如何创建一个conda环境的\n具体来说就是通过conda-lock去将一个锁文件里的配置加载到一个conda环境了去，锁文件也是通过脚本generate-conda-lockfiles.sh生成的，所以根本文件是chipyard.yaml的配置文件\n# setup and install conda environment if run_step \u0026#34;1\u0026#34;; then # note: lock file must end in .conda-lock.yml - see https://github.com/conda-incubator/conda-lock/issues/154 CONDA_REQS=$CYDIR/conda-reqs CONDA_LOCK_REQS=$CONDA_REQS/conda-lock-reqs # must match with the file generated by generate-conda-lockfile.sh LOCKFILE=$CONDA_LOCK_REQS/conda-requirements-$TOOLCHAIN_TYPE-linux-64.conda-lock.yml if [ \u0026#34;$USE_UNPINNED_DEPS\u0026#34; = true ]; then # auto-gen the lockfiles $CYDIR/scripts/generate-conda-lockfiles.sh fi # use conda-lock to create env conda-lock install -p $CYDIR/.conda-env $LOCKFILE source $CYDIR/.conda-env/etc/profile.d/conda.sh conda activate $CYDIR/.conda-env fi ## chipyard.yaml channels: - ucb-bar - conda-forge - litex-hub - nodefaults platforms: - linux-64 dependencies: # https://conda-forge.org/feedstock-outputs/ # filterable list of all conda-forge packages # https://conda-forge.org/#contribute # instructions on adding a recipe # https://docs.conda.io/projects/conda/en/latest/user-guide/concepts/pkg-specs.html#package-match-specifications # documentation on package_spec syntax for constraining versions # handy tool for introspecting package relationships and file ownership # see https://github.com/rvalieris/conda-tree - conda-tree # bundle FireSim driver with deps into installer shell-script - constructor - gcc - gxx - sysroot_linux-64=2.17 # needed to match pre-built CI XRT glibc version - conda-gcc-specs - binutils - dromajo # from ucb-bar channel - https://github.com/riscv-boom/dromajo - firtool==1.30.0 # from ucb-bar channel - https://github.com/ucb-bar/firtool-feedstock ... 有部分不存在的就还是通过apt安装\n然后构建脚本\nbuild-setup.sh\nUSE_UNPINNED_DEPS=true CYDIR=$(pwd) CONDA_REQS=$CYDIR/conda-req CONDA_LOCK_REQS=$CONDA_REQS/conda-lock-reqs # must match with the file generated by generate-conda-lockfile.sh LOCKFILE=$CONDA_LOCK_REQS/conda-requirements-linux-64.conda-lock.yml if [ \u0026#34;$USE_UNPINNED_DEPS\u0026#34; = true ]; then # auto-gen the lockfiles ./generate-conda-lockfiles.sh fi # use conda-lock to create env conda-lock install -p $CYDIR/.conda-env $LOCKFILE source $CYDIR/.conda-env/etc/profile.d/conda.sh conda activate $CYDIR/.conda-env generate-conda-lockfiles.sh\n#!/usr/bin/env bash set -ex CUR_DIR=$( cd -- \u0026#34;$( dirname -- \u0026#34;${BASH_SOURCE[0]}\u0026#34; )\u0026#34; \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; pwd ) REQS_DIR=\u0026#34;$CUR_DIR/conda-req\u0026#34; if [ ! -d \u0026#34;$REQS_DIR\u0026#34; ]; then echo \u0026#34;$REQS_DIR does not exist, make sure you\u0026#39;re calling this script from xs-env/\u0026#34; exit 1 fi mkdir -p $REQS_DIR/conda-lock-reqs # note: lock file must end in .conda-lock.yml - see https://github.com/conda-incubator/conda-lock/issues/154 LOCKFILE=$REQS_DIR/conda-lock-reqs/conda-requirements-linux-64.conda-lock.yml conda-lock -f \u0026#34;$REQS_DIR/xs-env.yaml\u0026#34; -p linux-64 --lockfile $LOCKFILE 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-11-24T21:58:06+08:00","permalink":"https://VastCircle.github.io/2024/%E4%BD%BF%E7%94%A8conda%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E9%9A%94%E7%A6%BB%E7%9A%84%E7%8E%AF%E5%A2%83/","title":"使用conda创建一个隔离的环境"},{"content":"概述 TileLink Cached (TL-C) 协议通过为主设备提供缓存共享数据块副本的能力，完善了 TileLink 协议。这些本地缓存副本必须根据实现定义的一致性策略保持一致性。本章节定义的 TL-C 标准一致性协议规定了哪些内存访问操作可以对缓存数据的副本执行，以及哪些消息可用于传输数据块的副本。实现中叠加的一致性策略则规定了在接收到内存访问操作后，如何在特定的 TileLink 代理网络中传播副本和权限。具体一致性策略的描述超出了本文档的范围。\n总的来说，TL-C 在 TileLink 协议规范中增加了以下内容：\n三种新操作 三个新通道 一种新的五步消息序列模板 十种新消息类型 新增的操作是用于创建或删除数据块缓存副本的传输操作。这些传输操作不会修改数据块的值，而是转移副本的读/写权限。传输操作与之前定义的 TL-UL 和 TL-UH 内存访问操作无缝协作，且二者在顺序上是串行化的。因为每个传输操作逻辑上要么发生在内存访问操作之前，要么发生在之后，并且所有代理对这种顺序一致认可，因此在 TileLink 网络中保持了一致性不变量。\n当内存访问操作通过 TileLink 网络时，中间缓存可能在其中嵌套递归传输操作。缓存通过首先使用传输操作获得数据块的足够权限，然后利用其一致的本地副本来处理内存访问操作。\n地址的“可缓存性”是一个属性，TileLink 的实现必须防止创建不可缓存地址的副本（见第 6.3 节）。相反，之前在 TL-UL 和 TL-UH 中定义的内存访问操作可以被主设备用来访问可缓存地址，而无需自行缓存它们。某些主设备可能选择缓存某个数据块，而同一内存层级中的其他主设备可能选择不缓存。\n下一节将概述可供设计者用于定义特定实现依赖一致性策略的基本操作、消息和权限。该规范并未强制使用某一种特定策略，而是定义了一个可供构建策略的协议基础。\n使用 TileLink 实现缓存一致性 所有基于Tilelink的一致性协议都由传输权限以读取和写入数据块的副本组成。内存访问操作需要agent获取正确的权限，然后agent才能将访问操作应用于缓存的副本。当agent想要在本地处理访问操作时，必须首先使用**传输操作(Transfer operations)**来获取必要的权限。传输操作通过网络创建或删除副本，从而修改每个副本提供的权限。\n代理的块副本拥有权限，“None\u0026quot;,\u0026ldquo;Read\u0026rdquo;,\u0026ldquo;Read+Write\u0026rdquo;。对于任何给定地址，任何给定master和拥有该地址的slave之间只有一条路径。当所有此类路径覆盖在 TileLink 网络 DAG 上时，它们会形成一棵树，其根为单个从属路径。对于每个地址，该树包含所有针对该地址的操作执行的路径。如果我们删除所有不能缓存数据的代理，我们就会留下一棵缓存代理树，描述可能缓存特定地址数据的所有位置。\n在逻辑时间的任何给定时刻，这些代理的某些子集实际上包含缓存数据的副本。这些代理形成了 CoherenceTree。包容性的 TileLink 一致性协议要求树根据内存访问操作而增长和收缩。图中的每个节点都属于描述其在树上位置的四个类别之一：\nNothing: 当前不缓存数据副本的节点。既没有读权限，也没有写权限。\nTrunk :具有缓存副本的节点，位于 Tip 和 Root 之间的路径上。对副本既没有读权限，也没有写权限。对于提示处发生的写入，该副本可能已过时。\nTip（with no Branches）:具有缓存副本的节点，用作内存访问序列化点。对其副本具有读/写权限，该副本可能包含脏数据。\nTip（with Branches）:具有缓存副本的节点，用作写入序列化点。对其副本具有读取和写入权限，该副本可能包含过去写入的脏数据。\nBranch: 具有位于提示上方的缓存副本的节点。对其副本具有只读权限。\nimage-20250107233542448 “TT”代 表 Trunk Tip，“T”代 表 Trunk，“B”代表Branch。\nA：根对唯一副本具有写+读权限。\nB：单个master对trunktip有写+读权限。\nC：多个master对分支有读权限。\nD：多个master对分支有读权限，部分分支被剪枝\n一致性树按照内存、L3、L2、L1的顺序自下而上生长，内存作为根节点拥有可读可写的权限，在每一层中子节点的权限都不能超过父节点的权限。其中TT代表拥有T权限的枝杈上的叶子节点，说明该节点上层只有N或B权限，相反T权限而不是TT权限的节点代表上层一定还有T/TT权限节点。\noperation three new operations are termed transfer operations (move permissions or cached copied of data through the network)\nAcquire\n在请求的主设备中创建数据块的新副本（或特定权限）。\nRelease\n将数据块的副本（或特定权限）从请求的主设备返还给从设备。\nProbe\n强制从主设备移除数据块的副本（或特定权限），并交给请求的从设备。\n获取（Acquire）操作通过延伸主干或从现有分支或末端添加新分支来扩展树结构。为了实现这一点，可能需要通过递归探测（Probe）操作修剪旧的主干或分支，才能生长新的分支。释放（Release）操作则通过自愿缩减树结构来修剪树，通常是为了响应缓存容量冲突。\nChannels 通道 A master发起获取读取或写入缓存数据块副本的权限。\n通道 B slave查询或修改master在缓存数据块上的权限，或将内存访问请求转发给master。\n通道 C master确认通道 B 消息，可能会释放数据块上的权限以及任何脏数据。也用于自愿回写脏缓存数据。\n通道 D\nslave向原始请求者提供数据或权限，授予访问缓存数据块的权限。也用于确认脏数据的自愿回写。\n通道 E master提供交易完成的最终确认，用于slave进行交易序列化。\nTL-C Messages 包含三个操作的十个消息\nPermissions Transitons 传输在逻辑上对权限进行操作，因此包含它们的消息必须指定预期结果：升级到更多权限、降级到更少权限或保持权限不变的无操作。这些变化是根据它们对特定地址的一致性树的形状的影响来指定的。我们将可能的权限转换集分为六个子集；不同的子集可用作某些消息的参数，如下小节中所定义。\nPrune 包括权限降级操作，缩小树结构，并记录先前的权限和新的较低权限。\nGrow 包括权限升级操作，扩展树结构，并记录先前的权限和新的较高权限。\nReport 包括不进行操作的情况，其中权限保持不变，但报告当前的权限状态。\nCap 包括权限变更操作，不指定原始权限是什么，而是只说明它们应该变成什么\nFlows and Waves 下图概括了3个新流程，Acquire总是触发a recursive Grant request and GrantAck response。根据块权限的状态和一致性策略，Acquire 也能触发一个或者多个Release or Probe operations.黑点的移动表明事务序列化点已受到该操作的影响。\n下图显示了一个消息流，该消息流更详细地说明了包含所有三个新操作的事务。在此流程中，主设备通过获取在目标数据块的本地副本中读取或写入数据的许可来对存储器访问操作请求做出反应。此事务完成后，主节点已获得读取或写入缓存块以及该块数据的副本的权限。其他主机被probed，迫使他们释放对该块的权限并写回其拥有的脏数据。此外，发出 Acquire 的 master 还使用 Release 来自愿释放其对缓存块的权限。通常，当高速缓存必须逐出包含脏数据的块，以便用重新填充到高速缓存中的块替换它时，就会发生这种类型的事务。此事务完成后，主服务器将失去读取或写入第二个缓存块及其数据副本的权限。如果从属设备能够使用目录跟踪哪些主设备拥有该块的副本，则此元数据已更新以反映两个块的权限更改。l\n把master1 看成l1,slave看成l2\n1.缓存主设备向从设备发送 Acquire\n2.为了为预期的响应腾出空间，同一个主设备发送 Release\n3.从设备与后备存储(backing memory)通信（如果需要）\n4.从设备使用 ReleaseAck 确认写回事务完成\n5.从设备还向其他主设备发送必要的 Probes。\n6.从设备等待接收每个发送的 Probe 的 ProbeAck\n7.从设备与后备存储通信（如果需要）。\n8.从设备向原始请求者发送 Grant\n9.原始主设备通过 GrantAck 响应，从而完成事务。\nTileLink 协议基于三个消息流：Acquire、Release 和 Grant（或类似的），这些流构成了所有涉及缓存块传输的事务基础。然而，当这些流在时间上交错或层次上组合时，会出现一些边界情况。接下来讨论的是 主设备 和 从设备 之间如何分配并发管理的责任。\nTileLink 协议并不假定存在点对点的有序消息传递。实际上，高优先级的消息可以绕过低优先级的消息，即使它们的目标是同一个设备。这意味着，从设备 充当了一个便利的同步点，所有与它连接的 主设备 都通过它来协调消息流。\n由于每个事务必须通过向从设备发送 Acquire 消息来发起，因此从设备能够方便地对事务进行排序。一个非常安全的实现方式是让从设备一次只接受一个事务，但是这样做的性能影响非常严重，因此实际上我们可以通过限制代理行为，依然保持正确的事务顺序，同时提高并发性。\n通过对代理行为施加一些限制，我们能够保证即使问题是分布式的，也能够构建出事务的总顺序。图 28 提供了关于每种操作并发性限制的概述。\nTileLink 代理的并发限制最容易通过发起或阻止请求消息来理解。每个请求消息都会生成响应消息，而响应消息最终都能向前推进。但是，在某些条件下，针对同一数据块的递归请求消息 在未接收到未处理的响应消息之前，不应被发出。\nAcquire（获取） 主设备如果该块上有挂起的Grant（授权），则不应发起Acquire请求。发起Acquire后，主设备在收到Grant之前，不应再对该块发起其他Acquire请求。\nGrant（授权） 从设备如果该块上有挂起的ProbeAck（探针确认），则不应发起Grant授权。一旦发出Grant授权，从设备在收到GrantAck（授权确认）之前，不应对该块发起进一步的Probe请求。\nRelease（释放） 主设备如果该块上有挂起的Grant授权，则不应发起Release请求。发出Release后，主设备在收到Slave确认完成写回的ReleaseAck之前，不应再发起ProbeAcks、Acquires或其他Release请求。\nProbe（探针） 从设备如果该块上有挂起的GrantAck授权确认，则不应发起Probe请求。一旦发出Probe请求，从设备在收到ProbeAck（探针确认）之前，不应对该块发起进一步的Probe请求。\n总而言之就是如果有*ack的话，就不要发起*\n未完\n附录 参考文献 tilelink_spec_1.8.1\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-11-22T16:29:39+08:00","permalink":"https://VastCircle.github.io/2024/%E4%BD%BF%E7%94%A8tilelink%E5%AE%9E%E7%8E%B0%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/","title":"使用Tilelink实现缓存一致性（cache conherence）"},{"content":"多核心的一致性问题 在一个核心修改Cache数据后，如何同步给其他核心Cache\n1、Core 1 和 Core 2 读取了同一个内存块的数据，在两个 Core 都缓存了一份内存块的副本。此时，Cache 和内存块是一致的；\n2、Core 1 执行内存写入操作：\n2.1 在写直达策略中，新数据会直接写回内存，此时，Cache 和内存块一致。但由于之前 Core 2 已经读过这块数据，所以 Core 2 缓存的数据还是旧的。此时，Core 1 和 Core 2 不一致； 2.2 在写回策略中，新数据会延迟写回内存，此时 Cache 和内存块不一致。不管 Core 2 之前有没有读过这块数据，Core 2 的数据都是旧的。此时，Core 1 和 Core 2 不一致。 3、由于 Core 2 无法感知到 Core 1 的写入操作，如果继续使用过时的数据，就会出现逻辑问题。\n需要一种机制，将多个核心的工作联合起来，共同保证多个核心下Cache一致性\n4.1 写传播 \u0026amp; 事务串行化 缓存一致性机制需要解决的问题就是 2 点：\n特性 1 - 写传播（Write Propagation）： 每个 CPU 核心的写入操作，需要传播到其他 CPU 核心； 特性 2 - 事务串行化（Transaction Serialization）： 各个 CPU 核心所有写入操作的顺序，在所有 CPU 核心看起来是一致。 第 1 个特性解决了 “感知” 问题，如果一个核心修改了数据，就需要同步给其它核心，很好理解。但只做到同步还不够，如果各个核心收到的同步信号顺序不一致，那最终的同步结果也会不一致。\n举个例子：假如 CPU 有 4 个核心，Core 1 将共享数据修改为 1000，随后 Core 2 将共享数据修改为 2000。在写传播下，“修改为 1000” 和 “修改为 2000” 两个事务会同步到 Core 3 和 Core 4。但是，如果没有事务串行化，不同核心收到的事务顺序可能是不同的，最终数据还是不一致\n4.2 总线嗅探 \u0026amp; 总线仲裁 写传播和事务串行化在 CPU 中是如何实现的呢？\n写传播 - 总线嗅探： 总线除了能在一个主模块和一个从模块之间传输数据，还支持一个主模块对多个从模块写入数据，这种操作就是广播。要实现写传播，其实就是将所有的读写操作广播到所有 CPU 核心，而其它 CPU 核心时刻监听总线上的广播，再修改本地的数据； 事务串行化 - 总线仲裁： 总线的独占性要求同一时刻最多只有一个主模块占用总线，天然地会将所有核心对内存的读写操作串行化。如果多个核心同时发起总线事务，此时总线仲裁单元会对竞争做出仲裁，未获胜的事务只能等待获胜的事务处理完成后才能执行 MESI协议 MESI 协议其实是 CPU Cache 的有限状态机，一共有 4 个状态（MESI 就是状态的首字母）：\nM（Modified，已修改）： 表明 Cache 块被修改过，但未同步回内存； E（Exclusive，独占）： 表明 Cache 块被当前核心独占，而其它核心的同一个 Cache 块会失效； S（Shared，共享）： 表明 Cache 块被多个核心持有且都是有效的； I（Invalidated，已失效）： 表明 Cache 块的数据是过时的。 在 “独占” 和 “共享” 状态下，Cache 块的数据是 “清” 的，任何读取操作可以直接使用 Cache 数据；\n在 “已失效” 和 “已修改” 状态下，Cache 块的数据是 “脏” 的，它们和内存的数据都可能不一致。在读取或写入 “已失效” 数据时，需要先将其它核心 “已修改” 的数据写回内存，再从内存读取；\n在 “共享” 和 “已失效” 状态，核心没有获得 Cache 块的独占权（锁）。在修改数据时不能直接修改，而是要先向所有核心广播 RFO（Request For Ownership）请求 ，将其它核心的 Cache 置为 “已失效”，等到获得回应 ACK 后才算获得 Cache 块的独占权。这个独占权这有点类似于开发语言层面的锁概念，在修改资源之前，需要先获取资源的锁；\n在 “已修改” 和 “独占” 状态下，核心已经获得了 Cache 块的独占权（锁）。在修改数据时不需要向总线发送广播，能够减轻总线的通信压力。\n事实上，完整的 MESI 协议更复杂，但我们没必要记得这么细。我们只需要记住最关键的 2 点：\n关键 1 - 阻止同时有多个核心修改的共享数据： 当一个 CPU 核心要求修改数据时，会先广播 RFO 请求获得 Cache 块的所有权，并将其它 CPU 核心中对应的 Cache 块置为已失效状态； 关键 2 - 延迟回写： 只有在需要的时候才将数据写回内存，当一个 CPU 核心要求访问已失效状态的 Cache 块时，会先要求其它核心先将数据写回内存，再从内存读取。 提示： MESI 协议在 MSI 的基础上增加了 E（独占）状态，以减少只有一份缓存的写操作造成的总线通信。\nMESI 协议有一个非常 nice 的在线体验网站，你可以对照文章内容，在网站上操作指令区，并观察内存和缓存的数据和状态变化。网站地址：www.scss.tcd.ie/Jeremy.Jone…\n4.4 写缓冲区 \u0026amp; 失效队列 MESI 协议保证了 Cache 的一致性，但完全地遵循协议会影响性能。 因此，现代的 CPU 会在增加写缓冲区和失效队列将 MESI 协议的请求异步化，以提高并行度：\n写缓冲区（Store Buffer） 由于在写入操作之前，CPU 核心 1 需要先广播 RFO 请求获得独占权，在其它核心回应 ACK 之前，当前核心只能空等待，这对 CPU 资源是一种浪费。因此，现代 CPU 会采用 “写缓冲区” 机制：写入指令放到写缓冲区后并发送 RFO 请求后，CPU 就可以去执行其它任务，等收到 ACK 后再将写入操作写到 Cache 上。\n失效队列（Invalidation Queue） 由于其他核心在收到 RFO 请求时，需要及时回应 ACK。但如果核心很忙不能及时回复，就会造成发送 RFO 请求的核心在等待 ACK。因此，现代 CPU 会采用 “失效队列” 机制：先把其它核心发过来的 RFO 请求放到失效队列，然后直接返回 ACK，等当前核心处理完任务后再去处理失效队列中的失效请求。\n事实上，写缓冲区和失效队列破坏了 Cache 的一致性\nCore1 指令 a = 1; // A1 x = b; // A2 Core2 指令 b = 2; // B1 y = a; // B2 因为写缓存区和失效队列允许在当前指令未完成的时候CPU继续去运行，所有就可能会破坏指令的执行顺序\n就像下面A2读取的是没有写入的数据，但是这样其实只要能够从写缓存区和Cache中去读取就行了，问题不是特别大\n附录 参考文献 12图看懂CPU缓存一致性问题\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-11-19T20:03:48+08:00","permalink":"https://VastCircle.github.io/2024/cache%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/","title":"Cache缓存一致性"},{"content":"Cache的一般设计 Cache line = Cache data block + Cache Tag ,如果一个数据可以存储在Cache中的多个地方,能够被同一个地址找到的多个Cache Line 称为Cache Set\nCache缺失的原因(3C定理:\n(1)Compulsory , 第一次访问的指令或数据肯定不会在Cache中,\n(2)Capcity,容量,\n(3)Conflict,冲突\nCache的组成方式 直接相连 组相联 并行访问和串行访问 并行访问\n当Tag的地址被读取的同时,Data部分的所有数据也能够被读出来,送到一个多路选择器中,这个多路选择器受到Tag比较结果的控制,选出对应的Data block,然后根据Block offset的值,选择合适的字节,选择字节的过程称为数据对齐(Data Alignment)\n对于i-cache,流水线的结构不会有太大的影响,可以实现每周期读取指令,因为读取指令本身就是连续的,但是对于D-cache,会增大load的延时\n串行访问\n首先访问Tag SRAM,根据Tag比较的结果,直接去访问对应的way ,这样就不需要多路选择器了,可以节省功耗\n相比于并行会增加一个周期,但是它也降低了同时访问Tag SRAM和Data RAM的延迟\n全相连 Cache的写入 在一般的RISC处理器中,Icache都不会被直接写入内容,即使是有自修改指令,也需要借助D-cache,将要改写的指令作为数据写到D-cache中,然后将D-cahce中的内容写到下级存储器中(例如L2-cache,这个存储器是被i-cache和d-cache共享的,这个过程称为clean),并将I-cache的所有内容置为无效,这样处理器再次执行的时候,就会去读取修改过的指令\nWrite Through 和 Write Back\nWrite Allocate,在发生write miss之后先把下级数据写入D-cache,再将数据写入D-cache\nNon-Write Allocate ,发生write miss 直接写入内存\nWrite Through 配合 Non-Write Allocate\nCache的替换策略 LRU(Least Recently Used) 选择最近被使用次数最少的Cache line,这样需要为每一个Cache Line设置一个Age部分,每当一个Cache line被访问时,对应的年龄部分会增大,进行替换时,替换年龄最少的那个,实际上,为了减少代价,会使用\u0026quot;伪LRU\u0026quot;的方法,将所有的way进行分组,每一组使用一个1位的年龄部分\n类似于二分法,三级年龄位可以分8个way\n随机替换 可以通过时钟算法实现近似的随机\n提高Cache的性能 Write buffer 可以将dirty的数据先放到write buffer里,等到下一级存储器有空闲的时候,将write buffer的数据写到下一级存储器中\n当读取D-cache发生缺失时,不仅需要从下级存储器中查找数据,还需要在write buffer中也查找\n流水线 对于写D-Cache来说,读取Tag SRAM和写Data SRAM只能串行的完成.\n可以将Tag SRAM的读取和比较放在一个周期,写Data SRAM放在下一个周期\n对于store指令,需要两个周期来完成,如果连续的执行store指令,任然可以获得没周期执行一条store指令的效果\n当执行load指令时,可能出现load需要的数据正好在store指令的流水线寄存器中,因此还需要一种机制来检查load指令携带的地址和store指令的流水线寄存器\n多级结构 一般在处理器中.L2 cache会使用write back的方式,但是对于L1 cache来说,write through也可以接受,可以简化流水线的设计,也便于在多核的环境中,管理存储器之间的一致性\ninclusive 和 exclusive Inclusive : 如果 l2包括了l1中的所有内容,称l2 cache是inclusive的\nexclusive:如果l2 cache 和l1 cache的内容互不相同,称l2 cache是exclusive的\ninclusive类型的cache,在覆盖l1 cache不会存在问题;inclusive类型的cache也简化了一致性(coherence)的管理,例如在多核的处理器中,当其中一个处理器改变了存储器中一个地址的数据时,如果在其他处理器的私有Cache中也保存了地址的数据,需要置为无效,此时只需要检查最低级的存储器,因为如果l2 cache没有数据,l1 cache中必然没有数据\nVictim Cache 有时候,cache中被踢出的数据在之后可能马上又要被使用,比方说对于2-way的Cache,有3个数据恰好位于同一个Cache set\nVictim Cache可以保存最近被踢出Cache的数据,因此所有的Cache set都可以利用它来提高way的个数,通常Victim Cache采用全相连的方式,容量比较小,Victim本质就是增加了Cache中way的个数,能够避免多个数据竞争Cache中有限的位置,从而降低Cache的缺失率.一般来说Victim Cache和 Cache的数据是互斥的,可以同时去查找Victim Cache和Cache,如果Cache中没有数据的话,就使用Victim Cache的数据\nFilter cache,当一个数据第一次被使用,会放在Filter cache中,当数据被再次使用,才放在Cache中,这样可以避免偶然使用的数据,从而提高Cache的利用效率\nimage-20241116195003330 预取 可以使用预取（prefetching)来猜测处理器在以后可能使用什么指令和数据，提前将其放到Cache中，可以通过硬件完成，也可以通过软件完成。\n硬件预取 在访问I-cache的一个数据块的时候，可以将它后面的数据块也取出来放在I-cache,但是由于分支预测指令的存在，可能会使得不被使用的指令进入I-cache,一方面降低I-cache实际可用的容量，一方面有占用了本来可能有用的指令，称为“cache 污染” ，可以先将预取的指令放在一个单独的缓存中（stream Buffer)\n软件预取 在程序的编译阶段，编译器可以对程序分析，进而知道哪些数据是需要进行预取的，在程序中设置预取指令，就可以在计算时直接从D-cache中找到需要的数据，这种预取需要把握预取的时机，\n并且使用软件预取时，在执行预取指令的时候，处理器需要继续执行，也就是继续能够从D-cache中取数据，而不能让预取指令阻碍后面指令的执行，这要求D-cache是non-blocking结构的\n在实现虚拟存储器器的系统中，预取指令可能会引起异常，例如发生Page Fault,虚拟地址错误（Virtual Address Falut）或者保护违例（Protection Violation),此时有两种选择，如果对异常进行处理，称这种预取指令为处理错误的预取指令（Faulting Prefetch Instruction),反之，如果不对异常处理并且抛弃掉这条预取指令，称这种预取指令为不处理错误的预取指令（NonFaulting Prefetch Instruction),此时发生异常的预取指令会变成空指令\n多端口Cache 在超标量处理器中，为提高性能，处理器需要能够每周期执行多条load/store指令，这需要多端口D-Cache,需要一些特殊的方式来避免多端口对芯片的面积和速度带来很大的负面影响\nTrue Multi-port 真正的多端口需要所有在Cache中的控制通路和数据通路进行复制，这表示它有两套地址解码器（Address Decoder),使得两个端口可以同时寻址Tag SRAM和Data SRAM,有两个多路选择器，用来同时读取两个端口的数据，比较器的数量也需要同时增加一杯，用来判断两个端口的命中情况，同时需要两个对齐器（Aligner).\nSRAM中的每个Cell也需要同时支持两个并行的读取操作。因此需要更长的访问时间，功耗也会随之增大。\nMultiple Cache Copies 和上面类似，将Cache进行复制，SRAM将不使用多端口的结构，可以基本消除对处理器周期的影响，但是浪费了很多面积，而且需要保存两个Cache的同步，即需要保证两个Cache是完全一致的\nMulti-banking 将Cache分为很多个小bank,每个bank只有一个端口，如果一个周期之内，Cache的多个端口上的访问地址位于不同bank之中，没有任何问题，当端口的地址位于同一个bank之中时，会引起bank冲突（bank conflict)\n这种方法仍然需要两个地址解码器，有两个多路选择器，两套比较器，两个对齐器（Aligner)。此时Data SRAM不需要实现多端口结构了（一个地址只会读一次），提高了速度减少了面积。但是由于需要判断Cache的每个端口是不是命中，对于Tag SRAM来说，仍旧需要提供多个端口同时读取的功能（why?），即采用多端口SRAM,或者将单端口SRAM进行复制\n当端口冲突时，当前周期Cache只能对一个端口进行响应\n可以采用更多的bank来降低bank冲突的概率，由于每个端口都会访问所有的bank,那需要更多的布线资源\nAMD opteron 的多端口 Cache 40位物理地址，48位虚拟地址\n数据块的大小是64Bits,需要6字节寻址找到其中的某一个字节，每个数据块被分为8个独立的bank,每个bank都是64位的单端口SRAM\n整个Cache的大小是64KB,采用两路组相连，每一路大小为32KB.使用“Virtually-indexed,Pyhsically-tagged\u0026quot;的实现方式，可以使用虚拟地址寻址Cache,每一路是32KB的大小，需要VA[14:0]进行寻址，前面6位寻址块内字节，所以VA[14:6]用来寻址Cache set ,\n由于每个Cache line划分为8个bank,所以使用VA[5:3]来找到某一个bank,剩下的VA[2:0]用来找到某个字节，这种方式将两个连续的64位数据放在两个相邻的不同bank中，对它访问不会存在冲突。\n大小为64KB,两路组相连，每一路都有8个4KB的bank,整个cache有16个4KB的bank,Cache的每一个端口访问时，都会同时访问两个way的数据，然后根据tag去选择命中了哪个，所以Cache的一个端口访问时，会同时访问到两个bank,每个way各一个，\nPA[39:12]就是tag部分，用来判断哪个way是命中的，每一个端口都有一个TLB.每个端口都要同时读取两个way的tag进行比较，理论上来说，每个way的Tag SRAM需要支持两个读端口，这个Cache采用将Tag SRAM复制的方法\n虚拟地址的[11:0]寻址page内部，[47：12]寻址TLB,对应PFN[39:12],它用来和Cache对应的Tag部分比较，来判断是否命中\n该Cache相比于单端口，需要两个TLB,两个Tag比较电路，两倍的Tag SRAM,除了Data SRAM没有被复制，其他都被复制了，所以面积大，但是速度快。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-11-16T16:00:54+08:00","permalink":"https://VastCircle.github.io/2024/cache/","title":"Cache"},{"content":"概述 虚拟存储器的思想是对于一个程序来说,它的程序(code),数据(data)和堆栈(stack)的总大小可以超过实际物理内存的大小,操作系统把当前使用的部分内容放在物理内存中,而把其他未使用的内容放在更下一级的存储器中\n虚拟存储器空间的大小由处理器的位数决定,对于32位处理器,地址范围就是0~0xFFFFFFFF,就是4GB ,这些地址就是虚拟地址\n和虚拟存储器相对应的就是物理存储器,是在现实世界中能够使用的存储器,其中的地址就是物理地址\nMMU(memory manage unit,MMU)内存管理单元\n使用物理地址,运行程序时需要为每个程序分配一块地址空间,每个程序需要在地址空间中进行运行\n使用虚拟地址,每个程序会认为它独占了整个地址空间,这样在编写程序时不需要考虑地址的限制,由操作系统负责调度,将物理存储器动态分配给各个程序,将每个程序的虚拟地址转为物理地址.\n虚拟地址还可以带来保护(protect)和共享(share)\n地址转化 -基于分页(page)的虚拟存储器 典型的页大小是4KB ,物理地址中称为frame,page和frame的大小必须相等\n程序运行时会进行把程序从硬盘搬移到物理内存中,每次搬移的单位就是一个页\nVA[11:0]表示页内的位置,称为page offset ,VA剩余的部分表示哪个页,称为VPN(Virtual Page Number)\nPA[11:0]表示frame的位置,称为frame offset,剩余部分表示哪个frame,称为PFN(Physical Frame Number)\n从VPN到PFN,offset不需要变化\n比方说 page0 -\u0026gt; frame 2 ,offset = 4 , 那只需要把VPN换成PFN ,就是把0换成2,\n如果程序的内容没有存储在物理内存中,MMU就会产生Page Fault的异常给处理器,处理器通过异常处理程序(操作系统的一部分代码)找到替换的frame ,需要先解除frame 和 page的映射,然后把硬盘的内容搬移到frame,然后添加frame和page的映射,如果被替换的frame是dirty的,还需要先将内容搬移到硬盘中,处理完成之后返回发生异常的指令重新执行\n单级页表(线性页表) 页表(page Table,PT)用来存储从虚拟地址到物理地址的映射关系,一般页表是放在物理内存中的,需要使用虚拟地址寻址,页表内被寻址到的内容就是这个虚拟地址对应的物理地址,处理器中会有一个页表寄存器(Page Table Register,PTR)来存放当前运行程序的页表在物理内存中的起始位置,每次操作系统将程序调入物理内存都会去将PTR设置好\n两次内存访问,先使用虚拟地址访问页表,再使用物理地址进行寻址\n使用PTR和虚拟地址共同寻址页表,相当于使用它们共同组成一个地址,用来寻址物理内存\nvalid用来指示当前的page是否在物理内存中\n下图展示如何通过PTR从物理内存中定位一个页表,并且使用虚拟地址来寻址页表,从而找到物理地址,\n具体来说就是一个虚拟地址VPN[31:12],页表的起始物理地址是addr,那这个虚拟地址对应的物理地址就是addr + VPN[31:12]所对应的entry的值,就完成了相应的映射\n页表的表项数为2^32 / 4K = 2 ^20 = 1M ,需要20位来寻址,在页表中包括的所有VPN的映射关系,页表的大小是4B * 1M = 4M , 一个entry 需要32位,因为物理内存的数据位宽是32位\n程序对应的页表,连同pc和通用寄存器,组成了程序的状态,在切换程序时,需要去保存状态,该程序称为进程,用户打开程序,操作系统会分配物理内存的空间,创建页表和堆栈等,进程的页表指定了能够在物理内存中访问的地址空间\n可以通过页表通过相同的虚拟地址访问不同的物理地址 ,通过不同的虚拟地址访问相同的物理地址,实现进程的保护和共享\n多级页表 将4MB的线性页表划分为若干个更小的页表,称为子页表.操作系统在处理进程的时候,根据需求逐步放入子页表,并且子页表不再占用连续的物理内存空间.需要一个表格记录子页表在物理内存中存储的位置,称为第一级页表(level1 page Table),子页表称为第二级页表(level2 Page Table)\n一个2^20的entry的页表可以划分为2^10 entry的一级页表+2^10个2^10大小的二级页表,一个页表的表项称为PTE(Page Table Entry),当操作系统创建一个进程,就在物理内存找一块4KB空间存放一级页表,并将基地址放在PTR寄存器中,一个虚拟地址肯定能够对应一个一级页表的表项,用后10位寻址一级页表,获取二级页表,然后再用前10位获取二级页表的表项,\n页表的映射关系应该都是操作系统分的,是在异常那边进行处理的\n不同的虚拟地址会导致出现不同的页表,极端情况为(1)4M程序连续,会建立一个一级页表和一个二级页表=8KB ,(2)都是离散的,并且全部都在4MB的边界上,这样需要建立1024个二级页表+一个一级页表=4100kB\n增加级数,一级页表寻址二级页表,寻址3级页表\u0026hellip;\n2^64entry -\u0026gt; 4096个2^40entry\n​ -\u0026gt; 4096个4096个2^28 entry\n​ -\u0026gt; 4096 4096 4096 2^16 entry \u0026hellip;\n需要多次访问物理内存,\n处理器多个进程时,为进程分配的物理内存之和可能大于实际可用的物理内存,部分页可能临时存在在下一级的硬盘中,成为swap空间 ,需要用到这些页时才会被调入到物理内存\n把页从物理内存写入硬盘称为Page out ,从硬盘写入swap空间称为Page In\n利用虚拟存储器,可以管理每一个页的访问权限,只需要在页表中去设置每一个页的属性就可以了,\nPage Fault Page Fault是异常的一种,通过操作系统来进行完成\n(1)Page Fault需要访问硬盘,通常为毫米级别,与Page Fault对应的异常处理程序来说是微乎其微的\n(2)使用软件可以根据实现情况实现灵活的替换算法,找到最合适的页进行替换\n直接使用虚拟地址不能知道页位于硬盘的哪个位置,只能知道物理内存的,需要操作系统在开辟swap空间的同时,会使用一个表格记录每个页在硬盘中存储的位置,可以和页表进行合并\n如果valid为0,代表页在硬盘中,反之在物理内存里\n但是实际上物理上仍然是分开的,因为不管一个页是不是在物理内存中,操作系统都必须记录一个进程的所有页在硬盘中的位置\n(1)写通(Write Through),将改变的内容马上写回到硬件中去\n(2)写回(Write Back),只有等到地址的内容在物理内存中要被替换时,才将内容写回到硬盘\n在PTE中增加一个dirty的状态位,当页内的某个地址被写入是,dirty的状态会被置1.在需要被替换时,根据dirty位去决定是否要先写回到硬盘中去\n替换算法可以在硬件上提供支持,在PTE中增加一位来记录每个页最近是否被访问过,称为\u0026quot;使用位(use)\u0026quot;,可以周期性的去将使用位清零\n为了处理Page Fault,硬件需要\n(1)在发现Page Fault,能够产生对应类型的异常,并跳转到异常处理程序\n(2)当写入物理内存时,需要将页表中对应PTE的脏状态置1.\n(3)当store/load物理内存时,将use位置1\n小结 没有Page Fault时 处理器送出的VA送到MMU MMU使用PRT和VA[31:12]组成访问页表的地址,送到物理内存 将寻址到的PTE返回给MMU MMU判断valid=1,使用PA={PFN,VA[11:0]}访问物理地址 发生Page Fault 1~3一致\nMMU发现valid=0,触发Page Fault,处理器会跳转到Page Fault对应的异常程序中,此时MMU还会吧发生Page Fault的虚拟地址VA保存到专业的处理器,供异常处理程序使用 如果物理内存没有空闲空间,异常处理程序会根据替换算法,从物理内存找出未来可能不被使用的页,将其替换,页称为Victim Page,如果dirty为1,需要写入到硬盘 Page Fault异常处理程序会使用MMU保存的虚拟地址VA寻址硬盘,找到对应的页,将其写入到Victim page所在的位置 从异常程序返回时,引发Page Fault的指令会被重新取到流水线中,处理器会重新发送虚拟地址到MMU 程序保护 操作系统的内容不允许被用户进程随意修改,操作系统中的有一部分允许用户进程读取.操作系统相对于普通用户进程来说,应该有足够多的权限,来保证操作系统对于系统的控制权;不同进程之间一个加以保护,一个进程不能让其他的进程随便修改自己的内容\n上述条件需要操作系统和用户进程对于不同的页有不同的访问权限,通过页表可以实现,\n操作系统一般不会使用页表,而是直接访问物理内存,物理内存中的专门一部分供操作系统来使用\nARMv7架构,AP部分决定每个页的访问权限\n一旦发现当前的访问不符合规定,会产生非法访问异常,使得处理器跳转到异常处理程序,由操作系统决定如何处理非法的访问\n也可以对一级页表设置权限控制,每个一级页表可以映射4KB*1024=4MB的地址范围,可以\n00 -\u0026gt; 4MB空间不允许访问, 11 -\u0026gt; 对应的4MB空间不设限制 , 01 -\u0026gt; 需要产看第二级页表的PTE,获得页访问的权限,通过粗粒度和细粒度的组合,可以提高处理器的执行效率\n在有dcache的处理器中,在虚拟地址转化为物理地址之后先去访问dcache,需要有一部分空间是不允许缓存的\nPTE包含\n(1)PFN,表示虚拟地址对应的物理地址的页号\n(2)Valid,表示对应页当前是否在物理内存中\n(3)Dirty,表示对应页中内容是否被修改\n(4)Use,表示对应页中的内容是否被修改过\n(5)AP,访问权限控制,表示操作系统和用户程序对当前页的访问权限\n(6)Cacheable,表示对应页是否被缓存\nTLB和Cache TLB TLB(Translation Lookaside Buffer)用来缓存页表中最近使用的PTE,这样就不需要每次都去访问两次物理内存\nTLB只有时间相关性,空间相关性没有明显的规律\n一般TLB使用全相连的方式来设计\n现代处理器采用两级TLB,一级TLB采用哈佛结构,分为I-TLB和D-TLB,采用全相联,二级TLB是指令和数据共用,一般采用组相连\nTLB命中,直接返回从TLB中得到的物理地址,TLB缺失,需要访问物理内存中的页表\n页表中的PTE有效,直接从页表中得到对应的物理地址 页表中的PTE无效,需要从硬盘中去将相应的页搬移到物理内存中 现代处理器中都支持大小可变的页,由操作系统进行管理,根据不同应用的特点选用不同大小的页\nTLB缺失 (1)虚拟地址对应的页不再物理内存中\n(2)虚拟地址对应的页在物理内存中,但是PTE没有放在TLB中\nPage Table Walk:从页表中找到对应的映射关系,并将其写回到TLB中\n软件实现Page Table Walk.当发生TLB缺失,硬件把产生TLB缺失的虚拟地址保存到特殊寄存器中,产生TLB缺失的异常,在异常处理程序中,软件使用虚拟地址去寻址物理内存中的页表,找到对应的PTE,并且写回到TLB中 .为了防止在异常处理程序中又发生TLB缺失,这个程序会放在不需要进行地址转化的物理内存上 ,软件处理会冲说流水线 硬件实现Page Table Walk. 当发生TLB缺失时,自动使用当前的虚拟地址去寻址页表.硬件进行逐级寻址是比较方便的.这种方式比较适合超标量处理器,不需要打断流水线,但是如果操作系统没有在物理内存中建立好了页表,那硬件没有办法,还是得通过操作系统 采用硬件处理TLB缺失需要使用硬件状态机来寻址页表,还需要将整个流水线暂停等待MMU处理缺失,但是在处理完之后就可以直接去执行.采用软件处理,需要执行异常处理程序,而且从异常处理程序退出后,将流水线恢复到TLB缺失发生之前的状态\n发生TLB缺失,如果需要的PTE在页表中,则TLB缺失的处理时间需要十几个周期,如果发生Page Fault异常,则需要成百上千个周期\n对于TLB来说,随机替换算法是比较合适的,可以采用称为时钟算法的方法,就是通过计数器去随机取值,128的表项就可以通过7位的计数器来随机编号\nTLB的写入 在使用TLB作为页表的缓存,处理器送出的虚拟缓存会访问TLB,如果直接从TLB得到物理地址的话,会使得TLB对应的\u0026quot;use\u0026quot;set,如果是store,会使得dirty=1.但是,如果TLB采用写回,那此时不会去更新页表,所以页表的信息可能是过时的,一种方法是在Page Fault的时候,把所有TLB的表项写回到页表\n但实际上没有必要,可以认为被TLB记录的页都是要被使用的,是无法被替换的,操作系统可以记录哪些PTE被放到了TLB中,这样实际上也能够避免当物理内存中一个页被踢出了之后,还需要查找它在TLB中是否被记录了,如果有还需要置0\n操作系统也需要有能够控制dcache的能力,因为操作系统在物理内存中选择一个页进行替换的时候,如果这个页是脏的,它最新的内容不一定是在物理内存中,还有可能在dcache中.虽然说,存在在TLB的页不会被替换,那按理来说,存在在dcache的数据所对应的页也不会被替换.但是也有例外,比方说,发生TLB缺失之后,有TLB表项的会被替换,但是此时D-cache是没有发生变化的,\n对TLB进行控制 TLB是页表的缓存,如果一个页的映射关系在页表中不存在了,那么它在TLB中也不应该存在\n(1)当一个进程结束,进程的指令(code),数据(data)和堆栈(stack)占据的页表置为无效,此时TLB中可能还存在对应的PTE,可以通过ASID去吧I-TLB和D-TLB的内容置为无效\n(2)当一个进程占用的物理内存过大时,操作系统可能将进程中一部分不经常使用的页写回到硬盘中,也需要将TLB置为无效\n对TLB的管理需要包括,1.能够将I-TLB和D-TLB的所有表项置为无效 2. 能够将I-TLB和D-TLB中的某一个ASID对应的所有表项置为无效 3.能够将某个VPN对应的表项置为无效\nARM的TLB管理 (1)用来管理I-TLB的控制寄存器\n将VPN匹配的表项(entry)置为无效的控制寄存器 VPN相等 如果TLB中一个表项的Global位无效,需要ASID相等,如果Global有效,则不需要 进程中某些地址的映射信息被改变时,需要将TLB对应的表项置为无效\n将TLB中ASID匹配的所有表项置为无效的控制寄存器 ​ 当一个进程退出的时候,需要将当前进程在TLB中的所有内容都置为无效\n将TLB中所有未锁定(unlocker)状态的表项置为无效,锁定状态的表项不发生改变.为了加快处理器某些关键程序的执行时间,可以吧一些表项设为锁定状态 (2) 用来管理D-TLB的控制寄存器同理\n(3)用于将TLB的内容进行读出和写入\n使用两个寄存器来对应一个表项,data1和data0,当读取TLB时,被读取表项的内容会放在寄存器中,\n上面的寄存器都位于系统控制协处理器中,只需要通过访问协处理器的指令(MCR和MRC)就可以了\nMIPS风格的TLB管理 MIPS,TLB缺失通过软件来解决,MIPS定义了专门操作TLB的指令,使用这些指令可以直接对TLB进行操作\nMIPS处理器中,为了加快寻址页表的过程,硬件会自动将这两个部分(页表的基地址和偏移地址)放在context寄存器中,位于协处理器CP0.由于load指令无法直接使用CP0中的寄存器,首先要把context寄存器放在通用寄存器$k1中,在MIPS架构中,R26和R27只用在中断和异常中,也称为$k1和$k0\nTLBWR将entryHi和EntryLo寄存器的内容写到TLB内随机指定的一个表项中,在发生TLB缺失,会自动将当前未能转换的虚拟地址的VPN以及当前进程的ASID写入到EntryHi寄存器中\nCache的设计 TLB只是加速了从虚拟地址到物理地址的转换,但是没有加速从物理内存中取数据的过程,也可以使用cache来加速\n下面是物理Cache,和没有加入TLB其实是一样的\n因为要经过TLB,才能访问物理Cache,所以会增加流水线的延时,如果要获得和之前一样的运行频率,需要再加入一级流水线,但是这样增大了分支预测失败的惩罚,也增大了load指令的延迟\n可以直接使用Virtual Cache来缓存数据\n虚拟Cache会导致两个问题\n(1)同义问题(synonyms),也称为重名(aliasing),即多个不同的名字对应相同的物理位置,会出现Cache不同虚拟地址但实际上对应着相同的物理地址,这样就会浪费Cache的空间,而且load了数据了之后需要对其他虚拟地址的Cache都进行更改,因为实际上它们对应着同一个物理地址.\n如果Cache的容量\u0026lt;4KB,寻址的地址不会\u0026gt;12位,那么对应同一个物理地址的不同虚拟地址也会放在Cache的相同地址上,反之就可能出现同义\n要实现同时更新相同物理地址的Cache,就需要使用物理地址作为Cache的Tag部分,\n下图的结构就可以解决同义的问题,\n未完待续\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-11-12T20:12:09+08:00","permalink":"https://VastCircle.github.io/2024/%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8/","title":"虚拟存储器"},{"content":"Dcache结构图 image-20241111163907552 概述 noblockcache 中共例化了3个小模块,writebackUnit,ProbeUnit,MSHRFile\n该Cache支持主缺失和次缺失两种情况。主缺失是指某个缓存行的首次缺失，导致向主存发送回填请求；而次缺失则是指对缓存的访问也发生缺失，但目标缓存行与之前的主缺失是同一个。\n在MSHR（缺失状态保持寄存器）中，通过主缺失标签和重放队列来跟踪缺失。主缺失标签记录处于处理中的回填请求的地址，并在每次缺失时被搜索，以判断是否为次缺失。发生主缺失时，会分配一个新的主缺失标签来记录地址，发出回填请求，必要时执行驱逐（eviction），并在主缺失标签旁的链表中添加一个新的重放队列条目。重放队列条目包含关于访问的信息，包括对应的缓存行偏移量、字节宽度、用于加载的目标寄存器以及待存储的数据。\n次缺失会在对应的重放队列中添加新的条目，但不会向主存发送额外的回填请求。\nThe cache supports both primary misses and secondary misses. A primary miss is the first miss to a cache line and causes a refill request to be sent to main memory, while secondary misses are accesses which miss in the cache but are for the same cache line as an earlier primary miss.\nMisses are tracked in the MSHR using primary miss tags and replay queues. Primary miss tags hold the address of an in-flight refill request and are searched on every miss to determine if it is a secondary miss. A primary miss allocates a new primary miss tag to hold the address, issues a refill request, performs an eviction if needed, and adds a new replay queue entry to a linked list next to the primary miss tag. Replay queue entries contain information about the access including the corresponding cache line offset, the byte width, the destination register for loads, and pending data for stores. A secondary miss adds a new replay queue entry to the appropriate replay queue, but does not send an additional refill request to main memory\n模块介绍 NonBlockingDCacheModule 目前配置的dcache , 16路\n​ d-cache-block-size = \u0026lt;64\u0026gt;; ​\td-cache-sets = \u0026lt;16\u0026gt;; ​\td-cache-size = \u0026lt;4096\u0026gt;\n4路组相联cache 4096/16/64=4\nval s1_req = Reg(new HellaCacheReq) // s1主要是打了一拍,下面其实是在决定把什么数据打一拍，第一拍就是在仲裁什么数据地址该去读data和meta // cpu_req : cpu的请求信号 when (io.cpu.req.valid) { s1_req := io.cpu.req.bits } // 写回module的请求信号 when (wb.io.meta_read.valid) { s1_req.addr := Cat(wb.io.meta_read.bits.tag, wb.io.meta_read.bits.idx) \u0026lt;\u0026lt; blockOffBits s1_req.phys := true.B } // 控制module的请求信号 when (prober.io.meta_read.valid) { s1_req.addr := Cat(prober.io.meta_read.bits.tag, prober.io.meta_read.bits.idx) \u0026lt;\u0026lt; blockOffBits s1_req.phys := true.B } // when (mshrs.io.replay.valid) { s1_req := mshrs.io.replay.bits } when (s2_recycle) { s1_req := s2_req } s1_clk_en := metaReadArb.io.out.valid //TODO: should be metaReadArb.io.out.fire, but triggers Verilog backend bug // metaReadArb按理有5个端口,但是生成的时候端口0貌似被优化了 metaReadArb.io.in(0).valid := s2_recycle metaReadArb.io.in(0).bits.idx := s2_req.addr \u0026gt;\u0026gt; blockOffBits metaReadArb.io.in(0).bits.way_en := ~0.U(nWays.W) metaReadArb.io.in(0).bits.tag := s2_req.tag metaReadArb.io.in(1) \u0026lt;\u0026gt; mshrs.io.meta_read metaReadArb.io.in(2) \u0026lt;\u0026gt; prober.io.meta_read metaReadArb.io.in(3) \u0026lt;\u0026gt; wb.io.meta_read metaReadArb.io.in(4).valid := io.cpu.req.valid metaReadArb.io.in(4).bits.idx := io.cpu.req.bits.addr \u0026gt;\u0026gt; blockOffBits metaReadArb.io.in(4).bits.tag := io.cpu.req.bits.addr \u0026gt;\u0026gt; untagBits metaReadArb.io.in(4).bits.way_en := ~0.U(nWays.W) WBU WritebackUnit 模块实现了一个缓存的写回单元，负责通过 TL-C 的 C 通道向 L2 Cache 释放替换块 (Release)。\nrefillCycles 表示在发生缓存未命中（cache miss）时，从主存或其他缓存中读取数据并将其填充到目标缓存的过程所需的时钟周期数\n需要wbu的module只有 prober 和 mshrs , prober和wbu的数据都是通过c通道进行回复的\nwbArb.io.in(0) \u0026lt;\u0026gt; prober.io.wb_req wbArb.io.in(1) \u0026lt;\u0026gt; mshrs.io.wb_req wb.io.req \u0026lt;\u0026gt; wbArb.io.out when (active) { r1_data_req_fired := false.B r2_data_req_fired := r1_data_req_fired // 返回数据并且返回tag的时候 when (io.data_req.fire \u0026amp;\u0026amp; io.meta_read.fire) { // 拉高r1_data_req_fired r1_data_req_fired := true.B // 计数器+1 data_req_cnt := data_req_cnt + 1.U } when (r2_data_req_fired) { // 在返回后的第二拍,拉高release.valid io.release.valid := true.B when(!io.release.ready) { r1_data_req_fired := false.B r2_data_req_fired := false.B // 一般都是减去2,除非refilllCycles \u0026lt;= 1 data_req_cnt := data_req_cnt - Mux[UInt]((refillCycles \u0026gt; 1).B \u0026amp;\u0026amp; r1_data_req_fired, 2.U, 1.U) } when(!r1_data_req_fired) { // We\u0026#39;re done if this is the final data request and the Release can be sent active := data_req_cnt \u0026lt; refillCycles.U || !io.release.ready } } } // 发起请求的时候进行active 和 赋值 when (io.req.fire) { active := true.B data_req_cnt := 0.U req := io.req.bits } io.data_req.valid := fire io.data_req.bits.way_en := req.way_en io.data_req.bits.addr := (if(refillCycles \u0026gt; 1) Cat(req.idx, data_req_cnt(log2Up(refillCycles)-1,0)) else req.idx) \u0026lt;\u0026lt; rowOffBits Probe 实现了Cache管理模块的状态机，主要用于处理探测请求的操作，管理Cache的状态，判断命中情况，以及处理数据写回操作,主要针对的是tag,不是data\nprober的请求输入的数据不是cpu_req,而是auto_out_b_ , 代表这是下一级存储l2，比方说外设发起的读数据，或者在多核心的情况下，core0去读cache0,为了缓存一致性的问题，可能需要sbus去读cache1，然后再去写cache0等\nprober应该就是去把dcache的内容给disabled并且写入l2 cache的\n发起auto_out_b_*的是l2 cache\n// 9个状态 val (s_invalid :: s_meta_read :: s_meta_resp :: s_mshr_req :: s_mshr_resp :: s_release :: s_writeback_req :: s_writeback_resp :: s_meta_write :: Nil) = Enum(9) when (io.meta_read.fire) { state := s_meta_resp } // we need to wait one cycle for the metadata to be read from the array when (state === s_meta_resp) { state := s_mshr_req } when (state === s_mshr_req) { old_coh := io.block_state way_en := io.way_en // 比较有意思,如果没有rdy,不是选择wait,而是retry // if the read didn\u0026#39;t go through, we need to retry state := Mux(io.mshr_rdy, s_mshr_resp, s_meta_read) } // 如果是脏数据的话，就要写回到l2, 反之需要释放相应的权限（我觉得主要就是权限的改变，但是不需要伴随数据） when (state === s_mshr_resp) { state := Mux(tag_matches \u0026amp;\u0026amp; is_dirty, s_writeback_req, s_release) } when (state === s_release \u0026amp;\u0026amp; io.rep.ready) { state := Mux(tag_matches, s_meta_write, s_invalid) } // 不管怎么样，最后一步都是write_meta // wait for the writeback request to finish before updating the metadata // meta write 应该有将改变的权限写入meta when (state === s_writeback_resp \u0026amp;\u0026amp; io.wb_req.ready) { state := s_meta_write } 逻辑是比较简单的,就是当发起请求时,去meta_read,meta_read之后去读mshr,读出mshr之后,当tag_match的时候且为dirty,需要写回,所以切换到s_writeback_req ,否则到release,release之后去meta_write.写回是由wb模块控制的\nb通道找不到opcode,但和probe相关是肯定的，param代表10,和c一致\nc通道是probe_ack , c_param指示由于探测而在主代理中发生的特定类型的权限更改,\n如下代表probe_ack , BtoN ,降权限的\n如果是通过wb写回的话，c通道返回就是probe_ackdata ,TtoB,权限降到可读\nL1MetadataArray mata meta就是存储tag的地方,是一个同步ram\n// () =\u0026gt; T是函数的写法 ,无输入参数,输出参数是T类型的 class L1MetadataArray[T \u0026lt;: L1Metadata](onReset: () =\u0026gt; T)(implicit p: Parameters) extends L1HellaCacheModule()(p) { val rstVal = onReset() val io = IO(new Bundle { val read = Flipped(Decoupled(new L1MetaReadReq)) val write = Flipped(Decoupled(new L1MetaWriteReq)) val resp = Output(Vec(nWays, rstVal.cloneType)) }) val rst_cnt = RegInit(0.U(log2Up(nSets+1).W)) val rst = rst_cnt \u0026lt; nSets.U val waddr = Mux(rst, rst_cnt, io.write.bits.idx) val wdata = Mux(rst, rstVal, io.write.bits.data).asUInt // way_en是独热码的形式 val wmask = Mux(rst || (nWays == 1).B, (-1).S, io.write.bits.way_en.asSInt).asBools val rmask = Mux(rst || (nWays == 1).B, (-1).S, io.read.bits.way_en.asSInt).asBools when (rst) { rst_cnt := rst_cnt+1.U } val metabits = rstVal.getWidth // way 是路数 , sets是组数 , way_en 就是用来选择路的 // 同步mem val tag_array = SyncReadMem(nSets, Vec(nWays, UInt(metabits.W))) val wen = rst || io.write.valid when (wen) { tag_array.write(waddr, VecInit.fill(nWays)(wdata), wmask) } // read data io.resp := tag_array.read(io.read.bits.idx, io.read.fire()).map(_.asTypeOf(chiselTypeOf(rstVal))) io.read.ready := !wen // so really this could be a 6T RAM io.write.ready := !rst } metaReadArb or metaWriteArb metaReadArb仲裁输入为 mshrs , prober , wb ,mata 和 data都支持多路读取\nMSHRFile 缓存控制中的关键部分，用于处理多组MSHR（Miss Status Holding Register），协调多种请求（读、写、填充、写回等）在一级缓存（L1 Cache）中的操作。\n顶层输入的每一个req会发送到每一个mshr中，但是最终只有一个mshr会被选中 ，也就代表只有一个mshr会被写入本笔数据\nmshr.io.req_sec_val := io.req.valid \u0026amp;\u0026amp; sdq_rdy \u0026amp;\u0026amp; tag_match mshr.io.req_bits.viewAsSupertype(new HellaCacheReqInternal) := io.req.bits.viewAsSupertype(new HellaCacheReqInternal) mshr.io.req_bits.tag_match := io.req.bits.tag_match mshr.io.req_bits.old_meta := io.req.bits.old_meta mshr.io.req_bits.way_en := io.req.bits.way_en mshr.io.req_bits.sdq_id := sdq_alloc_id cacheable val cacheable = edge.manager.supportsAcquireBFast(io.req.bits.addr, lgCacheBlockBytes.U) cacheable用于检测当前请求的地址是否可以被缓存。edge.manager.supportsAcquireBFast方法检查缓存控制器是否支持快速获取操作。\nsdq 用于管理store data queue\n// 位向量寄存器，用于跟踪SDQ中的空闲条目。每一位代表一个位置，如果为1则表示该位置已被分配，若为0则表示空闲 val sdq_val = RegInit(0.U(cfg.nSDQ.W)) // 通过优先编码获取其中一个空闲的sdq的id,从左往右第一个0 // 比方说 priorityEncoder(0b0100) = 2 ,priorityEncoder(0b0111) = 2 ,独热转数值 val sdq_alloc_id = PriorityEncoder(~sdq_val(cfg.nSDQ-1,0)) // 如果不是全部为1代表有空闲,设为ready val sdq_rdy = !sdq_val.andR // 表示当前请求是否满足写入SDQ的条件 ,需要请求有效,请求能够被接受,可缓存,并且是写命令 val sdq_enq = io.req.valid \u0026amp;\u0026amp; io.req.ready \u0026amp;\u0026amp; cacheable \u0026amp;\u0026amp; isWrite(io.req.bits.cmd) // store data queue ,存放数据 val sdq = Mem(cfg.nSDQ, UInt(coreDataBits.W)) // 当满足条件,就写入相应数据 when (sdq_enq) { sdq(sdq_alloc_id) := io.req.bits.data } // 用于指示是否可以释放存储数据队列中的一个条目,当io.replay.fire（即重放请求有效且被接受）且当前重放指令是写操作（isWrite(io.replay.bits.cmd)）时，free_sdq为true，表示可以释放该条目。 val free_sdq = io.replay.fire \u0026amp;\u0026amp; isWrite(io.replay.bits.cmd) io.replay.bits.data := sdq(RegEnable(replay_arb.io.out.bits.sdq_id, free_sdq)) io.replay.bits.mask := 0.U io.replay \u0026lt;\u0026gt; replay_arb.io.out // sdq_enq代表要去分配sdq了 io_replay.valid 代表sdq使用完了 // uIntToOH(3) = 0b0100 // priotityEncoderOH把最靠近左边的1 set , 比方说 sdq_val = 0b0011, 则 priorityEncoderOH(~sdq_val(cfg.SDQ-1,0)) = 0b0010 when (io.replay.valid || sdq_enq) { sdq_val := sdq_val \u0026amp; ~(UIntToOH(replay_arb.io.out.bits.sdq_id) \u0026amp; Fill(cfg.nSDQ, free_sdq)) // reset | PriorityEncoderOH(~sdq_val(cfg.nSDQ-1,0)) \u0026amp; Fill(cfg.nSDQ, sdq_enq) // set } val replay_arb = Module(new Arbiter(new ReplayInternal, cfg.nMSHRs)) iomshr 输入是s2_req ， 回应resp，这里的resp是直接接入到MSHRfile顶层端口的，它和mshr是同一类东西，应该就是mmio,就是不经过cache的数据,但是本身mshr保存的是缓存未命中的请求以及相关状态，层次有点问题吧\nmmio_alloc_arb.io.out.ready := io.req.valid \u0026amp;\u0026amp; !cacheable val io = IO(new Bundle { val req = Flipped(Decoupled(new HellaCacheReq)) // MSHRfile发起的req val resp = Decoupled(new HellaCacheResp) // resp val mem_access = Decoupled(new TLBundleA(edge.bundle)) // 向mem发起的请求 val mem_ack = Flipped(Valid(new TLBundleD(edge.bundle))) // mem ack val replay_next = Output(Bool()) }) // 输入握手的时候，获取数据 req stage 3 when (io.req.fire) { req := io.req.bits state := s_mem_access } // 获取内存数据 when (io.mem_access.fire) { state := s_mem_ack } // 内存数据响应 when (state === s_mem_ack \u0026amp;\u0026amp; io.mem_ack.valid) { state := s_resp when (isRead(req.cmd)) { // 获取响应的数据 grant_word := wordFromBeat(req.addr, io.mem_ack.bits.data) } } // 发出去了 when (io.resp.fire) { state := s_idle } 其实这个仲裁器像是倒着用的，是把io.req信号去选择一个mshr去输出\nmshr 输入是s2_req\n每个MSHR处理一个缓存块的缺失请求\nmshr应该就是其中的一个表项,这里通过状态机来判断表项是一次缺失还是二次缺失 ,是不是太奢侈了\n该模块的主要功能是管理和协调多种缓存操作，\n处理缓存未命中时的请求。 向主存发出请求并等待响应。 维护状态机以跟踪请求的进度。 根据不同情况执行不同的控制流。 val idxMatch = Wire(Vec(cfg.nMSHRs, Bool())) val tagList = Wire(Vec(cfg.nMSHRs, Bits(tagBits.W))) // idxMatch 只有一个会拉高 val tag_match = Mux1H(idxMatch, tagList) === io.req.bits.addr \u0026gt;\u0026gt; untagBits 状态转移及相应输出 // state 是一个寄存器，用于跟踪 MSHR 的状态。状态机的主要状态包括： // s_invalid：空闲状态，表示 MSHR 未被占用。 // s_wb_req 和 s_wb_resp：处理写回操作的状态。 // s_meta_clear：清理缓存元数据。 // s_refill_req 和 s_refill_resp：处理从主存中获取数据的请求。 // s_meta_write_req 和 s_meta_write_resp：更新缓存元数据。 // s_drain_rpq：处理重放队列的请求 when (state === s_drain_rpq \u0026amp;\u0026amp; !rpq.io.deq.valid) { state := s_invalid } when (state === s_meta_write_resp) { // this wait state allows us to catch RAW hazards on the tags via nack_victim state := s_drain_rpq } when (state === s_meta_write_req \u0026amp;\u0026amp; io.meta_write.ready) { state := s_meta_write_resp } when (state === s_refill_resp \u0026amp;\u0026amp; refill_done) { new_coh := coh_on_grant state := s_meta_write_req } when (io.mem_acquire.fire) { // s_refill_req state := s_refill_resp } when (state === s_meta_clear \u0026amp;\u0026amp; io.meta_write.ready) { state := s_refill_req } when (state === s_wb_resp \u0026amp;\u0026amp; io.wb_req.ready \u0026amp;\u0026amp; acked) { state := s_meta_clear } when (io.wb_req.fire) { // s_wb_req state := s_wb_resp } when (io.req_sec_val \u0026amp;\u0026amp; io.req_sec_rdy) { // s_wb_req, s_wb_resp, s_refill_req //If we get a secondary miss that needs more permissions before we\u0026#39;ve sent // out the primary miss\u0026#39;s Acquire, we can upgrade the permissions we\u0026#39;re // going to ask for in s_refill_req req.cmd := dirtier_cmd when (is_hit_again) { new_coh := dirtier_coh } } // 首次miss的时候,赋值req, 这说明req是被保存在mshr上的,只有首次缺失才会改变 when (io.req_pri_val \u0026amp;\u0026amp; io.req_pri_rdy) { req := io.req_bits acked := false.B val old_coh = io.req_bits.old_meta.coh val needs_wb = old_coh.onCacheControl(M_FLUSH)._1 val (is_hit, _, coh_on_hit) = old_coh.onAccess(io.req_bits.cmd) // 如果命中： //更新一致性状态：将new_coh设为coh_on_hit。 //设置状态为MetaWrite：准备写回元数据。 //如果未命中但标记匹配： //保持一致性状态不变。 //状态转为Refill：准备请求新的数据。 when (io.req_bits.tag_match) { when (is_hit) { // set dirty bit new_coh := coh_on_hit state := s_meta_write_req }.otherwise { // upgrade permissions new_coh := old_coh state := s_refill_req } }.otherwise { // writback if necessary and refill 标记不匹配：判断是否需要写回旧数据，并准备加载新数据。 new_coh := ClientMetadata.onReset state := Mux(needs_wb, s_wb_req, s_meta_clear) } } // state === s_meta_write_req or s_mata_clear io.meta_write.valid := state.isOneOf(s_meta_write_req, s_meta_clear) io.meta_write.bits.idx := req_idx io.meta_write.bits.tag := io.tag io.meta_write.bits.data.coh := Mux(state === s_meta_clear, coh_on_clear, new_coh) io.meta_write.bits.data.tag := io.tag io.meta_write.bits.way_en := req.way_en // state === s_wb_req io.wb_req.valid := state === s_wb_req io.wb_req.bits.source := id.U io.wb_req.bits.tag := req.old_meta.tag io.wb_req.bits.idx := req_idx io.wb_req.bits.param := shrink_param io.wb_req.bits.way_en := req.way_en io.wb_req.bits.voluntary := true.B // state === s_refill_req io.mem_acquire.valid := state === s_refill_req \u0026amp;\u0026amp; grantackq.io.enq.ready io.mem_acquire.bits := edge.AcquireBlock( fromSource = id.U, toAddress = Cat(io.tag, req_idx) \u0026lt;\u0026lt; blockOffBits, lgSize = lgCacheBlockBytes.U, growPermissions = grow_param)._2 // state === s_drain_rpq io.meta_read.valid := state === s_drain_rpq io.meta_read.bits.idx := req_idx io.meta_read.bits.tag := io.tag io.meta_read.bits.way_en := ~(0.U(nWays.W)) // 重放接口 io.replay.valid := state === s_drain_rpq \u0026amp;\u0026amp; rpq.io.deq.valid io.replay.bits := rpq.io.deq.bits io.replay.bits.phys := true.B io.replay.bits.addr := Cat(io.tag, req_idx, rpq.io.deq.bits.addr(blockOffBits-1,0)) rpq 重放队列\n用于暂存未能成功处理的请求，比如因缺少权限、数据尚未准备好等原因导致的请求失败。 这些请求将在条件满足时重新尝试（重放）。 val rpq = Module(new NBDcacheQueue(new ReplayInternal, cfg.nRPQ)) // 无论是一次缺失还是二次缺失，数据都会存放在rpq里 rpq.io.enq.valid := (io.req_pri_val \u0026amp;\u0026amp; io.req_pri_rdy || io.req_sec_val \u0026amp;\u0026amp; sec_rdy) \u0026amp;\u0026amp; !isPrefetch(io.req_bits.cmd) rpq.io.enq.bits := io.req_bits rpq.io.deq.ready := (io.replay.ready \u0026amp;\u0026amp; state === s_drain_rpq) || state === s_invalid addr的划分 val req = Reg(new MSHRReqInternal) val req_idx = req.addr(untagBits-1,blockOffBits) val req_tag = req.addr \u0026gt;\u0026gt; untagBits val req_block_addr = (req.addr \u0026gt;\u0026gt; blockOffBits) \u0026lt;\u0026lt; blockOffBits val idx_match = Mux(io.runahead_flag \u0026amp;\u0026amp; req_block_addr =/= (io.req_bits.addr \u0026gt;\u0026gt; blockOffBits) \u0026lt;\u0026lt; blockOffBits, false.B,req_idx === io.req_bits.addr(untagBits-1,blockOffBits)) io.tag := req_tag io.idx_match := (state =/= s_invalid) \u0026amp;\u0026amp; idx_match pri_val和pri_rdy 首次缺失 仲裁器的逻辑是多个valid同时拉高,取优先级最高的,然后把相应的ready拉高\nmshr.io.req_pri_val := alloc_arb.io.in(i).ready io.req_pri_rdy := state === s_invalid alloc_arb.io.in(i).valid := mshr.io.req_pri_rdy alloc_arb.io.out.ready := io.req.valid \u0026amp;\u0026amp; sdq_rdy \u0026amp;\u0026amp; cacheable \u0026amp;\u0026amp; !idx_match 内存的输出与回复（ack和acquire) 通过TLAbiter 去选择优先级最低的一个进行输出\nTLArbiter.lowestFromSeq(edge, io.mem_acquire, mshrs.map(_.io.mem_acquire) ++ mmios.map(_.io.mem_access)) TLArbiter.lowestFromSeq(edge, io.mem_finish, mshrs.map(_.io.mem_finish)) // 可以看到，主要是通过id来识别回复的数据该回复给谁 mshr.io.mem_ack.bits := io.mem_grant.bits mshr.io.mem_ack.valid := io.mem_grant.valid \u0026amp;\u0026amp; io.mem_grant.bits.source === id.U 数据流向 读 从cpu发起数据起\n可以看到，cpu发起请求时，req和data是差了一拍的，后续会有一个s1来同步data\n然后，cpu_req的信号会进入meta_read和data_read的仲裁器，就是要读tag和data ,index 为 addr [9:6],同时，vaddr会被转换为paddr,然后，再下一拍s2_req_addr被赋值\n第一拍仲裁并输入data,mata,第二拍返回数据（s1),第三拍送给mshr(s2),第四拍写回mata和data(s3)，\n// s2在第1级流水线存在有效指令 (s1_valid)，且该指令未被取消 (~io_cpu_s1_kill)，同时该指令是一个 SFENCE 操作 (s1_sfence) 时，并且没有出现任何异常的时候，就会被赋值为1 s2_valid = s2_valid_REG \u0026amp; {_io_cpu_s2_xcpt_ma_ld_output, _io_cpu_s2_xcpt_ma_st_output, _io_cpu_s2_xcpt_pf_ld_output, _io_cpu_s2_xcpt_pf_st_output, _io_cpu_s2_xcpt_gf_ld_output, _io_cpu_s2_xcpt_gf_st_output, _io_cpu_s2_xcpt_ae_ld_output, _io_cpu_s2_xcpt_ae_st_output} == 8\u0026#39;h0; s1_clk_en \u0026lt;= _metaReadArb_io_out_valid if (s1_clk_en) begin s2_req_addr \u0026lt;= {8\u0026#39;h0,_dtlb_io_resp_paddr} end //当以下条件同时满足时，该表达式为真： //s2_valid_masked：当前请求在第2阶段有效且没有被屏蔽。 //!s2_hit：该请求在缓存中未命中。 所以说发起mshr的请求首先需要没有命中 val s2_hit = s2_tag_match \u0026amp;\u0026amp; s2_has_permission \u0026amp;\u0026amp; s2_hit_state === s2_new_hit_state mshr_valid = s2_valid_masked \u0026amp;\u0026amp; !s2_hit \u0026amp;\u0026amp; (isPrefetch(s2_req.cmd) || isRead(s2_req.cmd) || isWrite(s2_req.cmd)) // 这个过程发生在stage 2,即读出来时就会进行检查，发起读是在stage 1 def wayMap[T \u0026lt;: Data](f: Int =\u0026gt; T) = VecInit((0 until nWays).map(f)) val s1_tag_eq_way = wayMap((w: Int) =\u0026gt; meta.io.resp(w).tag === (s1_addr \u0026gt;\u0026gt; untagBits)).asUInt val s1_tag_match_way = wayMap((w: Int) =\u0026gt; s1_tag_eq_way(w) \u0026amp;\u0026amp; meta.io.resp(w).coh.isValid()).asUInt 附录 参考文献 rocket-chip学习基础篇\n香山手册\nTileLink介绍\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-11-11T16:33:27+08:00","permalink":"https://VastCircle.github.io/2024/nbdcache/","title":"NBDcache"},{"content":"Rocket chip Fronted frontend TilePRCIDomain_3.sv ICache_3 icache frontend.sv ShiftQueue fq frontend.sv Fronted frontend TilePRCIDomain_3.sv Rocket core TocketTile.sv IBuf ibuf Rocket.sv ex image-20241108211542867 mem image-20241108211632083 image-20241108211601921 wb dcache Rocket core TocketTile.sv HellaCacheArbiter_3 dcacheArb RocketTile.sv image-20241109004426330 NonBlockingDcache dcache RocketTile.sv HellaCacheArbiter_3 dcacheArb RocketTile.sv image-20241109005444805 Rocket core TocketTile.sv Boom BoomFronted frontend TilePRCIDomain.sv ICache icache BoomFrontend.sv Queue_66 f3 BoomFrontend.sv Queue_69 f4 BoomFrontend.sv 8条指令,io_enq_bits_insts_ 是单纯的截位,io_enq_bits_exp_insts_ 是做了rvc的判断\nimage-20241109103010659 image-20241109103033295 FetchBuffer fb BoomFrontend.sv BoomFrontend frontend BoomTile.sv io_cpu_fetchpacket_bits_uops_0_\nio_cpu_fetchpacket_bits_uops_1_\nio_cpu_fetchpacket_bits_uops_2_\nio_cpu_fetchpacket_bits_uops_3_\nimage-20241109101138570 BoomCore core BoomTile.sv DecodeUnit decode_units_0 有四个0-3\nRenameStage rename_stage 还有一个 RenameStage_1 fp_rename_stage,路径也是类似的\n0-3 四个\nBasicDispatcher dispatcher 分发有 0_0-3 to mem_issue_unit\n1_0-3 to int_issue_unit\n2_0-3 to fp_pipline\nIssueUnitCollapsing_2 int_issue_unit RegisterRead_1 iregister_read mem_issue int_issue都一样\n_iregister_read_io_exe_reqs_5_ alu_exe_unit_1\n_iregister_read_io_exe_reqs_4_ alu_exe_unit\n_iregister_read_io_exe_reqs_3_ csr_exe_unit\n_iregister_read_io_exe_reqs_2_ jmp_unit\n_iregister_read_io_exe_reqs_1_ mem_units_1\n_iregister_read_io_exe_reqs_0_ mem_units_0\nimage-20241109130000628 BoomCore core BoomTile.sv image-20241109130128445 LSU lsu 然后就是lsu到dcache,dcache又返回相应的数据到lsu,lsu再返回到core\n如果不是访存肯定就不走lsu那条路径\n下面就是unit完成执行之后给rob valid信号,rob应该会相应restore指令,然后给rename_stage commit的一些信息\nimg ","date":"2024-11-07T20:15:39+08:00","permalink":"https://VastCircle.github.io/2024/cpu%E8%B7%AF%E5%BE%84%E6%9F%A5%E6%89%BE/","title":"CPU路径查找"},{"content":"introduction (i) 一种适用于顺序执行核心的高性能、低开销的硬件预取技术，称为标量前推执行（𝑆𝑅𝐸）。𝑆𝑅𝐸在寄存器传输级有效预取复杂的内存访问模式，并实现了硬件优化策略，以尽量减少能量和面积的开销（如图1所示）。\n(ii) 为解决前推执行和缓存替换对有效预取的掩盖问题，我们引入了一种新的工作负载分析方法。该方法通过探索独特的工作负载特性，增强了前推技术在隐藏内存延迟方面的能力，从而缩短总执行时间。\n(iii) 利用自定义指令，我们提出了三种不同的模式，以解决前推技术的安全漏洞，并进一步提升性能。\nbackground A.标量核心中的长延迟内存访问\n顺序执行核心在面积和功耗方面相比乱序执行核心具有显著优势，使其本质上更适合需要长时间运行的场景。然而，在访问稀疏数据结构时，乱序核心可以通过诸如ROB（重排序缓冲区）、保留站、加载缓冲区和存储缓冲区等组件缓解由末级缓存未命中引起的内存访问延迟。相比之下，顺序执行核心缺乏应对内存延迟的有效策略，甚至L1缓存未命中也会显著影响性能。在严重情况下，执行时间的大部分都花费在等待内存上，导致顺序核心的平均每指令周期（CPI）可能达到数十。因此，解决内存延迟问题对于提升顺序执行核心的性能至关重要。\nB. runahead technique 然而，由于高开销，它们并不适合在顺序处理器上实现。以原始的runahead execute为例，当一条长延迟内存访问指令位于指令窗口的头部，导致指令窗口已满并阻塞流水线时，处理器会对架构寄存器文件和分支历史寄存器的状态进行检查点操作，促使处理器进入runahead mode。阻塞指令窗口的内存访问指令的目标寄存器将被标记为INV（无效），并在后续指令流中传播，以防止错误的内存请求。当内存请求返回时，处理器退出前推模式并恢复相关的架构状态。\noverview 目前处理器中的推测预取技术能够有效管理复杂的间接内存访问模式，但在微架构设计中带来了显著的硬件开销，使其不适用于小型核心。在周期精确的仿真器中实现这些技术会导致设计侵入性，并需开发专门的拦截电路。𝑆𝑅𝐸在寄存器传输级开发，通过一系列优化策略来减轻开销，从而确保在低成本的情况下实现高性能。在runahead execute进入条件中集成了一种间接内存访问检测机制，提升了预取的准确性和覆盖范围。\n在RCU中，为拦截正常执行模式下预取数据的回写，MSHR追踪每个缓存未命中请求的详细信息，包括回写位置、请求地址和顺序。在寄存器文件中构建了拦截电路（图2a）。在寄存器文件中还建立了一个CP提取和回写电路，并包含多端口的CP（图2b），通过与级联控制电路集成，利用多个周期提取和回写处理器的状态信息。\n对于在runahead阶段的内存未命中请求以及瞬态执行(transient execution)期间识别的无效内存未命中请求，会检测随后使用缺失数据的寄存器编号，并在scoreboard上重置相应位置（图2c）。开发了一个无效检测和传播机制，用于追踪负责流水线释放的寄存器编号和内存未命中地址，从而防止错误的预取请求。此外，构建了一个紧凑的dual-way cache，用于在runahead 阶段收集存储指令的存储值，确保内存指令的正确执行（图2d）。\n我们还开发了一个自定义ISA接口以增强灵活性，包括（图2e）：(i) Safe Mode，解决在前推推测执行期间因分支预测错误导致的机密数据泄漏风险；(ii) Miss Counter Table,，一个双入口表，用于自定义前推过程的终止点，以优化不同硬件和工作负载的性能；(iii) Aggressive Mode，提供禁用前推期间的FPU选项，防止在浮点运算密集型工作负载中长指令阻塞，并允许发出更多预取请求。\n微架构 选择了开源的Rocket Chip SoC作为𝑆𝑅𝐸微架构的基础。Rocket Chip包含一个低功耗的Rocket核心，支持开源的RV64GC RISC-V指令集，并使用Chisel硬件描述语言编写。它具备支持基于页面的虚拟内存的内存管理单元（MMU）、一个非阻塞数据缓存，以及带有分支预测功能的前端。\nA. The Runahead Control Unit 进入 pseudo-enter 阶段的条件通过处理来自L2缓存MSHR的未命中请求信息（回写位置）来确定。对于non-blocking cache的stall-on-use机制，在解码阶段检测数据使用的时机，使处理器能够在该周期进入pseudo-enter阶段（图3a）。在pseudo-enter阶段，处理器检查是否存在间接内存访问。如果检测到这种访问，处理器将转入runahead execution phase，通常持续十个周期（图3b）。在runahead execution phase，为了便于后续释放流水线并有效管理数据回写寄存器，必须跟踪来自L1缓存MSHR的Load-Miss和Gain-Miss信息，其中包括回写寄存器编号、请求地址和读/写指针等详细信息（图3c）。同时，为防止Load-Miss和Gain-Miss阻塞流水线，通过识别未命中回写寄存器编号来释放流水线并使对应的寄存器和地址无效（图3d）。在进入伪退出阶段时，目标是拦截与Gain-miss相关的数据回写。通过基于L1缓存MSHR中的请求回写寄存器编号、地址和读/写指针，精确拦截相同或不同块的回写请求来实现。此外，同一块内的Gain-miss会触发MSHR重放机制，可能会中断前推过程。拦截电路的扩展设计通过检测并拦截重复请求来解决此问题，以防止此类中断（图3f）。\nB. The Runahead Control FSM 为了实现对预取架构的精确控制，我们将有限状态机（FSM）机制与前推执行模式紧密集成，以增强处理器在处理长延迟内存访问时的效率。FSM通过在各状态间切换动态管理预取操作，确保处理器在内存延迟期间仍保持高效。FSM从伪进入状态开始，在该状态下，它处理来自L2缓存的未命中状态保持寄存器（MSHR）的未命中请求信息（回写位置）。此时，由于数据缓存的“stall on use”机制，处理器不仅不会完全停顿，还会继续执行指令。在这里，处理器检查流水线指令，识别出间接内存访问后，进入前推进入状态。此状态下处理器保存当前状态和寄存器，为后续从前推模式无缝恢复正常操作做好准备，以维护系统完整性（图3a）。完成前推进入状态的相关处理后，处理器直接进入前推执行状态。在前推执行状态下，处理器继续执行指令而不将结果提交至寄存器文件，通过在Load-Miss解决前预取数据来有效减少空闲时间。\n为实现此目的，FSM从L1缓存的MSHR中跟踪Load-Miss和Gain-Miss的详细信息，包括回写寄存器编号、请求地址和读/写指针。流水线被释放，对应的寄存器和地址被无效化，以防止阻塞。一旦Load-Miss数据返回，FSM便切换至前推通过状态，该状态作为中介，决定处理器应进入伪退出状态还是直接进入正常退出状态。FSM在两种情况下会进入伪退出状态：(i) 在数据回写前达到效益点，通过比较请求地址和读/写指针；或(ii) Gain-Miss计数器在数据回写后达到指定值，表明已达到效益点。在伪退出状态，FSM通过准确检测相同和不同块的重复请求来拦截与Gain-Miss相关的回写请求。此拦截机制防止了因相同块中的Gain-Miss触发重放机制而中断前推过程。FSM随后完成操作，确保所有前推执行的指令已完成或安全丢弃。\n如果前推过程中没有未解决的依赖关系，FSM将进入前推退出状态，允许处理器恢复正常处理。然而，若前推执行期间存在无法解决的依赖关系或执行异常，FSM可能会暂时切换至前推无效状态，并通过控制流水线停顿、等待Load-Miss正常返回后再退出前推模式。\nC. 多周期检查点和释放电路\n处理器状态的checkpoint and restore，包括 GHR（全局历史寄存器）、RAS（返回地址堆栈）和架构寄存器文件，对于确保超前运行中的正确操作至关重要。模式和普通模式。 GHR 和 RAS 处理分支历史记录和返回地址跟踪。当处理器进入超前运行模式时，这些结构在单个周期内设置检查点，保留分支预测和返回地址计算所需的信息。退出超前运行模式后，先前保存的分支历史记录和返回地址将被恢复，从而保持准确的控制流，而不会增加显着的性能开销。相比之下，存储处理器架构状态的架构寄存器文件涉及更多数据和复杂性。为了管理这一点，使用了多周期检查点和释放机制，这减少了对扩展模块接口的需求并降低了处理器之间的通信压力。尽管对架构寄存器文件进行检查点需要多个周期，但它与在超前运行模式和正常模式之间转换时清除和重新填充管道所需的五个周期过程相一致，从而避免了任何额外的性能损失。\nD. 预取管理单元 我们设计了预取管理单元（PMU）以检测和拦截错误的预取请求，从而使推测执行能够有效处理内存访问指令。PMU由两个主要结构组成：无效集合单元（ISU），用于拦截错误的预取地址，以及前推缓存（RC），用于在前推过程中存储存储指令的值。\nISU（无效集合单元）：Invfile用于存储无效寄存器编号和地址信息，类似于记分板。每个寄存器编号或前推缓存条目都有一个指示其有效性的位（图4 a）。Load-miss和Gain-miss的写回寄存器编号以及在前推过程中存储的无效地址，通常是Invfile的来源，相关机制检测到时，Invfile被激活。我们将来自执行阶段的RS与内存请求地址进行比较，并与Invfile中的相应位进行比对，产生三种情况（图4 b）：\n当源寄存器编号存在于Invfile中时，启动无效传播机制，设置相应的目标寄存器编号。 如果加载指令的地址有效或所有源寄存器有效，则触发无效重置机制，重置相应寄存器编号的无效位。 如果发现存储地址有效，则激活无效重置机制，重置相应地址位。 基于这些操作的结果，无效寄存器信号转变为内存访问阻塞信号和在写回阶段对处理器的流水线释放信号。无效地址信号被转发到前推缓存模块，以确定加载块是否有效命中前推缓存。\nRC（前推缓存）：前推缓存被设计为紧凑的二路关联存储结构，每个条目包含标签和数据信息，每个数据条目的大小为两个字（具体为16B）（图4 c）。在前推过程中，加载地址同时访问该缓存和L1缓存。它根据内存访问地址的索引信息选择行，匹配适当的集合，然后根据偏移信息选择字节，最后根据方式命中检索匹配的数据。命中机制涉及将内存访问地址的标签信息与前推缓存的标签信息进行比较。如果匹配，则进一步验证数据的有效性。如果有效，则生成命中信号，并用作数据选择的控制信号（图4 d）。在退出前推时，前推缓存中的所有值都被置为无效，以防止访问过时的值，直到新的前推过程重置存储的地址。对于数据替换机制，我们采用伪LRU替换策略选择最不常用的方式进行替换。\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-31T20:13:06+08:00","permalink":"https://VastCircle.github.io/2024/scalar_runahead_execution/","title":"Scalar_runahead_execution"},{"content":"处理器运行 总共的过程应该是在exit之后,处理器(core0)会循环执行下面的代码,主要是要向0x80001ec0写入数据1,会写入到dcache那边\n而serdesser会去l2读取0x80001ec0的数据,中间通过fbus,sbus到l2,如果读取到数据为1的话,就会相应的去发送相关exit信号\n对于fbus_serdesser那边什么时候发送的a_valid ,粗略的看了一下是它和SerialRAM里的serdesser有相互依赖的关系,最后估计会追溯到c代码那边去,从波形图看的话,发送是较为规律的\n路径 TilePRCIDomain tile_prici_domain DigitalTop.sv SystemBus subsystem_sbus DigitalTop.sv CoherenceManagerWrapper subsystem_l2_wrapper DigitalTop.sv 已经从l2读取数据\nSystemBus subsystem_sbus DigitalTop.sv TLBuffer_2 subsystem_fbus_buffer Digitaltop.sv TLInterconnectCoupler_16 subsystem_fbus_coupler_from_port_named_serial_tl_ctrl Digitaltop.sv TLSerdesser subsystem_fbus_serdesser Digitaltop.sv serdesser应该在定时发送请求\nimage-20241112002039647 AsyncQueue subsystem_fbus_out_async Digitaltop.sv image-20241112001843957 DigitalTop system ChipTop.sv image-20241112001700816 ChipTop chiptop0 TestHarness.sv SerialRAM ram TestHarness.sv image-20241111235459860 image-20241111234654487 SimTSI success_exit_sim TestHarness.sv input clock, input reset, input tsi_out_valid, output tsi_out_ready, input [31:0] tsi_out_bits, output tsi_in_valid, input tsi_in_ready, output [31:0] tsi_in_bits, output [31:0] exit ","date":"2024-10-31T13:11:58+08:00","permalink":"https://VastCircle.github.io/2024/%E5%A4%84%E7%90%86%E5%99%A8%E6%88%90%E5%8A%9F%E8%BF%90%E8%A1%8C%E7%9A%84%E6%A0%87%E5%BF%97/","title":"处理器成功运行的标志"},{"content":"路径查找 Bootrom ClockSinkDomain_1.sv ClockSinkDomain_1 bootROMDomainWrapper DigitalTop.sv PeripheryBus_1 subsystem_cbus DigitalTop.sv TLInterconnectCoupler_33 coupler_to_bootrom TLInterconnectCoupler_33.sv TLXbar_5 out_xbar PeripheryBus_1.sv TLFIFOFixer_2 fixer PeripheryBus_1.sv TLBuffer_4 buffer PeripheryBus_1.sv TLAtomicAutomata_1 atomics PeripheryBus_1.sv TLXbar_4 in_xbar PeripheryBus_1.sv image-20241104201454888 PeripyheryBus_1 subsystem_cbus DigitalTop.sv image-20241104200308864 SystemBus subsystem_sbus DigitalTop.sv image-20241104200104409 TLInterconnectCoupler aoupler_to_bus_named_subsystem_cbus SystemBus.sv TLXbar system_bus_xbar SystemBus.sv TLFIFOFixer fixer SystemBus.sv SystemBus subsystem_sbus DigitalTop.sv TilePRCIDomain tile_prci_domain DigitalTop.sv TLBuffer_15 buffer TilePRCIDomain.sv ToomTile tile_reset_domain_boom_tile TilePRCIDomain.sv TLXbar_8 tlMasterXbar BoomTile.sv image-20241104215304702 后面可以不看了\nCoherenceManagerWrapper subsystem_l2_wrapper DigitalTop.sv InclusiveCache l2 CoherenceManagerWrapper.sv TLCacheCork cork CoherenceManagerWrapper.sv image-20241031113807118 BankBinder binder CoherenceManagerWrapper.sv CoherenceManagerWrapper subsystem_l2_wrapper DigitalTop.sv memorybus subsystem_mbus DigitalTop.sv DigitalTop system chiptop.sv Dram 略\n","date":"2024-10-30T16:25:09+08:00","permalink":"https://VastCircle.github.io/2024/big_soc_%E8%B7%AF%E5%BE%84%E6%9F%A5%E6%89%BE/","title":"Big_soc_路径查找"},{"content":"Chipyard SoC 中三个最高层次是ChipTop(DUT)、TestHarness和TestDriver。ChipTop和TestHarness均由 Chisel 生成器发出。TestDriver用作我们的测试平台，是 Rocket Chip 中的 Verilog 文件。\nChipTop(DUT) ChipTop 是顶层模块，负责实例化 System 子模块，通常是 DigitalTop 的具体实例。设计的大部分内容位于 System 中。ChipTop 层中存在的其他组件通常是 IO 单元、时钟接收器和多路复用器、重置同步器以及其他需要存在于 System 之外的模拟 IP。IOBinders 负责实例化与 System 的 IO 相对应的 ChipTop IO 的 IO 单元。HarnessBinders 负责实例化测试夹具，以连接到 ChipTop 端口。大多数类型的设备和测试夹具都可以使用自定义的 IOBinders 和 HarnessBinders 进行实例化。\nDigitalTop system (\t// @[ChipTop.scala:28:35] .clock (_system_auto_implicitClockGrouper_out_clock),\t// @[ChipTop.scala:28:35] .reset (_system_auto_implicitClockGrouper_out_reset),\t// @[ChipTop.scala:28:35] .auto_prci_ctrl_domain_reset_setter_clock_in_member_allClocks_uncore_clock (clock_uncore_clock), .auto_prci_ctrl_domain_reset_setter_clock_in_member_allClocks_uncore_reset (reset_io), .resetctrl_hartIsInReset_0 (_system_auto_subsystem_cbus_fixedClockNode_out_reset),\t// @[ChipTop.scala:28:35] .resetctrl_hartIsInReset_1 (_system_auto_subsystem_cbus_fixedClockNode_out_reset),\t// @[ChipTop.scala:28:35] --- ); 自定义 ChipTop 默认的标准 ChipTop 提供了一个最小的、基本的模板，以便 IOBinders 在 DigitalTop 特性周围生成 IO 单元。对于 tapeout、集成模拟 IP 或其他非标准用例，Chipyard 支持使用 BuildTop 键指定自定义 ChipTop。一个使用非标准 IO 单元的自定义 ChipTop 示例位于 generators/chipyard/src/main/scala/example/CustomChipTop.scala。\n您还可以指定一个完全自定义的 ChipTop，该 ChipTop 不使用任何 RocketChip 或 Chipyard SoC 组件。示例位于 generators/chipyard/src/main/scala/example/EmptyChipTop.scala。可以使用以下命令构建 EmptyChipTop 示例：make CONFIG=EmptyChipTopConfig TOP=EmptyChipTop。\nSystem/DigitalTop Rocket Chip SoC 的系统模块是通过 cake-pattern 组合而成的。具体而言，DigitalTop 扩展了 System，System 扩展了 Subsystem，Subsystem 又扩展了 BaseSubsystem。\nBaseSubsystem BaseSubsystem 在 generators/rocketchip/src/main/scala/subsystem/BaseSubsystem.scala 中定义。查看 BaseSubsystem 抽象类，我们看到该类实例化了顶层总线（frontbus、systembus、peripherybus 等），但没有指定拓扑结构。该类还定义了多个 ElaborationArtefacts，这些文件是在 Chisel 细化后生成的（例如，设备树字符串和外交图可视化 GraphML 文件）。\nSubsystem 在 generators/chipyard/src/main/scala/Subsystem.scala 中，我们可以看到 Chipyard 的 Subsystem 是如何扩展 BaseSubsystem 抽象类的。Subsystem 混入了 HasBoomAndRocketTiles 特性，该特性根据指定的参数定义并实例化 BOOM 或 Rocket 瓦片。我们在这里为每个瓦片连接一些基本的 IO，特别是 hartids 和复位向量。\nSystem generators/chipyard/src/main/scala/System.scala 完成了 System 的定义。\nHasHierarchicalBusTopology 在 Rocket Chip 中定义，指定顶层总线之间的连接。 HasAsyncExtInterrupts 和 HasExtInterruptsModuleImp 添加外部中断的 IO，并将其适当地连接到瓦片。 CanHave\u0026hellip;AXI4Port 添加各种主从 AXI4 端口，添加 TL-to-AXI4 转换器，并将其连接到适当的总线。 HasPeripheryBootROM 添加 BootROM 设备。 Tops SoC Top 继承 System 类，并包含自定义组件的特性。在 Chipyard 中，这包括添加 NIC、UART 和 GPIO，以及为引导方法设置硬件。\nTestHarness TestHarness 与 Top 之间的连接是在添加到 Top 的特性中定义的方法中执行的。当这些方法从 TestHarness 中调用时，它们可以在scope of the harness内实例化模块，然后将其连接到 DUT。例如，从 CanHaveMasterAXI4MemPortModuleImp 特性定义的 connectSimAXIMem 方法，在 TestHarness 中调用时，会实例化 SimAXIMems，并将其连接到顶层的正确 IO。\n尽管这种间接方式连接顶层 IO 可能看起来不必要地复杂，但它允许设计师组合自定义特性，而无需担心任何特定特性的实现细节。\nTestDriver TestDriver 在 generators/rocketchip/src/main/resources/vsrc/TestDriver.v 中定义。该 Verilog 文件通过实例化 TestHarness、驱动时钟和复位信号以及解释成功输出来执行仿真。该文件与为 TestHarness 和 Top 生成的 Verilog 一起编译，以生成仿真器。\n`MODEL testHarness( .clock(clock), .reset(reset), .io_success(success) 总结 TestDriver就是完全的仿真文件\nTestHarness 中包含simdram等仿真组件\nChipTop 是顶层模块，负责实例化 System 子模块，通常是 DigitalTop 的具体实例\n整个system就是一个soc,包含core和外设\n附录 参考文献 Tops,Test-Harnesses,and the Test-Driver\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-29T21:56:38+08:00","permalink":"https://VastCircle.github.io/2024/chipyard%E7%9A%84%E4%B8%89%E4%B8%AAhighest_level/","title":"Chipyard的三个highest_level"},{"content":"rocket-chip 框图 rocket-chip流水线 rocket-chip Icache rocket-chip Dcache rocket-chip 代码结构 ## rocket-chip generator的一级目录结构 bootrom : 在BootROM的bootloader第一阶段所使用的代码 csrc Verilator: 仿真用的C代码 emulator Verilator :用来编译和跑仿真的工作目录 project Scala: 构建工具sbt用来构建Scala的工作目录 regression: 定义的持续的整合和一套nightly regression scripts: 用来分析仿真的输出或者处理代码文件的内容 vsim VCS: 用来编译和跑仿真的工作目录 vsrc Verilog: 代码，包含接口、测试框架和Verilog过程接口VPI chisel3 :包含Chisel自定义的各种类和规则，用来生成RTL firrtl: 存放Chisel编译器处理代码而生成的一种中间表示，由中间表示能生成Verilog代码或C++代码 hardfloat: 用chisel写成的浮点单元 riscv-tools: 支持RISC-V的一套软件，与生成RTL有关 torture: 用来生成压力测试所需的一些随机指令 ## src/main/scala: 构筑rocket-chip的代码 amba: 协议的实现代码，包括AXI4，AHB-lite，APB config: 提供能配置Generator的Scala的接口 coreplex: 包含Rocket核、系统总线、coherence agents、debug设备、中断处理、面向外部的外设、时钟同步处理和TileLink到外设总线转换 devices: 一些外设，包括debug模块和各种挂在TileLink的从设备 diplomacy: 用来扩展Chisel，通过允许对硬件进行两个阶段的阐述，可以让参数在模块之间协调传递 groundtest: 生成可综合的硬件测试平台，通过发出随机的访问存储器指令流，进行对核外的存储器系统进行压力测试 jtag: 用来生成JTAG总线接口 regmapper: 用来生成带有能访问内存映射寄存器的标准接口的从设备 rocket: 用来生成顺序核Rocket、L1指令cache和L1数据cache tile: 包含可以与Rocket核组成tile的组件，如FPU和RoCC协处理器 tilelink: 用来生成TileLink总线（协议），包含一些适配器和转其他总线（协议）的转换器 system:Rocket Chip的顶层代码包，同时也是用作测试的硬件平台的顶层代码包 unittest: 用作生成硬件测试平台来测试单独的一个个模块 util: 提供一些能被其他代码包调用的通用的Scala和Chisel结构 /src/main/scala/system TestHarness.scala TestHarness 模块通过模拟配置、接口连接和调试信号设置，构建了一个测试环境，用于验证 ExampleRocketSystem的功能\nTestGeneration.scala 这段代码定义了RISC-V处理器的测试框架，它主要由一些抽象和具体的测试套件类组成，用于生成用于RISC-V测试的Makefile脚本片段。以下是代码的主要结构与功能：\nRocketTestSuite 抽象类： 这个抽象类定义了一个通用的测试套件结构，包含测试目录、目标名称、测试用例集合等关键参数。postScript属性生成用于链接目标文件的Makefile命令模板。\nAssemblyTestSuite 类：\n这是RocketTestSuite的子类，用于定义汇编语言的测试套件。每个实例表示特定环境（如rv32ui）下的测试集合，并生成包含测试文件的Makefile片段。 BenchmarkTestSuite 类：\n用于定义基准测试套件，支持特定目录中的多个基准测试，例如性能评估用的程序。 RegressionTestSuite 类：\n包含一组用于回归测试的测试文件，通过简单定义makeTargetName来统一生成Makefile片段。 TestGeneration 对象：\n该对象定义了添加测试套件并生成Makefile片段的逻辑。通过gen方法根据测试类型和环境生成目标名称和Perl脚本，用于捕获和处理测试结果。 DefaultTestSuites 对象：\n包含多个默认测试套件的实例，这些测试套件涵盖了不同类型的RISC-V指令集扩展，例如rv32ui、rv64ui、rv32ua、rv64ua等。还包括了一些性能基准和单一回归测试的示例。\nConfigs.scala TestHarness.scala 就是testbench，而 ExampleRocketSystem.scala 就是SOC的层次，包括Core以外的其他外设\u0026amp;总线，Configs.scala 就是核心Core的配置。\nclass BaseConfig extends Config( new WithDefaultMemPort ++ new WithDefaultMMIOPort ++ new WithDefaultSlavePort ++ new WithTimebase(BigInt(1000000)) ++ // 1 MHz new WithDTS(\u0026#34;freechips,rocketchip-unknown\u0026#34;, Nil) ++ new WithNExtTopInterrupts(2) ++ new BaseSubsystemConfig ) ExampleRocketSystem.scala 对于SOC层面的设计\n/** Example Top with periphery devices and ports, and a Rocket subsystem */ class ExampleRocketSystem(implicit p: Parameters) extends RocketSubsystem with HasAsyncExtInterrupts // 提供异步外部中断接口，允许系统处理来自外部设备的异步中断信号 with CanHaveMasterAXI4MemPort // 添加 AXI4 主接口，用于连接存储器 with CanHaveMasterAXI4MMIOPort // 添加 AXI4 主接口，用于连接内存映射的 I/O 端口 with CanHaveSlaveAXI4Port // 添加 AXI4 从接口，支持与其他主设备的交互 { // optionally add ROM devices // 可选地添加 ROM 设备 // Note that setting BootROMLocated will override the reset_vector for all tiles // 设置 BootROMLocated 将覆盖所有核心的重置向量 val bootROM = p(BootROMLocated(location)).map { BootROM.attach(_, this, CBUS) } // 连接 BootROM 到 CBUS，以配置系统启动入口 val maskROMs = p(MaskROMLocated(location)).map { MaskROM.attach(_, this, CBUS) } // 将 MaskROMs 连接到 CBUS，作为只读存储器使用 override lazy val module = new ExampleRocketSystemModuleImp(this) // 延迟加载模块实现 } simAXIMem.scala Memory with AXI port for use in elaboratable test harnesses(一个mem的仿真模型)\n/src/main/scala/rocket 此 RTL 包生成 Rocket 顺序流水线核心以及 L1 指令和数据缓存。此库旨在供芯片生成器使用，该生成器在内存系统中实例化核心并将其连接到外部世界。\n附录 参考文献 rocket-chip目录\nrocketchip学习笔记\nhttps://www.cnblogs.com/gujiangtaoFuture/articles/11766114.html\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-29T17:12:22+08:00","permalink":"https://VastCircle.github.io/2024/rocket-chip%E5%AD%A6%E4%B9%A0/","title":"Rocket Chip学习"},{"content":"差异文件 ### 新加入的 rocket/RCU.scala rocket/rh_cache.scala rocket/RH_Cache.scala rocket/rh_data.scala rocket/rh_tag.scala rocket/Runahead_cache.scala ### 修改过的 rocket/BTB.scala rocket/Frontend.scala rocket/HellaCacheArbiter.scala rocket/HellaCache.scala rocket/NBDcache.scala rocket/RocketCore.scala subsystem/Configs.scala subsystem/SystemBus.scala tile/Core.scala tilelink/Bundles.scala tilelink/Edges.scala 附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-27T21:23:02+08:00","permalink":"https://VastCircle.github.io/2024/%E5%BE%AE%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/","title":"rocket-src微架构代码解读"},{"content":"附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-26T15:23:09+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B09/","title":"提交"},{"content":"概述 无\n重排序缓存 一般结构 ROB是一个FIFO\n(1)Complete:表示一条指令是否执行完毕\n(2)Areg:指令在原始程序中指定的目的寄存器,逻辑寄存器\n(3)Preg:指令的Areg经过寄存器重命名之后,对应的物理寄存器编号\n(4)OPreg:指令的Areg被重命名为新的Preg之前,对应的旧的Preg,当指令发生异常(exception)进行恢复,会用到\n(5)PC:指令对应的PC值,当发生中断或异常之后,需要保存指令的PC值\n(6)Exception:指令发生异常的异常类型\n(7)Type:指令的类型会被记录到这里,当指令retire时,不同类型的指令会有不同的动作,例如store指令写D-cache(那执行在干嘛)\n在流水线的分发阶段,指令会按照进入流水线的顺序写入ROB,ROB中对应的complete会被置0,执行完成之后会被置1.指令的计算结果可以放在ROB中,也可以放在物理寄存器堆(PRF)中.\n异常的处理统一放在提交阶段\n指令表项的编号会一直随着指令在流水线中流动\ni1是除法指令,i2使用i1的结果,所以i1,i2执行时间很长\n端口需求 对于一个4-way的超标量处理器来说,在ROB中每周期可以退休的指令不少于4条,ROB选择那些Complete的指令进行退休,但是由于是顺序的,如果连续4条中出现一条not ready ,后续的就无法retire\n(1)4个读端口:retire时检测指令是否complete\n(2)8个读端口 : 在流水线的寄存器重命名阶段,需要从ROB读取4条指令的源操作数 ????\n(3)4个写端口:分发阶段需要向ROB写入4条指令 ????\n(4)最少4个写端口:在write back 阶段,需要写入最小4条指令的结果 (最少是由于很多处理器的issue width \u0026gt; machine width)\n管理处理器的状态 Architecture State , 通用寄存器的值,PC的值,存储器的值 Speculative State,超标量处理器内部的状态,例如重命名使用的物理寄存器,重排序缓存(ROB),发射队列(Issue Queue)和store buffer 等,这些状态超前于指令集定义的状态 对于采用将通用寄存器扩展进行寄存器重命名的架构,需要将目的寄存器的值从物理寄存器搬移到通用寄存器中\n对于采用通用的物理寄存器进行重命名的架构,需要将目的寄存器在物理寄存器堆中标记为外界可见的状态???\n如果退休的指令是store, 需要把store buffer对应的值写到D-cache去(难道不是写完了再退休的吗)\n如果退休的指令是分支指令,需要进行状态恢复,并且冲刷错误指令,从正确地址取地址 ,\n在提交阶段还需要对异常进行统一处理\n两种方法\n(1)使用ROB管理指令集定义的状态\n(2)使用物理寄存器管理指令集定义的状态\n使用ROB管理指令集定义的状态 (Retire Register File) 当指令退休的时候,指令的结果可以对指令集定义的状态进行更新,此时会将指令的结果从ROB中搬移到指令集中定义的逻辑寄存器中.逻辑寄存器存储了所有退休指令对应的目的寄存器的值\n一般情况下,使用ROB管理指令集定义的状态,都对应着使用数据捕捉的结构来进行发射(issue),因为指令的内容会存在在ROB和通用寄存器当中,通过数据捕捉可以在执行阶段把数据送到payload RAM ,可以直接从payload RAM去获取所有数据\n对于非捕获队列,没有payload RAM,相应的数据是直接从ROB或者通用寄存器获取,所有需要发射队列支持额外的写端口(通知操作数的位置变动),和额外的旁路网络来\n使用物理寄存器管理指令集定义的状态 当物理寄存器的结果被计算出来之后,指令的状态变成了complete,当它退休的时候,直接把相应的状态标记为 Architecture state ,直到另一条指令写入同样的目标寄存器并且退休了,就相当于直接把指令集定义的逻辑寄存器融入到物理寄存器中\n(1)当指令从ROB中退休之后,不需要把指令的结果进行搬移,便于实现低功耗\n(2)在基于ROB进行状态管理时,需要ROB开辟空间存放指令的结果,但例如store,比较指令,分支指令是没有目的寄存器的,ROB会有一部分空间浪费掉了,但是这种方法只会对于存在目的寄存器的指令分配空间\n(3)ROB是集中管理方式,指令需要从其中读取操作数,同时指令也需要把结果写入其中,需要大量的读写端口,但是使用物理寄存器可以采用cluster结构等方式来避免多端口的负面影响\n但是这样会造成寄存器重命名比较复杂 ,使用ROB管理时,只需要写入ROB就完成了重命名,但是使用物理寄存器管理,需要额外的表格存放哪些物理寄存器是空闲的,并且重映射关系的建立和释放都比较困难,并且需要一个额外的表格来存放那些物理寄存器是Architecture state (这不是加一个标志位就可以了)\n特殊情况的处理 分支预测错误,或者异常\nstore指令只有在retire阶段才能够真正改变处理器的状态(写D-cache),如果发射了D-cache缺失,会阻碍流水线中所以后面指令继续退休\n分支预测失败 以流水线的寄存器重命名为分界\n前端的状态回复(front-end recovery):将流水线中重命名阶段之前的所有指令都抹掉,将分支预测器中的历史状态标进行恢复,并使用正确的地址取指令\n后端的状态恢复(back-end recovery time):把处理器中所有内部组件(Issue Queue,Store Buffer 和 ROB)错误的指令都抹掉,恢复重命名映射表(RAT),以便那些错误指令对RAT的修改进行改正,同时被错误的指令占据的物理寄存器和ROB的空间需要被释放\n满足后端恢复的时间小于前端恢复的时间+取指和寄存器重命名的时间,不需要暂停流水线\n基于ROB重命名的架构(基于扩展的ARF进行寄存器重命名同理) 当寄存器位于ROB时,在RAT中存储在ROB的位置,位于ARF,直接进行寻址 , RAT的地址是逻辑寄存器的值,数据是存储类型及对应具体位置\n一条退休的指令将目的寄存器从ROB搬移到ARF中后,并不一定表示以后指令需要从ARF读取寄存器的值\nA :ADD R1,R2,R3 B :ADD R1,R1,R4 C :ADD R1,R1,R5 只有指令C的映射关系会写入到RAT中, 即使指令A从流水线中退休了,后续的指令也只使用指令C的结果(why???).为了实现能够在指令实现搬移之后从ARF读取寄存器的值,在ROB中的每条指令都会检查自身是否是最新的映射关系,只有当一条指令从ROB中退休的时候,发现自身也是最新的映射关系,才能够将RAT中对应的内容改为ARF状态\n从ROB中退休的指令检查自身是不是最新的映射关系:在指令退休的时候,使用目的寄存器读取RAT,读出逻辑寄存器此时对应的ROB pointer,如果发现它和当前退休指令在ROB中占据的地址是一样的,表面这条退休的指令是最新的映射关系\n在流水线中发现分支预测失败时(一般是在执行阶段),此时流水线中有一部分指令是在分支指令之前进人到流水线的，它们可以被继续执行，因此当发现分支指令预测失败时，并不马上进行状态修复，而是停止取新的指令，让流水线继续执行，这个过程称为将流水线抽干(drain out),直到分支指令之前的所有指令(包括分支指令本身)都退休。此时 ARF 中所有寄存器的内容都是正确的，同时在流水线中的所有指令都是处于错误的路径上，可以将流水线中的指令全部抹掉，然后将 RAT 中所有的内容都标记为 ARF 状态，这样处理器就从分支预测失败的状态恢复过来了，此时可以从正确的地址开始取指.\n优点:重命名易于实现,状态恢复容易\n基于统一的PRF进行重命名的架构 两个RAT (前端RAT(Speculative RAT)和后端RAT(Architecture RAT)),可以使用后端RAT对处理器进行状态恢复\n和前面类似,当发现分支指令预测失败时，并不马上进行状态修复，而是停止取新的指令，让流水线继续执行，这个过程称为将流水线抽干(drain out),直到分支指令之前的所有指令(包括分支指令本身)都退休,之后可以将流水线中的指令全部抹掉，然后将后端RAT 中所有的内容都复制到前端RAT，这样处理器就从分支预测失败的状态恢复过来了，此时可以从正确的地址开始取指.这种方法就是Recovery at Retire\n还是会遇到问题,就是分支指令之前存在D-cache缺失的指令,会等待时间过程导致分支预测失败时的惩罚(mis-prediction penalty)过大\n为了解决上述问题,可以使用checkpoint,即在每条分支指令改变处理器状态之前,把处理器的状态保存起来,然后通过分支指令编号选择性去抹除流水线错误路径的指令,然后使用checkpoint去恢复RAT,基于SRAM的RAT需要保存整个表格,基于CAM的RAT只需要保存映射表中的状态位\n还可以去选择性的分配checkpoint的资源,对于分支预测错误率比较高的才分配checkpoint,但是如果分支预测失败,还是需要采用Recovery at Retire恢复,也可以使用ROB进行恢复,因为ROB中还是保存着旧的映射关系,即记录着每条指令对于重命名映射表的修改\n异常的处理 使用ROB去顺序的执行所有的异常\n在指令即将要退休的时候,如果发生了异常就不能退休,而是要去转而处理异常\n精确异常:处理器能够知道哪条指令发生了异常,并且这条发生异常的指令之后所有的指令都不允许改变处理器的状态,这样在处理完异常之后,可以精确的进行返回,返回地方有两种,(1)返回到发生异常指令本身,重新执行指令(TLB缺失),(2)不重新执行指令,而是返回到它的下一条指令(系统调用) ,精确异常需要抹去产生异常的指令后面的所有指令,并回复处理器修改的状态\n可以采用前面所说的Recovery ai Retire来恢复异常\n还有一种方法就是WALK,通过ROB保存的旧数据来恢复\n在使用统一的PRF进行寄存器重命名的方式中,和RAT相关的还有两个表格,一个存储那些物理寄存器是空闲的,Free Register ,一个存储物理寄存器的值是否被计算出来,Busy Table\n对于Free Register Pool ,因为刚刚读取的内容不会消失,不会被退休的指令覆盖,所以只需要恢复读指针,可以利用ROB的旧映射关系来进行恢复(如果是顺序读取Free Register Pool的话其实感觉只需要回退读指针就可以了)\n对于Busy Table,由于指令运算完成之后,就可以在写回阶段写入对应的物理寄存器,所以在发生异常时,Busy Table已经进行了多次修改.还是可以通过ROB,在从ROB读取指令时,每读取一条指令,就将指令的目的寄存器在Busy Table对应的内容置为无效 ,这样后续的指令也不会使用到错误的值了\n对于统一的PRF进行重命名的架构,使用WALK的方法是合适的,因为涉及到对Free Register Pool和Busy Table的恢复\n中断的处理 中断是处理器外部发生的 ,是异步的\n(1)马上处理,当中断发生时,就将流水线中的指令全部抹掉,按照异常处理的方式进行恢复,并将流水线中最旧的指令PC值(还有其他状态寄存器)保存起来,然后跳转到对应的中断处理程序,返回时,使用保存的PC值重新取指令 .这种方式实时性最强,但是相当于之前的那些指令需要重新执行\n(2)延迟处理 .当中断发生时，流水线停止取指令，但是要等到流水线中所有的指令都退休(retire)之后才对这个中断进行处理，这样能够保证流水线中这些已有的指令不被“浪费”,而且当流水线中所有的指令都退休之后，此时流水线的状态肯定是正确的，也就不需要进行状态恢复了。\n(1)如果在流水线中的这些指令发生了 D-Cache 缺失，那么需要很长的时间才能够解决，这样导致了过长的中断响应时间。 (2)如果在流水线中发现了一条预测失败的分支指令，那么首先需要对这个情况进行处理，将处理器的状态进行恢复，这需要消耗一定的时间，也造成了中断响应时间的增大。\n(3)如果流水线中的这些指令中发生了异常(exception),那么是先对异常进行处理，还是先对中断进行处理？这需要仔细地进行权衡，但是一般来说，应该是先对中断进行处理， 因为很多类型的异常处理需要耗费很长的时间，如 D-Cache 缺失、TLB 缺失或者 Page Fault等，这样会导致中断的响应时间讨长而无法忍受。\nstore指令的处理 store指令通常在retire之前都是不写入D-cache的,它会写入store buffer,这样load指令就会从store buffer 或者D-cache去获取数据.这种方法最安全,但是一旦store指令D-cache缺失,需要等待很长的时间,会造成ROB的堵塞\n可以在store buffer中增加一个状态位,标记store指令是否具备退休的条件,这样store在缓存中有3个状态\nun-complete(未执行完毕),当store指令在分发阶段占据一个store buffer的时候标记为un-complete\ncomplete(已经执行完毕),当store指令已经得到地址和数据,但是没有变成最旧的指令,标记为complete\n(retire)离开流水线,当store指令成为最旧的指令并退休是,在store buffer标记该状态,这样store指令可以离开ROB,就不会阻碍后面的指令离开流水线,而硬件会自动将store buffer中处于retire状态的store指令写到D-cache中,并且此时store buffer中的retire的内容也会成为Architecture state的一部分\nstore buffer中的指令只有在完成写D-cache的任务之后才会释放空间,这样会造成分发之前的流水线发生阻塞,可以把已经退休的store指令存储在一个叫做write back buffer的地方,硬件会自动将write back buffer的store指令写到D-cache中\n这样write back buffer也会成为Architecture state的一部分,load指令需要在store buffer和write back buffer中查找.一旦write back buffer没有空间了,就不能再将store指令退休\nstore 指令也是顺序进入write back buffer的,但是在进入的同时需要查找有没有写入相同地址的store指令,有的话需要把前面的store指令置为无效 ,保证load能够查找罪行的数据\n对于软件处理TLB缺失的处理器,在store指令需要退休时,如果ROB中记录了TLB缺失的异常,那么store指令不能够进入write back buffer,而是需要异常的处理,需要将流水线清空,进行处理器的状态恢复.然后跳转到对应的异常处理程序中去,处理完之后重新执行store,这样可以保证所有进入write back buffer中的store指令不会产生TLB缺失\n指令离开流水线的限制 在4-way的超标量处理器中,如果ROB中最旧的四条指令都处于complete状态,理论上四条指令都能够退休\n但是 (1)每周期有四条store指令退休,意味着D-Cache或者Write Back Buffer需要支持四个写端口\n(2)每周期有四条分支指令退休,意味着没周期需要将四条分支指令的信息写回分支预测器,这需要分支预测器中是偶有部件需要支持四个写端口,同时需要能够将Checkpoint资源在每周期释放四个\n(3)如果在处理器中对 store/load 指令之间的相关性实现了预测，即预测一条 load 指令是否会和它之前的 store 指令存在相关性，在这种情况下，如果每周期有四条 load 指令退休，意味着每周期需要将四条 load 指令的信息写回到相关的预测器中，这也导致了四个写端口的需求。\n但是上述情况出现的概率很小,所以增加硬件结构不如对指令进行限制,比方说限制每次退休的分支指令只能有1条之类的\nbr_mask = 1110 (如果假设分支指令是1,那对分支指令进行异或应该能够得到1110这一串数字), st_mask = 1111 , ld_mask = 1111 ,那么代表第四条指令是第二条分支指令,再把3个结果相与,得到1110,代表只有前三条指令有资格退休\n同理,对于异常指令,也只能退休一条,所以在检测到异常指令之后,需要对后续的指令进行屏蔽\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-26T15:06:32+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B05/","title":"提交"},{"content":"概述 旁路网络:负责将FU的运算结果送到需要的地方\n每个FU都和一个1-of-M的仲裁电路一一对应,被选择的指令去读取物理寄存器堆(或者payload RAM),从而得到对应的操作数,每个仲裁电路和物理寄存器也数一一对应的\nFU的类型 ALU AGU(address generate unit) 用于计算访问存储器类型的指令在指令中携带的地址\nBRU(Branch Unit) 负责处理程序控制流(control flow)类型的指令\n负责将分支指令携带的目标地址计算出来,并且根据一定的情况来决定是否使用地址,同时对进行分支预测正确与否的判断\n对于ARM和PowerPC在每一条指令都加入的条件码,不局限于分支指令,相当于吧程序中的控制相关性使用数据相关性代替了,这样可以降低分支指令使用的频率,但是条件执行会占据指令编码的位数,减少指令中分配给通用寄存器的部分,并且可能会出现很多条无效的指令,反而可能会降低效率\n而且,如果跳转指令的条件不成立,比方说下面的ADD指令,可能就会使用错误的数据,可以通过暂停流水线或者预测的方式来解决\nselect-uOP指令 对于Intel,通过硬件插入额外的指令来选择正确的结果\n通过加入uOP来选择结果,但是这要求条件执行的指令必须成对出现,但是这样对编译器存在一定的制约,可以采取对于每一条条件指令都加入select-uOP的方法来解决,就相当于在执行完成条件指令之后,又对执行条件指令之后的值和执行条件指令之前的值进行了一次选择,将选择的值用于后续的寄存器重命名\n对于ARM指令,有一个条件寄存器CPSR,对于每一条条件指令例如ADDEQ,都需要先去判断条件寄存器的值,再决定执行不执行\nBRU还负责对于分支指令结果的检查,通过分支缓存和BRU单元的结果进行对比来实现,因为分支缓存中是保存了所有预测跳转的指令\n旁路网络 从FU的输出端到输入端架起一个通路,可以将FU的结果送到所有FU的输入端,物理寄存器堆,payload RAM,即旁路网络\n在更为现实的处理器中,在Regfile read 之后还会加入一个流水段称为 source Drive,因为对于一条指令从源操作数从物理寄存器读出来之后,还需要经过很长的一段布线,才能达到输入端,而且FU的输入端有大量的多路选择器,用来从不同的旁路网路或者物理寄存器堆选择合适的操作数,同理 FU的输出段也需要经过复杂的网路到达输入端,也需要一级,即Result drive\n简单的旁路网络 一个FU中也会有多个计算单元,一个周期只能送一条指令进FU,如果计算单元需要的周期数(latency)相等,那无所谓,但是如果不能,就可能出现在不同周期被送进来,但是在相同周期计算出结果,都想通过旁路网络进行传送\n一种解决方法就是对于一条指令正常进行唤醒和仲裁,在FU中被执行前,首先检查当前FU是否可以被自己使用(通过周期数,上周期接收了一条latency=2的指令,当周期就不要接收latency=1的指令),如果不行,放回发射队列,重新进行仲裁.\n但是这样会造成一些本来可以仲裁成功的指令被耽搁了,因此可以直接让latency作为某个值的指令就不参与仲裁的过程\n在设计发射队列时,也需要考虑是否当前的FU是能够被使用的\n对每个仲裁电路设计一个位宽为2位的控制寄存器,高位用来拦截所有latency=2的指令,低位拦截latency=1的指令,并且在发射队列的表项中增加两个信号,指示latency=1 or 2\n每个周期都需要对两位寄存器进行赋值,也要进行移位,比方说 latency = 3,就将两位寄存器赋值为10,latency = 2 ,就将两位寄存器赋值为01\n如果第一个周期选中了latency = 3的指令 , 第二个周期选中了latency = 3的指令 ,cycle 1 , a = 10 , cycle 2 , a = 11 = (10 \u0026raquo; 1 )| 10\n复杂设计的旁路网络 (1)指令 B 只能在流水线的 Execute 阶段，从指令 A 的 Result drive 阶段获得操作数。\n(2)指令 C 可以在流水线的 Source drive 阶段，从指令 A 的 Result drive 阶段获得操作数；或者指令 C 也可以在流水线的 Execute 阶段，从指令 A 的 Write back 阶段获得操作数。 (3)指令 D可以在流水线的 Source drive 阶段，从指令 A 的 Write back 阶段获得操作数。 (4)指令 E 在流水线的 RF Read 阶段读取物理寄存器堆(PRF)时，就可以得到指令 A 的结果了，因此它不需要从旁路网络中获得操作数，这里假设物理寄存器堆可以在前半个周期写人，后半个周期读取。\n对于每一个指令,不一定是在执行阶段得到旁路网络的结果\nexecute阶段的操作数除了来自于上一级流水线,还可以来自于两个FU计算的结果 ,来自于流水线的 Result Drive (B相对于A)\nSource Drive 阶段,操作数除了来自于上一级流水线,还可以来自于以前流水线的结果,分布在Result Drive(C相对A)和Write Back(D相对于A)\nA和E是不需要旁路网络的 ,即某一条指令处在RF Read 里,另一条指令处在Write back 里,就不需要进行旁路\n(1)当两条指令处在相邻周期,旁路路径只能发生在Execute 和 Result Drive\n(2)当两条指令相差一个周期,旁路路径能够发生在Source Drive和Result Drive, Execute 和Write Back 之间\n(3)当两条指令相差两个周期,旁路路径只能发生在Source Drive 和 Write Back 之间\n提供数据的指令一定得在Execute后,接受数据的指令一定要在RF read后\n操作数的选择 ScoreBoard\nFU#:记录物理寄存器从哪个FU中被计算出来,当一条指令被仲裁电路选中的时候,如果指令存在目的寄存器,就将这条指令在哪个FU中执行的信息写到表格中\nR:表示物理寄存器的值已经从FU中计算出来了,并且已经被写到物理寄存器堆中了(在写回的时候更新)\n指令B通过读取scoreBoard可以得知需要从FU中取数据\n指令C可以得知可以从PRF中取数据\n可以把读取scoreboard的过程放到流水线的RF Read阶段,使得ScoreBoard和PRF同时读取,但是这样会出现问题就是比方说指令A和指令C,如果移动到了Regfile Read阶段,指令C无法获知指令A修改的ScordBoard的值,需要加入比较逻辑,当ScoreBoard写入和读取的编号一致的话,就设置为从PRF取得操作数\n对于能够并行执行N条指令的处理器,需要2N个读端口,2N个写端口\n用最简单的方法,就是因为每个FU会把一条指令的计算结果广播送到FU输入和物理寄存器堆,同时也会送出对应的寄存器编号,所以可以直接和源寄存器进行比较就行,需要选择操作数的两个周期Source Drive 和 Execute阶段(为什么是两个阶段????)\nCluster Cluster IQ 通过将一个集中式的发射队列分成几个小的分布式发射队列,每个发射队列只对应一个仲裁电路和FU,这样每个分布式发射队列只需要存储对应的FU能够执行的指令\n(1)可以减少每个分布式发射队列的端口个数\n(2)每个分布式发射队列的仲裁电路只需要从少量的指令进行选择,可以加快每个仲裁电路的速度\n(3)分布式发射队列的容量比较小,指令被唤醒的速度也比较快\n缺点就是一个发射队列的指令对其他发射队列指令进行唤醒时,需要经历很长的走线,可能需要增加一级流水线,这样当两条存在相关性的相邻指令属于两个不同Cluster事,不能背靠背执行\n但是通过对指令进行合理的算法分配cluster,也可以做到周期的合理使用\n对于普通的集中式发射队列,需要3个周期,如果A,B,E在同一个cluster,C,D在另一个cluster那需要5个周期,但是如果A,C分到一个cluster,B,D,E分到另一个cluster中,那就只需要3个周期\n对于非数据捕捉结果的处理器,指令会先读取物理寄存器堆,需要PRF支持多个读端口,所以可以对寄存器堆也采用cluster结构,对每一个采用cluster结构的发射队列使用同一个物理寄存器堆\n原来4个FU有8个读端口,4个写端口,可以变成4个读端口,4个写端口,不过需要让两个PRF保持一致,还需要去更新另一个寄存器(那不是会影响并u行性)\n当两个存在相关性的连续指令属于两个不同的cluster时,后续的指令需要等到前面的指令更新完寄存器堆之后,才能够从寄存器堆读取操作数????? 因为旁路网络最好不好跨越两个cluster\ncluster bypass 采用cluster结构的可以直接去除流水线的Source Drive 和 Result Drive流水段\n在顺序执行的处理器,由于硬件无法调度不相关的指令,非完全的旁路网络会带来很大的负面影响,会产生大量的气泡,显然降低了处理器的性能,因此尽量会采用完全的旁路网络\n可以类比发射队列,在相邻的cluster加入一级流水线来降低路径延时,形成完全的旁路网络\n发射队列的流水和旁路网络的流水导致的延时不会叠加\n存储器指令的加速 memory diambiguation 访存地址也会存在相关性,但是这个相关性是在执行阶段计算出访存的指令之后才能够被发现 ,在解码阶段是无法被发现的\n大部分的store是按照顺序执行的(in-order),可以避免WAW相关性(why?)\nload指令可以分为\n(1)完全的顺序执行,没有WAW和WAR相关性\n(2)部分的乱序执行,顺序执行的store将程序分成不同的块,每当一条指令store的地址被计算出来,store指令和后续的store指令之间的所有load指令可以乱序执行,可以避免WAR相关性的发生\n当一条store指令地址被计算出来后,load指令就具备判断RAW相关性的条件了,每条load指令把它携带的地址计算出来之后,需要和前面所有已经执行的store指令携带的地址进行比较.通过 store buffer保存已经被仲裁电路选择倒是没有离开流水线的指令\n当store被选中时,其实就可以去允许后面的load指令参与仲裁,因为store指令地址计算的结果肯定先于load地址 存在的问题就是,如果在BCD没有被选中完毕之后,指令E被选择了,此时如果指令E和指令D的地址一致,指令D也不应该获取指令E的内容,所有需要判断出那些store指令在load的前面,哪些在后面\nPC值,但是存在向前跳转的指令 ROB,ROB是顺序的,但是由于访存指令还是少数,所以会比较稀疏 解码阶段为load/store指令分配编号 对于上述指令,部分的乱序也是会浪费很多性能\n(3)完全的乱序执行,WAR和RAW都需要在流水线中执行\n只要load指令的操作数准备好了,就可以直接发起仲裁请求了\n可以让load/store共用发射队列,但还是需要独立的仲裁电路,store指令的仲裁电路需要根据年龄,找到最旧的指令(in-order),load指令,只需要选择准备好的最老的一条指令就行了(out-of-order)\n如果分开发射队列的话,store的发射队列只需要使用FIFO结构\n需要精确的预测机制来避免RAW的相关性,例如如果发现一条LOAD指令和之前的STORE指令存在RAW相关性,就先进行记录,在后续从store buffer 中获取数据 ,这样其实也可以去减少store buffer需要的端口和比较电路\n非阻塞cache 阻塞cache:在发生cache缺失的时候,就锁定D-Cache与数据内存之间的数据通路,处理器无法执行其他的load/store指令\n非阻塞cache:在发生缺失时还是可以执行其它的load/store指令,所以需要去保存load/store相应的一些数据,比方说store的数据 ,load的目的寄存器,但是实际上访问存储器还是通过一条数据通路\n为了支持非阻塞cache,需要将那些已经产生D-cache缺失的load/store指令保存起来(MSHR(Miss Status/infornmation Holding Register))\n(1)首次缺失 ,对于一个给定的地址,访问D-Cache时第一次产生的缺失\n(2)再次缺失,首次缺失但是没有被解决,后续访问存储器的指令再次访问发生缺失的cache line ,再次缺失针对的是cache line 不是相同的地址,\nMSHR:\nV:valid ,指示当前的表项(entry)是否被占用 ,首次缺失MSHR本体的一个表项会被占用,Valid置一,直到Cache line从下级存储器被取回来.\nBlock Address : Cache line 数据块的公共地址\nIssued: 表示发生首次缺失的load/store指令是否已经开始处理,即是否向一级存储器发送读数据的请求\nLOAD/STORE Table\nValid : 表示一个表项是否被占用,无论是首次缺失还是再次缺失\nMSHR entry : 表示发生缺失的指令属于MSHR本体的哪个表项,产生缺失的指令可能会对应同一个cache line , 为了避免重复占用下一级存储器的带宽,只会占据同一个MSHR entry ,但是占据多个LOAD/STORE Table\nDest.register : 对于load指令,记录目的寄存器的编号, 对于store指令,这部分记录store指令在store buffer中的编号,一是可以找到store指令所携带的数据,以便和下级存储器中取出的数据块合并,二是能够释放store指令占据的store buffer中的空间\nType :记录访问存储器指令的类型\nOffset:访问存储器的指令所需要的数据在数据块中的位置\n当发生缺失是,首先查找MSHR的本体,如果有相同的表项,代表再次缺失,只需要写到LOAD/STORE Table ,如果没有,需要写入MSHR和LOAD/SOTRE Table\n如果满了,就无法去处理新的访问存储器指令,就阻塞了\n对于load指令,需要把数据送到对应目的寄存器,并写到D-cache里 ,\n对于store指令,需要从Store buffer中找到对应的数据,和数据块合并,然后写到D-cache 里,然后释放store buffer\n(in-cache MSHR )\n在分支预测失败之后,需要去删除LOAD/SOTRE Table正在执行的load/store指令 ,并且如果针对于一个数据块的所有load/store指令都处于分支预测的路径上,那这个数据块也不能去更新到D-cache上去\n关键字优先 就是去改进读取cache块数据的顺序 ,本来是0,1,2,3,4,5,6,7,8,可以修改为 \u0026mdash; 之类的 ,可以去把访存需要的数据提前\n提前开始 在Cache line读取到指令需要的数据之后,就可以让CPU去继续执行了 ,相比于关键字优先不需要额外的硬件,但是如果数据处在数据块比较后面的位置,那就没有太大的用处\n对于I-cache ,虽然指令需要做到顺序取出,但是由于存在分支跳转,也可以通过非阻塞的操作来加快取指,不同于D-cahce的是取出的指令必须是顺序的,如果前面的指令没有被取出来也必须进行等待直到数据被取出\n附录 参考文献 超标量处理器\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-22T13:17:32+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B08/","title":"执行"},{"content":"概述 只要发射队列中的一条指令的草做书都准备好了,且满足了发射的条件,就可以送到相应的FU中执行.发射队列的作用就是使用硬件保存一定数量的指令,然后从指令中找出可以执行的指令\n发射时序一般处在处理器的关键路径上,直接影响处理器的周期时间\n(1)发射队列(Issue Queue),用来存储已经被寄存器重命名,但是没有被送到FU执行的指令,也称为保留站(Reservation station)\n(2)分配(allocation)电路,用来从发射队列中找到空闲的空间,将寄存器重命名之后的指令存储在其中\n(3)选择电路(仲裁电路),发射队列中多条指令的操作数都准备好了,电路会按照一定规律,从其中找到最合适的指令,送到Fu中去\n(4)唤醒电路,当一条指令经过FU执行而得到结果数据时,会将其通知给发射队列中所有等待数据的指令,指令对应的源寄存器就会被设置为有效的状态,即为唤醒.\n集中式 or 分布式发射队列 如果所有FU共用一个发射队列,即为集中式发射队列(centralized issue queue,CIQ)\n如果每一个FU都有单独的发射队列,称为分布式发射队列(Distributed issue queue,DIQ)\nCIQ容量大,选择电路和唤醒电路复杂,电路利用率高\nDIQ会出现一个发射队列满了,其他发射队列没有满,但是最终数据被阻塞的情况,就会出现效率低下的问题\n数据捕捉 or 非数据捕捉 寄存器的数据读取时间\n数据捕捉 流水线的发射阶段之前读取寄存器,被寄存器重命名的指令会先读取物理寄存器堆,然后将读取到的值一起写入到发射队列,没有被计算出来的数据会以编号的形式写入,供唤醒时使用,会被标记为无法获得状态(non-available),这些值会通过旁路网络获取.在发射队列中,存储指令操作数的地方称为payload RAM\n一条指令被仲裁电路选中发射到FU中去,它会将目标寄存器进行广播,其他在发射队列的指令就会去对比,有相等的情况时就会在payload RAM进行标记,在FU计算完成之后会写入到payload RAM 对应的位置 .\nmachine width : 每周期实际解码和重命名的指令个数\nissue width : 每周期最多可以在FU中并行执行的指令个数\n在RISC 里 machine width \u0026lt;= issue width\n物理寄存器的端口数 = machine width * 2\n大多数源操作数会经历两读1写,从寄存器读取出来,送到发射队列,从发射队列中读取送到FU ,功耗高 ,面积大\n寄存器重命名方便 ,指令在顺利离开流水线的时候,需要将结果从重排序缓存中搬移到ARF中,采用数据捕捉的方式可以不用惯性指令结果的变化??????\n非数据捕捉 在发射阶段之后读取物理寄存器堆,被重命名之后的指令不去读取物理寄存器堆,而是直接将源寄存器堆的编号放到发射队列中去.当指令被选中时,通过编号读取物理寄存器堆,将读取值送到FU中\n寄存器堆的读端口 = issue width ,比较大\n压缩 or 非压缩 压缩 当一条指令被选中离开发射队列之后,指令上面所有的指令都会下移一格\n通过多路选择器进行压缩\n这种方式选择电路比较简单,通过优先编码选择最旧的就行了,oldest-first方法 ,但是选择电路的延时很长\n优点如下:\n1.分配电路简单,发射队列中的空闲空间总是处于上层,只需要使用发射队列的写指针,指向第一个空闲空间\n2.选择电路简单.最旧的指令存在的RAW相关性也越多,先执行可以最大程度释放和它存在RAW相关性的指令\n但是\n1.实现起来浪费面积\n2.功耗大\n非压缩 没有移动\n发射过程中的流水线 非数据捕捉结构的流水线 要被FU执行\n(1)指令所有的源操作数准备好了\n(2)指令被发射队列选中\n(3)能够从寄存器,payload RAM或者旁路网络获得源操作数\n下图发射过程被分为了唤醒(wake-up)和仲裁(Select)两个流水线阶段\n唤醒阶段,发射队列中的所有相关寄存器会被置为准备好的状态\n仲裁阶段,会使用仲裁电路选择一条最合适的指令送到FU中\ntomasulo算法:在指令执行完才对相关指令进行唤醒\n可以通过将唤醒过程提前来获得更高性能\n即在指令A被仲裁电路选中后就对其他寄存器进行唤醒,这样指令B在下一个周期就能够被仲裁\n意思是 Select 和 wake-up应该是在同一个周期的串行,A被唤醒才能够去selectB\n这种操作称为\u0026quot;原子的\u0026quot;\n拆分流水线可以使得主频升高,但是\n(1)分支预测失败,惩罚增加\n(2)cache访问的周期数增加\n(3)功耗增大\n以上是假设执行是一个周期,实际上并不止\n数据捕捉结构的流水线 可以把select和payload放在同一个流水段 ,在指令被仲裁电路选中之后,在同一个周期对发射队列其他的指令进行唤醒,同时去读取payload RAM,这两个操作是并行进行的,在这个流水段还会负责payload RAM的读取和写入,会导致处理器的周期时间变得过大.\n旁路网络这样是啥意思????\n另一种设计方式是把payload单独放成一个流水段,旁路和执行分成两个流水段,在旁路阶段,FU的结果会被送到payload RAM和FU的输入端\n分配 对于非压缩的方式设计的发射队列,需要分配电路扫描整个发射队列,找到四个空闲的表项并将四条指令写入\n可以使用一个表格来记录所有空闲表项的编号,按照FIFO的方式管理,也可以简单把发射队列分为多个部分,每个段选一个空闲编号,但是会出现问题就是如果有一个表项非空的话,会阻碍其他指令的放入,甚至由于在寄存器重命名阶段是in-order状态A的无法放入会导致后续指令都无法放入\n仲裁 最好实现oldest-first功能的仲裁\n1-of-M仲裁 可以通过指令在ROB中的位置作为指令的年龄信息,但是由于ROB是一个循环队列,所有单纯的地址是无法表征年龄的\n其实我觉得,直接比较读写地址可以的吧,读指针 \u0026gt; 写指针 , 下新上旧 , 读指针 \u0026lt; 写指针 , 上新下旧 ,其实读指针 \u0026gt; 写的时候,也代表两者不是一面的\n可以在ROB中地址前面再加入一位,称为位置值.想当于对于读写地址又加了一位\n(1)位置值相同时,ROB地址越小,对应的指令越旧\n(2)位置值不同时,ROB地址越大,对应的指令越旧,比方说情况2的 0 10 与 1 01 比较,明显是0 10 旧\n先根据是否rdy选出指令,再根据年龄进行筛选\n二分\n该电路能够得到最小的年龄值,但是还需要得到最小年龄值对应的指令,最方便的是将指令信息也一同附上去\nN of M 仲裁电路 几个FU共用一个发射队列,发射队列需要在一个周期内为没一个FU选择出一条指令,就要求有一个N of M的仲裁电路\n可以通过两级仲裁电路实现,第一级选择一条指令后对第二级进行标记,但是这样延时极大\n对每一个FU使用一个1 of M的仲裁器, 根据指令类型进行分类,这样就会存在相同类型的指令会阻塞或者一部分FU处在空闲状态的问题\n可以通过增加FU的数量解决上述问题,但是比方数两个ALU,指令该分配给哪个ALU又是一个问题,可以通过轮换分配法实现,但是这样是无法保证严格的oldest-first原则的,而且有可能会浪费FU资源\n一般来说,加减法,逻辑运算,移位运算合成一个FU,\n惩罚和除法合成一个,\n访问存储器和访问协处理器合并在一起,\n浮点运算合并在一起\n唤醒 单周期的唤醒 唤醒是指被仲裁器选中的指令将目的寄存器的编号(dst_tag)和发射队列中所有源寄存器的编号进行比较,并将那些比较结果相等的源寄存器进行标记的过程\n下面的电路是所有仲裁电路共享一个发射队列的情况, 所以发射队列只会接受到一个响应,因为同一时刻肯定只有一条指令被仲裁,每个FU都会使用一个仲裁电路\nimage-20241020213306752 (1)ValL:指令中是否存在第一个源寄存器\n(2)SrcL:指令中第一个源寄存器的编号\n(3)RdyL:指令中第一个源寄存器是否已经被唤醒而处于准备好的状态\n(4)ValR:第二个\n(5)Dest:目的寄存器的编号\n(6)Issued:一条指令被仲裁电路选中之后,可能不会马上离开发射队列,需要进行标记,这样的指令不会向仲裁电路发出请求信号\n为什么有四个仲裁电路?????是不是指多个FU,但是多个FU不是应该可以接受多个请求\n发射队列的每一个表项都会根据四个响应信号的值,将自身的目的寄存器编号送到对应的总线上去,每个仲裁电路对应一个总线\n被仲裁电路选择的指令会将它的目的寄存器编号送到对应的总线上 每一条总线的值会和发射队列中所有指令的源寄存器的编号进行比较,如果发现相等,标记为准备好的状态 当发射队列某条指令的操作数都准备好了,并且没有被仲裁电路选中过,就可以想仲裁电路发送请求信号 如果仲裁电路发现有更高优先级的指令发出请求,当前指令不会得到有效响应信号,需要再之后的周期继续发送请求信号.在一些设计中,可以轮流向多个仲裁电路发送请求.如果从仲裁电路中得到有效信号,就会吧issued置位.一条被选中的指令不会立刻离开发射队列,因为一个指令如果使用了load指令的结果,即使被仲裁电路选中,也不能离开 发射队列的指令更具响应信号,,把目的寄存器编号送到对应总线上去,用来唤醒发射队列中所有相关的源寄存器 多周期的唤醒 单周期的唤醒能够在一个周期被FU执行完毕,但是当一条指令无法在一个周期执行完毕时,需要根据她在FU中的周期数,将唤醒过程延迟\n根据唤醒的过程\n延迟广播. 发现被仲裁电路选中的指令执行周期大于1,则在选中的当前周期,不讲指令的目的寄存器编号送到总线上,而是根据选中指令需要执行的周期数(N),延迟N-1周期,才送到总线上去\n延迟广播之后可能出现tag bus产生冲突,比方说下面的MUL和ADD在同一时刻需要将目的寄存器的值送到tag broadcast bus上\n可以通过增加总线的数量,也可以利用表格,记录下FU执行指令所需要的周期数,被仲裁电路选中的指令,如果发现冲突,被选中的指令不会送到FU中执行,而是在下一个周期继续参与仲裁\n但是还是存在一个问题,就是指令B被否决(cycle 1),本身指令C是可以被仲裁的,但是C比B要新,所以这个周期被浪费掉了,所以可以先检查是否冲突,如果冲突的话就不向仲裁电路发起请求了(不发请求很奇怪啊,发请求在仲裁的时候否决行不行),但是这样访问网络和仲裁电路是串行的\n延迟唤醒 最优解就就是要去实现背对背执行,一条指令的执行和后一条指令的执行是先后的\n在比较结果相等时,不马上置为准备好的状态,而是根据指令所需要的执行周期数,进行相应周期的延时,然后再改变发射队列中源寄存器的状态\n通过移位寄存器实现延迟唤醒的效果.在解码阶段对每条指令执行周期数进行编码,称为DELAY,在将目的寄存器送到总线外,还需要将DELAY值也送到总线上去.称为DELAY bus .\nFreed :表项是否空闲\nIssued:指令是否被仲裁电路选择\nSrcL:第一个源寄存器编号\nSrcL_M:当寄存器编号比较结果相等时,置1;当接收到仲裁电路的响应信号后,清0,它是移位寄存器进行算数右移的使能标志\nSrcL_SHIFT:移位寄存器,当编号比较结果相等时,将DELAY写入移位寄存器,每周期进行算数右移\nRdy:表示第一个源寄存器是否准备好了\nSrcR_imm_valid :表示第二个操作数是否是立即数\nROB ID:指令在ROB的位置,使得其能够实现oldest-first选择\n编码形式是类似于11111000(8位),在经过3个算数右移之后最低位就是1,就是Rdy=1\n直到被仲裁电路响应或者说选择之后,SrcL_M,srcL_SHIFT都会清零,其他时候Rdy都会保持着1的状态发送请求,直到被仲裁\n推测唤醒 对于某些指令,指令在FU中执行的周期数是可以被预测的,这样才可能分配一个确定的DELAY值\n但是对于\n(1)Load指令\n(2)某些处理器的特殊情况,例如RowerPC 603处理器存在early out,即当被除数值比较小时能够被提前预测指令\n比较简单的方法就是等指令执行完了之后再去唤醒其他指令\n可以优化一下就是一般load指令在第一个周期计算地址,第二个周期访问Tag SRAM,第三个周期将读取到的数据写入目的寄存器,所以在第二个周期就可以判断,命中后去唤醒\n假设d-cache是一直命中的,就能够得到一个比较理想的情况 但是一旦指令A发生了D-cache缺失,此时B就不能停住而等待操作数,这样会使得FU无法接受其他新指令,严重影响处理器的性能.最好的办法是将指令B重新放回发射队列(Issue Queue),因为load指令在D-cache缺失之后,会到L2 cache寻找数据,此时可以假设L2 cache是命中的,并按照命中时间重新对相关寄存器进行唤醒,还是使用延迟唤醒\n对于不确定周期的指令,可以去预测指令执行的周期数,在指令得到结果之前,对相关的指令进行唤醒操作\n预测成功就执行,预测失败就去进行状态会被,被唤醒的所有寄存器需要重新设置为(not ready)状态,如果一些指令离开了发射队列,还需要从流水线中抹去,放回发射队列\n未完待续\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-19T20:25:19+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B07/","title":"发射"},{"content":"超标量处理器的寄存器重命名 对于 Dest = Src1 op ASrc2\n(1)从RAT中找到Src1和Src2对应的物理寄存器Psrc1和Psrc2\n(2)从空闲列表(Free list)中找到一个空闲的物理寄存器Pdest,将其作为指令的目的寄存器Dest对应的物理寄存器\n(3)将逻辑寄存器Dest和物理寄存器Pdest的映射关系写到RAT中\nRAT需要3个读端口(Src1,Src2和Dest作为地址) Dest这个端口用于和ROB进行交互,将之前的映射关系写入ROB中\n对于超标量,就需要成倍的端口\n(1) A,B存在RAW相关性 , 所以r0对应的物理寄存器之列来自于指令A对应的P30,不来自于从RAT读取的值\n(2)A,B,D存在WAW相关性,\nA.在写入RAT时,如果多条命令有同一个目标寄存器,那映射关系实际上写的还是最新的那条指令\nB.在将旧映射关系写入ROB的时候,如果发现一个周期内有多条指令都使用的同一个目的寄存器,此时写入到ROB中的旧映射关系不再来自于RAT读取的值,还是直接来自于和他存在WAW相关的指令,例如指令B的物理寄存器来自r0,或者所物理寄存器来自于P31\n(3)B,D存在WAR相关性,通过寄存器重命名可以客服\n解决RAW相关性 意思就是如果在同一周期进行寄存器重命名,对于源寄存器,应该获取当前赋值给目的寄存器的物理寄存器(P31),而不是之前的物理寄存器(P25),所以需要进行组内相关性检查,由于此时是顺序的,所以相关性检查和顺序处理器相似,只需要比较源寄存器与目的寄存器的编号就可以了\n解决WAW相关性 对写RAT进行检查 在寄存器重命名周期,如果存在多个指令的目的寄存器都相等的情况,那么只有最新的那条指令的映射关系才运行写入到RAT中 ,可以通过检查目标寄存器来实现,例如对于dst0只要和dst1,dst2,dst3中的任意一个存在相同的情况,就不需要将dst0对应的映射关系写到RAT中\n对写ROB进行检查 为了能够释放掉那些不再使用的物理寄存器,同时可以对处理器的状态进行恢复,每条指令需要从RAT中读出他以前对应的物理寄存器,并将其写到ROB当中,如果两条指令存在WAW,那么比较新的这条指令对应的就的物理寄存器就直接来自与比较旧的那条指令,而不是RAT中\n通过比较指令与前面指令的目的寄存器就可以实现\nRAT的SRAM结构 读优先 : 当前写入的数据在下一个周期才能被读取\n写优先:当前写入的数据在当前数据就能够被读取\n对于RAT,需要做到先读,读完再修改,所以采取读优先\n对于读取目的寄存器,由于本来就要获取目的寄存器之前对应的物理寄存器,所以读优先是必须的\n对于读取源寄存器,其实需要得到新的映射,需要使用之前的RAW相关性的检查和处理电路\n特殊情况的标记 对于没有一个目标寄存器和两个源寄存器的指令,采取以下方式\n(1)根据需要重命名的目的寄存器个数,觉得当前周期需要从空闲列表读取数字的个数\n(2)使用目的寄存器读取RAT时,目的寄存器不存在的指令不会读取RAT\n(3)使用源寄存器读取RAT时,源寄存器不存在的指令不会读取RAT\n(4)在RAW和WAW相关性检查时,如果源寄存器和目的寄存器不存在,那就忽略\n寄存器重命名的恢复 使用checkpoint对RAT进行恢复 SRAM的最小存储单元(Main Bit Cell,MBC), (Checkpoint Bit Cell ,CBC)\n当需要对RAT进行状态保存时,将MBC的内容复制到指定的CBC中(Allocation),当对RAT进行状态恢复时,将对应CBC的内容复制到MBC中(Restore)\n使用WALK对RAT进行恢复 对每一条指令,在ROB中都储存了这条指令之前对应的物理寄存器,利用这个信息,可以将RAT的状态逐步\u0026quot;倒回去\u0026quot;,使得那些处在错误路径上的指令,对RAT的修改都进行修复\nROB中储存着物理寄存器,逻辑寄存器,之前的物理寄存器,一条一条回退到之前的物理寄存器,应该就可以做到\n使用Architecture State对RAT进行恢复 在流水线提交阶段有一个RAT,,叫做aRAT(architecture RAT),它所保存的物理寄存器和逻辑寄存器的映射是完全正确的\n对于如下的指令,在重命名阶段的RAT,对于r1的映射应该是P34,但是实际上此时指令D是处在推测阶段,是有可能被冲刷掉的,但是对于aRAT,它保存的就是已经提交的指令之间的映射,例如R1对应P31,它的状态是完全正确的\n所以说,可以通过aRAT进行恢复,具体就是在分支预测失败时,让指令继续执行,直到分支指令变成最旧的一条指令,那此时所保存的状态就是分支指令之前的指令所得到的状态,再复制,就能够恢复了\n等到分支指令变到流水线最旧的指令,才恢复RAT的另一个好处就是,如果在一条分支指令之前存在异常或者另一个分支预测失败,那这条分支指令就不会被处理,也避免了一些无用功\n分发 (1) 发射队列 (out-of-order),指令在送到FU中被执行之前,先被放到一个缓存中,每个FU都对应一个发射队列,\n只要一条指令的所有源操作数都准备好了,就可以直接送到FU中执行,不用理会指令的原始顺序,在多发射处理器中,需要从缓存中找到多个空闲的表项\n(2)发射队列(in-order),分支指令和store指令是按照顺序执行的,该队列就是FIFO\n(3)重排序缓存(ROB),将乱序拉回顺序\n分发就是将寄存器重命名之后的指令写到发射队列和重排序队列当中\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-19T11:46:41+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B06/","title":"寄存器重命名(超标量+过程恢复)"},{"content":"概述 WAW 和 WAR (写后写 和读后写) 可以通过更换寄存器的名字来解决相应冲突\n存在原因 (1)有限个数的寄存器\n(2)循环体,很容易出现写后写冲突\n(3)代码重用,一些小函数被频繁的调用\n物理寄存器(Physical Register)和逻辑寄存器(Logical Register或者 architecture Register)物理寄存器数量多于逻辑寄存器\n重命名映射表 (Register Renaming Table, Register Alias Table ,RAT)空闲寄存器列表(Free Register List)\n寄存器重命名的方式 (1)将逻辑寄存器(architecture Register File,ARF)扩展来实现\n(2)使用统一的物理寄存器(Physical Register File,PRF)实现\n(3)使用ROB实现\nROB 将ROB作为物理寄存器,存储所有**推测状态(speculative)**的结果,使用逻辑寄存器(ARF)存储所有正确的结果\n当一条指令被写入ROB中的一个表项(entry)时,表项的编号即为物理寄存器,这样将逻辑寄存器和表项建立了关系,\nROB存储着所有没有离开流水线的指令结果,逻辑寄存器(ARF)存储着所有\u0026quot;最新\u0026quot;离开流水线的指令结果\n重命名映射表用来指示每一个逻辑寄存器的值是位于ROB中还是位于ARF中\n缺点 (1)即使没有目的寄存器也会占用ROB的一个表项,代表物理寄存器的浪费\n(2)对应ROB和ARF需要有多个读端口来支持多条指令的访问\nARF扩展 可以使用一个独立的存储部件来存储流水线中所有指令的结果,只有那些存在目的寄存器的指令才会占据该部件,称为 PRF(Physical Register File),PRF和ROB类似,只是在没有目标寄存器的指令不会占据PRF,寄存器重命名时存在目的寄存器的指令会占据PRF的空间,在退休时,结果会从PRF搬移到ARF中\n重命名映射表用来指示每一个逻辑寄存器的值是位于PRF中还是位于ARF中,需要保存PRF的地址空间\n使用统一的PRF 存储所有推测的和正确的寄存器值,\n使用空闲列表记录PRF哪些寄存器处在空闲状态\n当指令被寄存器重命名,并且存在目的寄存器的时候,就会占据PRF当中的一个寄存器,该寄存器会经历值未被计算,值被计算但是没有退休,退休三个过程\n通过重命名映射表存储每个逻辑寄存器和物理寄存器的对应关系\n寄存器重命名时,\n源寄存器:查找重命名的映射表(RAT),找出对应物理寄存器的编号\n目的寄存器:给目的寄存器指定一个空闲状态的物理寄存器,并且该关系会被更新到RAT中\n指令退休之后释放物理寄存器\n一条指令之后在退休的时候,结果才会被外部看到,推测时是无法被外界看到的,需要使用另外一个RAT,存储所有\u0026quot;退休\u0026quot;状态的指令和物理寄存器的对应关系(啥时候释放?),外部只能通过查找这个RAT,找到逻辑寄存器对应的物理寄存器\n**只有后续的指令不使用物理寄存器之后,物理寄存器才能够变成空闲.**可以采取比较保守的方式,就是当一个指令和后面的莫条指令都写到同一个目的寄存器时,前面指令的物理寄存器可以释放了,**所以在ROB中除了记录逻辑寄存器当前对应的物理寄存器之外,还需要存储它之前对应的物理寄存器,**以便在指令退休的时候,将旧映射关系释放\n优点 (1)寄存器的值只需要被写入一次?\n(2)源寄存器的值只能存储在一个地方,即PRF中\n重命名映射表(RAT) RAT是一个表格,使用逻辑寄存器作为地址寻址,对于指令的源寄存器,可以从表格中得到对应的物理寄存器的编号\n对指令的目的寄存器来说,会将物理寄存器编号写到这个表格,即建立映射关系\n可以使用多端口的SRAM(sRAT)和CAM(cRAT)实现,CAM(内容寻址的存储器)\nSRAM表项个数等于逻辑寄存器的个数,里面存放对应物理寄存器的编号,位宽为log(物理寄存器数量)\nCAM表项个数等于物理寄存器的个数,里面存放对应逻辑寄存器的编号,位宽为log(逻辑寄存器数量),寻址时逻辑寄存器的编号会和每个表项进行对比,返回对应的地址\n使用SRAM寻址功耗小,面积小\n由于对于cRAT进行checkpoint只需要保存状态位(V),而不需要将整个cRAT进行保存,能够大大减少checkpoint电路的面积,当checkpoint数量大时,反而cRAT具有优势\n基于SRAM的重命名映射表 checkpoint需要把整个sRAT都保存下来\n对于4-way的超标量处理器,每周期最多需要对四条指令进行寄存器重命名,sRRAT需要8个读端口和4个写端口(每条指令包含2个源寄存器和1个目的寄存器)\n新写入到sRAT的值会覆盖掉原来旧的对应关系,需要记录下来\n(1)方便指令在退休的时候,将对应的物理寄存器变为空闲状态???? (还是无法理解,按理来说覆盖了说明该逻辑寄存器又分配了新的物理寄存器,那原来那个确实可以删除了)(覆盖的时候后面的指令还没有退休,是有可能无效的(分支失败异常之类的,那后面分配的必定是要被还原的,所以物理寄存器是应该在后面指令退休的时候再变成空闲状态))\n(2)当一条指令之前存在异常或者分支预测失败时,需要从流水线中被抹去 ,同时这条指令对于RAT的修改需要被恢复过来,通过将旧的映射关系保存下来,可以协助RAT的修复\n缺点就是无法使用多的checkpoint\n只要预测的足够准,就不怎么需要checkpoint ,就可以去减少checkpoint的数量,但是如果预测错了又没有checkpoint,那对于RAT的恢复也会很麻烦\n??? RAT里面的值不是应该也是保存在ROB里的吗,那保存ROB不就行了,为什么还要RAT\n基于CAM的重命名映射表 任意时刻,每个逻辑寄存器都只有一个物理寄存器与之对应,可以使用一个有效位(V)表示\ncRAT需要8个读端口和4个写端口(每条指令包含2个源寄存器和1个目的寄存器)\nSRAM + CAM ,SRAM用来存储每个物理寄存器对应的逻辑寄存器,CAM用来进行内容的比较\n需要等到后面写入到同一个逻辑寄存器的指令退休(retire)的时候,才可以将这个逻辑寄存器之前对应的物理寄存器变为空闲状态\n并不是一个物理寄存器对应的有效位为0,就表示物理寄存器是空闲状态,有可能是这个映射关系刚刚被覆盖了.通过使用ROB和空闲列表可以管理物理寄存器何时变为空闲\n在分支指令寄存器重命名之前,将cRAT的有效位保存起来;在流水线的后续阶段,发现分支指令预测失败是,将分支指令对应的checkpoint写回到cRAT的有效位就完成恢复了(why?这样能保证恢复映射关系?)\n恢复时可能把一些本身处在非空闲状态的物理寄存器变成了空闲状态,因为非空闲状态的物理寄存器有效位也可以是0\n有可能在进行checkpoint保存的时候为0,到了状态恢复的时候变成1了.典型情况是物理寄存器在变为空闲之后又被新的指令使用了.但是该指令处在分支预测失败或者异常路径上.应该是要恢复为0的\n举例 在指令F进行寄存器重命名时,需要对cRAT进行Checkpoint保存\n分支F被发现了分支预测失败,对cRAT进行状态恢复前 ,在F解码时,就保存了此时的状态,所以如果预测失败写回,就直接恢复了那之前的表\n每次在流水线的寄存器重命名阶段遇到分支2指令时,都会从表7.2找出一个空闲的GC来存储此时的有效位(V),并将GC的编号放在分支指令的信息中,这样当得到分支预测的结果之后,就可以根据编号来找到与之对应的GC.在分支预测失败之后直接进行相应的复原\n为了保证正确性,在分支预测失败进行恢复的时候,需要对空闲列表(free list)也进行状态恢复,那些别占用的物理寄存器都将重新变为空闲的状态(通过恢复free list的读指针)\n对cRAT进行状态恢复,就是要还原出逻辑寄存器真正对应的物理寄存器,因为会续分支预测失败路径上的指令可能会修改对应关系,需要进行纠正.对于物理寄存器的空闲管理交给ROB和free list\n附录 参考文献 超标量处理器设计\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-18T19:25:31+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B04/","title":"寄存器重命名(方式+映射表)"},{"content":"分支预测的目标地址预测 对于直接跳转的分支指令,由于它的偏移值(offset)是以立即数的形式固定在指令中,目标地址是固定的,只需要记录分支指令的目标地址即可.\n对于间接分支跳转,大部分是CALL和Return ,所以可以进行一定程度的预测\n直接跳转类型的分支预测 (1)当分支指令不发生跳转时,\n目标地址 = 当前分支指令的PC值 + Sizeof(fetch group)\n(2)当发生跳转时\n目标指令 = 当前分支指令的PC值 + Sign_Eextend(offset)\nBTB 通过BTB(Branch Target Buffer)(相当于一个cache)使得多个PC值共用一个空间来存储目标地址,\nindex + tag ,\nBTA (Branch Target Address)分支目标地址\n可以使用组相联的BTA来提高分支预测的准确率\n如果已经被替换了,那该跳哪去 : 先跳再冲刷吗?\nimage-20241016185417711 partial-tag BTB 如果映射到BTB中的指令中只有一条,那可以简化tag的部分,只使用很小的一部分,\n这种方法实际上也是在赌,减少了tag的大小,万一出现了重合,那就会出现目标地址预测失败的情况,但实际上,如果出现了重合,即使不减少tag,仍然会导致预测失败.\nimage-20241016185852818 和之前类似,仍然可以采取一定运算,来降低tag的位数,比方说异或\n我比较好奇,如果tag没有对上,对于直接相连来说,本身也无法得到正确地址,那为什么不直接把tag删除了\n应该是组相联有用吧\nimage-20241016190929007 BTB缺失的处理 停止执行 暂停取指,直到目标地址被计算出来\n对于直接跳转指令,在解码阶段就可以分离出偏移值\n解码阶段分离指令 停止取指会造成气泡,其实就是导致流水线停滞\nimage-20241016192510520 继续执行 使用顺序的PC值去指令\n计算出的地址和原来PC不一致,就冲刷流水线,重新开始取指\n这么做会浪费功耗\n间接跳转类型的分支预测 CALL/Return 指令的分支预测 CALL的地址一般也是固定的,所以也可以通过BTB进行预测\nReturn的目标地址是不固定的,但是Return的目标地址总是等于最近一次执行的\n但是Return指令的目标地址,是按照CALL指令执行的相反顺序排列的\n所以可以做一个存储器,保存最近执行的CALL指令的下一条指令的地址,这个存储器是后进先出的(Last In First Out,LIFO),原理与堆栈类似,称为返回地址堆栈(Return Address Stack,RAS)\nCALL/Return 指令分支预测 RAS工作条件 (1)需要及时保存PC + 4的值, 指令类型只有在解码阶段才能获知,因此可以在BTB中多加一项来保存分支指令的类型,这样在后续取到这一条指令就可以获知分支指令类型\n(2)在对Return指令进行目标地址预测是,能够选择RAS的数据,而非BTB的数据,按照上面的方法就可以做到\n将指令类型存储到BTB中 RAS满了 如果函数层次过深,就会出现RAS无法继续存放的问题\n(1)不保存CALL了,这样下一次Return 就会出现分支预测失败,并且还要求RAS指针不发生改变\n(2)继续按照顺序向RAS写入,此时最旧的会被覆盖掉.最后一次return 可能会出现分支预测失败,但是也是可能性事件,比方说递归函数\n可以通过带计数器的RAS来扩展RAS的容量, 即对于相邻的CALL,如果是同一条指令,就存放在RAS的同一个地址,再用计数器进行标识\n其他指令的预测 case指令 image-20241016210205293 使用基于局部历史的分支预测方法,把PHT换成了Target Cache,\n每当分支指令执行一次,就将目标地址写到Target Cache 中\n小结 分支预测使用 BHR , GHR和饱和计数器配合进行分支指令方向的预测\n使用 BTB, RAS和 Target Cache对分支指令的目标地址进行预测\n完整的分支预测方法 , decoupled BTB : 将分支指令的方向预测独立于BTB ,本身不会被记录到BTB的分支指令也会被记录(不跳转的分支也会记录到BTB)\n预测为发生跳转,但是发生了BTB缺失,比发生分支预测失败的情况好,可以节省功耗\n完整的分支预测方法 分支预测失败的恢复 处在错误路径上的指令有可能已经将处理器中某个部位的内容进行了更改,例如寄存器重命名阶段的重命名映射表(mapping table),需要对操作进行撤销,即分支预测失败时的恢复\n分支预测检查 (1) 解码阶段可以检查直接跳转的正确性,可以得到分支指令的方向和目标地址,\n对于间接跳转,即使得知预测错误,也无法得到正确的地址,但是可以通过流水线暂停来避免抹掉指令造成的功耗浪费\n(2)在读取物理物理寄存器的阶段,读取到寄存器的值,就可以得到目标地址是否错误,进行重新取指令,\n还是需要对不必要的指令进行抹去,对于进入发射队列的指令,可能比较困难,需要选择性的进行抹去\n(3)在执行阶段,任何分支指令的结果都可以被计算出结果,可以进行检查,但是造成的惩罚(penalty)是最大的.需要清除在这条分支指令之后进入流水线的所有数据\n基于ROB的恢复 在乱序执行中,在这条分支指令之前的数据也会在发射队列或者执行中,可以采取重排序缓存(ROB)对处理器进行状态恢复 (ROB是顺序存储指令的)\n当发生分支指令预测失败时,将信息记录在ROB对应的表项(entry)中,并且暂停流水线的取指令,但是让流水线继续执行,当这条指令变为最旧的指令后,冲刷掉流水线中的所有数据,重新取指令. 缺点就是停滞时间会比较长.\n基于checkpoint的状态恢复 checkpoint, 发现分支指令,并且在分支指令之后的指令更改处理器的状态之前,将处理器的状态保存起来,包括寄存器重命名中使用的映射表(mapping table),预测跳转的分支指令对应的下一条指令的PC等.在寄存器重命名阶段进行.\n需要将流水线中所有处于分支预测失败路径上的指令抹去. 需要一种机制识别哪些指令处在错误的路径上,可以通过编号实现,(编号可以在顺序阶段就编号完成),编号之后就可以获知哪些指令位于分支指令后面\n分支指令的编号个数决定了最多可以在流水线中存在的分支指令个数:假设处理器中最多支持128条指令存在于流水线中,按照每五条指令存在一条分支,最多后128/5 = 26 条分支指令存在与流水线中,需要5位\n所有在流水线中的分支指令会被分配一个编号值,编号会被保存在FIFO中,称为编号列表(tag list)\n可以使用 (free tag list 和 tag list)来进行设计\n编号值不再被使用 : 分支指令成功retire , 分支预测失败 (分支预测失败之后就要根据编号来冲刷流水线了,所有编号可以回收了)\n流水线抹去 (1)发射之前的所有指令需要全部被抹去\n(2)流水线的发射阶段以及之后的流水段中,使用比寻找分支指令之后的指令全部抹去\ntag list 是顺序保存对应标号的 , 所以 比方说监测到分支指令3 预测失败,所以 0 ,1, 4 都需要被直接清除 , 因此通过广播编号值及将ROB中对应的指令置为无效\n一个周期内使用所有编号去抹去ROB的指令是不现实的,可以采取一个周期广播一个编号的方式 , 因为从取指到发射还是需要经过几个周期的,只要在这之前重排序缓存和发射队列指令被抹去了就行了\n编号值在解码阶段分配最合适 ,因为此时已经知道属于分支指令了\n对于多条分支指令,通过控制第二条分支指令及其后面的所有指令在本周期不能进入解码阶段,可以避免使用多端口的FIFO来进行赋值\nPTAB (Prediction Target Address Buffer) 通过将分支指令的预测值保存到一个缓存中,使得其在执行阶段进行分支预测是否正确的检查时能够正确调用,并且可以只保存方向预测为跳转的分支指令 PTAB , (Prediction Target Address Buffer)\n它不是本身就在BTB中吗,为啥还要一个buffer\n(1)valid , 表示PTAB中某个表项是否被占用, 当分支指令写入PATB时,置1,当完成检查之后,Reset\n(2)Predict Address,分支指令被预测的目标地址\n(3)Next PC, 分支指令的下一条PC , 如果预测错误,就直接使用其作为正确地址取指\n怎么去找PTAB对应的表项 ? 用 PC吗 ? 或者说用 Next PC吗\n写PTAB可以在取指阶段就完成\n自修改代码一般都会去清空分支预测器和I-Cache\n超标量处理器的分支预测 由于超标量取一个地址,会取出多条指令,所以如果只使用取指令时的地址进行分支预测,相当于只是对指令你个组中的第一条指令进行分支预测\n可以使用公共地址寻址分支预测器 (对于4-way超标量处理器[31:4]),因为多数情况下,实际只有一条分支指令 .在BTB中需要记录下分支指令在四条指令中的位置,避免错误使用它的结果 (为什么指令会出现非对齐存储?)\n目标地址的预测 要对指令组的所有指令进行分支预测,需要得到所有指令的PC值,需要使用3个加法器实现PC地址的获取,\n但是由于需要同时获取四个PC值对应的目标地址,需要BTB支持四个读端口,即使采用交疊避免真正的多端口,但是硬件利用率还是较低\n在分支指令的方向预测完毕之后,利用结果信息再进行目标地址的预测,可以避免对于BTB部件的多端口需求,,这种方法对于方向预测和目标地址预测是串行的\n对于RISC指令,大多数指令是直接跳转类型,目标地址无需预测,在取指之后实际就可以被计算出来.实现这样的功能需要进行预解码\n目标方向的预测 对于基于局部历史的分支预测方法来说,需要PHT和BHT支持多个读端口,可以通过交疊(interleaving)模拟实现多端口\n对于全局历史的分支预测,由于一个周期内进行分支预测的多条指令对应的GHR是不同的,需要进行特殊的处理\n交疊 : 7位地址Addr[6:0],通过Addr [1:0]进行寻址bank ,通过Addr[6:2]寻址bank对应的内容 ,就是使用多个单端口的存储器去组成多端口的功能\n附录 参考文献 超标量处理器设计\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-16T18:26:42+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B03/","title":"分支预测(目标地址预测)"},{"content":"概述 分支预测需要的内容 方向，决定跳转与否\n目标地址 决定跳转的目的地，riscv中有两种体现形式\nPC + 立即数，跳转范围受限。\n寄存器跳转，预测风险难度高，但是除了RETURN/CALL,一般建议不使用间接跳转。\n分支预测的解码 快速分辨出哪条指令是分支指令\nI-cache得出结果可能需要多个周期，这些周期无法得到准确的预测结果\n解码+分支预测放在一个周期 ， 严重影响周期时间\n快速解码 可以在指令从L2 cache 写入到I-cache时进行快速解码,(pre-decode),然后将指令否是分支的信息也写入I-cache.\n分支预测的最好时机是在当前周期得到去指令地址的时候\n可以直接通过PC值来进行分支预测，那就不需要进行解码了，但是只能够知道它是分支指令\npc分支预测 分支预测的方向预测 跳转 （taken)和不发生跳转（not token）\n一bit的跳转预测 image-20241015182744711 基于两位饱和计数器（2-bit saturating counter) 根据分支前两次的结果预测下一次的结果\n状态机 基于两位饱和计数器 （1）计数器处于饱和状态，分支指令本次被预测发生跳转\n（2） 计数器处于不饱和状态，分支指令预测发生跳转\n（3） 计数器处于不饱和状态，分支指令预测不发生跳转\n（4） 计数器处于饱和状态，分支指令被预测不发生跳转\n初始状态位于 strongly not taken 或者 weakly not taken\n状态机处于饱和状态，只有两次预测失败才会改变预测的结果\n对于以下的情况，该种方法能够有50%的成功预测率\nimage-20241015184801299 TTNTNTNTNT 对于这种情况，预测还是有问题，就是始终进入不了饱和，那还是相当于1bit\n另外两种预测方法 情况1是如果两次连续的跳转，就直接变成饱和的强跳转，那就需要两次不跳转才能预测为不跳转\n情况2是如果两次连续的不跳转，就直接变成饱和的不跳转，那就需要两次跳转才能预测为跳转\n利用格雷码降低功耗，减少出错的概率\n对于一般的for循环，TTTTTTTTTTTTTTN ,只会出现2次预测失败 ，开始时 weakly not taken , 当再次执行for循环，第一次就会预测成功\n存储方式 每一个PC需要一个两位的饱和计数器， 32 位 PC需要 2^30 * 2b 存储器 ， 使用如下方法存储（PHT（Pattern History Table））: 使用 PC的一部分进行存储\n别名 （aliasing) 不同PC有相同的饱和计数器，导致相互之间的干扰\n中立别名 ： 分支指令的方向一致\n破坏性别名 ： 分支指令的方向不一致\n使用PC值的一部分来寻址饱和计数器 image-20241015194600012 避免别名的方法 —— 哈希表 哈希表能够压缩32位PC到一个比较小的值\nimage-20241015194955893 更新时间点\n（1）在流水线的取指令阶段，进行分支预测，根据预测的结果更新PHT 预测的结果更新PHT肯定不合理\n（2） 在流水线的执行阶段，当分支指令的方向被计算出来时，更新PHT\n（3） 在流水线的提交阶段，当分支指令要离开流水线是，更新PHT\n对于2,3，分支指令可能在PHT更新之前就被取过很多次了，会影响结果，但是影响的不多\n在乱序执行中，即使在执行阶段得到了一条分支指令的结果，也无法保证该结果是正确的，因为分支指令可能位于分支预测失败的路径上，所以（3）是最保险的\n顺序执行不会吗 ？ 不会 ，主要是乱序执行有可能前面的指令后于后面指令的执行 ，这样后面的指令不一定会执行\n基于局部历史的分支预测 BHR(Branch History Register):分支历史寄存器\n通过一个寄存器记录一条分支指令在过去的历史状态\nn位BHR记录n次结果\nBHR和PHT一一对应，BHR有多少种取值，PHT有多少表项（entry)\n结果从BHR右侧移入，对应的BHR值改变对应的PHT\n那就相当于把一个PC对应的表项有进行了细分 -\u0026gt; 一个BHR和多个PHT\n如果一个序列，连续相同的数有p位，则虚了的循环周期为p,只要BHR不小于p,就可以做完美预测\n寻址 将所有分支指令的BHR组合在一起称为分支历史寄存器表(Branch History Register Table,BHT)\n如果进行全寻址的话 ， 1个PC值 需要 N位BTR + 2^N * 2 位PHT , 2^n 就需要 2^n（ N + 2^N * 2）\n所以需要PC部分值来寻址\nimage-20241016102002253 1个PHT\nPC部分值寻址PHT,PC通过hash处理寻址BHT\nimage-20241016104245339 异或（XOR)法\n位拼接法和异或法 基于全局历史的分支预测 对一条分支指令进行分支预测，考虑前面分支指令的执行结果\n需要一个全局历史寄存器（GHR(global history register)),记录最近执行的所有分支指令的结果、\n最理想的情况是对每条分支指令都使用一个PHT\n一个全局寄存器 + 每一条分支指令对应的PHT\nimage-20241016144951117 量变引起质变，当局部BHR少到只剩下一个的时候，就是全局GHR\nimage-20241016144931624 总结 两种分支预测方法\n局部历史分支预测：基于分支指令自身在过去的执行状况来进行分支预测，对每一条分支指令都使用分支历史寄存器（BHR),并使用了由两位饱和计数器组成的PHT(Pattern History Table)来捕捉每一个BHR的规律，使用BHR和PHT配合进行分支预测\n全局历史分支预测：基于一条分支指令之前的一些分支指令的执行状况来进行分支预测，使用全局历史寄存器（GHR)记录所有分支指令的执行情况，由两位饱和计数器组成的PHT(Pattern History Table)来捕捉每一个GHR的规律,使用GHR和PHT配合进行分支预测\n竞争的分支预测 竞争的分支预测原理图 竞争的分支预测_更详细的原理图 理想情况下每一条分支指令都有一个CPHT(choice PHT)\nCPHT中的两位饱和计数器 当P1预测正确,P2预测错误时,计数器减1 当P1预测错误,P2预测正确时,计数器加1 当P1和P2预测结果一致时,不管预测正确与否,计数器保持不变 对于每一条指令,在GHR内容不同时,会导致使用不同的分支预测方法,所以将PC值与GHR进行相应运算再去寻址CPHT的地址.\n分支预测的更新 历史寄存器 （1）在流水线的取指令阶段，进行分支预测，根据预测的结果更新\n（2） 在流水线的执行阶段，当分支指令的方向被计算出来时，更新,分支指令可能在错误预测的路径上,造成错误\n（3） 在流水线的提交阶段，当分支指令要离开流水线是，更新 ,最保险的方法,但是浪费了性能\n一条分支指令b在时间t被分支预测,在时间 $t + \\Delta t$ 从流水线退休, 任何在 $ \\Delta t $内的时间被预测的分支指令都不会从分支指令的结果受益\nimage-20241016153738302 采取方法1更新 ,但是会出现分支预测失败的情况 ,即使后续的分支指令使用的错误的 GHR ,由于他们在预测失败的路径上,都会从流水线中被抹去\n修复GHR错误值的方法 提交(commit)阶段修复法 前端阶段Speculative GHR, 提交阶段放置一个 Ritired GHR, 在前端推测失败之后,需要等待分支指令退休的时候,将后端的GHR写到前端的GHR中,然后根据这条分支指令所指定的目标地址,重新取指令执行.\n该方法的缺点是会造成分支预测失败时惩罚的增大,(why?)\n利用提交阶段的GHR修复分支预测器的GHR checkpoint修复法 在取指令阶段更新GHR时,可以把旧的GHR值保存起来,保存的内容称为checkpoint GHR .一旦分支指令的结果在流水线中被计算出来,就可以对分支指令的分支预测是否正确进行检查.如果分支预测正确,说明GHR中的值是正确的,如果预测失败,将这条分支指令对于的checkpoint GHR恢复到前端的GHR中,并从这条分支指令正确的目标地址开始取指令执行\n我的理解是把原来的GHR和分支预测结果的反向结合然后放进fifo中,在预测失败时把这个值取出来\n如果是顺序执行,读取存储器的方式也可以用FIFO,\n方式二是对方式一的一种补充,使得能够在执行阶段也去实现恢复\n利用checkpoint的方法会GHR进行修复 修复BHR错误值的方法 方式和修复GHR基本是类似的,并且BHR很少出现一条分支指令在流水线的提交阶段更新BHR,流水线中又出现了这条分支指令使用BHR进行分支预测的情况,除非循环体很短\nimage-20241016181356130 两位饱和寄存器 由于饱和寄存器一般是处在饱和状态的,所以选择在分支指令退休的时候更新PHT的饱和计数器,也不会产生很大的负面影响\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-15T14:08:47+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B02/","title":"分支预测(概述+方向预测)"},{"content":"超标量处理器概览 超标量处理器的流水线 顺序执行 in-order pipline 假设流水线每周期可以从 I-Cache 中取出两条指令来执行，则称为2-way 的超标量处理器，在指令经过解码之后，需要根据自身的类型，将两条指令送到对应的 FU 中执行，这个过程称为发射(Issue)。在这个阶段，指令会读取寄存器而得到操作数，同时根据指令的类型，将指令送到对应的 FU 中进行执行。在执行阶段使用了三个 FU:第一个 FU 用来执行 ALU 类型的指令，第二个 FU 用来执行访问存储器类型的指令，第三个 FU 用来执行乘法操作，因为要保证流水线的写回(Write back)阶段是顺序执行的，因此所有 FU 都需要经历同样周期数的流水线，ScoreBoard 用来记录流水线中每条指令的执行情况，例如一条指令在哪个 FU 中执行，在什么时候这条指令可以将结果计算出来等， 一个典型的 ScoreBoard如下。\nscoreboard P: Pending,表示指令的结果还没有写回到逻辑寄存器中。\nF:一条指令在哪个 FU 中执行，在将指令结果进行旁路时会使用这个信息。\nResult Position:在这个部分记录了一条指令到达 FU 中流水段的哪个阶段，3 表示指令处于 FU 流水线的第一个流水段，1 表示指令到达 FU 流水段的最后一个阶段， 0 表示指令处于流水线的写回阶段，在流水线的发射阶段，会将指令的信息写到ScoreBoard 中，同时，这条指令会查询 ScoreBoard 来获知自己的源操作数是否都准备好了，在这条指令被送到 FU 中执行之后的每个周期，都会将这个值右移一位，这样使用这个值就可以表达出指令在 FU 中执行到哪个阶段，对于执行 ALU 类型指令的第一个 FU 来说，当指令到达 3 时，就可以将它的结果进行旁路了；而对于执行乘法指令的第三个 FU 来说，只有当指令到达 1 时，才可以将它的结果进行旁路。本书采取的应该是第二种。\nimage-20241014210458774 阻塞发生在译码级\n指令能够跳转到发射级的条件是scoreboard 对应处在级为2\n？一发就发两条，两条必须要同步吗 应该只是由于下条导致的等待\n指令D不能提前发射应该就是由于需要等待指令C发射\n指令C无法进入执行是由于前递的问题，需要等待指令A的前递\nimage-20241014212008795 乱序执行 乱序执行流水线 解码(Decode)阶段：为了在乱序执行时解决 WAW 和 WAR 这两种相关性，需要对寄存器进行重命名(register renaming),这个过程可以在流水线的解码(Decode)阶段完成，也可以单独使用一个流水段来完成，处理器中需要增加物理寄存器堆(Physical Register File, PRF)来配合对指令集中定义的寄存器( Architecture Register File,ARF)进行重命名，PRF 中寄存器的个数要多于 ARF。\n**Dispatch(分发):**在这个阶段，被重命名之后的指令会按照程序中规定的顺序，写到发射队列(Issue Queue)、重排序缓存(ROB)和 Store Buffer 等部件中，如果在这些部件中没有空闲的空间可以容纳当前的指令，那么这些指令就需要在流水线的重命名阶段进行等待，这就相当于暂停了寄存器重命名以及之前的所有流水线，直到这些部件中有空闲的空间为止。分发阶段可以和寄存器重命名阶段放在一起，在一些对周期时间要求比较紧的处理器中，也可以将这个部分单独使用一个流水段。\n发射(Issue)阶段：一旦指令的操作数准备好了，就可以从发射队列中离开，送到对应的 FU 中执行，因此发射阶段是流水线从顺序执行到乱序执行的分界点。每个 FU 都有自己的流水线级数，在这种流水线中，由于每个 FU 的执行周期数都不相同，所以指令在流水线的写回(Write Back)阶段是乱序的，在这个阶段，一条指令只要计算完毕， 就会将结果写到 PRF中，由于分支预测失败( mis-prediction)或者异常( exception)的存在，PRF 中的结果未必都会写到 ARF 中，因此也将 PRF 称为 Future File。\nRegister File Read(读取寄存器):被仲裁电路选中的指令需要从物理寄存器堆(Physical Register File,PRF)中读取操作数，一般情况下，被仲裁电路选中的指令可以从PRF 中得到源操作数，当然还有“不一般”的情况，那就是指令不能从 PRF 中得到操作数， 但是却可以在送到 FU 中执行之前，从旁路网络(bypassing network)中得到操作数，事实上很大一部分指令都是通过旁路网络获得操作数的，这也为减少 PRF 的读端口提供了可能。由于超标量处理器每周期需要执行好几条指令，PRF 所需要的端口个数也是比较多的，多端口寄存器堆的访问速度一般都不会很快，因此在现实世界的处理器中，这个阶段都会单独使用一个流水段。\n提交(Commit)阶段：为了保证程序的串行结果，指令需要按照程序中规定的顺序更新处理器的状态，这需要使用一个称为重排序缓存(ROB)的部件来配合，流水线中的所有指令都按照程序中规定的顺序存储在重排序缓存中，使用重排序缓存来实现程序对处理器状态的顺序更新，一条指令在这个阶段，会将它的结果从 PRF 搬移到 ARF 中，同时重排序缓存也会配合完成对异常(exception)的处理，如果不存在异常，那么这条指令就可以顺利地离开流水线， 并对处理器的状态进行更改，此时称这条指令退休(retire)了，一条指令一旦退休，它就再也不可能回到之前的状态了。\n因为 store 指令需要写存储器，如果在流水线的写回阶段就将 store 指令的结果写到存储器中，那么一旦由于分支预测失败或者异常等原因，需要将这条 store 指令从流水线中抹掉时，就没有办法将存储器的状态进行恢复了，因为存储器中原来的值已经被覆盖， Store Buffer(SB),来存储 store 指令没有退休之前的结果，store 指令在流水线的写回阶段，会将它的结果写到 Store Buffer 中，只有一条 store 指令真的从流水线中退休的时候，才可以将它的值从 Store Buffer 写到存储器中。使用了这个部件之后，Load 指令此时除了从 D-Cache 中寻找数据，还需要从 Store Buffer 中进行查找，这样在一定程度上增加了设计的复杂度。\n在重排序这里也会处理异常 ， 如果没有异常就会写入ARF, 并成功退休，但是无论有没有异常都会写入SB。退休了才可以去修改相应状态。\n发射阶段选择相应的指令并且送到FU,被选择的指令才会去读取物理寄存器\n写回阶段进行统一旁路，为什么我写的RISCV有这么多的旁路网络 ?\nimage-20241015131538323 image-20241014212008795 附录 参考文献 超标量处理器设计\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处\n","date":"2024-10-14T16:43:30+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/","title":"超标量处理器概览"},{"content":"Tomasulo\u0026rsquo;s algorithm Tomasulo‘s algorithm创新 Tomasulo算法的主要创新包括硬件实现的寄存器重命名、为所有执行单元设计的保留站（reservation stations），以及一个公共数据总线（CDB），通过该总线计算出的值可以广播到所有可能需要它们的保留站。这些创新使得指令能够实现更好的并行执行，避免在使用记分板或其他早期算法时可能导致的停滞.\nTomasulo_Architechure CDB总线 公共数据总线（CDB）将保留站直接连接到功能单元。根据Tomasulo的设计，它“在保持优先顺序的同时促进并发执行” 。这带来了两个重要影响：\n功能单元可以直接访问任何操作的结果，而无需通过浮点寄存器。这使得多个等待同一结果的单元可以继续执行，而不必等待解决对寄存器文件读端口的争用问题。 危险检测和控制执行是分布式的。保留站负责控制指令何时可以执行，而不是依赖一个专门的危险单元来进行统一管理。 指令顺序 指令是按顺序发出的，因此即使它们是乱序执行的（即非顺序执行），指令序列的效果（如指令引发的异常）仍然会按照顺序执行处理器中的顺序发生。这确保了乱序执行不会影响程序的正确性和预期行为\n寄存器重命名 Tomasulo算法通过寄存器重命名来实现正确的乱序执行。所有的通用寄存器和保留站寄存器要么保存真实值，要么保存占位符值。如果在发射阶段某个目标寄存器的真实值不可用，则最初会使用占位符值。占位符值是一个标签，指示哪个保留站将生成真实值。当功能单元完成计算并在公共数据总线（CDB）上广播结果时，占位符将被真实值替换。\n每个功能单元都有一个保留站。保留站保存执行单条指令所需的信息，包括操作和操作数。当功能单元空闲且指令所需的所有源操作数均为真实值时，功能单元便开始处理指令。\n附录 参考文献 乱序执行CPU\nwikipedia Tomasulo\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-12T16:08:08+08:00","permalink":"https://VastCircle.github.io/2024/%E4%B9%B1%E5%BA%8F%E6%89%A7%E8%A1%8Ccpu/","title":"乱序执行CPU"},{"content":"Abstract 当今的高性能处理器通过乱序执行来容忍长延迟操作。然而，随着延迟的增加，如果我们要继续容忍这些延迟，指令窗口的大小必须增加得更快。本文提出先行(runahead)执行是提高乱序处理器内存延迟容忍度(memory latency tolerance)的有效方法，而不需要不合理的大指令窗口。超前执行可解除因长延迟操作而阻塞的指令窗口的阻塞，从而使处理器能够在程序路径中提前执行,这会导致数据在需要之前就被预取到缓存中。\nintroduction 乱序执行处理器上的超前执行不会将长延迟操作“移开”（这需要在指令窗口中缓冲它及其后面的指令），而是将其扔出指令窗口。\n当指令窗口被一个长延迟操作阻塞时，架构寄存器文件(architectural register file)的状态会被checkpoint保存。然后处理器进入“超前运行模式”。它为阻塞操作分配一个虚假结果并将其扔出指令窗口。阻塞操作后的指令被**获取、执行，并以伪退休（pseudo-retired）**的方式从指令窗口中移除。当阻塞操作完成时，处理器重新进入“正常模式”。此时，它会恢复之前保存的检查点状态，并从阻塞操作开始重新获取和执行指令。 伪退出(pseudo-retire):指令按照传统意义上的方式执行和完成，只是它们不更新架构状态。\nimage-20241012153516456 Runahead 的好处来自于将被长延迟操作阻塞的小指令窗口转换为非阻塞窗口，从而使其具有大得多的窗口的性能。\n在这篇论文中，仅评估了runahead mode对于在二级缓存失效的内存操作的表现，尽管它也可以在任何阻塞指令窗口的长延迟操作上启动。基于英特尔奔腾4处理器的机器模型，该处理器拥有128个条目的指令窗口。 首先展示了当前的乱序执行引擎无法容忍长延迟的主存访问时间。接下来，展示了runahead mode如何更好地应对这些延迟，并且能够达到一个具有更大指令窗口的机器的性能。\nRelate work 暂无\nOut-of-order execution and memory latency tolerance(乱序执行和内存容忍度) Instruction and scheduling windows 乱序执行比顺序执行更能容忍缓存缺失，因为它能够调度与缓存缺失无关的操作。乱序执行的机器通过两个窗口实现这一点：指令窗口和调度窗口。 指令窗口保存所有已解码但尚未提交到架构状态的指令(ROB)，其主要目的是保证指令按顺序退休，以支持精确异常。 调度窗口包含指令窗口中的一部分指令，其主要目的是每个周期搜索那些准备好执行的指令，并对它们进行调度执行(类似于发射队列)。\n当一个长延迟操作发生时，它会阻塞指令窗口，直到操作完成。尽管后续的指令可能已经执行完成，但它们无法从指令窗口中退休(顺序)。如果操作的延迟时间足够长，并且指令窗口不够大，指令会在窗口中堆积，最终导致指令窗口被填满。此时，机器会停顿并停止向前执行。\nMemory latency tolerance 取指理想 变 调度窗口 L2理想程度 指令窗口\n图 1 显示了七台不同机器的指令窗口停滞的周期百分比。每个栏顶部的数字是机器的IPC。该数据是所有模拟基准的平均值。\n具有完整指令窗口停顿的周期的百分比 Runahead 的性能优势来自于将指令提取到提取引擎的缓存中，并执行未命中一级或二级缓存的独立加载和存储。\nImplementation of runahead execution in an out-of-order processor 在本节中，我们描述了在乱序处理器上实现超前执行的情况，其中指令在被调度后并在执行之前访问寄存器文件。Intel Pentium 4 处理器 [13]、MIPS R10000 微处理器 [30] 和 Compaq Alpha 21264 处理器 [18] 是这种微架构的例子。在其他一些微架构中，例如 Intel Pentium Pro 处理器 [12]，指令在放入调度器之前访问寄存器文件。\nFrontend RAT(Register Alias Table)用于寄存器重命名，并包含架构寄存器到物理寄存器的推测映射。\nRetirement RAT 包含指向包含已提交架构值的物理寄存器的指针。它用于在分支错误预测和异常之后恢复状态。\nimage-20241010195821755 Entering runahead mode **当内存操作在二级缓存中未命中且该内存操作到达指令窗口的头部时，处理器进入超前执行模式。**导致进入超前执行模式的指令地址会被记录。为了在从超前运行模式退出时正确恢复架构状态，处理器对架构寄存器文件的状态进行checkpoint。出于性能原因，处理器还检查分支历史寄存器和返回地址堆栈的状态。\n架构寄存器文件的checkpoint可以通过复制提交寄存器别名表（Retirement RAT）指向的物理寄存器内容来完成，但这可能需要时间。为了避免因复制导致的性能损失，处理器可以在正常模式下不断更新checkpoint的架构寄存器文件。当非超前指令从指令窗口中提交时，它会将其结果更新到检查点寄存器文件中的架构目标寄存器。这样检查点操作不会浪费任何时钟周期。\n尽管Retirement RAT 在正常模式下指向架构寄存器状态，但在超前运行模式下它指向伪架构寄存器状态并反映伪退休指令更新的状态\nExecution in runahead mode 无效位和指令:每个物理寄存器都有一个与其关联的无效（INV）位，以指示它是否具有虚假值。任何源自设置了无效位的寄存器的指令都是无效指令。 INV 位用于防止使用虚假数据进行虚假预取和分支解析。 如果存储指令是无效的，它会在runahead期间将一个 INV 值引入内存映像。为了处理runahead mode下数据值(和 INV 值)通过内存的通信，我们使用一个小的“runahead cache”，它与一级数据缓存并行访问。\nINV 值的传播:引入 INV 值的第一条指令是导致处理器进入runahead mode的指令,如果这条指令是加载指令，它会将其物理目的寄存器标记为 INV。如果它是存储指令，则会在runahead cache中分配一行，并将其目标字节标记为 INV。\n任何无效的指令在调度或执行后写入寄存器时，会将该寄存器标记为 INV。任何有效的操作在写入寄存器时，会重置其目的寄存器的 INV 位。\n其实意思就是因为此时存储是没有得到相应结果的,所以后续与目的寄存器相关的指令都是无效的,从第一条无效的指令衍射开\nRunahead store operations and runahead cache 先行存储(store)指令不会将其结果写入任何地方??。因此，依赖于有效先行存储的先行加载被视为无效指令并被丢弃。由于寄存器数量有限，因此将先行存储(store)的结果转发到先行加载(load)对于高性能至关重要。 如果存储及其相关加载都在指令窗口中，则此转发是通过当前乱序处理器中已存在的store buffer来完成的(应该是cache那边的buffer)。 如果超前运行加载依赖于已经pseudo-retired的超前运行存储（这意味着该存储不再位于store buffer???前面是说的runahead store是不会将结果写入任何地方的），则它应该从某个其他位置获取存储的结果。1是写入data cache (提高复杂度,并且可能会占据其他有效指令的位置),2是弄一个大的fully-associative buffer。\n使用 runahead cache 来保存伪退休先行存储的结果和 INV 状态 ，提供指令之间的数据和INV状态的通信,被逐出的缓存行不会写入其他地方。为了支持存储和加载之间 INV 位的正确通信，store buffer中的每个条目和runahead cache 中的每个字节都有一个相应的 INV 位。runahead cache 的每个字节还有另一个与其关联的位（STO 位），指示存储是否已写入该字节。仅当访问的字节由存储写入（设置了 STO 位）并且访问runahead cache 有效时，对超前运行高速缓存的访问才会导致命中。\n更新 INV 和 STO的规则:\n当有效的先行存储完成执行时，它将其数据写入其store buffer entry（就像在普通处理器中一样）并重置该条目的关联 INV 位。同时，它查询数据缓存，如果数据缓存未命中，则向内存层次结构发送预取请求。 当一个无效的先行存储被scheduled时，它会set其相关store buff条目的 INV 位。 当一个有效的先行存储离开指令窗口时，它会将其结果写入runahead cache，并重置已写入字节的 INV 位。同时，它还会设置已写入字节的 STO 位。 当一个无效的先行存储离开指令窗口时，如果其地址有效，它会设置写入字节的 INV 位和 STO 位 先行存储从不将结果写入数据缓存??????。 当存储操作的地址无效时，存储操作会被简单地视为一个空操作（NOP）。由于加载操作无法识别与这些无效存储操作的依赖关系，它们可能会错误地从内存中加载一个陈旧的值。这个问题可以通过使用内存依赖预测器来缓解，**预测器可以识别无效地址存储操作与其依赖的加载操作之间的依赖关系。**一旦依赖关系被识别，如果存储操作的数据值是无效的，则加载操作会被标记为无效（INV）；如果存储操作的数据值是有效的，则可以将其forward给加载操作。\nRunahead load operations runahead load invalid :\n源自无效的物理寄存器\n依赖于store buffer中标记为无效（INV）的存储操作\n依赖于一个已经伪退休且是无效（INV）的存储操作(runahead cache)\n有效load会并行访问3个结构 ： data cache , runahead cache , store buffer .\n加载操作命中store buffer ，并且命中的条目被标记为有效，那么加载操作会从store buffer获取数据。 加载操作命中store buffer ，并且命中的条目被标记为无效（INV），那么加载操作会将其物理目标寄存器标记为无效（INV）。\n只有当加载指令访问的cache line有效且其访问的任何字节的 STO 位被set时，该加载才被视为在runahead cache 中命中。 如果load在store buffer未命中但在runahead cache 命中，则它会检查在runahead cache 访问的字节的 INV 位。如果没有INV 位set ，将使用runahead cache 中的数据。如果任意一个源数据字节被标记为 INV，则将其目标寄存器标记为INV。 如果load在store buffer和runahead cache 都未命中，但在data cache中命中，则它将使用data cache中的值，并被视为valid(data cache 应该是不涉及runahead的)。然而，由于以下两个原因，它实际上可能是无效的????：1）它可能依赖于具有 INV 地址的store，(依赖于无效的store 就不应该被判定为有效啊)或者 2）它可能依赖于一个 INV store，该store在runahead cache中将其目标字节标记为 INV，但由于冲突，相应的runahead cache被释放(意思就是,实际上load是无效的,但是由于load所访问的runahead cache被别的指令释放了,比方说另一个store把cache 给挤掉了)。然而，这两种情况都是罕见的，不会显著影响性能。\n如果加载在所有三个结构中都未命中，它会向L2 cache 发送请求以获取其数据。如果该请求在L2 cache 中命中，则数据将从L2 cache 传输到L1 cache ，加载完成其执行。如果请求在L2 cache 中未命中，加载会将其目标寄存器标记为 INV，并像导致进入runahead mode的加载那样(未命中L1 cache)从调度器中移除。该请求会发送到内存像一个未命中 L2 缓存的正常加载请求一样。\nstore buffer \u0026gt; runahead cache \u0026gt; data cache \u0026gt; L2 cache\nExecution and prediction of branches 在runahead mode中，分支的预测和解决方式与正常模式完全相同，唯一的区别是：具有 INV 源(寄存器标记为INV)的分支（与所有分支一样）被预测并以推测的方式更新全局分支历史寄存器，但与其他分支不同，它永远无法被解决。???如果分支预测错误，处理器在获取到该分支后将始终处于错误路径，直到遇到一个与控制流无关的点。我们将获取到错误预测的 INV 分支的程序中的点称为“分歧点”。分歧点的存在不一定对性能有害分歧点在runahead mode中出现得越晚，性能提升就越好。\n前置模式下分支预测器表的训练策略:\n(1)始终训练分支预测器表。如果一个分支首先在前置模式下执行，然后在正常模式下执行，这种策略将导致同一个分支对分支预测器进行两次训练。因此，预测器表的性能得到了增强，计数器可能会失去滞后效应。\n(2)不在前置模式下训练分支预测器。这会导致前置模式下的分支预测准确率降低，从而降低性能，并使分歧点更接近前置入口点。\n(3)第三种选择是始终在前置模式下训练分支预测器，但同时使用一个队列将前置模式下分支的结果传递给正常模式。在正常模式下，如果存在预测，则使用该队列中的预测来进行分支预测。如果一个分支使用来自队列的预测进行预测，则不会再次训练预测器表。\n(4)前置模式和正常模式使用两个独立的预测器表，并在进入前置模式时将正常模式的表信息复制到前置模式。这一选项在硬件实现上成本较高，但我们进行了模拟以确定第一种选项的双重训练策略有多重要。\n我们的结果显示，与第四种选择相比，二次训练分支预测器表条目并没有显著降低性能(方法1)。\nInstruction pseudo-retirement during runahead mode. 在runahead mode下，指令按照程序顺序离开指令窗口。如果某条指令到达指令窗口的队头，它将被考虑进行pseudo-retire。 如果被考虑pseudo-retire的指令是无效的（INV），它会立即从窗口中移除。 如果指令是有效的，它需要等待执行完毕（此时它可能变为无效的），并将结果写入物理寄存器文件。在pseudo-retire时，一条指令会释放为其执行分配的所有资源。\n无论是有效还是无效的指令，在它们离开指令窗口时都会更新退休重命名表（Retirement RAT）。退休重命名表不需要存储与每个寄存器关联的无效（INV）位，因为物理寄存器已经各自关联了无效位。\nExiting runahead mode 可以随时启动退出预运行模式的过程。为了简化处理，我们将退出预运行模式的操作与处理分支预测错误的方式相同。处理器中的所有指令都会被flush，相关的缓冲区会被释放。检查点保存的架构寄存器文件会复制到物理寄存器文件的预定区域。前端和退休阶段的寄存器重命名表（RATs）也会修复，以指向保存架构寄存器值的物理寄存器。这种恢复通过重新加载相同的硬编码映射到两个别名表来实现。预运行缓存中的所有行都将失效（并且 STO 位被清零），在退出预运行模式时，检查点保存的分支历史寄存器和返回地址栈将被恢复。处理器会从导致进入预运行模式的指令地址开始获取指令。\n我们的策略是在阻塞的加载指令从内存中取回数据时退出runahead mode。另一种策略是通过使用定时器提前退出，这样可以消除部分流水线填充或窗口填充的开销。我们发现，对于某些基准测试，这种替代策略表现良好，而在其他基准测试中表现不佳。总体上，提前退出的效果略差。提前退出对于某些基准测试表现较差的原因是，如果处理器不尽早退出预运行模式，可能会生成更多的二级缓存丢失预取请求。\n知识点补充 store buffer 分支预测 Architectural Register 架构寄存器是指每个CPU独有的一组全局寄存器，这些寄存器不与其他CPU共享。它们可以存储任意类型的数据，并且能够在CPU内部的线程之间实现快速通信。\n参考文献 paper-reading\narchitectural register\n浅谈乱序执行CPU\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-10T14:23:54+08:00","permalink":"https://VastCircle.github.io/2024/runahead_execution_an_alternative_to_very_large_instruction_windows_for_out-of-order_processors/","title":"Runahead_Execution_An_Alternative_to_Very_Large_Instruction_Windows_for_Out of Order_Processors"},{"content":"chipyard 从下载到构建 git clone https://github.com/ucb-bar/chipyard.git cd chipyard git checkout 1.10.0 ## 为了使得clone顺利，把http都换成ssh ，使用命令 find . -name \u0026#34;.gitmodules\u0026#34; -type f -exec sed -i \u0026#39;s/https:\\/\\/github.com\\//git@github.com:/g\u0026#39; {} + ## 同步 git submodule sync ## 运行初始化脚本 ./build-setup.sh ## 导入conda环境 source ./env.sh ## 初始化software ，例如coremark ./scripts/init-software.sh 配置一个2核心soc chipyard 配置文件 chipyard的配置文件是在chipyard/generators/chipyard/src/main/scala/config中，\nclass MyCoreConfigs extends Config( new freechips.rocketchip.subsystem.WithNBigCores(2) ++ // single rocket-core new chipyard.config.AbstractConfig) 在sim/verilator界面去执行命令,可以生成文件 simulator-chipyard-MyCoreConfig\nmake CONFIG=MyCoreConfig 裸机编译riscv #include \u0026lt;stdio.h\u0026gt; int main(void) { printf(\u0026#34;Hello, World!\\n\u0026#34;); return 0; } $ riscv64-unknown-elf-gcc -fno-common -fno-builtin-printf -specs=htif_nano.specs -c hello.c $ riscv64-unknown-elf-gcc -static -specs=htif_nano.specs hello.o -o hello.riscv $ spike hello.riscv Hello, World! -fno-common ​ 默认情况下，C语言会将未初始化的全局变量放在一个“common”区域，可以被多个文件共享。-fno-common 禁止这种行为，要求每个未初始化的全局变量必须在一个文件中定义。\n-fno-builtin-printf ​ 禁用编译器内置的 printf 函数，强制使用标准库中的 printf 函数\n-specs=htif_nano.specs ​ htif_nano.specs 可能是为特定硬件平台（例如 RISC-V）的模拟环境或硬件接口（HTIF）准备的编译和链接配置，确保生成的代码可以在特定环境中运行\n-static\n强制使用静态链接库，而不是动态链接库。所有需要的库代码都会在编译时直接链接到生成的可执行文件中，而不是在运行时动态加载。\n生成波形 make run-binary-debug BINARY=test.riscv 应该是要重新编译前文生成的bin文件\n## 方法1 make run-binary-debug BINARY=test.riscv CONFIG=MyCoreConfig ## 方法2 ./simulator-chipyard-RocketConfig $RISCV/riscv64-unknown-elf/share/riscv-tests/isa/rv64ui-p-simple 在output/chipyard.harness.TestHarness.MyCoreConfig 可以看到hello.vcd\n使用 gtkwave可以打开hello.vcd 查看\nrocket chip tiles 每个Rocket核心都与一个页表遍历器、L1 指令缓存和 L1 数据缓存组合成一个RocketTile\n每个 CPU 块都有一个 L1 指令缓存和 L1 数据缓存。这些缓存的大小和关联性可以配置。默认RocketConfig 使用 16 KiB、4 路组关联指令和数据缓存\nMemory System 这些图块(Tiles)连接到SystemBus，后者将其连接到 L2 缓存组。然后，L2 缓存组连接到MemoryBus，后者通过 TileLink 到 AXI 转换器连接到 DRAM 控制器\nMMIO 对于 MMIO 外围设备，SystemBus连接到ControlBus和PeripheryBus\nControlBus连接标准外围设备，如 BootROM、平台级中断控制器 (PLIC)、核心本地中断 (CLINT) 和调试单元\nBootROM BootROM 包含第一阶段引导加载程序，即系统复位后运行的第一条指令。它还包含设备树，Linux 会使用它来确定连接了哪些其他外设，具体在 /generators/rocket-chip/bootrom\n#define DRAM_BASE 0x80000000 .section .text.start, \u0026#34;ax\u0026#34;, @progbits .globl _start _start: csrwi 0x7c1, 0 // disable chicken bits li s0, DRAM_BASE csrr a0, mhartid la a1, _dtb jr s0 .section .text.hang, \u0026#34;ax\u0026#34;, @progbits .globl _hang _hang: csrwi 0x7c1, 0 // disable chicken bits csrr a0, mhartid la a1, _dtb csrwi mie, 0 1: wfi j 1b .section .rodata.dtb, \u0026#34;a\u0026#34;, @progbits .globl _dtb .align 5, 0 _dtb: .ascii \u0026#34;DTB goes here\u0026#34; linker.ld\nSECTIONS { ROM_BASE = 0x10000; /* ... but actually position independent */ . = ROM_BASE; .text.start : { *(.text.start) } . = ROM_BASE + 0x40; .text.hang : { *(.text.hang) } . = ROM_BASE + 0x80; .rodata.dtb : { *(.rodata.dtb) } } 第一条指令应该是从0x10000开始\n源码解读 variables.mk 构建系统的不同方式之间共享的变量和/或值在目录结构中位于较高位置。因此，该项目的一些最重要的命令和变量chipyard/variables.mk中定义.\nifeq ($(SUB_PROJECT),chipyard) SBT_PROJECT ?= chipyard MODEL ?= TestHarness VLOG_MODEL ?= $(MODEL) MODEL_PACKAGE ?= chipyard.harness CONFIG ?= RocketConfig CONFIG_PACKAGE ?= $(SBT_PROJECT) GENERATOR_PACKAGE ?= $(SBT_PROJECT) TB ?= TestDriver TOP ?= ChipTop endif SUB_PROJECT 这对应于chipyard/generators 目录中的项目之一。更正式地说，它是由相应生成器目录中的 build.sbt 文件中的条目之一以及 Chipyard 根目录中的主 build.sbt 文件定义的.\n通过在定义良好的选项之一之间更改此文件，人们可以轻松地重用 Chipyard 架构的主要部分。\nconstellation icenet rocketchip testchipip hwacha \u0026hellip;\n// 可以看到chipyard depend on 几乎所有其他的文件 lazy val chipyard = (project in file(\u0026#34;generators/chipyard\u0026#34;)) .dependsOn(testchipip, rocketchip, boom, hwacha, sifive_blocks, sifive_cache, iocell, sha3, // On separate line to allow for cleaner tutorial-setup patches dsptools, `rocket-dsp-utils`, gemmini, icenet, tracegen, cva6, nvdla, sodor, ibex, fft_generator, constellation, mempress, barf, shuttle) .settings(libraryDependencies ++= rocketLibDeps.value) .settings( libraryDependencies ++= Seq( \u0026#34;org.reflections\u0026#34; % \u0026#34;reflections\u0026#34; % \u0026#34;0.10.2\u0026#34; ) ) .settings(commonSettings) lazy val hwacha = (project in file(\u0026#34;generators/hwacha\u0026#34;)) .dependsOn(rocketchip) .settings(libraryDependencies ++= rocketLibDeps.value) .settings(commonSettings) SBT_PROJECT 这对应于要构建的芯片的顶级存储库。这是定义许多更高级别的构造的地方，例如测试工具和测试平台。\nMODEL 该模型是 Chisel 应该使用的项目的顶级模块。通常，这应该定义为与测试工具相同，但不一定必须如此。\nVLOG_MODEL 这是 FIRRTL/Verilog 应该使用的项目的顶层模块。与 MODEL 一样，这通常与测试工具相同，但不一定需要如此。\nMODEL_PACKAGE 这是用于查找 CPU 整体模型的 Scala 包。这应该对应于 Scala CPU 配置文件中的包 。\nCONFIG 这定义了项目应使用的参数。通常，这用于选择 SBT_PROJECT 中定义的 CPU 配置之一。\nCONFIG_PACKAGE 这是定义 Config 类的 Scala 包。该文件必须包含 Config 的类定义，这意味着对象 Config 必须存在。例如CONFIG=IceNetUnitTestConfig ,CONFIG_PACKAGE=icenet,这代表IceNetUnitTestConfig这个类是在包icenet里面的\nGENERATOR_PACKAGE 这是定义 Generator 类的 Scala 包。该文件必须包含 Generator 的类定义，这意味着 Generator 对象必须存在。\nTB 这定义了测试台包装器，该包装器延伸到测试工具上，以允许在 Verilog 模拟器中进行模拟。默认是TestDriver\n路径位于generators/rocket-chip/src/main/resources/vsrc/TestDriver.v\n里面包含着这个\n`MODEL testHarness( .clock(clock), .reset(reset), .io_success(success) TOP 这是该项目的顶层模块。通常，这是由测试工具实例化的模块。 例如chiptop\n在sim文件里make 发生了什么 ## 拷贝镜像 cp -f /chipyard/resources/testchipip/bootrom/bootrom.rv64.img chipyard/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/bootrom.rv64.img ## Chipyard环境中生成基于MyCoreConfig配置的模拟代码，同时输出生成过程的日志以便后续调试和查看。 (set -o pipefail \u0026amp;\u0026amp; cd CHIPYARD_HOME \u0026amp;\u0026amp; java -cp CHIPYARD_HOME/.classpath_cache/chipyard.jar chipyard.Generator --target-dir CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig ## 指定生成代码的输出目录 --name chipyard.harness.TestHarness.MyCoreConfig ## 指定生成文件的名字 --top-module chipyard.harness.TestHarness ## 指定生成代码的顶层文件 --legacy-configs chipyard:MyCoreConfig ## 指定代码的配置 | tee CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.chisel.log) ## 执行了一个 Chipyard 项目模型生成过程。它读取设计的 FIRRTL 文件和相关注解，生成指定的 SFC 模型和注解文件，以便后续仿真或综合使用。 cd CHIPYARD_HOME \u0026amp;\u0026amp; java -cp CHIPYARD_HOME/.classpath_cache/tapeout.jar barstools.tapeout.transforms.GenerateModelStageMain --no-dedup ## 禁用模块去重 --output-file CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.sfc ## 指定生成SFC文件的路径,用于存储生成的模型数据 --output-annotation-file CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.sfc.anno.json ## 生成模型的注解文件,将附加信息保存为json文件 --target-dir CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/gen-collateral ## 指定生成的附加文件的目标目录.gen-collateral 用于存放存放其他的生成数据和文件。 --input-file CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.fir ## 输入的 FIRRTL 文件，用于描述整个设计的结构和逻辑。 --annotation-file CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.appended.anno.json ## 输入注解文件，包含了与 FIRRTL 文件相关的额外信息。 --log-level error ## 设置日志等级为 error，只输出错误信息，以减少不必要的日志信息。 --allow-unrecognized-annotations ##允许工具跳过无法识别的注解，保证生成过程顺利进行。 -X firtool \\ --format=fir \\ # 指定输入文件为 FIRRTL 格式 --dedup \\ # 启用模块去重，减少重复模块 --export-module-hierarchy \\ # 导出模块的层次结构，便于理解模块关系 --emit-metadata \\ # 生成包含设计元数据的文件 --verify-each=true \\ # 每次转换后验证 FIRRTL，确保转换正确性 --warn-on-unprocessed-annotations \\ # 对无法识别的注解给出警告，便于调试 --disable-annotation-classless \\ # 禁用无明确类型的注解，避免生成不确定信息 --disable-annotation-unknown \\ # 禁用未知类型的注解，确保生成过程可控 --mlir-timing \\ # 记录 MLIR 的执行时间，便于性能分析 --lowering-options= \\ # 控制降低选项（留空使用默认设置） --repl-seq-mem \\ # 启用序列内存替换，将高层内存结构转换为可综合内存 --repl-seq-mem-file=CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.mems.conf \\ # 指定内存替换配置文件，描述生成的内存模块 --repl-seq-mem-circuit=TestHarness \\ # 指定内存替换的电路名称 --annotation-file=CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.sfc.anno.json \\ # 输入注解文件，提供生成过程所需的额外信息 --split-verilog \\ # 将生成的 Verilog 拆分为多个文件，便于管理 -o CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/gen-collateral \\ # 指定输出目录，存放生成的文件 CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.sfc.fir # 输入 FIRRTL 文件，包含电路的高层次描述 ## 这条命令运行 uniquify-module-names.py 脚本，用于对模块名称进行唯一化。其目的在于解决模块名重复问题，确保在文件列表和层次结构中，每个模块的名称都是唯一的，便于 Verilog 生成和仿真流程的管理。 CHIPYARD_HOME/scripts/uniquify-module-names.py \\ --model-hier-json CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/model_module_hierarchy.json \\ # 输入：模型模块的层次结构 JSON 文件 --top-hier-json CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/top_module_hierarchy.json \\ # 输入：顶层模块的层次结构 JSON 文件 --in-all-filelist CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/gen-collateral/filelist.f \\ # 输入：包含所有模块的文件列表 --dut ChipTop \\ # 指定待验证的顶层模块为 ChipTop --model TestHarness \\ # 指定模型的顶层模块为 TestHarness --target-dir CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/gen-collateral \\ # 指定目标目录，用于存放输出文件 --out-dut-filelist CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.top.f \\ # 输出：顶层模块的文件列表 --out-model-filelist CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.model.f \\ # 输出：模型模块的文件列表 --out-model-hier-json CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/model_module_hierarchy.uniquified.json \\ # 输出：唯一化后的模型模块层次结构 JSON 文件 --gcpath CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/gen-collateral # 指定生成文件的路径（用于在唯一化过程中查找生成文件）\\ ## 复制TestDriver.v到gen-collateral文件夹 cp -f CHIPYARD_HOME/generators/rocket-chip/src/main/resources/vsrc/TestDriver.v CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/gen-collateral ## 运行 split-mems-conf.py 脚本，将包含所有内存配置的文件分离为顶层模块和模型模块各自独立的内存配置文件。使顶层模块 ChipTop 和模型模块 TestHarness 各自拥有独立的内存配置文件，便于后续的综合和仿真过程。 CHIPYARD_HOME/scripts/split-mems-conf.py \\ --in-smems-conf CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.mems.conf \\ # 输入：包含所有内存的配置文件 --in-model-hrchy-json CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/model_module_hierarchy.uniquified.json \\ # 输入：唯一化的模型模块层次结构 JSON 文件 --dut-module-name ChipTop \\ # 指定顶层模块名称为 ChipTop --model-module-name TestHarness \\ # 指定模型模块名称为 TestHarness --out-dut-smems-conf CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.top.mems.conf \\ # 输出：用于顶层模块 ChipTop 的内存配置文件 --out-model-smems-conf CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.model.mems.conf # 输出：用于模型模块 TestHarness 的内存配置文件 ### 这条命令使用 MacroCompiler 工具，根据内存配置生成顶层模块的内存宏单元。通过指定 synflops 模式，可以确保生成的内存结构符合同步触发器的合成要求，并生成对应的 Verilog 文件，用于后续的仿真或综合步骤。 cd CHIPYARD_HOME \u0026amp;\u0026amp; java -cp CHIPYARD_HOME/.classpath_cache/tapeout.jar barstools.macros.MacroCompiler \\ -n CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.top.mems.conf \\ # 输入内存配置文件，为顶层模块生成内存宏单元 -v CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/gen-collateral/chipyard.harness.TestHarness.MyCoreConfig.top.mems.v \\ # 输出 Verilog 文件，生成的内存宏单元描述 -f CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.top.mems.fir \\ # 输入 FIRRTL 文件，用于描述内存结构 --mode synflops # 指定生成模式为 synflops，用于同步触发器合成 ### 这条命令与之前的命令类似，但这是针对模型模块 TestHarness 的内存配置。它使用 MacroCompiler 工具生成该模块的内存宏单元，确保生成的内存结构符合同步触发器的合成要求。生成的 Verilog 文件将用于后续的仿真或综合过程。 cd CHIPYARD_HOME \u0026amp;\u0026amp; java -cp CHIPYARD_HOME/.classpath_cache/tapeout.jar barstools.macros.MacroCompiler \\ -n CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.model.mems.conf \\ # 输入：模型模块的内存配置文件 -v CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/gen-collateral/chipyard.harness.TestHarness.MyCoreConfig.model.mems.v \\ # 输出：生成的 Verilog 文件，描述模型模块的内存宏单元 -f CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.model.mems.fir \\ # 输入：用于描述模型模块内存结构的 FIRRTL 文件 --mode synflops # 指定生成模式为 synflops，以支持同步触发器的合成 ## 这条命令使用 Verilator 工具生成一个基于 TestDriver 顶层模块的 C++ 模拟器 verilator --main --timing --cc --exe \\ -CFLAGS \u0026#34; -O3 -std=c++17 -ICHIPYARD_HOME/.conda-env/riscv-tools/include -ICHIPYARD_HOME/tools/DRAMSim2 -ICHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/gen-collateral -DVERILATOR -include CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig.plusArgs\u0026#34; \\ # 编译标志，包含优化选项、标准和包含路径 -LDFLAGS \u0026#34; -LCHIPYARD_HOME/.conda-env/riscv-tools/lib -Wl,-rpath,CHIPYARD_HOME/.conda-env/riscv-tools/lib -LCHIPYARD_HOME/sims/verilator -LCHIPYARD_HOME/tools/DRAMSim2 -lriscv -lfesvr -ldramsim \u0026#34; \\ # 链接标志，指定库路径和链接的库 --threads 1 --threads-dpi all -O3 --x-assign fast --x-initial fast \\ # 设置线程数，优化和快速初始化选项 --output-split 10000 --output-split-cfuncs 100 --assert -Wno-fatal \\ # 输出分割设置、启用断言，禁止致命警告 --timescale 1ns/1ps --max-num-width 1048576 \\ # 设置时间尺度和宽度限制 +define+CLOCK_PERIOD=1.0 +define+RESET_DELAY=777.7 +define+PRINTF_COND=TestDriver.printf_cond \\ # 定义宏，包括时钟周期和重置延迟 +define+STOP_COND=!TestDriver.reset +define+MODEL=TestHarness \\ # 进一步定义条件和模型 +define+RANDOMIZE_MEM_INIT +define+RANDOMIZE_REG_INIT +define+RANDOMIZE_GARBAGE_ASSIGN +define+RANDOMIZE_INVALID_ASSIGN +define+VERILATOR \\ # 启用随机化选项 --top-module TestDriver --vpi \\ # 指定顶层模块为 TestDriver，启用 VPI -f CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/sim_files.common.f \\ # 输入文件列表 -o CHIPYARD_HOME/sims/verilator/simulator-chipyard.harness-MyCoreConfig \\ # 指定输出的模拟器文件 -Mdir CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig \\ # 指定模型目录 -CFLAGS \u0026#34;-include CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig/VTestDriver.h\u0026#34; # 额外的编译标志，包含 VTestDriver 头文件 ## 建立VtestDriver.mk touch CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig/VTestDriver.mk ## 编译DRAMSim2的源文件 make -C CHIPYARD_HOME/tools/DRAMSim2 libdramsim.a ## 使用VTestDriver.mk来生成可执行文件simulator-chipyard.harness-MyCoreConfig make VM_PARALLEL_BUILDS=1 -C CHIPYARD_HOME/sims/verilator/generated-src/chipyard.harness.TestHarness.MyCoreConfig/chipyard.harness.TestHarness.MyCoreConfig -f VTestDriver.mk 附录 参考文献 An Introduction to Declarative CPU Design and FPGA Development using the Chipyard SoC Design Framework\nchipyard手册\nhttps://www.cnblogs.com/hwzhao/p/17363380.html\nTops,Test-Harnesses,and the Test-Driver\nchipyard的设备树介绍\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-07T16:15:07+08:00","permalink":"https://VastCircle.github.io/2024/chipyard-learning/","title":"Chipyard Learning"},{"content":"安装Hugo ubuntu 系统使用\nsudo apt install hugo 使用以下命令进行验证\nhugo version 创建 Hugo 网站 通过上述命令安装 hugo 程序后，就可以通过 hugo new site 命令进行网站创建、配置与本地调试了。\nhugo new site robin-site 配置主题 当通过上文命令创建我们的站点后，需要进行主题配置，Hugo 社区有了很丰富的主题，可以通过官网 Themes 菜单选择自己喜欢的风格，查看预览效果，选择后可以进入主题项目仓库，一般都会有很详细的安装及配置说明。\n官方主题网站: https://themes.gohugo.io/\n主题推荐:\nPure: https://themes.gohugo.io/hugo-theme-pure/ 关联主题仓库 https://github.com/reuixiy/hugo-theme-meme/blob/main/README.zh-cn.md\n我们可以将主题仓库直接 git clone 下来进行使用，例如在根目录robin-site下运行以下代码，即可下载pure主题.\ngit clone https://github.com/xiaoheiAh/hugo-theme-pure themes/pure 这种方式有一些弊端，当之后自己对主题进行修改后，可能会与原主题产生一些冲突，不方便版本管理与后续更新。官方更推荐使用的是将原主题仓库 fork 到自己的账户，并使用 git submodule 方式进行仓库链接，这样后续可以对主题的修改进行单独维护。\ncd robin-site/ git init git submodule add https://github.com/pseudoyu/pure themes/pure 然后在根目录下的 config.toml文件中添加新的一行:\ntheme = \u0026#34;pure\u0026#34; 更新主题 如果是 clone 了其他人的博客项目进行修改，则需要用以下命令进行初始化：\ngit submodule update --init --recursive 如果需要同步主题仓库的最新修改，需要运行以下命令：\ngit submodule update --remote hugo-theme-meme主题配置 ## 安装meme git submodule add --depth 1 https://github.com/reuixiy/hugo-theme-meme.git themes/meme ## 替换配置 rm config.toml \u0026amp;\u0026amp; cp themes/meme/config-examples/zh-cn/config.toml config.toml zozo 主题配置 git submodule add https://github.com/varkai/hugo-theme-zozo themes/zozo rm config.toml \u0026amp;\u0026amp; cp themes/zozo/config.toml config.toml https://gojun.me/posts/hello-hugo-blog/\nHugo-theme-stack主题配置 https://stack.jimmycai.com/guide/getting-started\n新建博文 完成后，可以通过 hugo new 命令发布新文章。\nhugo new posts/test.md --- title: \u0026#34;Test\u0026#34; date: 2022-10-21T19:00:43+08:00 draft: true --- 这个命令会在 content 目录下建立 post 目录，并在 post 下生成 test.md 文件，博文书写就在这个文件里使用 Markdown 语法完成。博文的 front matter 里draft 选项默认为 true，需要改为 false 才能发表博文，建议直接更改上面说的archetypes 目录下的 default 文件，把 draft: true 改为 draft: false，这样生成的博文就是默认可以发表的。\n生成网页 为了查看生成的博客的效果，我们在本地编辑调试时可以通过 hugo server 命令进行本地实时调试预览，无须每次都重新生成。在cmd中运行以下命令，即我们可以通过浏览器 http://localhost:1313/ 地址访问我们的本地预览网页。\nhugo server -D 但此时只能在本地访问，如果想发布到 Github Pages ， 还需要借助 GithubPages 工具。\n配置文件 打开配置config.toml可以看到很多的参数可以配置，这里只描述最基本的内容，不同的主题可能会支持不同的参数配置，具体请看对应主题的说明文档。baseURL是站点的域名。title是站点的名称。theme是站点的主题。还有关于评论和打赏的相关配置，这些配置都可以参考官网主题的说明。\n每次发布的时候，都需要先执行hugo，把新写的文档按照主题进行渲染，所有生成的文件默认都在当前pulic的子目录下，可以在config里面配置到其他目录。然后把所有新的文件提交到github。提交代码之后，要等一段时间才生效。\ngithub actions 部署 两个仓库 如果想使用 Github Actions 自动部署 hugo 博客，则最起码需要创建两个 Github 的仓库。\n第一个，便是存储博客 .md 源文件的地方，其实就是 hugo 系统； 第二个，则是部署 Github Pages 的仓库，仓库名必须是 \u0026lt;username\u0026gt;.github.io，这是 github 官方要求的。 最终版 主题 使用的是大佬美化后的版本 Mantyke/Hugo-stack-theme-mod。\n因为还是想用github工作流，不使用vercel,所以接下来结合前面的多篇文章操作,第一步是clone fork 之后的仓库，然后修改remote为一个创建好的私人仓库\ngit clone git@github.com:VastCircle/Hugo-stack.git git remote set-url origin git@github.com:VastCircle/hugostack.git 之后通过一系列的git操作将网页部署到gh-pages分支上\nrm -rf public git add . git commit -m \u0026#39;hugo project init\u0026#39; git push -u origin master ## create a new orphand branch (no commit history) named gh-pages git checkout --orphan gh-pages ## Unstage all files git rm -rf --cached $(git ls-files) ## Add and commit that file git add . git commit -m \u0026#34;INIT: initial commit on gh-pages branch\u0026#34; ## Push to remote gh-pages branch git push origin gh-pages ## Return to master branch git checkout master ## Add the gh-pages branch of the repository. It will look like a folder named public git subtree add --prefix=public git@github.com:VastCircle/hugostack.git gh-pages --squash ## Pull down the file we just committed. This helps avoid merge conflicts git subtree pull --prefix=public git@github.com:VastCircle/hugostack.git gh-pages ## Push the public subtree to the gh-pages branch git subtree push --prefix=public git@github.com:VastCircle/hugostack.git gh-pages 貌似失败了\n再来一次 这次把public作为一个独立的仓库，通过.gitignore去屏蔽public ,使得 主仓库不包括 public ,\nrm -rf public ## 主仓库 git add . git commit -m \u0026#39;hugo project init\u0026#39; git push -u origin master ## 推送仓库 hugo cd public git remote add origin https://github.com/VastCircle/VastCircle.github.io.git git add . git commit -m \u0026#34;INIT: initial commit on public\u0026#34; git push -u origin master shell 脚本\n#deploy.sh #!/bin/bash echo -e \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026#34; # Build the project. hugo # if using a theme, replace by `hugo -t \u0026lt;yourtheme\u0026gt;` # Go To Public folder cd public # Add changes to git. git add -A # Commit changes. msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master # Come Back cd .. 添加 github action .github/workflows/deploy-site.yaml\nname: deploy on: push: branches: [\u0026#34;master\u0026#34;] workflow_dispatch: # schedule: # # Runs everyday at 8:00 AM # - cron: \u0026#34;0 0 * * *\u0026#34; # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow one concurrent deployment concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: true # Default to bash defaults: run: shell: bash jobs: # BUild job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.134.0 TZ: America/Los_Angeles steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo id: pages uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.134.0\u0026#39; extended: true - name: Build Hugo env: # For maximum backward compatibility with Hugo modules HUGO_ENVIRONMENT: production HUGO_ENV: production run: hugo --minify - name: Deploy Web id: deployment uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} EXTERNAL_REPOSITORY: VastCircle/VastCircle.github.io PUBLISH_BRANCH: master PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} 如何编写博客 正如同其他的博客，使用 Markdown 语言来编写博客。Markdown 流行且极易上手，因此这里就不多介绍语法，如果不会的可以自己搜索了解。\n使用 Hugo 创建文章 在博客根目录下运行：\nhugo new post/untitled.md 为什么要用 hugo 来新建而不是创建一个 .md 文件呢？这是因为使用 hugo 创建会自动使用已填入 Front Matter的模板。\nFront Matter 用于标识文章的标题、时间等信息，hugo 就是据此来生成静态页面。关于属性的含义和用法可以参考 Hugo 中文文档。\n模板可以在 \\archetypes\\default.md 下找到：\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; # 标题，创建时自动填充 description: # 文章简介 date: {{ .Date }} # 日期，创建时自动填充，格式同 2023-01-15T12:00:00+08:00 image: # 文章的封面，留空就是没有，填文章所在位置的相对地址，通常放在同目录下， math: # 是否启用 KaTex，填 true 启用 license: # 文章尾部显示的协议，false 为隐藏，其他作为内容，留空就是使用 config.yaml 里默认的 hidden: false # 是否隐藏，一般用不到 comments: true # 因为 bug 所以这个属性只要存在，不管是 true 还是 false 都会导致回复无法显示，需要删掉 draft: true # 是否为草稿，建议改为 false 或者删掉这个属性以防止忘记修改，毕竟我们一般都是写好了才部署到服务器上 --- 为了方便，我参考网络以及 stack-mod 的功能对模板进行了一些改造：\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; slug: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; description: date: \u0026#34;{{ .Date }}\u0026#34; lastmod: \u0026#34;{{ .Date }}\u0026#34; image: cover.png math: license: hidden: false draft: false categories: [\u0026#34;\u0026#34;] tags: [\u0026#34;\u0026#34;] --- ## 附录 ### 参考文献 ### 版权信息 本文原载于 [reincarnatey.net](https://blog.reincarnatey.net)，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。 因此我们可以编写一个批处理程序来快速帮我们生成文章：\ncreate_post.sh：\n#!/bin/bash # 输出提示信息 echo \u0026#34;【创建文章】\u0026#34; # 读取用户输入的 Slug read -p \u0026#34;请输入Slug: \u0026#34; input # 获取当前日期 current_date=$(date +%Y%m%d) # 使用 Hugo 创建新文章 hugo new post/$current_date-$input/index.md # 暂停，提示用户操作完成 read -p \u0026#34;按任意键继续...\u0026#34; 用此批处理程序生成的文章会创建在 \\content\\post\\2023\\0115-test\\index.md，便于我们整理文章资料，同时后续在同目录下存放文章的封面也不会导致内容很乱。\n使用 Hugo 创建类别、标签 创建 Categories 和 Tag 也同理：\nhugo new categories/testcat.md hugo new tags/testtag.md hugo 会自动应用 \\archetypes\\categories.md 和 \\archetypes\\tags.md 的模板，但是这两个模板都不太好，建议都改为：\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; slug: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; description: image: cover.png style: background: \u0026#34;#2a9d8f\u0026#34; color: \u0026#34;#fff\u0026#34; --- create_Categories.sh：\n@echo off echo 【创建类别】 set /p input= 请输入类别名: hugo new categories/%input%/_index.md pause 生成的categories就是在改变如下图所示的界面\nimage1 create_tag.sh：\n@echo off echo 【创建标签】 set /p input= 请输入标签名: hugo new tags/%input%/_index.md pause 注意：如果创建多级文件夹时文章文件名不是 index.md 或者类别、标签文件名不是 _index.md 的话，设置封面图片会出现问题。\n引用 https://hk.v2ex.com/t/1009591\nhttps://jianzhnie.github.io/post/hugo_site/\nhttps://hyrtee.github.io/2023/start-blog/\nhttps://smc.im/post/deploy-hugo-blog-with-github-actions/\n建站技术 | 使用 Hugo + Stack 简单搭建一个博客\nhttps://kaichu.io/posts/my-first-post/\nstack 手册\n部署hugo 踩过的坑_\nhttps://xrg.fj.cn/p/hugo-stack%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%96%B0%E5%B0%8F%E8%AE%B0/\n","date":"2024-10-06T21:57:38+08:00","permalink":"https://VastCircle.github.io/2024/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","title":"博客搭建"}]