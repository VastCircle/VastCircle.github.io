[{"content":"附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-26T15:23:09+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B09/","title":"超标量处理器笔记9"},{"content":"概述 旁路网络:负责将FU的运算结果送到需要的地方\n每个FU都和一个1-of-M的仲裁电路一一对应,被选择的指令去读取物理寄存器堆(或者payload RAM),从而得到对应的操作数,每个仲裁电路和物理寄存器也数一一对应的\nFU的类型 ALU AGU(address generate unit) 用于计算访问存储器类型的指令在指令中携带的地址\nBRU(Branch Unit) 负责处理程序控制流(control flow)类型的指令\n负责将分支指令携带的目标地址计算出来,并且根据一定的情况来决定是否使用地址,同时对进行分支预测正确与否的判断\n对于ARM和PowerPC在每一条指令都加入的条件码,不局限于分支指令,相当于吧程序中的控制相关性使用数据相关性代替了,这样可以降低分支指令使用的频率,但是条件执行会占据指令编码的位数,减少指令中分配给通用寄存器的部分,并且可能会出现很多条无效的指令,反而可能会降低效率\n而且,如果跳转指令的条件不成立,比方说下面的ADD指令,可能就会使用错误的数据,可以通过暂停流水线或者预测的方式来解决\nselect-uOP指令 对于Intel,通过硬件插入额外的指令来选择正确的结果\n通过加入uOP来选择结果,但是这要求条件执行的指令必须成对出现,但是这样对编译器存在一定的制约,可以采取对于每一条条件指令都加入select-uOP的方法来解决,就相当于在执行完成条件指令之后,又对执行条件指令之后的值和执行条件指令之前的值进行了一次选择,将选择的值用于后续的寄存器重命名\n对于ARM指令,有一个条件寄存器CPSR,对于每一条条件指令例如ADDEQ,都需要先去判断条件寄存器的值,再决定执行不执行\nBRU还负责对于分支指令结果的检查,通过分支缓存和BRU单元的结果进行对比来实现,因为分支缓存中是保存了所有预测跳转的指令\n旁路网络 从FU的输出端到输入端架起一个通路,可以将FU的结果送到所有FU的输入端,物理寄存器堆,payload RAM,即旁路网络\n在更为现实的处理器中,在Regfile read 之后还会加入一个流水段称为 source Drive,因为对于一条指令从源操作数从物理寄存器读出来之后,还需要经过很长的一段布线,才能达到输入端,而且FU的输入端有大量的多路选择器,用来从不同的旁路网路或者物理寄存器堆选择合适的操作数,同理 FU的输出段也需要经过复杂的网路到达输入端,也需要一级,即Result drive\n简单的旁路网络 一个FU中也会有多个计算单元,一个周期只能送一条指令进FU,如果计算单元需要的周期数(latency)相等,那无所谓,但是如果不能,就可能出现在不同周期被送进来,但是在相同周期计算出结果,都想通过旁路网络进行传送\n一种解决方法就是对于一条指令正常进行唤醒和仲裁,在FU中被执行前,首先检查当前FU是否可以被自己使用(通过周期数,上周期接收了一条latency=2的指令,当周期就不要接收latency=1的指令),如果不行,放回发射队列,重新进行仲裁.\n但是这样会造成一些本来可以仲裁成功的指令被耽搁了,因此可以直接让latency作为某个值的指令就不参与仲裁的过程\n在设计发射队列时,也需要考虑是否当前的FU是能够被使用的\n对每个仲裁电路设计一个位宽为2位的控制寄存器,高位用来拦截所有latency=2的指令,低位拦截latency=1的指令,并且在发射队列的表项中增加两个信号,指示latency=1 or 2\n每个周期都需要对两位寄存器进行赋值,也要进行移位,比方说 latency = 3,就将两位寄存器赋值为10,latency = 2 ,就将两位寄存器赋值为01\n如果第一个周期选中了latency = 3的指令 , 第二个周期选中了latency = 3的指令 ,cycle 1 , a = 10 , cycle 2 , a = 11 = (10 \u0026raquo; 1 )| 10\n复杂设计的旁路网络 (1)指令 B 只能在流水线的 Execute 阶段，从指令 A 的 Result drive 阶段获得操作数。\n(2)指令 C 可以在流水线的 Source drive 阶段，从指令 A 的 Result drive 阶段获得操作数；或者指令 C 也可以在流水线的 Execute 阶段，从指令 A 的 Write back 阶段获得操作数。 (3)指令 D可以在流水线的 Source drive 阶段，从指令 A 的 Write back 阶段获得操作数。 (4)指令 E 在流水线的 RF Read 阶段读取物理寄存器堆(PRF)时，就可以得到指令 A 的结果了，因此它不需要从旁路网络中获得操作数，这里假设物理寄存器堆可以在前半个周期写人，后半个周期读取。\n对于每一个指令,不一定是在执行阶段得到旁路网络的结果\nexecute阶段的操作数除了来自于上一级流水线,还可以来自于两个FU计算的结果 ,来自于流水线的 Result Drive (B相对于A)\nSource Drive 阶段,操作数除了来自于上一级流水线,还可以来自于以前流水线的结果,分布在Result Drive(C相对A)和Write Back(D相对于A)\nA和E是不需要旁路网络的 ,即某一条指令处在RF Read 里,另一条指令处在Write back 里,就不需要进行旁路\n(1)当两条指令处在相邻周期,旁路路径只能发生在Execute 和 Result Drive\n(2)当两条指令相差一个周期,旁路路径能够发生在Source Drive和Result Drive, Execute 和Write Back 之间\n(3)当两条指令相差两个周期,旁路路径只能发生在Source Drive 和 Write Back 之间\n提供数据的指令一定得在Execute后,接受数据的指令一定要在RF read后\n操作数的选择 ScoreBoard\nFU#:记录物理寄存器从哪个FU中被计算出来,当一条指令被仲裁电路选中的时候,如果指令存在目的寄存器,就将这条指令在哪个FU中执行的信息写到表格中\nR:表示物理寄存器的值已经从FU中计算出来了,并且已经被写到物理寄存器堆中了(在写回的时候更新)\n指令B通过读取scoreBoard可以得知需要从FU中取数据\n指令C可以得知可以从PRF中取数据\n可以把读取scoreboard的过程放到流水线的RF Read阶段,使得ScoreBoard和PRF同时读取,但是这样会出现问题就是比方说指令A和指令C,如果移动到了Regfile Read阶段,指令C无法获知指令A修改的ScordBoard的值,需要加入比较逻辑,当ScoreBoard写入和读取的编号一致的话,就设置为从PRF取得操作数\n对于能够并行执行N条指令的处理器,需要2N个读端口,2N个写端口\n用最简单的方法,就是因为每个FU会把一条指令的计算结果广播送到FU输入和物理寄存器堆,同时也会送出对应的寄存器编号,所以可以直接和源寄存器进行比较就行,需要选择操作数的两个周期Source Drive 和 Execute阶段(为什么是两个阶段????)\nCluster Cluster IQ 通过将一个集中式的发射队列分成几个小的分布式发射队列,每个发射队列只对应一个仲裁电路和FU,这样每个分布式发射队列只需要存储对应的FU能够执行的指令\n(1)可以减少每个分布式发射队列的端口个数\n(2)每个分布式发射队列的仲裁电路只需要从少量的指令进行选择,可以加快每个仲裁电路的速度\n(3)分布式发射队列的容量比较小,指令被唤醒的速度也比较快\n缺点就是一个发射队列的指令对其他发射队列指令进行唤醒时,需要经历很长的走线,可能需要增加一级流水线,这样当两条存在相关性的相邻指令属于两个不同Cluster事,不能背靠背执行\n但是通过对指令进行合理的算法分配cluster,也可以做到周期的合理使用\n对于普通的集中式发射队列,需要3个周期,如果A,B,E在同一个cluster,C,D在另一个cluster那需要5个周期,但是如果A,C分到一个cluster,B,D,E分到另一个cluster中,那就只需要3个周期\n对于非数据捕捉结果的处理器,指令会先读取物理寄存器堆,需要PRF支持多个读端口,所以可以对寄存器堆也采用cluster结构,对每一个采用cluster结构的发射队列使用同一个物理寄存器堆\n原来4个FU有8个读端口,4个写端口,可以变成4个读端口,4个写端口,不过需要让两个PRF保持一致,还需要去更新另一个寄存器(那不是会影响并u行性)\n当两个存在相关性的连续指令属于两个不同的cluster时,后续的指令需要等到前面的指令更新完寄存器堆之后,才能够从寄存器堆读取操作数????? 因为旁路网络最好不好跨越两个cluster\ncluster bypass 采用cluster结构的可以直接去除流水线的Source Drive 和 Result Drive流水段\n在顺序执行的处理器,由于硬件无法调度不相关的指令,非完全的旁路网络会带来很大的负面影响,会产生大量的气泡,显然降低了处理器的性能,因此尽量会采用完全的旁路网络\n可以类比发射队列,在相邻的cluster加入一级流水线来降低路径延时,形成完全的旁路网络\n发射队列的流水和旁路网络的流水导致的延时不会叠加\n存储器指令的加速 memory diambiguation 访存地址也会存在相关性,但是这个相关性是在执行阶段计算出访存的指令之后才能够被发现 ,在解码阶段是无法被发现的\n大部分的store是按照顺序执行的(in-order),可以避免WAW相关性(why?)\nload指令可以分为\n(1)完全的顺序执行,没有WAW和WAR相关性\n(2)部分的乱序执行,顺序执行的store将程序分成不同的块,每当一条指令store的地址被计算出来,store指令和后续的store指令之间的所有load指令可以乱序执行,可以避免WAR相关性的发生\n当一条store指令地址被计算出来后,load指令就具备判断RAW相关性的条件了,每条load指令把它携带的地址计算出来之后,需要和前面所有已经执行的store指令携带的地址进行比较.通过 store buffer保存已经被仲裁电路选择倒是没有离开流水线的指令\n当store被选中时,其实就可以去允许后面的load指令参与仲裁,因为store指令地址计算的结果肯定先于load地址 存在的问题就是,如果在BCD没有被选中完毕之后,指令E被选择了,此时如果指令E和指令D的地址一致,指令D也不应该获取指令E的内容,所有需要判断出那些store指令在load的前面,哪些在后面\nPC值,但是存在向前跳转的指令 ROB,ROB是顺序的,但是由于访存指令还是少数,所以会比较稀疏 解码阶段为load/store指令分配编号 对于上述指令,部分的乱序也是会浪费很多性能\n(3)完全的乱序执行,WAR和RAW都需要在流水线中执行\n只要load指令的操作数准备好了,就可以直接发起仲裁请求了\n可以让load/store共用发射队列,但还是需要独立的仲裁电路,store指令的仲裁电路需要根据年龄,找到最旧的指令(in-order),load指令,只需要选择准备好的最老的一条指令就行了(out-of-order)\n如果分开发射队列的话,store的发射队列只需要使用FIFO结构\n需要精确的预测机制来避免RAW的相关性,例如如果发现一条LOAD指令和之前的STORE指令存在RAW相关性,就先进行记录,在后续从store buffer 中获取数据 ,这样其实也可以去减少store buffer需要的端口和比较电路\n非阻塞cache 阻塞cache:在发生cache缺失的时候,就锁定D-Cache与数据内存之间的数据通路,处理器无法执行其他的load/store指令\n非阻塞cache:在发生缺失时还是可以执行其它的load/store指令,所以需要去保存load/store相应的一些数据,比方说store的数据 ,load的目的寄存器,但是实际上访问存储器还是通过一条数据通路\n为了支持非阻塞cache,需要将那些已经产生D-cache缺失的load/store指令保存起来(MSHR(Miss Status/infornmation Holding Register))\n(1)首次缺失 ,对于一个给定的地址,访问D-Cache时第一次产生的缺失\n(2)再次缺失,首次缺失但是没有被解决,后续访问存储器的指令再次访问发生缺失的cache line ,再次缺失针对的是cache line 不是相同的地址,\nMSHR:\nV:valid ,指示当前的表项(entry)是否被占用 ,首次缺失MSHR本体的一个表项会被占用,Valid置一,直到Cache line从下级存储器被取回来.\nBlock Address : Cache line 数据块的公共地址\nIssued: 表示发生首次缺失的load/store指令是否已经开始处理,即是否向一级存储器发送读数据的请求\nLOAD/STORE Table\nValid : 表示一个表项是否被占用,无论是首次缺失还是再次缺失\nMSHR entry : 表示发生缺失的指令属于MSHR本体的哪个表项,产生缺失的指令可能会对应同一个cache line , 为了避免重复占用下一级存储器的带宽,只会占据同一个MSHR entry ,但是占据多个LOAD/STORE Table\nDest.register : 对于load指令,记录目的寄存器的编号, 对于store指令,这部分记录store指令在store buffer中的编号,一是可以找到store指令所携带的数据,以便和下级存储器中取出的数据块合并,二是能够释放store指令占据的store buffer中的空间\nType :记录访问存储器指令的类型\nOffset:访问存储器的指令所需要的数据在数据块中的位置\n当发生缺失是,首先查找MSHR的本体,如果有相同的表项,代表再次缺失,只需要写到LOAD/STORE Table ,如果没有,需要写入MSHR和LOAD/SOTRE Table\n如果满了,就无法去处理新的访问存储器指令,就阻塞了\n对于load指令,需要把数据送到对应目的寄存器,并写到D-cache里 ,\n对于store指令,需要从Store buffer中找到对应的数据,和数据块合并,然后写到D-cache 里,然后释放store buffer\n(in-cache MSHR )\n在分支预测失败之后,需要去删除LOAD/SOTRE Table正在执行的load/store指令 ,并且如果针对于一个数据块的所有load/store指令都处于分支预测的路径上,那这个数据块也不能去更新到D-cache上去\n关键字优先 就是去改进读取cache块数据的顺序 ,本来是0,1,2,3,4,5,6,7,8,可以修改为 \u0026mdash; 之类的 ,可以去把访存需要的数据提前\n提前开始 在Cache line读取到指令需要的数据之后,就可以让CPU去继续执行了 ,相比于关键字优先不需要额外的硬件,但是如果数据处在数据块比较后面的位置,那就没有太大的用处\n对于I-cache ,虽然指令需要做到顺序取出,但是由于存在分支跳转,也可以通过非阻塞的操作来加快取指,不同于D-cahce的是取出的指令必须是顺序的,如果前面的指令没有被取出来也必须进行等待直到数据被取出\n附录 参考文献 超标量处理器\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-22T13:17:32+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B08/","title":"执行"},{"content":"概述 只要发射队列中的一条指令的草做书都准备好了,且满足了发射的条件,就可以送到相应的FU中执行.发射队列的作用就是使用硬件保存一定数量的指令,然后从指令中找出可以执行的指令\n发射时序一般处在处理器的关键路径上,直接影响处理器的周期时间\n(1)发射队列(Issue Queue),用来存储已经被寄存器重命名,但是没有被送到FU执行的指令,也称为保留站(Reservation station)\n(2)分配(allocation)电路,用来从发射队列中找到空闲的空间,将寄存器重命名之后的指令存储在其中\n(3)选择电路(仲裁电路),发射队列中多条指令的操作数都准备好了,电路会按照一定规律,从其中找到最合适的指令,送到Fu中去\n(4)唤醒电路,当一条指令经过FU执行而得到结果数据时,会将其通知给发射队列中所有等待数据的指令,指令对应的源寄存器就会被设置为有效的状态,即为唤醒.\n集中式 or 分布式发射队列 如果所有FU共用一个发射队列,即为集中式发射队列(centralized issue queue,CIQ)\n如果每一个FU都有单独的发射队列,称为分布式发射队列(Distributed issue queue,DIQ)\nCIQ容量大,选择电路和唤醒电路复杂,电路利用率高\nDIQ会出现一个发射队列满了,其他发射队列没有满,但是最终数据被阻塞的情况,就会出现效率低下的问题\n数据捕捉 or 非数据捕捉 寄存器的数据读取时间\n数据捕捉 流水线的发射阶段之前读取寄存器,被寄存器重命名的指令会先读取物理寄存器堆,然后将读取到的值一起写入到发射队列,没有被计算出来的数据会以编号的形式写入,供唤醒时使用,会被标记为无法获得状态(non-available),这些值会通过旁路网络获取.在发射队列中,存储指令操作数的地方称为payload RAM\n一条指令被仲裁电路选中发射到FU中去,它会将目标寄存器进行广播,其他在发射队列的指令就会去对比,有相等的情况时就会在payload RAM进行标记,在FU计算完成之后会写入到payload RAM 对应的位置 .\nmachine width : 每周期实际解码和重命名的指令个数\nissue width : 每周期最多可以在FU中并行执行的指令个数\n在RISC 里 machine width \u0026lt;= issue width\n物理寄存器的端口数 = machine width * 2\n大多数源操作数会经历两读1写,从寄存器读取出来,送到发射队列,从发射队列中读取送到FU ,功耗高 ,面积大\n寄存器重命名方便 ,指令在顺利离开流水线的时候,需要将结果从重排序缓存中搬移到ARF中,采用数据捕捉的方式可以不用惯性指令结果的变化??????\n非数据捕捉 在发射阶段之后读取物理寄存器堆,被重命名之后的指令不去读取物理寄存器堆,而是直接将源寄存器堆的编号放到发射队列中去.当指令被选中时,通过编号读取物理寄存器堆,将读取值送到FU中\n寄存器堆的读端口 = issue width ,比较大\n压缩 or 非压缩 压缩 当一条指令被选中离开发射队列之后,指令上面所有的指令都会下移一格\n通过多路选择器进行压缩\n这种方式选择电路比较简单,通过优先编码选择最旧的就行了,oldest-first方法 ,但是选择电路的延时很长\n优点如下:\n1.分配电路简单,发射队列中的空闲空间总是处于上层,只需要使用发射队列的写指针,指向第一个空闲空间\n2.选择电路简单.最旧的指令存在的RAW相关性也越多,先执行可以最大程度释放和它存在RAW相关性的指令\n但是\n1.实现起来浪费面积\n2.功耗大\n非压缩 没有移动\n发射过程中的流水线 非数据捕捉结构的流水线 要被FU执行\n(1)指令所有的源操作数准备好了\n(2)指令被发射队列选中\n(3)能够从寄存器,payload RAM或者旁路网络获得源操作数\n下图发射过程被分为了唤醒(wake-up)和仲裁(Select)两个流水线阶段\n唤醒阶段,发射队列中的所有相关寄存器会被置为准备好的状态\n仲裁阶段,会使用仲裁电路选择一条最合适的指令送到FU中\ntomasulo算法:在指令执行完才对相关指令进行唤醒\n可以通过将唤醒过程提前来获得更高性能\n即在指令A被仲裁电路选中后就对其他寄存器进行唤醒,这样指令B在下一个周期就能够被仲裁\n意思是 Select 和 wake-up应该是在同一个周期的串行,A被唤醒才能够去selectB\n这种操作称为\u0026quot;原子的\u0026quot;\n拆分流水线可以使得主频升高,但是\n(1)分支预测失败,惩罚增加\n(2)cache访问的周期数增加\n(3)功耗增大\n以上是假设执行是一个周期,实际上并不止\n数据捕捉结构的流水线 可以把select和payload放在同一个流水段 ,在指令被仲裁电路选中之后,在同一个周期对发射队列其他的指令进行唤醒,同时去读取payload RAM,这两个操作是并行进行的,在这个流水段还会负责payload RAM的读取和写入,会导致处理器的周期时间变得过大.\n旁路网络这样是啥意思????\n另一种设计方式是把payload单独放成一个流水段,旁路和执行分成两个流水段,在旁路阶段,FU的结果会被送到payload RAM和FU的输入端\n分配 对于非压缩的方式设计的发射队列,需要分配电路扫描整个发射队列,找到四个空闲的表项并将四条指令写入\n可以使用一个表格来记录所有空闲表项的编号,按照FIFO的方式管理,也可以简单把发射队列分为多个部分,每个段选一个空闲编号,但是会出现问题就是如果有一个表项非空的话,会阻碍其他指令的放入,甚至由于在寄存器重命名阶段是in-order状态A的无法放入会导致后续指令都无法放入\n仲裁 最好实现oldest-first功能的仲裁\n1-of-M仲裁 可以通过指令在ROB中的位置作为指令的年龄信息,但是由于ROB是一个循环队列,所有单纯的地址是无法表征年龄的\n其实我觉得,直接比较读写地址可以的吧,读指针 \u0026gt; 写指针 , 下新上旧 , 读指针 \u0026lt; 写指针 , 上新下旧 ,其实读指针 \u0026gt; 写的时候,也代表两者不是一面的\n可以在ROB中地址前面再加入一位,称为位置值.想当于对于读写地址又加了一位\n(1)位置值相同时,ROB地址越小,对应的指令越旧\n(2)位置值不同时,ROB地址越大,对应的指令越旧,比方说情况2的 0 10 与 1 01 比较,明显是0 10 旧\n先根据是否rdy选出指令,再根据年龄进行筛选\n二分\n该电路能够得到最小的年龄值,但是还需要得到最小年龄值对应的指令,最方便的是将指令信息也一同附上去\nN of M 仲裁电路 几个FU共用一个发射队列,发射队列需要在一个周期内为没一个FU选择出一条指令,就要求有一个N of M的仲裁电路\n可以通过两级仲裁电路实现,第一级选择一条指令后对第二级进行标记,但是这样延时极大\n对每一个FU使用一个1 of M的仲裁器, 根据指令类型进行分类,这样就会存在相同类型的指令会阻塞或者一部分FU处在空闲状态的问题\n可以通过增加FU的数量解决上述问题,但是比方数两个ALU,指令该分配给哪个ALU又是一个问题,可以通过轮换分配法实现,但是这样是无法保证严格的oldest-first原则的,而且有可能会浪费FU资源\n一般来说,加减法,逻辑运算,移位运算合成一个FU,\n惩罚和除法合成一个,\n访问存储器和访问协处理器合并在一起,\n浮点运算合并在一起\n唤醒 单周期的唤醒 唤醒是指被仲裁器选中的指令将目的寄存器的编号(dst_tag)和发射队列中所有源寄存器的编号进行比较,并将那些比较结果相等的源寄存器进行标记的过程\n下面的电路是所有仲裁电路共享一个发射队列的情况, 所以发射队列只会接受到一个响应,因为同一时刻肯定只有一条指令被仲裁,每个FU都会使用一个仲裁电路\nimage-20241020213306752 (1)ValL:指令中是否存在第一个源寄存器\n(2)SrcL:指令中第一个源寄存器的编号\n(3)RdyL:指令中第一个源寄存器是否已经被唤醒而处于准备好的状态\n(4)ValR:第二个\n(5)Dest:目的寄存器的编号\n(6)Issued:一条指令被仲裁电路选中之后,可能不会马上离开发射队列,需要进行标记,这样的指令不会向仲裁电路发出请求信号\n为什么有四个仲裁电路?????是不是指多个FU,但是多个FU不是应该可以接受多个请求\n发射队列的每一个表项都会根据四个响应信号的值,将自身的目的寄存器编号送到对应的总线上去,每个仲裁电路对应一个总线\n被仲裁电路选择的指令会将它的目的寄存器编号送到对应的总线上 每一条总线的值会和发射队列中所有指令的源寄存器的编号进行比较,如果发现相等,标记为准备好的状态 当发射队列某条指令的操作数都准备好了,并且没有被仲裁电路选中过,就可以想仲裁电路发送请求信号 如果仲裁电路发现有更高优先级的指令发出请求,当前指令不会得到有效响应信号,需要再之后的周期继续发送请求信号.在一些设计中,可以轮流向多个仲裁电路发送请求.如果从仲裁电路中得到有效信号,就会吧issued置位.一条被选中的指令不会立刻离开发射队列,因为一个指令如果使用了load指令的结果,即使被仲裁电路选中,也不能离开 发射队列的指令更具响应信号,,把目的寄存器编号送到对应总线上去,用来唤醒发射队列中所有相关的源寄存器 多周期的唤醒 单周期的唤醒能够在一个周期被FU执行完毕,但是当一条指令无法在一个周期执行完毕时,需要根据她在FU中的周期数,将唤醒过程延迟\n根据唤醒的过程\n延迟广播. 发现被仲裁电路选中的指令执行周期大于1,则在选中的当前周期,不讲指令的目的寄存器编号送到总线上,而是根据选中指令需要执行的周期数(N),延迟N-1周期,才送到总线上去\n延迟广播之后可能出现tag bus产生冲突,比方说下面的MUL和ADD在同一时刻需要将目的寄存器的值送到tag broadcast bus上\n可以通过增加总线的数量,也可以利用表格,记录下FU执行指令所需要的周期数,被仲裁电路选中的指令,如果发现冲突,被选中的指令不会送到FU中执行,而是在下一个周期继续参与仲裁\n但是还是存在一个问题,就是指令B被否决(cycle 1),本身指令C是可以被仲裁的,但是C比B要新,所以这个周期被浪费掉了,所以可以先检查是否冲突,如果冲突的话就不向仲裁电路发起请求了(不发请求很奇怪啊,发请求在仲裁的时候否决行不行),但是这样访问网络和仲裁电路是串行的\n延迟唤醒 最优解就就是要去实现背对背执行,一条指令的执行和后一条指令的执行是先后的\n在比较结果相等时,不马上置为准备好的状态,而是根据指令所需要的执行周期数,进行相应周期的延时,然后再改变发射队列中源寄存器的状态\n通过移位寄存器实现延迟唤醒的效果.在解码阶段对每条指令执行周期数进行编码,称为DELAY,在将目的寄存器送到总线外,还需要将DELAY值也送到总线上去.称为DELAY bus .\nFreed :表项是否空闲\nIssued:指令是否被仲裁电路选择\nSrcL:第一个源寄存器编号\nSrcL_M:当寄存器编号比较结果相等时,置1;当接收到仲裁电路的响应信号后,清0,它是移位寄存器进行算数右移的使能标志\nSrcL_SHIFT:移位寄存器,当编号比较结果相等时,将DELAY写入移位寄存器,每周期进行算数右移\nRdy:表示第一个源寄存器是否准备好了\nSrcR_imm_valid :表示第二个操作数是否是立即数\nROB ID:指令在ROB的位置,使得其能够实现oldest-first选择\n编码形式是类似于11111000(8位),在经过3个算数右移之后最低位就是1,就是Rdy=1\n直到被仲裁电路响应或者说选择之后,SrcL_M,srcL_SHIFT都会清零,其他时候Rdy都会保持着1的状态发送请求,直到被仲裁\n推测唤醒 对于某些指令,指令在FU中执行的周期数是可以被预测的,这样才可能分配一个确定的DELAY值\n但是对于\n(1)Load指令\n(2)某些处理器的特殊情况,例如RowerPC 603处理器存在early out,即当被除数值比较小时能够被提前预测指令\n比较简单的方法就是等指令执行完了之后再去唤醒其他指令\n可以优化一下就是一般load指令在第一个周期计算地址,第二个周期访问Tag SRAM,第三个周期将读取到的数据写入目的寄存器,所以在第二个周期就可以判断,命中后去唤醒\n假设d-cache是一直命中的,就能够得到一个比较理想的情况 但是一旦指令A发生了D-cache缺失,此时B就不能停住而等待操作数,这样会使得FU无法接受其他新指令,严重影响处理器的性能.最好的办法是将指令B重新放回发射队列(Issue Queue),因为load指令在D-cache缺失之后,会到L2 cache寻找数据,此时可以假设L2 cache是命中的,并按照命中时间重新对相关寄存器进行唤醒,还是使用延迟唤醒\n对于不确定周期的指令,可以去预测指令执行的周期数,在指令得到结果之前,对相关的指令进行唤醒操作\n预测成功就执行,预测失败就去进行状态会被,被唤醒的所有寄存器需要重新设置为(not ready)状态,如果一些指令离开了发射队列,还需要从流水线中抹去,放回发射队列\n未完待续\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-19T20:25:19+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B07/","title":"发射"},{"content":"超标量处理器的寄存器重命名 对于 Dest = Src1 op ASrc2\n(1)从RAT中找到Src1和Src2对应的物理寄存器Psrc1和Psrc2\n(2)从空闲列表(Free list)中找到一个空闲的物理寄存器Pdest,将其作为指令的目的寄存器Dest对应的物理寄存器\n(3)将逻辑寄存器Dest和物理寄存器Pdest的映射关系写到RAT中\nRAT需要3个读端口(Src1,Src2和Dest作为地址) Dest这个端口用于和ROB进行交互,将之前的映射关系写入ROB中\n对于超标量,就需要成倍的端口\n(1) A,B存在RAW相关性 , 所以r0对应的物理寄存器之列来自于指令A对应的P30,不来自于从RAT读取的值\n(2)A,B,D存在WAW相关性,\nA.在写入RAT时,如果多条命令有同一个目标寄存器,那映射关系实际上写的还是最新的那条指令\nB.在将旧映射关系写入ROB的时候,如果发现一个周期内有多条指令都使用的同一个目的寄存器,此时写入到ROB中的旧映射关系不再来自于RAT读取的值,还是直接来自于和他存在WAW相关的指令,例如指令B的物理寄存器来自r0,或者所物理寄存器来自于P31\n(3)B,D存在WAR相关性,通过寄存器重命名可以客服\n解决RAW相关性 意思就是如果在同一周期进行寄存器重命名,对于源寄存器,应该获取当前赋值给目的寄存器的物理寄存器(P31),而不是之前的物理寄存器(P25),所以需要进行组内相关性检查,由于此时是顺序的,所以相关性检查和顺序处理器相似,只需要比较源寄存器与目的寄存器的编号就可以了\n解决WAW相关性 对写RAT进行检查 在寄存器重命名周期,如果存在多个指令的目的寄存器都相等的情况,那么只有最新的那条指令的映射关系才运行写入到RAT中 ,可以通过检查目标寄存器来实现,例如对于dst0只要和dst1,dst2,dst3中的任意一个存在相同的情况,就不需要将dst0对应的映射关系写到RAT中\n对写ROB进行检查 为了能够释放掉那些不再使用的物理寄存器,同时可以对处理器的状态进行恢复,每条指令需要从RAT中读出他以前对应的物理寄存器,并将其写到ROB当中,如果两条指令存在WAW,那么比较新的这条指令对应的就的物理寄存器就直接来自与比较旧的那条指令,而不是RAT中\n通过比较指令与前面指令的目的寄存器就可以实现\nRAT的SRAM结构 读优先 : 当前写入的数据在下一个周期才能被读取\n写优先:当前写入的数据在当前数据就能够被读取\n对于RAT,需要做到先读,读完再修改,所以采取读优先\n对于读取目的寄存器,由于本来就要获取目的寄存器之前对应的物理寄存器,所以读优先是必须的\n对于读取源寄存器,其实需要得到新的映射,需要使用之前的RAW相关性的检查和处理电路\n特殊情况的标记 对于没有一个目标寄存器和两个源寄存器的指令,采取以下方式\n(1)根据需要重命名的目的寄存器个数,觉得当前周期需要从空闲列表读取数字的个数\n(2)使用目的寄存器读取RAT时,目的寄存器不存在的指令不会读取RAT\n(3)使用源寄存器读取RAT时,源寄存器不存在的指令不会读取RAT\n(4)在RAW和WAW相关性检查时,如果源寄存器和目的寄存器不存在,那就忽略\n寄存器重命名的恢复 使用checkpoint对RAT进行恢复 SRAM的最小存储单元(Main Bit Cell,MBC), (Checkpoint Bit Cell ,CBC)\n当需要对RAT进行状态保存时,将MBC的内容复制到指定的CBC中(Allocation),当对RAT进行状态恢复时,将对应CBC的内容复制到MBC中(Restore)\n使用WALK对RAT进行恢复 对每一条指令,在ROB中都储存了这条指令之前对应的物理寄存器,利用这个信息,可以将RAT的状态逐步\u0026quot;倒回去\u0026quot;,使得那些处在错误路径上的指令,对RAT的修改都进行修复\nROB中储存着物理寄存器,逻辑寄存器,之前的物理寄存器,一条一条回退到之前的物理寄存器,应该就可以做到\n使用Architecture State对RAT进行恢复 在流水线提交阶段有一个RAT,,叫做aRAT(architecture RAT),它所保存的物理寄存器和逻辑寄存器的映射是完全正确的\n对于如下的指令,在重命名阶段的RAT,对于r1的映射应该是P34,但是实际上此时指令D是处在推测阶段,是有可能被冲刷掉的,但是对于aRAT,它保存的就是已经提交的指令之间的映射,例如R1对应P31,它的状态是完全正确的\n所以说,可以通过aRAT进行恢复,具体就是在分支预测失败时,让指令继续执行,直到分支指令变成最旧的一条指令,那此时所保存的状态就是分支指令之前的指令所得到的状态,再复制,就能够恢复了\n等到分支指令变到流水线最旧的指令,才恢复RAT的另一个好处就是,如果在一条分支指令之前存在异常或者另一个分支预测失败,那这条分支指令就不会被处理,也避免了一些无用功\n分发 (1) 发射队列 (out-of-order),指令在送到FU中被执行之前,先被放到一个缓存中,每个FU都对应一个发射队列,\n只要一条指令的所有源操作数都准备好了,就可以直接送到FU中执行,不用理会指令的原始顺序,在多发射处理器中,需要从缓存中找到多个空闲的表项\n(2)发射队列(in-order),分支指令和store指令是按照顺序执行的,该队列就是FIFO\n(3)重排序缓存(ROB),将乱序拉回顺序\n分发就是将寄存器重命名之后的指令写到发射队列和重排序队列当中\n附录 参考文献 版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-19T11:46:41+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B06/","title":"寄存器重命名(超标量+过程恢复)"},{"content":"概述 WAW 和 WAR (写后写 和读后写) 可以通过更换寄存器的名字来解决相应冲突\n存在原因 (1)有限个数的寄存器\n(2)循环体,很容易出现写后写冲突\n(3)代码重用,一些小函数被频繁的调用\n物理寄存器(Physical Register)和逻辑寄存器(Logical Register或者 architecture Register)物理寄存器数量多于逻辑寄存器\n重命名映射表 (Register Renaming Table, Register Alias Table ,RAT)空闲寄存器列表(Free Register List)\n寄存器重命名的方式 (1)将逻辑寄存器(architecture Register File,ARF)扩展来实现\n(2)使用统一的物理寄存器(Physical Register File,PRF)实现\n(3)使用ROB实现\nROB 将ROB作为物理寄存器,存储所有**推测状态(speculative)**的结果,使用逻辑寄存器(ARF)存储所有正确的结果\n当一条指令被写入ROB中的一个表项(entry)时,表项的编号即为物理寄存器,这样将逻辑寄存器和表项建立了关系,\nROB存储着所有没有离开流水线的指令结果,逻辑寄存器(ARF)存储着所有\u0026quot;最新\u0026quot;离开流水线的指令结果\n重命名映射表用来指示每一个逻辑寄存器的值是位于ROB中还是位于ARF中\n缺点 (1)即使没有目的寄存器也会占用ROB的一个表项,代表物理寄存器的浪费\n(2)对应ROB和ARF需要有多个读端口来支持多条指令的访问\nARF扩展 可以使用一个独立的存储部件来存储流水线中所有指令的结果,只有那些存在目的寄存器的指令才会占据该部件,称为 PRF(Physical Register File),PRF和ROB类似,只是在没有目标寄存器的指令不会占据PRF,寄存器重命名时存在目的寄存器的指令会占据PRF的空间,在退休时,结果会从PRF搬移到ARF中\n重命名映射表用来指示每一个逻辑寄存器的值是位于PRF中还是位于ARF中,需要保存PRF的地址空间\n使用统一的PRF 存储所有推测的和正确的寄存器值,\n使用空闲列表记录PRF哪些寄存器处在空闲状态\n当指令被寄存器重命名,并且存在目的寄存器的时候,就会占据PRF当中的一个寄存器,该寄存器会经历值未被计算,值被计算但是没有退休,退休三个过程\n通过重命名映射表存储每个逻辑寄存器和物理寄存器的对应关系\n寄存器重命名时,\n源寄存器:查找重命名的映射表(RAT),找出对应物理寄存器的编号\n目的寄存器:给目的寄存器指定一个空闲状态的物理寄存器,并且该关系会被更新到RAT中\n指令退休之后释放物理寄存器\n一条指令之后在退休的时候,结果才会被外部看到,推测时是无法被外界看到的,需要使用另外一个RAT,存储所有\u0026quot;退休\u0026quot;状态的指令和物理寄存器的对应关系(啥时候释放?),外部只能通过查找这个RAT,找到逻辑寄存器对应的物理寄存器\n**只有后续的指令不使用物理寄存器之后,物理寄存器才能够变成空闲.**可以采取比较保守的方式,就是当一个指令和后面的莫条指令都写到同一个目的寄存器时,前面指令的物理寄存器可以释放了,**所以在ROB中除了记录逻辑寄存器当前对应的物理寄存器之外,还需要存储它之前对应的物理寄存器,**以便在指令退休的时候,将旧映射关系释放\n优点 (1)寄存器的值只需要被写入一次?\n(2)源寄存器的值只能存储在一个地方,即PRF中\n重命名映射表(RAT) RAT是一个表格,使用逻辑寄存器作为地址寻址,对于指令的源寄存器,可以从表格中得到对应的物理寄存器的编号\n对指令的目的寄存器来说,会将物理寄存器编号写到这个表格,即建立映射关系\n可以使用多端口的SRAM(sRAT)和CAM(cRAT)实现,CAM(内容寻址的存储器)\nSRAM表项个数等于逻辑寄存器的个数,里面存放对应物理寄存器的编号,位宽为log(物理寄存器数量)\nCAM表项个数等于物理寄存器的个数,里面存放对应逻辑寄存器的编号,位宽为log(逻辑寄存器数量),寻址时逻辑寄存器的编号会和每个表项进行对比,返回对应的地址\n使用SRAM寻址功耗小,面积小\n由于对于cRAT进行checkpoint只需要保存状态位(V),而不需要将整个cRAT进行保存,能够大大减少checkpoint电路的面积,当checkpoint数量大时,反而cRAT具有优势\n基于SRAM的重命名映射表 checkpoint需要把整个sRAT都保存下来\n对于4-way的超标量处理器,每周期最多需要对四条指令进行寄存器重命名,sRRAT需要8个读端口和4个写端口(每条指令包含2个源寄存器和1个目的寄存器)\n新写入到sRAT的值会覆盖掉原来旧的对应关系,需要记录下来\n(1)方便指令在退休的时候,将对应的物理寄存器变为空闲状态???? (还是无法理解,按理来说覆盖了说明该逻辑寄存器又分配了新的物理寄存器,那原来那个确实可以删除了)(覆盖的时候后面的指令还没有退休,是有可能无效的(分支失败异常之类的,那后面分配的必定是要被还原的,所以物理寄存器是应该在后面指令退休的时候再变成空闲状态))\n(2)当一条指令之前存在异常或者分支预测失败时,需要从流水线中被抹去 ,同时这条指令对于RAT的修改需要被恢复过来,通过将旧的映射关系保存下来,可以协助RAT的修复\n缺点就是无法使用多的checkpoint\n只要预测的足够准,就不怎么需要checkpoint ,就可以去减少checkpoint的数量,但是如果预测错了又没有checkpoint,那对于RAT的恢复也会很麻烦\n??? RAT里面的值不是应该也是保存在ROB里的吗,那保存ROB不就行了,为什么还要RAT\n基于CAM的重命名映射表 任意时刻,每个逻辑寄存器都只有一个物理寄存器与之对应,可以使用一个有效位(V)表示\ncRAT需要8个读端口和4个写端口(每条指令包含2个源寄存器和1个目的寄存器)\nSRAM + CAM ,SRAM用来存储每个物理寄存器对应的逻辑寄存器,CAM用来进行内容的比较\n需要等到后面写入到同一个逻辑寄存器的指令退休(retire)的时候,才可以将这个逻辑寄存器之前对应的物理寄存器变为空闲状态\n并不是一个物理寄存器对应的有效位为0,就表示物理寄存器是空闲状态,有可能是这个映射关系刚刚被覆盖了.通过使用ROB和空闲列表可以管理物理寄存器何时变为空闲\n在分支指令寄存器重命名之前,将cRAT的有效位保存起来;在流水线的后续阶段,发现分支指令预测失败是,将分支指令对应的checkpoint写回到cRAT的有效位就完成恢复了(why?这样能保证恢复映射关系?)\n恢复时可能把一些本身处在非空闲状态的物理寄存器变成了空闲状态,因为非空闲状态的物理寄存器有效位也可以是0\n有可能在进行checkpoint保存的时候为0,到了状态恢复的时候变成1了.典型情况是物理寄存器在变为空闲之后又被新的指令使用了.但是该指令处在分支预测失败或者异常路径上.应该是要恢复为0的\n举例 在指令F进行寄存器重命名时,需要对cRAT进行Checkpoint保存\n分支F被发现了分支预测失败,对cRAT进行状态恢复前 ,在F解码时,就保存了此时的状态,所以如果预测失败写回,就直接恢复了那之前的表\n每次在流水线的寄存器重命名阶段遇到分支2指令时,都会从表7.2找出一个空闲的GC来存储此时的有效位(V),并将GC的编号放在分支指令的信息中,这样当得到分支预测的结果之后,就可以根据编号来找到与之对应的GC.在分支预测失败之后直接进行相应的复原\n为了保证正确性,在分支预测失败进行恢复的时候,需要对空闲列表(free list)也进行状态恢复,那些别占用的物理寄存器都将重新变为空闲的状态(通过恢复free list的读指针)\n对cRAT进行状态恢复,就是要还原出逻辑寄存器真正对应的物理寄存器,因为会续分支预测失败路径上的指令可能会修改对应关系,需要进行纠正.对于物理寄存器的空闲管理交给ROB和free list\n附录 参考文献 超标量处理器设计\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-18T19:25:31+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B04/","title":"寄存器重命名(方式+映射表)"},{"content":"分支预测的目标地址预测 对于直接跳转的分支指令,由于它的偏移值(offset)是以立即数的形式固定在指令中,目标地址是固定的,只需要记录分支指令的目标地址即可.\n对于间接分支跳转,大部分是CALL和Return ,所以可以进行一定程度的预测\n直接跳转类型的分支预测 (1)当分支指令不发生跳转时,\n目标地址 = 当前分支指令的PC值 + Sizeof(fetch group)\n(2)当发生跳转时\n目标指令 = 当前分支指令的PC值 + Sign_Eextend(offset)\nBTB 通过BTB(Branch Target Buffer)(相当于一个cache)使得多个PC值共用一个空间来存储目标地址,\nindex + tag ,\nBTA (Branch Target Address)分支目标地址\n可以使用组相联的BTA来提高分支预测的准确率\n如果已经被替换了,那该跳哪去 : 先跳再冲刷吗?\nimage-20241016185417711 partial-tag BTB 如果映射到BTB中的指令中只有一条,那可以简化tag的部分,只使用很小的一部分,\n这种方法实际上也是在赌,减少了tag的大小,万一出现了重合,那就会出现目标地址预测失败的情况,但实际上,如果出现了重合,即使不减少tag,仍然会导致预测失败.\nimage-20241016185852818 和之前类似,仍然可以采取一定运算,来降低tag的位数,比方说异或\n我比较好奇,如果tag没有对上,对于直接相连来说,本身也无法得到正确地址,那为什么不直接把tag删除了\n应该是组相联有用吧\nimage-20241016190929007 BTB缺失的处理 停止执行 暂停取指,直到目标地址被计算出来\n对于直接跳转指令,在解码阶段就可以分离出偏移值\n解码阶段分离指令 停止取指会造成气泡,其实就是导致流水线停滞\nimage-20241016192510520 继续执行 使用顺序的PC值去指令\n计算出的地址和原来PC不一致,就冲刷流水线,重新开始取指\n这么做会浪费功耗\n间接跳转类型的分支预测 CALL/Return 指令的分支预测 CALL的地址一般也是固定的,所以也可以通过BTB进行预测\nReturn的目标地址是不固定的,但是Return的目标地址总是等于最近一次执行的\n但是Return指令的目标地址,是按照CALL指令执行的相反顺序排列的\n所以可以做一个存储器,保存最近执行的CALL指令的下一条指令的地址,这个存储器是后进先出的(Last In First Out,LIFO),原理与堆栈类似,称为返回地址堆栈(Return Address Stack,RAS)\nCALL/Return 指令分支预测 RAS工作条件 (1)需要及时保存PC + 4的值, 指令类型只有在解码阶段才能获知,因此可以在BTB中多加一项来保存分支指令的类型,这样在后续取到这一条指令就可以获知分支指令类型\n(2)在对Return指令进行目标地址预测是,能够选择RAS的数据,而非BTB的数据,按照上面的方法就可以做到\n将指令类型存储到BTB中 RAS满了 如果函数层次过深,就会出现RAS无法继续存放的问题\n(1)不保存CALL了,这样下一次Return 就会出现分支预测失败,并且还要求RAS指针不发生改变\n(2)继续按照顺序向RAS写入,此时最旧的会被覆盖掉.最后一次return 可能会出现分支预测失败,但是也是可能性事件,比方说递归函数\n可以通过带计数器的RAS来扩展RAS的容量, 即对于相邻的CALL,如果是同一条指令,就存放在RAS的同一个地址,再用计数器进行标识\n其他指令的预测 case指令 image-20241016210205293 使用基于局部历史的分支预测方法,把PHT换成了Target Cache,\n每当分支指令执行一次,就将目标地址写到Target Cache 中\n小结 分支预测使用 BHR , GHR和饱和计数器配合进行分支指令方向的预测\n使用 BTB, RAS和 Target Cache对分支指令的目标地址进行预测\n完整的分支预测方法 , decoupled BTB : 将分支指令的方向预测独立于BTB ,本身不会被记录到BTB的分支指令也会被记录(不跳转的分支也会记录到BTB)\n预测为发生跳转,但是发生了BTB缺失,比发生分支预测失败的情况好,可以节省功耗\n完整的分支预测方法 分支预测失败的恢复 处在错误路径上的指令有可能已经将处理器中某个部位的内容进行了更改,例如寄存器重命名阶段的重命名映射表(mapping table),需要对操作进行撤销,即分支预测失败时的恢复\n分支预测检查 (1) 解码阶段可以检查直接跳转的正确性,可以得到分支指令的方向和目标地址,\n对于间接跳转,即使得知预测错误,也无法得到正确的地址,但是可以通过流水线暂停来避免抹掉指令造成的功耗浪费\n(2)在读取物理物理寄存器的阶段,读取到寄存器的值,就可以得到目标地址是否错误,进行重新取指令,\n还是需要对不必要的指令进行抹去,对于进入发射队列的指令,可能比较困难,需要选择性的进行抹去\n(3)在执行阶段,任何分支指令的结果都可以被计算出结果,可以进行检查,但是造成的惩罚(penalty)是最大的.需要清除在这条分支指令之后进入流水线的所有数据\n基于ROB的恢复 在乱序执行中,在这条分支指令之前的数据也会在发射队列或者执行中,可以采取重排序缓存(ROB)对处理器进行状态恢复 (ROB是顺序存储指令的)\n当发生分支指令预测失败时,将信息记录在ROB对应的表项(entry)中,并且暂停流水线的取指令,但是让流水线继续执行,当这条指令变为最旧的指令后,冲刷掉流水线中的所有数据,重新取指令. 缺点就是停滞时间会比较长.\n基于checkpoint的状态恢复 checkpoint, 发现分支指令,并且在分支指令之后的指令更改处理器的状态之前,将处理器的状态保存起来,包括寄存器重命名中使用的映射表(mapping table),预测跳转的分支指令对应的下一条指令的PC等.在寄存器重命名阶段进行.\n需要将流水线中所有处于分支预测失败路径上的指令抹去. 需要一种机制识别哪些指令处在错误的路径上,可以通过编号实现,(编号可以在顺序阶段就编号完成),编号之后就可以获知哪些指令位于分支指令后面\n分支指令的编号个数决定了最多可以在流水线中存在的分支指令个数:假设处理器中最多支持128条指令存在于流水线中,按照每五条指令存在一条分支,最多后128/5 = 26 条分支指令存在与流水线中,需要5位\n所有在流水线中的分支指令会被分配一个编号值,编号会被保存在FIFO中,称为编号列表(tag list)\n可以使用 (free tag list 和 tag list)来进行设计\n编号值不再被使用 : 分支指令成功retire , 分支预测失败 (分支预测失败之后就要根据编号来冲刷流水线了,所有编号可以回收了)\n流水线抹去 (1)发射之前的所有指令需要全部被抹去\n(2)流水线的发射阶段以及之后的流水段中,使用比寻找分支指令之后的指令全部抹去\ntag list 是顺序保存对应标号的 , 所以 比方说监测到分支指令3 预测失败,所以 0 ,1, 4 都需要被直接清除 , 因此通过广播编号值及将ROB中对应的指令置为无效\n一个周期内使用所有编号去抹去ROB的指令是不现实的,可以采取一个周期广播一个编号的方式 , 因为从取指到发射还是需要经过几个周期的,只要在这之前重排序缓存和发射队列指令被抹去了就行了\n编号值在解码阶段分配最合适 ,因为此时已经知道属于分支指令了\n对于多条分支指令,通过控制第二条分支指令及其后面的所有指令在本周期不能进入解码阶段,可以避免使用多端口的FIFO来进行赋值\nPTAB (Prediction Target Address Buffer) 通过将分支指令的预测值保存到一个缓存中,使得其在执行阶段进行分支预测是否正确的检查时能够正确调用,并且可以只保存方向预测为跳转的分支指令 PTAB , (Prediction Target Address Buffer)\n它不是本身就在BTB中吗,为啥还要一个buffer\n(1)valid , 表示PTAB中某个表项是否被占用, 当分支指令写入PATB时,置1,当完成检查之后,Reset\n(2)Predict Address,分支指令被预测的目标地址\n(3)Next PC, 分支指令的下一条PC , 如果预测错误,就直接使用其作为正确地址取指\n怎么去找PTAB对应的表项 ? 用 PC吗 ? 或者说用 Next PC吗\n写PTAB可以在取指阶段就完成\n自修改代码一般都会去清空分支预测器和I-Cache\n超标量处理器的分支预测 由于超标量取一个地址,会取出多条指令,所以如果只使用取指令时的地址进行分支预测,相当于只是对指令你个组中的第一条指令进行分支预测\n可以使用公共地址寻址分支预测器 (对于4-way超标量处理器[31:4]),因为多数情况下,实际只有一条分支指令 .在BTB中需要记录下分支指令在四条指令中的位置,避免错误使用它的结果 (为什么指令会出现非对齐存储?)\n目标地址的预测 要对指令组的所有指令进行分支预测,需要得到所有指令的PC值,需要使用3个加法器实现PC地址的获取,\n但是由于需要同时获取四个PC值对应的目标地址,需要BTB支持四个读端口,即使采用交疊避免真正的多端口,但是硬件利用率还是较低\n在分支指令的方向预测完毕之后,利用结果信息再进行目标地址的预测,可以避免对于BTB部件的多端口需求,,这种方法对于方向预测和目标地址预测是串行的\n对于RISC指令,大多数指令是直接跳转类型,目标地址无需预测,在取指之后实际就可以被计算出来.实现这样的功能需要进行预解码\n目标方向的预测 对于基于局部历史的分支预测方法来说,需要PHT和BHT支持多个读端口,可以通过交疊(interleaving)模拟实现多端口\n对于全局历史的分支预测,由于一个周期内进行分支预测的多条指令对应的GHR是不同的,需要进行特殊的处理\n交疊 : 7位地址Addr[6:0],通过Addr [1:0]进行寻址bank ,通过Addr[6:2]寻址bank对应的内容 ,就是使用多个单端口的存储器去组成多端口的功能\n附录 参考文献 超标量处理器设计\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-16T18:26:42+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B03/","title":"分支预测(目标地址预测)"},{"content":"概述 分支预测需要的内容 方向，决定跳转与否\n目标地址 决定跳转的目的地，riscv中有两种体现形式\nPC + 立即数，跳转范围受限。\n寄存器跳转，预测风险难度高，但是除了RETURN/CALL,一般建议不使用间接跳转。\n分支预测的解码 快速分辨出哪条指令是分支指令\nI-cache得出结果可能需要多个周期，这些周期无法得到准确的预测结果\n解码+分支预测放在一个周期 ， 严重影响周期时间\n快速解码 可以在指令从L2 cache 写入到I-cache时进行快速解码,(pre-decode),然后将指令否是分支的信息也写入I-cache.\n分支预测的最好时机是在当前周期得到去指令地址的时候\n可以直接通过PC值来进行分支预测，那就不需要进行解码了，但是只能够知道它是分支指令\npc分支预测 分支预测的方向预测 跳转 （taken)和不发生跳转（not token）\n一bit的跳转预测 image-20241015182744711 基于两位饱和计数器（2-bit saturating counter) 根据分支前两次的结果预测下一次的结果\n状态机 基于两位饱和计数器 （1）计数器处于饱和状态，分支指令本次被预测发生跳转\n（2） 计数器处于不饱和状态，分支指令预测发生跳转\n（3） 计数器处于不饱和状态，分支指令预测不发生跳转\n（4） 计数器处于饱和状态，分支指令被预测不发生跳转\n初始状态位于 strongly not taken 或者 weakly not taken\n状态机处于饱和状态，只有两次预测失败才会改变预测的结果\n对于以下的情况，该种方法能够有50%的成功预测率\nimage-20241015184801299 TTNTNTNTNT 对于这种情况，预测还是有问题，就是始终进入不了饱和，那还是相当于1bit\n另外两种预测方法 情况1是如果两次连续的跳转，就直接变成饱和的强跳转，那就需要两次不跳转才能预测为不跳转\n情况2是如果两次连续的不跳转，就直接变成饱和的不跳转，那就需要两次跳转才能预测为跳转\n利用格雷码降低功耗，减少出错的概率\n对于一般的for循环，TTTTTTTTTTTTTTN ,只会出现2次预测失败 ，开始时 weakly not taken , 当再次执行for循环，第一次就会预测成功\n存储方式 每一个PC需要一个两位的饱和计数器， 32 位 PC需要 2^30 * 2b 存储器 ， 使用如下方法存储（PHT（Pattern History Table））: 使用 PC的一部分进行存储\n别名 （aliasing) 不同PC有相同的饱和计数器，导致相互之间的干扰\n中立别名 ： 分支指令的方向一致\n破坏性别名 ： 分支指令的方向不一致\n使用PC值的一部分来寻址饱和计数器 image-20241015194600012 避免别名的方法 —— 哈希表 哈希表能够压缩32位PC到一个比较小的值\nimage-20241015194955893 更新时间点\n（1）在流水线的取指令阶段，进行分支预测，根据预测的结果更新PHT 预测的结果更新PHT肯定不合理\n（2） 在流水线的执行阶段，当分支指令的方向被计算出来时，更新PHT\n（3） 在流水线的提交阶段，当分支指令要离开流水线是，更新PHT\n对于2,3，分支指令可能在PHT更新之前就被取过很多次了，会影响结果，但是影响的不多\n在乱序执行中，即使在执行阶段得到了一条分支指令的结果，也无法保证该结果是正确的，因为分支指令可能位于分支预测失败的路径上，所以（3）是最保险的\n顺序执行不会吗 ？ 不会 ，主要是乱序执行有可能前面的指令后于后面指令的执行 ，这样后面的指令不一定会执行\n基于局部历史的分支预测 BHR(Branch History Register):分支历史寄存器\n通过一个寄存器记录一条分支指令在过去的历史状态\nn位BHR记录n次结果\nBHR和PHT一一对应，BHR有多少种取值，PHT有多少表项（entry)\n结果从BHR右侧移入，对应的BHR值改变对应的PHT\n那就相当于把一个PC对应的表项有进行了细分 -\u0026gt; 一个BHR和多个PHT\n如果一个序列，连续相同的数有p位，则虚了的循环周期为p,只要BHR不小于p,就可以做完美预测\n寻址 如果进行全寻址的话 ， 1个PC值 需要 N位BTR + 2^N * 2 位PHT , 2^n 就需要 2^n（ N + 2^N * 2）\n所以需要PC部分值来寻址\nimage-20241016102002253 1个PHT\nPC部分值寻址PHT,PC通过hash处理寻址BHT\nimage-20241016104245339 异或（XOR)法\n位拼接法和异或法 基于全局历史的分支预测 对一条分支指令进行分支预测，考虑前面分支指令的执行结果\n需要一个全局历史寄存器（GHR(global history register)),记录最近执行的所有分支指令的结果、\n最理想的情况是对每条分支指令都使用一个PHT\n一个全局寄存器 + 每一条分支指令对应的PHT\nimage-20241016144951117 量变引起质变，当局部BHR少到只剩下一个的时候，就是全局GHR\nimage-20241016144931624 总结 两种分支预测方法\n局部历史分支预测：基于分支指令自身在过去的执行状况来进行分支预测，对每一条分支指令都使用分支历史寄存器（BHR),并使用了由两位饱和计数器组成的PHT(Pattern History Table)来捕捉每一个BHR的规律，使用BHR和PHT配合进行分支预测\n全局历史分支预测：基于一条分支指令之前的一些分支指令的执行状况来进行分支预测，使用全局历史寄存器（GHR)记录所有分支指令的执行情况，由两位饱和计数器组成的PHT(Pattern History Table)来捕捉每一个GHR的规律,使用GHR和PHT配合进行分支预测\n竞争的分支预测 竞争的分支预测原理图 竞争的分支预测_更详细的原理图 理想情况下每一条分支指令都有一个CPHT(choice PHT)\nCPHT中的两位饱和计数器 当P1预测正确,P2预测错误时,计数器减1 当P1预测错误,P2预测正确时,计数器加1 当P1和P2预测结果一致时,不管预测正确与否,计数器保持不变 对于每一条指令,在GHR内容不同时,会导致使用不同的分支预测方法,所以将PC值与GHR进行相应运算再去寻址CPHT的地址.\n分支预测的更新 历史寄存器 （1）在流水线的取指令阶段，进行分支预测，根据预测的结果更新\n（2） 在流水线的执行阶段，当分支指令的方向被计算出来时，更新,分支指令可能在错误预测的路径上,造成错误\n（3） 在流水线的提交阶段，当分支指令要离开流水线是，更新 ,最保险的方法,但是浪费了性能\n一条分支指令b在时间t被分支预测,在时间 $t + \\Delta t$ 从流水线退休, 任何在 $ \\Delta t $内的时间被预测的分支指令都不会从分支指令的结果受益\nimage-20241016153738302 采取方法1更新 ,但是会出现分支预测失败的情况 ,即使后续的分支指令使用的错误的 GHR ,由于他们在预测失败的路径上,都会从流水线中被抹去\n修复GHR错误值的方法 提交(commit)阶段修复法 前端阶段Speculative GHR, 提交阶段放置一个 Ritired GHR, 在前端推测失败之后,需要等待分支指令退休的时候,将后端的GHR写到前端的GHR中,然后根据这条分支指令所指定的目标地址,重新取指令执行.\n该方法的缺点是会造成分支预测失败时惩罚的增大,(why?)\n利用提交阶段的GHR修复分支预测器的GHR checkpoint修复法 在取指令阶段更新GHR时,可以把旧的GHR值保存起来,保存的内容称为checkpoint GHR .一旦分支指令的结果在流水线中被计算出来,就可以对分支指令的分支预测是否正确进行检查.如果分支预测正确,说明GHR中的值是正确的,如果预测失败,将这条分支指令对于的checkpoint GHR恢复到前端的GHR中,并从这条分支指令正确的目标地址开始取指令执行\n我的理解是把原来的GHR和分支预测结果的反向结合然后放进fifo中,在预测失败时把这个值取出来\n如果是顺序执行,读取存储器的方式也可以用FIFO,\n方式二是对方式一的一种补充,使得能够在执行阶段也去实现恢复\n利用checkpoint的方法会GHR进行修复 修复BHR错误值的方法 方式和修复GHR基本是类似的,并且BHR很少出现一条分支指令在流水线的提交阶段更新BHR,流水线中又出现了这条分支指令使用BHR进行分支预测的情况,除非循环体很短\nimage-20241016181356130 两位饱和寄存器 由于饱和寄存器一般是处在饱和状态的,所以选择在分支指令退休的时候更新PHT的饱和计数器,也不会产生很大的负面影响\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-15T14:08:47+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%AC%94%E8%AE%B02/","title":"分支预测(概述+方向预测)"},{"content":"超标量处理器概览 超标量处理器的流水线 顺序执行 in-order pipline 假设流水线每周期可以从 I-Cache 中取出两条指令来执行，则称为2-way 的超标量处理器，在指令经过解码之后，需要根据自身的类型，将两条指令送到对应的 FU 中执行，这个过程称为发射(Issue)。在这个阶段，指令会读取寄存器而得到操作数，同时根据指令的类型，将指令送到对应的 FU 中进行执行。在执行阶段使用了三个 FU:第一个 FU 用来执行 ALU 类型的指令，第二个 FU 用来执行访问存储器类型的指令，第三个 FU 用来执行乘法操作，因为要保证流水线的写回(Write back)阶段是顺序执行的，因此所有 FU 都需要经历同样周期数的流水线，ScoreBoard 用来记录流水线中每条指令的执行情况，例如一条指令在哪个 FU 中执行，在什么时候这条指令可以将结果计算出来等， 一个典型的 ScoreBoard如下。\nscoreboard P: Pending,表示指令的结果还没有写回到逻辑寄存器中。\nF:一条指令在哪个 FU 中执行，在将指令结果进行旁路时会使用这个信息。\nResult Position:在这个部分记录了一条指令到达 FU 中流水段的哪个阶段，3 表示指令处于 FU 流水线的第一个流水段，1 表示指令到达 FU 流水段的最后一个阶段， 0 表示指令处于流水线的写回阶段，在流水线的发射阶段，会将指令的信息写到ScoreBoard 中，同时，这条指令会查询 ScoreBoard 来获知自己的源操作数是否都准备好了，在这条指令被送到 FU 中执行之后的每个周期，都会将这个值右移一位，这样使用这个值就可以表达出指令在 FU 中执行到哪个阶段，对于执行 ALU 类型指令的第一个 FU 来说，当指令到达 3 时，就可以将它的结果进行旁路了；而对于执行乘法指令的第三个 FU 来说，只有当指令到达 1 时，才可以将它的结果进行旁路。本书采取的应该是第二种。\nimage-20241014210458774 阻塞发生在译码级\n指令能够跳转到发射级的条件是scoreboard 对应处在级为2\n？一发就发两条，两条必须要同步吗 应该只是由于下条导致的等待\n指令D不能提前发射应该就是由于需要等待指令C发射\n指令C无法进入执行是由于前递的问题，需要等待指令A的前递\nimage-20241014212008795 乱序执行 乱序执行流水线 解码(Decode)阶段：为了在乱序执行时解决 WAW 和 WAR 这两种相关性，需要对寄存器进行重命名(register renaming),这个过程可以在流水线的解码(Decode)阶段完成，也可以单独使用一个流水段来完成，处理器中需要增加物理寄存器堆(Physical Register File, PRF)来配合对指令集中定义的寄存器( Architecture Register File,ARF)进行重命名，PRF 中寄存器的个数要多于 ARF。\n**Dispatch(分发):**在这个阶段，被重命名之后的指令会按照程序中规定的顺序，写到发射队列(Issue Queue)、重排序缓存(ROB)和 Store Buffer 等部件中，如果在这些部件中没有空闲的空间可以容纳当前的指令，那么这些指令就需要在流水线的重命名阶段进行等待，这就相当于暂停了寄存器重命名以及之前的所有流水线，直到这些部件中有空闲的空间为止。分发阶段可以和寄存器重命名阶段放在一起，在一些对周期时间要求比较紧的处理器中，也可以将这个部分单独使用一个流水段。\n发射(Issue)阶段：一旦指令的操作数准备好了，就可以从发射队列中离开，送到对应的 FU 中执行，因此发射阶段是流水线从顺序执行到乱序执行的分界点。每个 FU 都有自己的流水线级数，在这种流水线中，由于每个 FU 的执行周期数都不相同，所以指令在流水线的写回(Write Back)阶段是乱序的，在这个阶段，一条指令只要计算完毕， 就会将结果写到 PRF中，由于分支预测失败( mis-prediction)或者异常( exception)的存在，PRF 中的结果未必都会写到 ARF 中，因此也将 PRF 称为 Future File。\nRegister File Read(读取寄存器):被仲裁电路选中的指令需要从物理寄存器堆(Physical Register File,PRF)中读取操作数，一般情况下，被仲裁电路选中的指令可以从PRF 中得到源操作数，当然还有“不一般”的情况，那就是指令不能从 PRF 中得到操作数， 但是却可以在送到 FU 中执行之前，从旁路网络(bypassing network)中得到操作数，事实上很大一部分指令都是通过旁路网络获得操作数的，这也为减少 PRF 的读端口提供了可能。由于超标量处理器每周期需要执行好几条指令，PRF 所需要的端口个数也是比较多的，多端口寄存器堆的访问速度一般都不会很快，因此在现实世界的处理器中，这个阶段都会单独使用一个流水段。\n提交(Commit)阶段：为了保证程序的串行结果，指令需要按照程序中规定的顺序更新处理器的状态，这需要使用一个称为重排序缓存(ROB)的部件来配合，流水线中的所有指令都按照程序中规定的顺序存储在重排序缓存中，使用重排序缓存来实现程序对处理器状态的顺序更新，一条指令在这个阶段，会将它的结果从 PRF 搬移到 ARF 中，同时重排序缓存也会配合完成对异常(exception)的处理，如果不存在异常，那么这条指令就可以顺利地离开流水线， 并对处理器的状态进行更改，此时称这条指令退休(retire)了，一条指令一旦退休，它就再也不可能回到之前的状态了。\n因为 store 指令需要写存储器，如果在流水线的写回阶段就将 store 指令的结果写到存储器中，那么一旦由于分支预测失败或者异常等原因，需要将这条 store 指令从流水线中抹掉时，就没有办法将存储器的状态进行恢复了，因为存储器中原来的值已经被覆盖， Store Buffer(SB),来存储 store 指令没有退休之前的结果，store 指令在流水线的写回阶段，会将它的结果写到 Store Buffer 中，只有一条 store 指令真的从流水线中退休的时候，才可以将它的值从 Store Buffer 写到存储器中。使用了这个部件之后，Load 指令此时除了从 D-Cache 中寻找数据，还需要从 Store Buffer 中进行查找，这样在一定程度上增加了设计的复杂度。\n在重排序这里也会处理异常 ， 如果没有异常就会写入ARF, 并成功退休，但是无论有没有异常都会写入SB。退休了才可以去修改相应状态。\n发射阶段选择相应的指令并且送到FU,被选择的指令才会去读取物理寄存器\n写回阶段进行统一旁路，为什么我写的RISCV有这么多的旁路网络 ?\nimage-20241015131538323 image-20241014212008795 附录 参考文献 超标量处理器设计\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处\n","date":"2024-10-14T16:43:30+08:00","permalink":"https://VastCircle.github.io/2024/%E8%B6%85%E6%A0%87%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/","title":"超标量处理器概览"},{"content":"Tomasulo\u0026rsquo;s algorithm Tomasulo‘s algorithm创新 Tomasulo算法的主要创新包括硬件实现的寄存器重命名、为所有执行单元设计的保留站（reservation stations），以及一个公共数据总线（CDB），通过该总线计算出的值可以广播到所有可能需要它们的保留站。这些创新使得指令能够实现更好的并行执行，避免在使用记分板或其他早期算法时可能导致的停滞.\nTomasulo_Architechure CDB总线 公共数据总线（CDB）将保留站直接连接到功能单元。根据Tomasulo的设计，它“在保持优先顺序的同时促进并发执行” 。这带来了两个重要影响：\n功能单元可以直接访问任何操作的结果，而无需通过浮点寄存器。这使得多个等待同一结果的单元可以继续执行，而不必等待解决对寄存器文件读端口的争用问题。 危险检测和控制执行是分布式的。保留站负责控制指令何时可以执行，而不是依赖一个专门的危险单元来进行统一管理。 指令顺序 指令是按顺序发出的，因此即使它们是乱序执行的（即非顺序执行），指令序列的效果（如指令引发的异常）仍然会按照顺序执行处理器中的顺序发生。这确保了乱序执行不会影响程序的正确性和预期行为\n寄存器重命名 Tomasulo算法通过寄存器重命名来实现正确的乱序执行。所有的通用寄存器和保留站寄存器要么保存真实值，要么保存占位符值。如果在发射阶段某个目标寄存器的真实值不可用，则最初会使用占位符值。占位符值是一个标签，指示哪个保留站将生成真实值。当功能单元完成计算并在公共数据总线（CDB）上广播结果时，占位符将被真实值替换。\n每个功能单元都有一个保留站。保留站保存执行单条指令所需的信息，包括操作和操作数。当功能单元空闲且指令所需的所有源操作数均为真实值时，功能单元便开始处理指令。\n附录 参考文献 乱序执行CPU\nwikipedia Tomasulo\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-12T16:08:08+08:00","permalink":"https://VastCircle.github.io/2024/%E4%B9%B1%E5%BA%8F%E6%89%A7%E8%A1%8Ccpu/","title":"乱序执行CPU"},{"content":"Abstract 当今的高性能处理器通过乱序执行来容忍长延迟操作。然而，随着延迟的增加，如果我们要继续容忍这些延迟，指令窗口的大小必须增加得更快。本文提出先行(runahead)执行是提高乱序处理器内存延迟容忍度(memory latency tolerance)的有效方法，而不需要不合理的大指令窗口。超前执行可解除因长延迟操作而阻塞的指令窗口的阻塞，从而使处理器能够在程序路径中提前执行,这会导致数据在需要之前就被预取到缓存中。\nintroduction 乱序执行处理器上的超前执行不会将长延迟操作“移开”（这需要在指令窗口中缓冲它及其后面的指令），而是将其扔出指令窗口。\n当指令窗口被一个长延迟操作阻塞时，架构寄存器文件(architectural register file)的状态会被checkpoint保存。然后处理器进入“超前运行模式”。它为阻塞操作分配一个虚假结果并将其扔出指令窗口。阻塞操作后的指令被**获取、执行，并以伪退休（pseudo-retired）**的方式从指令窗口中移除。当阻塞操作完成时，处理器重新进入“正常模式”。此时，它会恢复之前保存的检查点状态，并从阻塞操作开始重新获取和执行指令。 伪退出(pseudo-retire):指令按照传统意义上的方式执行和完成，只是它们不更新架构状态。\nimage-20241012153516456 Runahead 的好处来自于将被长延迟操作阻塞的小指令窗口转换为非阻塞窗口，从而使其具有大得多的窗口的性能。\n在这篇论文中，仅评估了runahead mode对于在二级缓存失效的内存操作的表现，尽管它也可以在任何阻塞指令窗口的长延迟操作上启动。基于英特尔奔腾4处理器的机器模型，该处理器拥有128个条目的指令窗口。 首先展示了当前的乱序执行引擎无法容忍长延迟的主存访问时间。接下来，展示了runahead mode如何更好地应对这些延迟，并且能够达到一个具有更大指令窗口的机器的性能。\nRelate work 暂无\nOut-of-order execution and memory latency tolerance(乱序执行和内存容忍度) Instruction and scheduling windows 乱序执行比顺序执行更能容忍缓存缺失，因为它能够调度与缓存缺失无关的操作。乱序执行的机器通过两个窗口实现这一点：指令窗口和调度窗口。 指令窗口保存所有已解码但尚未提交到架构状态的指令(ROB)，其主要目的是保证指令按顺序退休，以支持精确异常。 调度窗口包含指令窗口中的一部分指令，其主要目的是每个周期搜索那些准备好执行的指令，并对它们进行调度执行(类似于发射队列)。\n当一个长延迟操作发生时，它会阻塞指令窗口，直到操作完成。尽管后续的指令可能已经执行完成，但它们无法从指令窗口中退休(顺序)。如果操作的延迟时间足够长，并且指令窗口不够大，指令会在窗口中堆积，最终导致指令窗口被填满。此时，机器会停顿并停止向前执行。\nMemory latency tolerance 取指理想 变 调度窗口 L2理想程度 指令窗口\n图 1 显示了七台不同机器的指令窗口停滞的周期百分比。每个栏顶部的数字是机器的IPC。该数据是所有模拟基准的平均值。\n具有完整指令窗口停顿的周期的百分比 Runahead 的性能优势来自于将指令提取到提取引擎的缓存中，并执行未命中一级或二级缓存的独立加载和存储。\nImplementation of runahead execution in an out-of-order processor 在本节中，我们描述了在乱序处理器上实现超前执行的情况，其中指令在被调度后并在执行之前访问寄存器文件。Intel Pentium 4 处理器 [13]、MIPS R10000 微处理器 [30] 和 Compaq Alpha 21264 处理器 [18] 是这种微架构的例子。在其他一些微架构中，例如 Intel Pentium Pro 处理器 [12]，指令在放入调度器之前访问寄存器文件。\nFrontend RAT(Register Alias Table)用于寄存器重命名，并包含架构寄存器到物理寄存器的推测映射。\nRetirement RAT 包含指向包含已提交架构值的物理寄存器的指针。它用于在分支错误预测和异常之后恢复状态。\nimage-20241010195821755 Entering runahead mode **当内存操作在二级缓存中未命中且该内存操作到达指令窗口的头部时，处理器进入超前执行模式。**导致进入超前执行模式的指令地址会被记录。为了在从超前运行模式退出时正确恢复架构状态，处理器对架构寄存器文件的状态进行checkpoint。出于性能原因，处理器还检查分支历史寄存器和返回地址堆栈的状态。\n架构寄存器文件的checkpoint可以通过复制提交寄存器别名表（Retirement RAT）指向的物理寄存器内容来完成，但这可能需要时间。为了避免因复制导致的性能损失，处理器可以在正常模式下不断更新checkpoint的架构寄存器文件。当非超前指令从指令窗口中提交时，它会将其结果更新到检查点寄存器文件中的架构目标寄存器。这样检查点操作不会浪费任何时钟周期。\n尽管Retirement RAT 在正常模式下指向架构寄存器状态，但在超前运行模式下它指向伪架构寄存器状态并反映伪退休指令更新的状态\nExecution in runahead mode 无效位和指令:每个物理寄存器都有一个与其关联的无效（INV）位，以指示它是否具有虚假值。任何源自设置了无效位的寄存器的指令都是无效指令。 INV 位用于防止使用虚假数据进行虚假预取和分支解析。 如果存储指令是无效的，它会在runahead期间将一个 INV 值引入内存映像。为了处理runahead mode下数据值(和 INV 值)通过内存的通信，我们使用一个小的“runahead cache”，它与一级数据缓存并行访问。\nINV 值的传播:引入 INV 值的第一条指令是导致处理器进入runahead mode的指令,如果这条指令是加载指令，它会将其物理目的寄存器标记为 INV。如果它是存储指令，则会在runahead cache中分配一行，并将其目标字节标记为 INV。\n任何无效的指令在调度或执行后写入寄存器时，会将该寄存器标记为 INV。任何有效的操作在写入寄存器时，会重置其目的寄存器的 INV 位。\n其实意思就是因为此时存储是没有得到相应结果的,所以后续与目的寄存器相关的指令都是无效的,从第一条无效的指令衍射开\nRunahead store operations and runahead cache 先行存储(store)指令不会将其结果写入任何地方??。因此，依赖于有效先行存储的先行加载被视为无效指令并被丢弃。由于寄存器数量有限，因此将先行存储(store)的结果转发到先行加载(load)对于高性能至关重要。 如果存储及其相关加载都在指令窗口中，则此转发是通过当前乱序处理器中已存在的store buffer来完成的(应该是cache那边的buffer)。 如果超前运行加载依赖于已经pseudo-retired的超前运行存储（这意味着该存储不再位于store buffer???前面是说的runahead store是不会将结果写入任何地方的），则它应该从某个其他位置获取存储的结果。1是写入data cache (提高复杂度,并且可能会占据其他有效指令的位置),2是弄一个大的fully-associative buffer。\n使用 runahead cache 来保存伪退休先行存储的结果和 INV 状态 ，提供指令之间的数据和INV状态的通信,被逐出的缓存行不会写入其他地方。为了支持存储和加载之间 INV 位的正确通信，store buff中的每个条目和runahead cache 中的每个字节都有一个相应的 INV 位。runahead cache 的每个字节还有另一个与其关联的位（STO 位），指示存储是否已写入该字节。仅当访问的字节由存储写入（设置了 STO 位）并且访问runahead cache 有效时，对超前运行高速缓存的访问才会导致命中。\n更新 INV 和 STO的规则:\n当有效的先行存储完成执行时，它将其数据写入其store buffer entry（就像在普通处理器中一样）并重置该条目的关联 INV 位。同时，它查询数据缓存，如果数据缓存未命中，则向内存层次结构发送预取请求。 当一个无效的先行存储被scheduled时，它会set其相关store buff条目的 INV 位。 当一个有效的先行存储离开指令窗口时，它会将其结果写入runahead cache，并重置已写入字节的 INV 位。同时，它还会设置已写入字节的 STO 位。 当一个无效的先行存储离开指令窗口时，如果其地址有效，它会设置写入字节的 INV 位和 STO 位 先行存储从不将结果写入数据缓存??????。 当存储操作的地址无效时，存储操作会被简单地视为一个空操作（NOP）。由于加载操作无法识别与这些无效存储操作的依赖关系，它们可能会错误地从内存中加载一个陈旧的值。这个问题可以通过使用内存依赖预测器来缓解，**预测器可以识别无效地址存储操作与其依赖的加载操作之间的依赖关系。**一旦依赖关系被识别，如果存储操作的数据值是无效的，则加载操作会被标记为无效（INV）；如果存储操作的数据值是有效的，则可以将其forward给加载操作。\nRunahead load operations runahead load invalid :\n源自无效的物理寄存器\n依赖于store buffer中标记为无效（INV）的存储操作\n依赖于一个已经伪退休且是无效（INV）的存储操作(runahead cache)\n有效load会并行访问3个结构 ： data cache , runahead cache , store buffer .\n加载操作命中store buffer ，并且命中的条目被标记为有效，那么加载操作会从store buffer获取数据。 加载操作命中store buffer ，并且命中的条目被标记为无效（INV），那么加载操作会将其物理目标寄存器标记为无效（INV）。\n只有当加载指令访问的cache line有效且其访问的任何字节的 STO 位被set时，该加载才被视为在runahead cache 中命中。 如果load在store buffer未命中但在runahead cache 命中，则它会检查在runahead cache 访问的字节的 INV 位。如果没有INV 位set ，将使用runahead cache 中的数据。如果任意一个源数据字节被标记为 INV，则将其目标寄存器标记为INV。 如果load在store buffer和runahead cache 都未命中，但在data cache中命中，则它将使用data cache中的值，并被视为valid(data cache 应该是不涉及runahead的)。然而，由于以下两个原因，它实际上可能是无效的????：1）它可能依赖于具有 INV 地址的store，(依赖于无效的store 就不应该被判定为有效啊)或者 2）它可能依赖于一个 INV store，该store在runahead cache中将其目标字节标记为 INV，但由于冲突，相应的runahead cache被释放(意思就是,实际上load是无效的,但是由于load所访问的runahead cache被别的指令释放了,比方说另一个store把cache 给挤掉了)。然而，这两种情况都是罕见的，不会显著影响性能。\n如果加载在所有三个结构中都未命中，它会向L2 cache 发送请求以获取其数据。如果该请求在L2 cache 中命中，则数据将从L2 cache 传输到L1 cache ，加载完成其执行。如果请求在L2 cache 中未命中，加载会将其目标寄存器标记为 INV，并像导致进入runahead mode的加载那样(未命中L1 cache)从调度器中移除。该请求会发送到内存像一个未命中 L2 缓存的正常加载请求一样。\nstore buffer \u0026gt; runahead cache \u0026gt; data cache \u0026gt; L2 cache\nExecution and prediction of branches 在runahead mode中，分支的预测和解决方式与正常模式完全相同，唯一的区别是：具有 INV 源(寄存器标记为INV)的分支（与所有分支一样）被预测并以推测的方式更新全局分支历史寄存器，但与其他分支不同，它永远无法被解决。???如果分支预测错误，处理器在获取到该分支后将始终处于错误路径，直到遇到一个与控制流无关的点。我们将获取到错误预测的 INV 分支的程序中的点称为“分歧点”。分歧点的存在不一定对性能有害分歧点在runahead mode中出现得越晚，性能提升就越好。\n前置模式下分支预测器表的训练策略:\n(1)始终训练分支预测器表。如果一个分支首先在前置模式下执行，然后在正常模式下执行，这种策略将导致同一个分支对分支预测器进行两次训练。因此，预测器表的性能得到了增强，计数器可能会失去滞后效应。\n(2)不在前置模式下训练分支预测器。这会导致前置模式下的分支预测准确率降低，从而降低性能，并使分歧点更接近前置入口点。\n(3)第三种选择是始终在前置模式下训练分支预测器，但同时使用一个队列将前置模式下分支的结果传递给正常模式。在正常模式下，如果存在预测，则使用该队列中的预测来进行分支预测。如果一个分支使用来自队列的预测进行预测，则不会再次训练预测器表。\n(4)前置模式和正常模式使用两个独立的预测器表，并在进入前置模式时将正常模式的表信息复制到前置模式。这一选项在硬件实现上成本较高，但我们进行了模拟以确定第一种选项的双重训练策略有多重要。\n我们的结果显示，与第四种选择相比，二次训练分支预测器表条目并没有显著降低性能(方法1)。\nInstruction pseudo-retirement during runahead mode. 在runahead mode下，指令按照程序顺序离开指令窗口。如果某条指令到达指令窗口的队头，它将被考虑进行pseudo-retire。 如果被考虑pseudo-retire的指令是无效的（INV），它会立即从窗口中移除。 如果指令是有效的，它需要等待执行完毕（此时它可能变为无效的），并将结果写入物理寄存器文件。在pseudo-retire时，一条指令会释放为其执行分配的所有资源。\n无论是有效还是无效的指令，在它们离开指令窗口时都会更新退休重命名表（Retirement RAT）。退休重命名表不需要存储与每个寄存器关联的无效（INV）位，因为物理寄存器已经各自关联了无效位。\nExiting runahead mode 可以随时启动退出预运行模式的过程。为了简化处理，我们将退出预运行模式的操作与处理分支预测错误的方式相同。处理器中的所有指令都会被flush，相关的缓冲区会被释放。检查点保存的架构寄存器文件会复制到物理寄存器文件的预定区域。前端和退休阶段的寄存器重命名表（RATs）也会修复，以指向保存架构寄存器值的物理寄存器。这种恢复通过重新加载相同的硬编码映射到两个别名表来实现。预运行缓存中的所有行都将失效（并且 STO 位被清零），在退出预运行模式时，检查点保存的分支历史寄存器和返回地址栈将被恢复。处理器会从导致进入预运行模式的指令地址开始获取指令。\n我们的策略是在阻塞的加载指令从内存中取回数据时退出runahead mode。另一种策略是通过使用定时器提前退出，这样可以消除部分流水线填充或窗口填充的开销。我们发现，对于某些基准测试，这种替代策略表现良好，而在其他基准测试中表现不佳。总体上，提前退出的效果略差。提前退出对于某些基准测试表现较差的原因是，如果处理器不尽早退出预运行模式，可能会生成更多的二级缓存丢失预取请求。\n知识点补充 store buffer 分支预测 Architectural Register 架构寄存器是指每个CPU独有的一组全局寄存器，这些寄存器不与其他CPU共享。它们可以存储任意类型的数据，并且能够在CPU内部的线程之间实现快速通信。\n参考文献 architectural register\n浅谈乱序执行CPU\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-10T14:23:54+08:00","permalink":"https://VastCircle.github.io/2024/runahead_execution_an_alternative_to_very_large_instruction_windows_for_out-of-order_processors/","title":"Runahead_Execution_An_Alternative_to_Very_Large_Instruction_Windows_for_Out of Order_Processors"},{"content":"chipyard 从下载到构建 git clone https://github.com/ucb-bar/chipyard.git cd chipyard git checkout 1.10.0 ## 为了使得clone顺利，把http都换成ssh ，使用命令 find . -name \u0026#34;.gitmodules\u0026#34; -type f -exec sed -i \u0026#39;s/https:\\/\\/github.com\\//git@github.com:/g\u0026#39; {} + ## 同步 git submodule sync ## 运行初始化脚本 ./build-setup.sh ## 导入conda环境 source ./env.sh ## 初始化software ，例如coremark ./scripts/init-software.sh 配置一个2核心soc chipyard 配置文件 chipyard的配置文件是在chipyard/generators/chipyard/src/main/scala/config中，\nclass MyCoreConfigs extends Config( new freechips.rocketchip.subsystem.WithNBigCores(2) ++ // single rocket-core new chipyard.config.AbstractConfig) 在sim/verilator界面去执行命令,可以生成文件 simulator-chipyard-MyCoreConfig\nmake CONFIG=MyCoreConfig 裸机编译riscv #include \u0026lt;stdio.h\u0026gt; int main(void) { printf(\u0026#34;Hello, World!\\n\u0026#34;); return 0; } $ riscv64-unknown-elf-gcc -fno-common -fno-builtin-printf -specs=htif_nano.specs -c hello.c $ riscv64-unknown-elf-gcc -static -specs=htif_nano.specs hello.o -o hello.riscv $ spike hello.riscv Hello, World! -fno-common ​ 默认情况下，C语言会将未初始化的全局变量放在一个“common”区域，可以被多个文件共享。-fno-common 禁止这种行为，要求每个未初始化的全局变量必须在一个文件中定义。\n-fno-builtin-printf ​ 禁用编译器内置的 printf 函数，强制使用标准库中的 printf 函数\n-specs=htif_nano.specs ​ htif_nano.specs 可能是为特定硬件平台（例如 RISC-V）的模拟环境或硬件接口（HTIF）准备的编译和链接配置，确保生成的代码可以在特定环境中运行\n-static\n强制使用静态链接库，而不是动态链接库。所有需要的库代码都会在编译时直接链接到生成的可执行文件中，而不是在运行时动态加载。\n生成波形 make run-binary-debug BINARY=test.riscv 应该是要重新编译前文生成的bin文件\n## 方法1 make run-binary-debug BINARY=test.riscv CONFIG=MyCoreConfig ## 方法2 ./simulator-chipyard-RocketConfig $RISCV/riscv64-unknown-elf/share/riscv-tests/isa/rv64ui-p-simple 在output/chipyard.harness.TestHarness.MyCoreConfig 可以看到hello.vcd\n使用 gtkwave可以打开hello.vcd 查看\nrocket chip tiles 每个Rocket核心都与一个页表遍历器、L1 指令缓存和 L1 数据缓存组合成一个RocketTile\n每个 CPU 块都有一个 L1 指令缓存和 L1 数据缓存。这些缓存的大小和关联性可以配置。默认RocketConfig 使用 16 KiB、4 路组关联指令和数据缓存\nMemory System 这些图块(Tiles)连接到SystemBus，后者将其连接到 L2 缓存组。然后，L2 缓存组连接到MemoryBus，后者通过 TileLink 到 AXI 转换器连接到 DRAM 控制器\nMMIO 对于 MMIO 外围设备，SystemBus连接到ControlBus和PeripheryBus\nControlBus连接标准外围设备，如 BootROM、平台级中断控制器 (PLIC)、核心本地中断 (CLINT) 和调试单元\nBootROM BootROM 包含第一阶段引导加载程序，即系统复位后运行的第一条指令。它还包含设备树，Linux 会使用它来确定连接了哪些其他外设，具体在 /generators/rocket-chip/bootrom\n#define DRAM_BASE 0x80000000 .section .text.start, \u0026#34;ax\u0026#34;, @progbits .globl _start _start: csrwi 0x7c1, 0 // disable chicken bits li s0, DRAM_BASE csrr a0, mhartid la a1, _dtb jr s0 .section .text.hang, \u0026#34;ax\u0026#34;, @progbits .globl _hang _hang: csrwi 0x7c1, 0 // disable chicken bits csrr a0, mhartid la a1, _dtb csrwi mie, 0 1: wfi j 1b .section .rodata.dtb, \u0026#34;a\u0026#34;, @progbits .globl _dtb .align 5, 0 _dtb: .ascii \u0026#34;DTB goes here\u0026#34; linker.ld\nSECTIONS { ROM_BASE = 0x10000; /* ... but actually position independent */ . = ROM_BASE; .text.start : { *(.text.start) } . = ROM_BASE + 0x40; .text.hang : { *(.text.hang) } . = ROM_BASE + 0x80; .rodata.dtb : { *(.rodata.dtb) } } 第一条指令应该是从0x10000开始\n附录 参考文献 chipyard手册\nhttps://www.cnblogs.com/hwzhao/p/17363380.html\n版权信息 本文原载于 vastcircle.github.io，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。\n","date":"2024-10-07T16:15:07+08:00","permalink":"https://VastCircle.github.io/2024/chipyard-learning/","title":"Chipyard Learning"},{"content":"安装Hugo ubuntu 系统使用\nsudo apt install hugo 使用以下命令进行验证\nhugo version 创建 Hugo 网站 通过上述命令安装 hugo 程序后，就可以通过 hugo new site 命令进行网站创建、配置与本地调试了。\nhugo new site robin-site 配置主题 当通过上文命令创建我们的站点后，需要进行主题配置，Hugo 社区有了很丰富的主题，可以通过官网 Themes 菜单选择自己喜欢的风格，查看预览效果，选择后可以进入主题项目仓库，一般都会有很详细的安装及配置说明。\n官方主题网站: https://themes.gohugo.io/\n主题推荐:\nPure: https://themes.gohugo.io/hugo-theme-pure/ 关联主题仓库 https://github.com/reuixiy/hugo-theme-meme/blob/main/README.zh-cn.md\n我们可以将主题仓库直接 git clone 下来进行使用，例如在根目录robin-site下运行以下代码，即可下载pure主题.\ngit clone https://github.com/xiaoheiAh/hugo-theme-pure themes/pure 这种方式有一些弊端，当之后自己对主题进行修改后，可能会与原主题产生一些冲突，不方便版本管理与后续更新。官方更推荐使用的是将原主题仓库 fork 到自己的账户，并使用 git submodule 方式进行仓库链接，这样后续可以对主题的修改进行单独维护。\ncd robin-site/ git init git submodule add https://github.com/pseudoyu/pure themes/pure 然后在根目录下的 config.toml文件中添加新的一行:\ntheme = \u0026#34;pure\u0026#34; 更新主题 如果是 clone 了其他人的博客项目进行修改，则需要用以下命令进行初始化：\ngit submodule update --init --recursive 如果需要同步主题仓库的最新修改，需要运行以下命令：\ngit submodule update --remote hugo-theme-meme主题配置 ## 安装meme git submodule add --depth 1 https://github.com/reuixiy/hugo-theme-meme.git themes/meme ## 替换配置 rm config.toml \u0026amp;\u0026amp; cp themes/meme/config-examples/zh-cn/config.toml config.toml zozo 主题配置 git submodule add https://github.com/varkai/hugo-theme-zozo themes/zozo rm config.toml \u0026amp;\u0026amp; cp themes/zozo/config.toml config.toml https://gojun.me/posts/hello-hugo-blog/\nHugo-theme-stack主题配置 https://stack.jimmycai.com/guide/getting-started\n新建博文 完成后，可以通过 hugo new 命令发布新文章。\nhugo new posts/test.md --- title: \u0026#34;Test\u0026#34; date: 2022-10-21T19:00:43+08:00 draft: true --- 这个命令会在 content 目录下建立 post 目录，并在 post 下生成 test.md 文件，博文书写就在这个文件里使用 Markdown 语法完成。博文的 front matter 里draft 选项默认为 true，需要改为 false 才能发表博文，建议直接更改上面说的archetypes 目录下的 default 文件，把 draft: true 改为 draft: false，这样生成的博文就是默认可以发表的。\n生成网页 为了查看生成的博客的效果，我们在本地编辑调试时可以通过 hugo server 命令进行本地实时调试预览，无须每次都重新生成。在cmd中运行以下命令，即我们可以通过浏览器 http://localhost:1313/ 地址访问我们的本地预览网页。\nhugo server -D 但此时只能在本地访问，如果想发布到 Github Pages ， 还需要借助 GithubPages 工具。\n配置文件 打开配置config.toml可以看到很多的参数可以配置，这里只描述最基本的内容，不同的主题可能会支持不同的参数配置，具体请看对应主题的说明文档。baseURL是站点的域名。title是站点的名称。theme是站点的主题。还有关于评论和打赏的相关配置，这些配置都可以参考官网主题的说明。\n每次发布的时候，都需要先执行hugo，把新写的文档按照主题进行渲染，所有生成的文件默认都在当前pulic的子目录下，可以在config里面配置到其他目录。然后把所有新的文件提交到github。提交代码之后，要等一段时间才生效。\ngithub actions 部署 两个仓库 如果想使用 Github Actions 自动部署 hugo 博客，则最起码需要创建两个 Github 的仓库。\n第一个，便是存储博客 .md 源文件的地方，其实就是 hugo 系统； 第二个，则是部署 Github Pages 的仓库，仓库名必须是 \u0026lt;username\u0026gt;.github.io，这是 github 官方要求的。 最终版 主题 使用的是大佬美化后的版本 Mantyke/Hugo-stack-theme-mod。\n因为还是想用github工作流，不使用vercel,所以接下来结合前面的多篇文章操作,第一步是clone fork 之后的仓库，然后修改remote为一个创建好的私人仓库\ngit clone git@github.com:VastCircle/Hugo-stack.git git remote set-url origin git@github.com:VastCircle/hugostack.git 之后通过一系列的git操作将网页部署到gh-pages分支上\nrm -rf public git add . git commit -m \u0026#39;hugo project init\u0026#39; git push -u origin master ## create a new orphand branch (no commit history) named gh-pages git checkout --orphan gh-pages ## Unstage all files git rm -rf --cached $(git ls-files) ## Add and commit that file git add . git commit -m \u0026#34;INIT: initial commit on gh-pages branch\u0026#34; ## Push to remote gh-pages branch git push origin gh-pages ## Return to master branch git checkout master ## Add the gh-pages branch of the repository. It will look like a folder named public git subtree add --prefix=public git@github.com:VastCircle/hugostack.git gh-pages --squash ## Pull down the file we just committed. This helps avoid merge conflicts git subtree pull --prefix=public git@github.com:VastCircle/hugostack.git gh-pages ## Push the public subtree to the gh-pages branch git subtree push --prefix=public git@github.com:VastCircle/hugostack.git gh-pages 貌似失败了\n再来一次 这次把public作为一个独立的仓库，通过.gitignore去屏蔽public ,使得 主仓库不包括 public ,\nrm -rf public ## 主仓库 git add . git commit -m \u0026#39;hugo project init\u0026#39; git push -u origin master ## 推送仓库 hugo cd public git remote add origin https://github.com/VastCircle/VastCircle.github.io.git git add . git commit -m \u0026#34;INIT: initial commit on public\u0026#34; git push -u origin master shell 脚本\n#deploy.sh #!/bin/bash echo -e \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026#34; # Build the project. hugo # if using a theme, replace by `hugo -t \u0026lt;yourtheme\u0026gt;` # Go To Public folder cd public # Add changes to git. git add -A # Commit changes. msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master # Come Back cd .. 添加 github action .github/workflows/deploy-site.yaml\nname: deploy on: push: branches: [\u0026#34;master\u0026#34;] workflow_dispatch: # schedule: # # Runs everyday at 8:00 AM # - cron: \u0026#34;0 0 * * *\u0026#34; # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow one concurrent deployment concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: true # Default to bash defaults: run: shell: bash jobs: # BUild job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.134.0 TZ: America/Los_Angeles steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo id: pages uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.134.0\u0026#39; extended: true - name: Build Hugo env: # For maximum backward compatibility with Hugo modules HUGO_ENVIRONMENT: production HUGO_ENV: production run: hugo --minify - name: Deploy Web id: deployment uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} EXTERNAL_REPOSITORY: VastCircle/VastCircle.github.io PUBLISH_BRANCH: master PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} 如何编写博客 正如同其他的博客，使用 Markdown 语言来编写博客。Markdown 流行且极易上手，因此这里就不多介绍语法，如果不会的可以自己搜索了解。\n使用 Hugo 创建文章 在博客根目录下运行：\nhugo new post/untitled.md 为什么要用 hugo 来新建而不是创建一个 .md 文件呢？这是因为使用 hugo 创建会自动使用已填入 Front Matter的模板。\nFront Matter 用于标识文章的标题、时间等信息，hugo 就是据此来生成静态页面。关于属性的含义和用法可以参考 Hugo 中文文档。\n模板可以在 \\archetypes\\default.md 下找到：\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; # 标题，创建时自动填充 description: # 文章简介 date: {{ .Date }} # 日期，创建时自动填充，格式同 2023-01-15T12:00:00+08:00 image: # 文章的封面，留空就是没有，填文章所在位置的相对地址，通常放在同目录下， math: # 是否启用 KaTex，填 true 启用 license: # 文章尾部显示的协议，false 为隐藏，其他作为内容，留空就是使用 config.yaml 里默认的 hidden: false # 是否隐藏，一般用不到 comments: true # 因为 bug 所以这个属性只要存在，不管是 true 还是 false 都会导致回复无法显示，需要删掉 draft: true # 是否为草稿，建议改为 false 或者删掉这个属性以防止忘记修改，毕竟我们一般都是写好了才部署到服务器上 --- 为了方便，我参考网络以及 stack-mod 的功能对模板进行了一些改造：\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; slug: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; description: date: \u0026#34;{{ .Date }}\u0026#34; lastmod: \u0026#34;{{ .Date }}\u0026#34; image: cover.png math: license: hidden: false draft: false categories: [\u0026#34;\u0026#34;] tags: [\u0026#34;\u0026#34;] --- ## 附录 ### 参考文献 ### 版权信息 本文原载于 [reincarnatey.net](https://blog.reincarnatey.net)，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。 因此我们可以编写一个批处理程序来快速帮我们生成文章：\ncreate_post.sh：\n#!/bin/bash # 输出提示信息 echo \u0026#34;【创建文章】\u0026#34; # 读取用户输入的 Slug read -p \u0026#34;请输入Slug: \u0026#34; input # 获取当前日期 current_date=$(date +%Y%m%d) # 使用 Hugo 创建新文章 hugo new post/$current_date-$input/index.md # 暂停，提示用户操作完成 read -p \u0026#34;按任意键继续...\u0026#34; 用此批处理程序生成的文章会创建在 \\content\\post\\2023\\0115-test\\index.md，便于我们整理文章资料，同时后续在同目录下存放文章的封面也不会导致内容很乱。\n使用 Hugo 创建类别、标签 创建 Categories 和 Tag 也同理：\nhugo new categories/testcat.md hugo new tags/testtag.md hugo 会自动应用 \\archetypes\\categories.md 和 \\archetypes\\tags.md 的模板，但是这两个模板都不太好，建议都改为：\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; slug: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; description: image: cover.png style: background: \u0026#34;#2a9d8f\u0026#34; color: \u0026#34;#fff\u0026#34; --- create_Categories.sh：\n@echo off echo 【创建类别】 set /p input= 请输入类别名: hugo new categories/%input%/_index.md pause 生成的categories就是在改变如下图所示的界面\nimage1 create_tag.sh：\n@echo off echo 【创建标签】 set /p input= 请输入标签名: hugo new tags/%input%/_index.md pause 注意：如果创建多级文件夹时文章文件名不是 index.md 或者类别、标签文件名不是 _index.md 的话，设置封面图片会出现问题。\n引用 https://hk.v2ex.com/t/1009591\nhttps://jianzhnie.github.io/post/hugo_site/\nhttps://hyrtee.github.io/2023/start-blog/\nhttps://smc.im/post/deploy-hugo-blog-with-github-actions/\n建站技术 | 使用 Hugo + Stack 简单搭建一个博客\nhttps://kaichu.io/posts/my-first-post/\nstack 手册\n部署hugo 踩过的坑_\nhttps://xrg.fj.cn/p/hugo-stack%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%96%B0%E5%B0%8F%E8%AE%B0/\n","date":"2024-10-06T21:57:38+08:00","permalink":"https://VastCircle.github.io/2024/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","title":"博客搭建"}]