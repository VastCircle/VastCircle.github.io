<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>论文阅读 on VastCircle's blog</title><link>https://VastCircle.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link><description>Recent content in 论文阅读 on VastCircle's blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Tue, 17 Dec 2024 14:50:55 +0800</lastBuildDate><atom:link href="https://VastCircle.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/index.xml" rel="self" type="application/rss+xml"/><item><title>Vector_runahead</title><link>https://VastCircle.github.io/2024/vector_runahead/</link><pubDate>Tue, 17 Dec 2024 14:50:55 +0800</pubDate><guid>https://VastCircle.github.io/2024/vector_runahead/</guid><description>&lt;h2 id="摘要">摘要&lt;/h2>
&lt;p>内存墙对许多现代工作负载的性能造成了重大限制。这些应用程序具有复杂的依赖间接内存访问链，即使是最先进的微架构预取器也无法获取。结果是，当前无序超标量处理器的大部分时间都处于停滞状态。但是，为了实现高内存级别的并行性，标准的提前执行会在缓存未命中之前跳过。在现代工作负载中，这意味着它只预取每个依赖链中的第一个缺少缓存的负载。我们认为，这不是一个根本的限制。如果 runahead 是在 cache 未命中时停止以生成依赖链负载，那么如果它可以同时在多个 cache 上停止，则可以重新获得性能。&lt;/p></description></item><item><title>Decoupled_Vector_Runahead</title><link>https://VastCircle.github.io/2024/decoupled_vector_runahead/</link><pubDate>Tue, 17 Dec 2024 12:28:27 +0800</pubDate><guid>https://VastCircle.github.io/2024/decoupled_vector_runahead/</guid><description>&lt;h2 id="摘要">摘要&lt;/h2>
&lt;p>我们提出了解耦矢量预取 （DVR），这是一种内核内预取技术，与主应用程序线程分开执行，它利用大量内存级并行性来提高具有间接内存访问功能的应用程序的性能。DVR 在运行时动态推断循环边界，识别跨步负载，并矢量化作为间接链一部分的后续指令。它会主动为将来的负载发出内存访问，即使无序内核尚未停止，也会将其数据带入 L1 缓存，从而为主线程提供及时的预取。DVR 可以在运行时调整矢量化程度，在内部循环的多次调用中对同一间接内存访问链进行矢量化，并有效地处理沿矢量化链的分支发散。DVR 作为按需、推测性、按顺序、轻量级硬件子线程与内核内的主线程一起运行，并且产生的最小硬件开销仅为 1139 字节。相对于大型超标量 5 宽无序基线和 Vector Runahead（一种用于加速乱序处理器上的间接内存访问的最新微架构技术），DVR 为一组图形分析、数据库和 HPC 工作负载提供了 2.4× 和 2× 的性能。&lt;/p></description></item><item><title>Secure_prefetching_for_secure_cache_systems</title><link>https://VastCircle.github.io/2024/secure_prefetching_for_secure_cache_systems/</link><pubDate>Sat, 14 Dec 2024 13:17:45 +0800</pubDate><guid>https://VastCircle.github.io/2024/secure_prefetching_for_secure_cache_systems/</guid><description>&lt;h2 id="摘要">摘要&lt;/h2>
&lt;p>像Spectre及其变种这样的瞬态执行攻击可能通过缓存层次结构导致信息泄漏。缓解推测执行攻击的技术分为两类：基于延迟的技术和不可见推测技术。像GhostMinion这样的基于不可见推测的技术是高性能且安全的技术，可以缓解所有类型的推测执行攻击。与缓存系统类似，硬件预取器也可能导致推测性信息泄漏。为了解决这个问题，GhostMinion提倡在缓存系统中基于严格排序的提交时预取。我们的实验表明，GhostMinion缓存系统与硬件预取器之间的互动产生了负面影响，导致不同缓存层次之间的冗余流量。这些流量会引起争用，并增加丢失延迟，从而导致性能下降。接下来，我们观察到，由GhostMinion强制执行的提交时预取导致性能损失，因为它影响了预取器的及时性。我们首次对先进的预取技术和安全缓存系统之间的互动进行了彻底分析。在此基础上，我们提出了两种微架构解决方案，确保在设计安全预取器时能够提供高性能，同时保证安全的缓存系统。第一种解决方案通过非推测性更新缓存层次结构时检测和过滤冗余流量。第二种解决方案确保预取器的及时性，以弥补在提交时触发预取请求的延迟，从而实现既安全又高效的预取器。总体而言，我们的改进是安全的，并且在硬件预取器和安全缓存系统之间提供了协同作用。我们的实验表明，在使用先进的预取器的情况下，我们的过滤器始终能提高像GhostMinion这样的安全缓存系统的性能（对于单核系统提高1.9%，对于多核系统提高19.0%，使用的是性能最好的预取器）。我们还观察到过滤器与我们提出的安全预取器之间的协同效应，进一步提高了性能，单核和多核系统分别提高了6.3%和23.0%（相比于最好的预取器）。我们的改进极为轻量，每个核心的存储开销为0.59 KB。&lt;/p></description></item><item><title>ParaVerser_Harnessing_Heterogeneous_Parallelism_For_Affordable_Fault_Detection_in_Data_Centers</title><link>https://VastCircle.github.io/2024/paraverser_harnessing_heterogeneous_parallelism_for_affordable_fault_detection_in_data_centers/</link><pubDate>Sat, 07 Dec 2024 20:28:43 +0800</pubDate><guid>https://VastCircle.github.io/2024/paraverser_harnessing_heterogeneous_parallelism_for_affordable_fault_detection_in_data_centers/</guid><description>&lt;h1 id="paraverser利用异构并行性实现数据中心中经济实惠的故障检测">ParaVerser：利用异构并行性实现数据中心中经济实惠的故障检测&lt;/h1>
&lt;h2 id="abstract">abstract&lt;/h2>
&lt;p>数据中心运营商已经意识到，由于有缺陷的硅计算单元导致的无声数据损坏是大规模流行的。已经部署了软件扫描仪来缓解该问题，但要么覆盖率低，要么需要数月时间，从而导致长时间不正确行为。相比之下，汽车中使用的冗余机制使所需的功率和面积增加了一倍，因此无法实际部署在服务器空间中。我们推出了 ParaVerser，这是一种高覆盖率、低开销的服务器硬件级错误检测解决方案。通过较小的架构修改，我们使异构服务器级处理器中的传统核心能够充当检查器核心，从而利用异构性、扩展频率和重复运行中固有的并行性来提供节能的错误检查。通过将 big.LITTLE 型无序超标量核心与有序超标量核心动态耦合，在相同保证的情况下，我们相对于典型锁步系统将能源开销降低了 70%，而性能仅下降 4.3%，每核心面积开销为 1064B 。&lt;/p></description></item><item><title>An_Event_Triggered_Programmable_Prefetcher_for_Irregular_Workloads</title><link>https://VastCircle.github.io/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/</link><pubDate>Fri, 29 Nov 2024 23:39:07 +0800</pubDate><guid>https://VastCircle.github.io/2024/an_event_triggered_programmable_prefetcher_for_irregular_workloads/</guid><description>&lt;h1 id="针对不规则工作负载的事件触发可编程预取器">针对不规则工作负载的事件触发可编程预取器&lt;/h1>
&lt;h2 id="abstract">abstract&lt;/h2>
&lt;p>许多现代工作负载需要处理大量数据，通常伴随不规则的内存访问。现有架构在处理这些工作负载时表现不佳，因为现有的预取技术无法捕捉内存访问模式，导致这些应用程序严重依赖内存。尽管已经有一些技术可以通过显式配置预取器的遍历模式来显著提高性能，这些方法的适用性通常局限于特定的数据结构。&lt;/p></description></item><item><title>Scalar_runahead_execution</title><link>https://VastCircle.github.io/2024/scalar_runahead_execution/</link><pubDate>Thu, 31 Oct 2024 20:13:06 +0800</pubDate><guid>https://VastCircle.github.io/2024/scalar_runahead_execution/</guid><description>&lt;h3 id="introduction">introduction&lt;/h3>
&lt;p>(i) 一种适用于顺序执行核心的高性能、低开销的硬件预取技术，称为标量前推执行（𝑆𝑅𝐸）。𝑆𝑅𝐸在寄存器传输级有效预取复杂的内存访问模式，并实现了硬件优化策略，以尽量减少能量和面积的开销（如图1所示）。&lt;/p></description></item><item><title>Runahead_Execution_An_Alternative_to_Very_Large_Instruction_Windows_for_Out of Order_Processors</title><link>https://VastCircle.github.io/2024/runahead_execution_an_alternative_to_very_large_instruction_windows_for_out-of-order_processors/</link><pubDate>Thu, 10 Oct 2024 14:23:54 +0800</pubDate><guid>https://VastCircle.github.io/2024/runahead_execution_an_alternative_to_very_large_instruction_windows_for_out-of-order_processors/</guid><description>&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>当今的高性能处理器通过乱序执行来容忍长延迟操作。然而，随着延迟的增加，如果我们要继续容忍这些延迟，指令窗口的大小必须增加得更快。本文提出先行(runahead)执行是提高乱序处理器内存延迟容忍度(memory latency tolerance)的有效方法，而不需要不合理的大指令窗口。超前执行可解除因长延迟操作而阻塞的指令窗口的阻塞，从而使处理器能够在程序路径中提前执行,这会导致数据在需要之前就被预取到缓存中。&lt;/p></description></item></channel></rss>