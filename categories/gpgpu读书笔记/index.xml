<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GPGPU读书笔记 on VastCircle's blog</title><link>https://VastCircle.github.io/categories/gpgpu%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><description>Recent content in GPGPU读书笔记 on VastCircle's blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Tue, 04 Feb 2025 23:43:57 +0800</lastBuildDate><atom:link href="https://VastCircle.github.io/categories/gpgpu%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml"/><item><title>General Purpose_graphics_processor_architecture SIMT核心</title><link>https://VastCircle.github.io/2025/general-purpose_graphics_processor_architecture-simt%E6%A0%B8%E5%BF%83/</link><pubDate>Tue, 04 Feb 2025 23:43:57 +0800</pubDate><guid>https://VastCircle.github.io/2025/general-purpose_graphics_processor_architecture-simt%E6%A0%B8%E5%BF%83/</guid><description>&lt;p>在其传统的图形渲染角色中，GPU 访问数据集，例如详细的纹理图，这些数据集太大而无法完全缓存在芯片上。实现在图形中所期望的高性能可编程性，既可以随着图形模式数量的增加而降低验证成本，也可以使游戏开发人员更容易区分他们的产品 [Lindholm et al., 2001]，为此我们有必要采用能够维持大的片外 (&lt;a class="link" href="https://zhida.zhihu.com/search?content_id=201679542&amp;amp;content_type=Article&amp;amp;match_order=1&amp;amp;q=off-chip&amp;amp;zhida_source=entity" target="_blank" rel="noopener"
 >off-chip&lt;/a>) 带宽的架构。因此，今天的 GPU 会同时执行数万个线程。虽然每个线程的片上内存存储量很小，但缓存仍然可以有效地减少大量的片外内存访问。例如，在图形工作负载中，可以由片上缓存捕获的相邻像素操作之间存在显著的空间局部性。&lt;/p></description></item><item><title>General Purpose_graphics_processor_architecture 编程模型</title><link>https://VastCircle.github.io/2025/general-purpose_graphics_processor_architecture-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/</link><pubDate>Tue, 04 Feb 2025 21:43:57 +0800</pubDate><guid>https://VastCircle.github.io/2025/general-purpose_graphics_processor_architecture-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p>现代 GPU 采用广泛的 SIMD (单指令多数据)硬件来利用 GPU 应用程序中的数据级并行。 CUDA 和 OpenCL 等 GPU 计算 API 不是直接将 SIMD 硬件暴露给程序员，而是具有类似 MIMD（多指令多数据） 的编程模型，允许程序员在 GPU 上启动大量标量线程。这些标量线程中的每一个都可以遵循其独特的执行路径，并且可以访问任意内存位置。在运行时，GPU 硬件在 SIMD 硬件上执行称为 warp（或 AMD 术语中的 wavefront）的标量线程组，以利用它们的规律性和空间局部性。这种执行模型称为单指令、多线程 (SIMT) [Lindholm et al., 2008a, Nickolls and Reusch, 1993]。&lt;/p></description></item></channel></rss>